{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26687962170>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.EMNIST('/files/', split='byclass',train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.EMNIST('/files/',split='byclass', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "print(type(train_loader))\n",
    "print(np.size(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "        t, train_labels = data\n",
    "        \n",
    "for i, data in enumerate(test_loader):\n",
    "        t, test_labels = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Convert data to numpy arrays and normalize images to the interval [0, 1]\n",
    "\n",
    "train_loader = next(iter(train_loader))[0].numpy() / 255.0\n",
    "test_loader = next(iter(test_loader))[0].numpy() / 255.0\n",
    "print(type(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.5637510e-03, -1.4639216e-03, -1.4639216e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.4140070e-03, -6.6311601e-05,  1.8326160e-04,  2.3317624e-04,\n",
       "          2.8309089e-04,  2.4793351e-03,  4.0266886e-03,  4.0266886e-03,\n",
       "          8.8206650e-04,  2.8309089e-04,  2.3317624e-04,  2.3317624e-04,\n",
       "          2.3317624e-04,  1.8326160e-04, -1.6396958e-05, -1.3141778e-03,\n",
       "         -1.6136656e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.5637510e-03,\n",
       "         -6.6528737e-04,  3.8270303e-03,  4.6755793e-03,  4.7754091e-03,\n",
       "          4.8752381e-03,  7.0714825e-03,  8.5689221e-03,  8.5689221e-03,\n",
       "          5.4242993e-03,  4.8752381e-03,  4.7754091e-03,  4.7754091e-03,\n",
       "          4.7754091e-03,  4.6755793e-03,  4.0766033e-03,  8.3432315e-05,\n",
       "         -1.1145192e-03, -1.4639216e-03, -1.5637510e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.2642632e-03,\n",
       "          5.3266407e-04,  7.9200314e-03,  9.1678975e-03,  9.3176411e-03,\n",
       "          9.3675554e-03,  1.0166191e-02,  1.0715251e-02,  1.0715251e-02,\n",
       "          9.5672151e-03,  9.3675554e-03,  9.3176411e-03,  9.3176411e-03,\n",
       "          9.3176411e-03,  9.2178117e-03,  8.5689221e-03,  3.1781401e-03,\n",
       "          9.3198119e-04,  8.3432315e-05, -6.6528737e-04, -1.6136656e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6136656e-03, -8.6494593e-04,\n",
       "          1.7805303e-03,  9.6171293e-03,  1.0765165e-02,  1.0864995e-02,\n",
       "          1.0815081e-02,  1.0864995e-02,  1.0964825e-02,  1.0964825e-02,\n",
       "          1.0815081e-02,  1.0815081e-02,  1.0864995e-02,  1.0964825e-02,\n",
       "          1.0964825e-02,  1.0964825e-02,  1.0665337e-02,  7.2711413e-03,\n",
       "          5.3743850e-03,  4.1764327e-03,  2.2297620e-03, -1.2143485e-03,\n",
       "         -1.6136656e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.3640923e-03,\n",
       "         -6.6311601e-05,  6.2229340e-03,  7.8701172e-03,  6.9716531e-03,\n",
       "          5.4242993e-03,  4.7754091e-03,  4.7754091e-03,  4.7754091e-03,\n",
       "          4.8752381e-03,  5.4242993e-03,  7.0714825e-03,  8.6687505e-03,\n",
       "          9.3675554e-03,  9.5672151e-03,  1.0216105e-02,  1.1064654e-02,\n",
       "          1.0964825e-02,  1.0615421e-02,  9.2677269e-03,  2.1299326e-03,\n",
       "         -6.6528737e-04, -1.5637510e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6136656e-03,\n",
       "         -1.2642632e-03,  2.1798473e-03,  3.3777985e-03,  2.4294206e-03,\n",
       "          8.8206650e-04,  2.3317624e-04,  2.3317624e-04,  2.3317624e-04,\n",
       "          2.8309089e-04,  8.8206650e-04,  2.4793351e-03,  4.1265180e-03,\n",
       "          4.8752381e-03,  5.4742140e-03,  7.3210555e-03,  1.0665337e-02,\n",
       "          1.0914910e-02,  1.0665337e-02,  9.6171293e-03,  3.1282254e-03,\n",
       "         -3.1588488e-04, -1.5138363e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6136656e-03, -6.6528737e-04, -2.6597024e-04, -6.6528737e-04,\n",
       "         -1.2143485e-03, -1.4639216e-03, -1.4639216e-03, -1.4639216e-03,\n",
       "         -1.4140070e-03, -1.2143485e-03, -6.1537273e-04, -1.6396958e-05,\n",
       "          3.3300550e-04,  9.8189584e-04,  3.1781401e-03,  8.5689221e-03,\n",
       "          9.1678975e-03,  8.6188363e-03,  6.9217389e-03,  1.5309569e-03,\n",
       "         -7.6511665e-04, -1.5637510e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.5637510e-03, -1.5138363e-03, -1.5637510e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.5637510e-03, -1.4639216e-03,\n",
       "         -1.4140070e-03, -1.1145192e-03,  8.3432315e-05,  4.0766033e-03,\n",
       "          4.6256646e-03,  4.0766033e-03,  2.4793351e-03, -6.6528737e-04,\n",
       "         -1.4140070e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.4639216e-03,\n",
       "         -1.4639216e-03, -1.4639216e-03, -1.5637510e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03],\n",
       "        [-1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03,\n",
       "         -1.6635802e-03, -1.6635802e-03, -1.6635802e-03, -1.6635802e-03]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50176\n",
      "784000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Reshaping all images into 28*28 for pre-processing\n",
    "train_loader =train_loader.reshape(train_loader.shape[0], 28, 28)\n",
    "test_loader = test_loader.reshape(test_loader.shape[0], 28, 28)\n",
    "print(np.size(train_loader))\n",
    "print(np.size(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from matplotlib import pyplot as plt\n",
    "#Display a random image\n",
    "plt.imshow(test_loader[0])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([1,2,3,4])\n",
    "# s = []\n",
    "# print(type(a))\n",
    "# i=0\n",
    "# for t in a:\n",
    "#     s.append(t-1)\n",
    "# print(s)\n",
    "# print(type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Complete: Rotated and reversed test and train images!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now we perform Image preprocessing. We reverse and rotate all train and test images\n",
    "#for train data\n",
    "s = []\n",
    "for t in train_loader:\n",
    "    s.append(np.transpose(t))\n",
    "np.asarray(s)\n",
    "train_loader = s\n",
    "\n",
    "#checking\n",
    "plt.imshow(train_loader[0])\n",
    "plt.show\n",
    "\n",
    "s=[]\n",
    "#for test data  \n",
    "for t in test_loader:\n",
    "    s.append(np.transpose(t))\n",
    "np.asarray(s)\n",
    "test_loader = s\n",
    "#checking\n",
    "plt.imshow(test_loader[0])\n",
    "plt.show\n",
    "\n",
    "print('Process Complete: Rotated and reversed test and train images!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-213-4835f744db0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtr_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# create your datset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr_dataset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# create your dataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Converting back to dataloader form for giving it as input to model\n",
    "\n",
    "tensor_tr = torch.Tensor(train_loader) # transform to torch tensor\n",
    "tensor_te = torch.Tensor(test_loader)\n",
    "\n",
    "\n",
    "tr_dataset = torch.utils.data.TensorDataset(tensor_tr,train_labels) # create your datset\n",
    "train_loader = torch.utils.data.DataLoader(tr_dataset) # create your dataloader\n",
    "\n",
    "te_dataset = torch.utils.data.TensorDataset(tensor_te,test_labels) # create your datset\n",
    "test_loader = torch.utils.data.DataLoader(te_dataset) # create your dataloader\n",
    "\n",
    "print(type(train_loader))\n",
    "print(type(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples = enumerate(test_loader)\n",
    "# batch_idx, (example_data, example_targets) = next(examples,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig = plt.figure()\n",
    "# for i in range(100,106):\n",
    "#   plt.subplot(2,3,i+1-100)\n",
    "#   plt.tight_layout()\n",
    "#   plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "#   plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "#   plt.xticks([])\n",
    "#   plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "#       torch.save(network.state_dict(), 'results/model.pth')\n",
    "#       torch.save(optimizer.state_dict(), 'results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-ef6e122ea50c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-195-96d20ccab865>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m       \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m       \u001b[0mtest_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  output = network(example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(100,112):\n",
    "  plt.subplot(3,4,i+1-100)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Prediction: {}\".format(\n",
    "    output.data.max(1, keepdim=True)[1][i].item()))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
