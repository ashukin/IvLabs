{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "# from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ad41ca3170>"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "10906\n",
      "()\n",
      "697932\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.EMNIST('/files/', split='byclass',train=True, download=True,\n",
    "                              \n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.EMNIST('/files/',split='byclass', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                                \n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "print(type(train_loader))\n",
    "t1 = train_loader\n",
    "t2 = test_loader\n",
    "print(len(train_loader))\n",
    "print(np.shape(train_loader))\n",
    "print(len(t1.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#     d = data\n",
    "#     t = target\n",
    "# print(type(data))\n",
    "# print(type(target))\n",
    "# print(len(d))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "torch.Size([64, 1, 28, 28])\n",
      "10906\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, train_labels = dataiter.next()\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "images_t, test_labels = dataiter.next()\n",
    "\n",
    "print(np.shape(train_labels))\n",
    "print(np.shape(images))\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### example\n",
    "# grocery = ['bread', 'milk', 'butter']\n",
    "# enumerateGrocery = enumerate(grocery)\n",
    "\n",
    "# print(type(enumerateGrocery))\n",
    "\n",
    "# # converting to list\n",
    "# print(list(enumerateGrocery))\n",
    "\n",
    "# # changing the default counter\n",
    "# enumerateGrocery = enumerate(grocery, 10)\n",
    "# print(list(enumerateGrocery))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###### example\n",
    "# s = ['1','2','3']\n",
    "# r = 2\n",
    "\n",
    "# for data, target in enumerate(s,r):\n",
    "#     print(data,target)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "tensor([ 3, 49, 40, 39, 53, 53, 39,  9,  0, 53])\n",
      "tensor([ 4, 30, 53,  9, 29,  6,  6, 49, 31, 23])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(type(train_loader))\n",
    "# train_labels = train_labels.long()\n",
    "# test_labels = test_labels.long()\n",
    "# train_labels.type()\n",
    "print(train_labels[0:10])\n",
    "print(test_labels[0:10])\n",
    "print(np.shape(train_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "# Convert data to numpy arrays and normalize images to the interval [0, 1]\n",
    "\n",
    "train_loader = next(iter(train_loader))[0].numpy() / 255.0\n",
    "test_loader = next(iter(test_loader))[0].numpy() / 255.0\n",
    "print(type(train_loader))\n",
    "print(len(train_loader))         #len changes here from 10906 to 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1, 28, 28)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(train_loader.shape)\n",
    "print(type(train_loader))\n",
    "# print(train_loader[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 28, 28)\n",
      "784000\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Reshaping all images into 28*28 for pre-processing\n",
    "train_loader =train_loader.reshape(train_loader.shape[0], 28, 28)\n",
    "test_loader = test_loader.reshape(test_loader.shape[0], 28, 28)\n",
    "print(np.shape(train_loader))\n",
    "print(np.size(test_loader))\n",
    "print(type(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(49)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(train_labels[1])\n",
    "plt.imshow(train_loader[1])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.array([1,2,3,4])\n",
    "# s = []\n",
    "# print(type(a))\n",
    "# i=0\n",
    "# for t in a:\n",
    "#     s.append(t-1)\n",
    "# print(s)\n",
    "# print(type(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(49)\n",
      "Process Complete: Rotated and reversed test and train images!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now we perform Image preprocessing. We reverse and rotate all train and test images\n",
    "#for train data\n",
    "s = []\n",
    "for t in train_loader:\n",
    "    s.append(np.transpose(t))\n",
    "np.asarray(s)\n",
    "train_loader = s\n",
    "\n",
    "#checking\n",
    "print(train_labels[1])\n",
    "plt.imshow(train_loader[1])\n",
    "plt.show\n",
    "\n",
    "s=[]\n",
    "#for test data  \n",
    "for t in test_loader:\n",
    "    s.append(np.transpose(t))\n",
    "np.asarray(s)\n",
    "test_loader = s\n",
    "#checking\n",
    "# plt.imshow(test_loader[0])\n",
    "# plt.show\n",
    "\n",
    "print('Process Complete: Rotated and reversed test and train images!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([64])\n",
      "<class 'numpy.ndarray'>\n",
      "(64, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# converting labels into numpy array\n",
    "\n",
    "print(type(train_loader))\n",
    "print(type(train_labels))\n",
    "print(np.shape(train_labels))\n",
    "\n",
    "train_labels = train_labels.numpy()\n",
    "test_labels = test_labels.numpy()\n",
    "print(type(train_labels))\n",
    "\n",
    "print(np.shape(train_loader))      # len = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "64\n",
      "(64, 28, 28)\n",
      "(64, 1, 28, 28)\n",
      "64\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n",
      "()\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Converting back to dataloader form for giving it as input to model\n",
    "\n",
    "# tensor_tr = torch.Tensor(train_loader) # transform to torch tensor\n",
    "# tensor_te = torch.Tensor(test_loader)\n",
    "\n",
    "\n",
    "# tr_dataset = torch.utils.data.TensorDataset(tensor_tr) # create your datset\n",
    "# train_loader = torch.utils.data.DataLoader(tr_dataset) # create your dataloader\n",
    "\n",
    "# te_dataset = torch.utils.data.TensorDataset(tensor_te) # create your datset\n",
    "# test_loader = torch.utils.data.DataLoader(te_dataset) # create your dataloader\n",
    "print(len(train_loader))\n",
    "\n",
    "train_loader = np.asarray(train_loader)\n",
    "test_loader = np.asarray(test_loader)\n",
    "print(len(train_loader))\n",
    "\n",
    "print(np.shape(train_loader))\n",
    "train_loader =train_loader.reshape(train_loader.shape[0],1, 28, 28)\n",
    "test_loader =test_loader.reshape(test_loader.shape[0],1, 28, 28)\n",
    "print(np.shape(train_loader))\n",
    "print(len(train_loader))\n",
    "\n",
    "train_data = []\n",
    "for i in range(len(train_loader)):\n",
    "    train_data.append([train_loader[i], train_labels[i]])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=100)\n",
    "\n",
    "test_data = []\n",
    "for i in range(len(test_loader)):\n",
    "    test_data.append([test_loader[i], test_labels[i]])\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=100)\n",
    "\n",
    "\n",
    "print(type(train_loader))\n",
    "print(type(test_loader))\n",
    "print(np.shape(train_loader))\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig = plt.figure()\n",
    "# for i in range(6):\n",
    "#   plt.subplot(2,3,i+1)\n",
    "#   plt.tight_layout()\n",
    "#   plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "#   plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "#   plt.xticks([])\n",
    "#   plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(32*4*4, 128)\n",
    "        self.fc2 = nn.Linear(128, 62)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "#         print(x.shape)\n",
    "        x = x.view(-1, 32*4*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(t1.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx in range(len(t1)):\n",
    "        if batch_idx % log_interval == 0:\n",
    "            for (data, target) in (train_loader):\n",
    "        #         print(len(train_loader))       # which is 1.. so how will batch_idx change??????\n",
    "        #         print(len(t1))          # correct to use coz it comes out to 10906 (see above too)\n",
    "#                 print(len(train_loader.dataset))\n",
    "                optimizer.zero_grad()\n",
    "                output = network(data)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_losses.append(loss.item())\n",
    "                train_counter.append((batch_idx*64) + ((epoch-1)*len(t1.dataset)))\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                 epoch, batch_idx * len(data), len(t1.dataset),\n",
    "                   100. * batch_idx / len(t1), loss.item()))\n",
    "            \n",
    "#       torch.save(network.state_dict(), 'results/model.pth')\n",
    "#       torch.save(optimizer.state_dict(), 'results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in (test_loader):\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "            test_loss /= len(t2.dataset)\n",
    "            test_losses.append(test_loss)\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(t2.dataset),\n",
    "    100. * correct / len(t2.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(test_labels))\n",
    "print(type(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshata\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0043, Accuracy: 38/116323 (0%)\n",
      "\n",
      "Train Epoch: 1 [0/697932 (0%)]\tLoss: 3.196530\n",
      "Train Epoch: 1 [640/697932 (0%)]\tLoss: 3.183414\n",
      "Train Epoch: 1 [1280/697932 (0%)]\tLoss: 3.181930\n",
      "Train Epoch: 1 [1920/697932 (0%)]\tLoss: 3.179841\n",
      "Train Epoch: 1 [2560/697932 (0%)]\tLoss: 3.148721\n",
      "Train Epoch: 1 [3200/697932 (0%)]\tLoss: 3.134105\n",
      "Train Epoch: 1 [3840/697932 (1%)]\tLoss: 3.159969\n",
      "Train Epoch: 1 [4480/697932 (1%)]\tLoss: 3.182072\n",
      "Train Epoch: 1 [5120/697932 (1%)]\tLoss: 3.237235\n",
      "Train Epoch: 1 [5760/697932 (1%)]\tLoss: 3.204405\n",
      "Train Epoch: 1 [6400/697932 (1%)]\tLoss: 3.146964\n",
      "Train Epoch: 1 [7040/697932 (1%)]\tLoss: 3.184255\n",
      "Train Epoch: 1 [7680/697932 (1%)]\tLoss: 3.202422\n",
      "Train Epoch: 1 [8320/697932 (1%)]\tLoss: 3.178823\n",
      "Train Epoch: 1 [8960/697932 (1%)]\tLoss: 3.179480\n",
      "Train Epoch: 1 [9600/697932 (1%)]\tLoss: 3.187767\n",
      "Train Epoch: 1 [10240/697932 (1%)]\tLoss: 3.161274\n",
      "Train Epoch: 1 [10880/697932 (2%)]\tLoss: 3.196213\n",
      "Train Epoch: 1 [11520/697932 (2%)]\tLoss: 3.184565\n",
      "Train Epoch: 1 [12160/697932 (2%)]\tLoss: 3.189233\n",
      "Train Epoch: 1 [12800/697932 (2%)]\tLoss: 3.166877\n",
      "Train Epoch: 1 [13440/697932 (2%)]\tLoss: 3.178470\n",
      "Train Epoch: 1 [14080/697932 (2%)]\tLoss: 3.154783\n",
      "Train Epoch: 1 [14720/697932 (2%)]\tLoss: 3.172243\n",
      "Train Epoch: 1 [15360/697932 (2%)]\tLoss: 3.158573\n",
      "Train Epoch: 1 [16000/697932 (2%)]\tLoss: 3.184724\n",
      "Train Epoch: 1 [16640/697932 (2%)]\tLoss: 3.171834\n",
      "Train Epoch: 1 [17280/697932 (2%)]\tLoss: 3.179687\n",
      "Train Epoch: 1 [17920/697932 (3%)]\tLoss: 3.208408\n",
      "Train Epoch: 1 [18560/697932 (3%)]\tLoss: 3.188045\n",
      "Train Epoch: 1 [19200/697932 (3%)]\tLoss: 3.148493\n",
      "Train Epoch: 1 [19840/697932 (3%)]\tLoss: 3.196511\n",
      "Train Epoch: 1 [20480/697932 (3%)]\tLoss: 3.182616\n",
      "Train Epoch: 1 [21120/697932 (3%)]\tLoss: 3.178092\n",
      "Train Epoch: 1 [21760/697932 (3%)]\tLoss: 3.183625\n",
      "Train Epoch: 1 [22400/697932 (3%)]\tLoss: 3.192230\n",
      "Train Epoch: 1 [23040/697932 (3%)]\tLoss: 3.176915\n",
      "Train Epoch: 1 [23680/697932 (3%)]\tLoss: 3.160017\n",
      "Train Epoch: 1 [24320/697932 (3%)]\tLoss: 3.198014\n",
      "Train Epoch: 1 [24960/697932 (4%)]\tLoss: 3.166137\n",
      "Train Epoch: 1 [25600/697932 (4%)]\tLoss: 3.169827\n",
      "Train Epoch: 1 [26240/697932 (4%)]\tLoss: 3.141950\n",
      "Train Epoch: 1 [26880/697932 (4%)]\tLoss: 3.176625\n",
      "Train Epoch: 1 [27520/697932 (4%)]\tLoss: 3.135810\n",
      "Train Epoch: 1 [28160/697932 (4%)]\tLoss: 3.153514\n",
      "Train Epoch: 1 [28800/697932 (4%)]\tLoss: 3.154941\n",
      "Train Epoch: 1 [29440/697932 (4%)]\tLoss: 3.206927\n",
      "Train Epoch: 1 [30080/697932 (4%)]\tLoss: 3.189223\n",
      "Train Epoch: 1 [30720/697932 (4%)]\tLoss: 3.179577\n",
      "Train Epoch: 1 [31360/697932 (4%)]\tLoss: 3.178888\n",
      "Train Epoch: 1 [32000/697932 (5%)]\tLoss: 3.156060\n",
      "Train Epoch: 1 [32640/697932 (5%)]\tLoss: 3.149049\n",
      "Train Epoch: 1 [33280/697932 (5%)]\tLoss: 3.184113\n",
      "Train Epoch: 1 [33920/697932 (5%)]\tLoss: 3.158052\n",
      "Train Epoch: 1 [34560/697932 (5%)]\tLoss: 3.176175\n",
      "Train Epoch: 1 [35200/697932 (5%)]\tLoss: 3.186124\n",
      "Train Epoch: 1 [35840/697932 (5%)]\tLoss: 3.178954\n",
      "Train Epoch: 1 [36480/697932 (5%)]\tLoss: 3.165283\n",
      "Train Epoch: 1 [37120/697932 (5%)]\tLoss: 3.167776\n",
      "Train Epoch: 1 [37760/697932 (5%)]\tLoss: 3.146281\n",
      "Train Epoch: 1 [38400/697932 (6%)]\tLoss: 3.163918\n",
      "Train Epoch: 1 [39040/697932 (6%)]\tLoss: 3.159471\n",
      "Train Epoch: 1 [39680/697932 (6%)]\tLoss: 3.155920\n",
      "Train Epoch: 1 [40320/697932 (6%)]\tLoss: 3.187504\n",
      "Train Epoch: 1 [40960/697932 (6%)]\tLoss: 3.170427\n",
      "Train Epoch: 1 [41600/697932 (6%)]\tLoss: 3.156781\n",
      "Train Epoch: 1 [42240/697932 (6%)]\tLoss: 3.183488\n",
      "Train Epoch: 1 [42880/697932 (6%)]\tLoss: 3.161909\n",
      "Train Epoch: 1 [43520/697932 (6%)]\tLoss: 3.170228\n",
      "Train Epoch: 1 [44160/697932 (6%)]\tLoss: 3.170484\n",
      "Train Epoch: 1 [44800/697932 (6%)]\tLoss: 3.165958\n",
      "Train Epoch: 1 [45440/697932 (7%)]\tLoss: 3.182758\n",
      "Train Epoch: 1 [46080/697932 (7%)]\tLoss: 3.168247\n",
      "Train Epoch: 1 [46720/697932 (7%)]\tLoss: 3.163694\n",
      "Train Epoch: 1 [47360/697932 (7%)]\tLoss: 3.172975\n",
      "Train Epoch: 1 [48000/697932 (7%)]\tLoss: 3.138939\n",
      "Train Epoch: 1 [48640/697932 (7%)]\tLoss: 3.196706\n",
      "Train Epoch: 1 [49280/697932 (7%)]\tLoss: 3.169304\n",
      "Train Epoch: 1 [49920/697932 (7%)]\tLoss: 3.167181\n",
      "Train Epoch: 1 [50560/697932 (7%)]\tLoss: 3.190719\n",
      "Train Epoch: 1 [51200/697932 (7%)]\tLoss: 3.197735\n",
      "Train Epoch: 1 [51840/697932 (7%)]\tLoss: 3.220948\n",
      "Train Epoch: 1 [52480/697932 (8%)]\tLoss: 3.183756\n",
      "Train Epoch: 1 [53120/697932 (8%)]\tLoss: 3.168305\n",
      "Train Epoch: 1 [53760/697932 (8%)]\tLoss: 3.212979\n",
      "Train Epoch: 1 [54400/697932 (8%)]\tLoss: 3.190038\n",
      "Train Epoch: 1 [55040/697932 (8%)]\tLoss: 3.144276\n",
      "Train Epoch: 1 [55680/697932 (8%)]\tLoss: 3.192001\n",
      "Train Epoch: 1 [56320/697932 (8%)]\tLoss: 3.167176\n",
      "Train Epoch: 1 [56960/697932 (8%)]\tLoss: 3.190334\n",
      "Train Epoch: 1 [57600/697932 (8%)]\tLoss: 3.168224\n",
      "Train Epoch: 1 [58240/697932 (8%)]\tLoss: 3.170292\n",
      "Train Epoch: 1 [58880/697932 (8%)]\tLoss: 3.157158\n",
      "Train Epoch: 1 [59520/697932 (9%)]\tLoss: 3.172206\n",
      "Train Epoch: 1 [60160/697932 (9%)]\tLoss: 3.175969\n",
      "Train Epoch: 1 [60800/697932 (9%)]\tLoss: 3.189910\n",
      "Train Epoch: 1 [61440/697932 (9%)]\tLoss: 3.158607\n",
      "Train Epoch: 1 [62080/697932 (9%)]\tLoss: 3.174268\n",
      "Train Epoch: 1 [62720/697932 (9%)]\tLoss: 3.185948\n",
      "Train Epoch: 1 [63360/697932 (9%)]\tLoss: 3.177432\n",
      "Train Epoch: 1 [64000/697932 (9%)]\tLoss: 3.197304\n",
      "Train Epoch: 1 [64640/697932 (9%)]\tLoss: 3.153350\n",
      "Train Epoch: 1 [65280/697932 (9%)]\tLoss: 3.169509\n",
      "Train Epoch: 1 [65920/697932 (9%)]\tLoss: 3.182323\n",
      "Train Epoch: 1 [66560/697932 (10%)]\tLoss: 3.194059\n",
      "Train Epoch: 1 [67200/697932 (10%)]\tLoss: 3.183929\n",
      "Train Epoch: 1 [67840/697932 (10%)]\tLoss: 3.173390\n",
      "Train Epoch: 1 [68480/697932 (10%)]\tLoss: 3.180366\n",
      "Train Epoch: 1 [69120/697932 (10%)]\tLoss: 3.177668\n",
      "Train Epoch: 1 [69760/697932 (10%)]\tLoss: 3.185199\n",
      "Train Epoch: 1 [70400/697932 (10%)]\tLoss: 3.154899\n",
      "Train Epoch: 1 [71040/697932 (10%)]\tLoss: 3.168949\n",
      "Train Epoch: 1 [71680/697932 (10%)]\tLoss: 3.171988\n",
      "Train Epoch: 1 [72320/697932 (10%)]\tLoss: 3.178713\n",
      "Train Epoch: 1 [72960/697932 (10%)]\tLoss: 3.166121\n",
      "Train Epoch: 1 [73600/697932 (11%)]\tLoss: 3.175230\n",
      "Train Epoch: 1 [74240/697932 (11%)]\tLoss: 3.162088\n",
      "Train Epoch: 1 [74880/697932 (11%)]\tLoss: 3.137233\n",
      "Train Epoch: 1 [75520/697932 (11%)]\tLoss: 3.181224\n",
      "Train Epoch: 1 [76160/697932 (11%)]\tLoss: 3.156203\n",
      "Train Epoch: 1 [76800/697932 (11%)]\tLoss: 3.171950\n",
      "Train Epoch: 1 [77440/697932 (11%)]\tLoss: 3.179206\n",
      "Train Epoch: 1 [78080/697932 (11%)]\tLoss: 3.155246\n",
      "Train Epoch: 1 [78720/697932 (11%)]\tLoss: 3.147583\n",
      "Train Epoch: 1 [79360/697932 (11%)]\tLoss: 3.191442\n",
      "Train Epoch: 1 [80000/697932 (11%)]\tLoss: 3.161721\n",
      "Train Epoch: 1 [80640/697932 (12%)]\tLoss: 3.220912\n",
      "Train Epoch: 1 [81280/697932 (12%)]\tLoss: 3.179684\n",
      "Train Epoch: 1 [81920/697932 (12%)]\tLoss: 3.192049\n",
      "Train Epoch: 1 [82560/697932 (12%)]\tLoss: 3.167714\n",
      "Train Epoch: 1 [83200/697932 (12%)]\tLoss: 3.167618\n",
      "Train Epoch: 1 [83840/697932 (12%)]\tLoss: 3.176830\n",
      "Train Epoch: 1 [84480/697932 (12%)]\tLoss: 3.191429\n",
      "Train Epoch: 1 [85120/697932 (12%)]\tLoss: 3.175219\n",
      "Train Epoch: 1 [85760/697932 (12%)]\tLoss: 3.212724\n",
      "Train Epoch: 1 [86400/697932 (12%)]\tLoss: 3.174434\n",
      "Train Epoch: 1 [87040/697932 (12%)]\tLoss: 3.169732\n",
      "Train Epoch: 1 [87680/697932 (13%)]\tLoss: 3.178393\n",
      "Train Epoch: 1 [88320/697932 (13%)]\tLoss: 3.210243\n",
      "Train Epoch: 1 [88960/697932 (13%)]\tLoss: 3.160825\n",
      "Train Epoch: 1 [89600/697932 (13%)]\tLoss: 3.153355\n",
      "Train Epoch: 1 [90240/697932 (13%)]\tLoss: 3.178237\n",
      "Train Epoch: 1 [90880/697932 (13%)]\tLoss: 3.188831\n",
      "Train Epoch: 1 [91520/697932 (13%)]\tLoss: 3.176136\n",
      "Train Epoch: 1 [92160/697932 (13%)]\tLoss: 3.141776\n",
      "Train Epoch: 1 [92800/697932 (13%)]\tLoss: 3.183732\n",
      "Train Epoch: 1 [93440/697932 (13%)]\tLoss: 3.203320\n",
      "Train Epoch: 1 [94080/697932 (13%)]\tLoss: 3.164272\n",
      "Train Epoch: 1 [94720/697932 (14%)]\tLoss: 3.131451\n",
      "Train Epoch: 1 [95360/697932 (14%)]\tLoss: 3.174819\n",
      "Train Epoch: 1 [96000/697932 (14%)]\tLoss: 3.193818\n",
      "Train Epoch: 1 [96640/697932 (14%)]\tLoss: 3.153589\n",
      "Train Epoch: 1 [97280/697932 (14%)]\tLoss: 3.166181\n",
      "Train Epoch: 1 [97920/697932 (14%)]\tLoss: 3.187383\n",
      "Train Epoch: 1 [98560/697932 (14%)]\tLoss: 3.173519\n",
      "Train Epoch: 1 [99200/697932 (14%)]\tLoss: 3.170400\n",
      "Train Epoch: 1 [99840/697932 (14%)]\tLoss: 3.201308\n",
      "Train Epoch: 1 [100480/697932 (14%)]\tLoss: 3.147383\n",
      "Train Epoch: 1 [101120/697932 (14%)]\tLoss: 3.172732\n",
      "Train Epoch: 1 [101760/697932 (15%)]\tLoss: 3.162818\n",
      "Train Epoch: 1 [102400/697932 (15%)]\tLoss: 3.170748\n",
      "Train Epoch: 1 [103040/697932 (15%)]\tLoss: 3.205024\n",
      "Train Epoch: 1 [103680/697932 (15%)]\tLoss: 3.160334\n",
      "Train Epoch: 1 [104320/697932 (15%)]\tLoss: 3.186784\n",
      "Train Epoch: 1 [104960/697932 (15%)]\tLoss: 3.197222\n",
      "Train Epoch: 1 [105600/697932 (15%)]\tLoss: 3.182067\n",
      "Train Epoch: 1 [106240/697932 (15%)]\tLoss: 3.153848\n",
      "Train Epoch: 1 [106880/697932 (15%)]\tLoss: 3.182641\n",
      "Train Epoch: 1 [107520/697932 (15%)]\tLoss: 3.147648\n",
      "Train Epoch: 1 [108160/697932 (15%)]\tLoss: 3.142020\n",
      "Train Epoch: 1 [108800/697932 (16%)]\tLoss: 3.203779\n",
      "Train Epoch: 1 [109440/697932 (16%)]\tLoss: 3.155734\n",
      "Train Epoch: 1 [110080/697932 (16%)]\tLoss: 3.183865\n",
      "Train Epoch: 1 [110720/697932 (16%)]\tLoss: 3.182802\n",
      "Train Epoch: 1 [111360/697932 (16%)]\tLoss: 3.175144\n",
      "Train Epoch: 1 [112000/697932 (16%)]\tLoss: 3.193071\n",
      "Train Epoch: 1 [112640/697932 (16%)]\tLoss: 3.189003\n",
      "Train Epoch: 1 [113280/697932 (16%)]\tLoss: 3.169084\n",
      "Train Epoch: 1 [113920/697932 (16%)]\tLoss: 3.163657\n",
      "Train Epoch: 1 [114560/697932 (16%)]\tLoss: 3.176800\n",
      "Train Epoch: 1 [115200/697932 (17%)]\tLoss: 3.169555\n",
      "Train Epoch: 1 [115840/697932 (17%)]\tLoss: 3.184089\n",
      "Train Epoch: 1 [116480/697932 (17%)]\tLoss: 3.185346\n",
      "Train Epoch: 1 [117120/697932 (17%)]\tLoss: 3.182755\n",
      "Train Epoch: 1 [117760/697932 (17%)]\tLoss: 3.180825\n",
      "Train Epoch: 1 [118400/697932 (17%)]\tLoss: 3.162738\n",
      "Train Epoch: 1 [119040/697932 (17%)]\tLoss: 3.200905\n",
      "Train Epoch: 1 [119680/697932 (17%)]\tLoss: 3.193769\n",
      "Train Epoch: 1 [120320/697932 (17%)]\tLoss: 3.177743\n",
      "Train Epoch: 1 [120960/697932 (17%)]\tLoss: 3.152179\n",
      "Train Epoch: 1 [121600/697932 (17%)]\tLoss: 3.190780\n",
      "Train Epoch: 1 [122240/697932 (18%)]\tLoss: 3.176256\n",
      "Train Epoch: 1 [122880/697932 (18%)]\tLoss: 3.205804\n",
      "Train Epoch: 1 [123520/697932 (18%)]\tLoss: 3.166975\n",
      "Train Epoch: 1 [124160/697932 (18%)]\tLoss: 3.175263\n",
      "Train Epoch: 1 [124800/697932 (18%)]\tLoss: 3.156786\n",
      "Train Epoch: 1 [125440/697932 (18%)]\tLoss: 3.164147\n",
      "Train Epoch: 1 [126080/697932 (18%)]\tLoss: 3.165867\n",
      "Train Epoch: 1 [126720/697932 (18%)]\tLoss: 3.162051\n",
      "Train Epoch: 1 [127360/697932 (18%)]\tLoss: 3.183173\n",
      "Train Epoch: 1 [128000/697932 (18%)]\tLoss: 3.177951\n",
      "Train Epoch: 1 [128640/697932 (18%)]\tLoss: 3.173940\n",
      "Train Epoch: 1 [129280/697932 (19%)]\tLoss: 3.175390\n",
      "Train Epoch: 1 [129920/697932 (19%)]\tLoss: 3.184048\n",
      "Train Epoch: 1 [130560/697932 (19%)]\tLoss: 3.168822\n",
      "Train Epoch: 1 [131200/697932 (19%)]\tLoss: 3.166901\n",
      "Train Epoch: 1 [131840/697932 (19%)]\tLoss: 3.169163\n",
      "Train Epoch: 1 [132480/697932 (19%)]\tLoss: 3.177370\n",
      "Train Epoch: 1 [133120/697932 (19%)]\tLoss: 3.192574\n",
      "Train Epoch: 1 [133760/697932 (19%)]\tLoss: 3.178855\n",
      "Train Epoch: 1 [134400/697932 (19%)]\tLoss: 3.166828\n",
      "Train Epoch: 1 [135040/697932 (19%)]\tLoss: 3.167757\n",
      "Train Epoch: 1 [135680/697932 (19%)]\tLoss: 3.196487\n",
      "Train Epoch: 1 [136320/697932 (20%)]\tLoss: 3.166412\n",
      "Train Epoch: 1 [136960/697932 (20%)]\tLoss: 3.135927\n",
      "Train Epoch: 1 [137600/697932 (20%)]\tLoss: 3.177423\n",
      "Train Epoch: 1 [138240/697932 (20%)]\tLoss: 3.148624\n",
      "Train Epoch: 1 [138880/697932 (20%)]\tLoss: 3.180732\n",
      "Train Epoch: 1 [139520/697932 (20%)]\tLoss: 3.163615\n",
      "Train Epoch: 1 [140160/697932 (20%)]\tLoss: 3.175812\n",
      "Train Epoch: 1 [140800/697932 (20%)]\tLoss: 3.195826\n",
      "Train Epoch: 1 [141440/697932 (20%)]\tLoss: 3.183133\n",
      "Train Epoch: 1 [142080/697932 (20%)]\tLoss: 3.195051\n",
      "Train Epoch: 1 [142720/697932 (20%)]\tLoss: 3.187176\n",
      "Train Epoch: 1 [143360/697932 (21%)]\tLoss: 3.156301\n",
      "Train Epoch: 1 [144000/697932 (21%)]\tLoss: 3.164759\n",
      "Train Epoch: 1 [144640/697932 (21%)]\tLoss: 3.165878\n",
      "Train Epoch: 1 [145280/697932 (21%)]\tLoss: 3.169184\n",
      "Train Epoch: 1 [145920/697932 (21%)]\tLoss: 3.156707\n",
      "Train Epoch: 1 [146560/697932 (21%)]\tLoss: 3.174025\n",
      "Train Epoch: 1 [147200/697932 (21%)]\tLoss: 3.186724\n",
      "Train Epoch: 1 [147840/697932 (21%)]\tLoss: 3.151788\n",
      "Train Epoch: 1 [148480/697932 (21%)]\tLoss: 3.204400\n",
      "Train Epoch: 1 [149120/697932 (21%)]\tLoss: 3.159377\n",
      "Train Epoch: 1 [149760/697932 (21%)]\tLoss: 3.183758\n",
      "Train Epoch: 1 [150400/697932 (22%)]\tLoss: 3.167065\n",
      "Train Epoch: 1 [151040/697932 (22%)]\tLoss: 3.214135\n",
      "Train Epoch: 1 [151680/697932 (22%)]\tLoss: 3.214821\n",
      "Train Epoch: 1 [152320/697932 (22%)]\tLoss: 3.189320\n",
      "Train Epoch: 1 [152960/697932 (22%)]\tLoss: 3.168373\n",
      "Train Epoch: 1 [153600/697932 (22%)]\tLoss: 3.176405\n",
      "Train Epoch: 1 [154240/697932 (22%)]\tLoss: 3.156102\n",
      "Train Epoch: 1 [154880/697932 (22%)]\tLoss: 3.188996\n",
      "Train Epoch: 1 [155520/697932 (22%)]\tLoss: 3.186604\n",
      "Train Epoch: 1 [156160/697932 (22%)]\tLoss: 3.212956\n",
      "Train Epoch: 1 [156800/697932 (22%)]\tLoss: 3.167938\n",
      "Train Epoch: 1 [157440/697932 (23%)]\tLoss: 3.163436\n",
      "Train Epoch: 1 [158080/697932 (23%)]\tLoss: 3.184509\n",
      "Train Epoch: 1 [158720/697932 (23%)]\tLoss: 3.170256\n",
      "Train Epoch: 1 [159360/697932 (23%)]\tLoss: 3.154061\n",
      "Train Epoch: 1 [160000/697932 (23%)]\tLoss: 3.159843\n",
      "Train Epoch: 1 [160640/697932 (23%)]\tLoss: 3.170070\n",
      "Train Epoch: 1 [161280/697932 (23%)]\tLoss: 3.153910\n",
      "Train Epoch: 1 [161920/697932 (23%)]\tLoss: 3.184999\n",
      "Train Epoch: 1 [162560/697932 (23%)]\tLoss: 3.178321\n",
      "Train Epoch: 1 [163200/697932 (23%)]\tLoss: 3.142329\n",
      "Train Epoch: 1 [163840/697932 (23%)]\tLoss: 3.147804\n",
      "Train Epoch: 1 [164480/697932 (24%)]\tLoss: 3.150990\n",
      "Train Epoch: 1 [165120/697932 (24%)]\tLoss: 3.178692\n",
      "Train Epoch: 1 [165760/697932 (24%)]\tLoss: 3.155887\n",
      "Train Epoch: 1 [166400/697932 (24%)]\tLoss: 3.171815\n",
      "Train Epoch: 1 [167040/697932 (24%)]\tLoss: 3.167829\n",
      "Train Epoch: 1 [167680/697932 (24%)]\tLoss: 3.164095\n",
      "Train Epoch: 1 [168320/697932 (24%)]\tLoss: 3.140217\n",
      "Train Epoch: 1 [168960/697932 (24%)]\tLoss: 3.184165\n",
      "Train Epoch: 1 [169600/697932 (24%)]\tLoss: 3.178178\n",
      "Train Epoch: 1 [170240/697932 (24%)]\tLoss: 3.172127\n",
      "Train Epoch: 1 [170880/697932 (24%)]\tLoss: 3.140031\n",
      "Train Epoch: 1 [171520/697932 (25%)]\tLoss: 3.163187\n",
      "Train Epoch: 1 [172160/697932 (25%)]\tLoss: 3.176417\n",
      "Train Epoch: 1 [172800/697932 (25%)]\tLoss: 3.167989\n",
      "Train Epoch: 1 [173440/697932 (25%)]\tLoss: 3.157492\n",
      "Train Epoch: 1 [174080/697932 (25%)]\tLoss: 3.225569\n",
      "Train Epoch: 1 [174720/697932 (25%)]\tLoss: 3.150094\n",
      "Train Epoch: 1 [175360/697932 (25%)]\tLoss: 3.183934\n",
      "Train Epoch: 1 [176000/697932 (25%)]\tLoss: 3.197015\n",
      "Train Epoch: 1 [176640/697932 (25%)]\tLoss: 3.173297\n",
      "Train Epoch: 1 [177280/697932 (25%)]\tLoss: 3.163043\n",
      "Train Epoch: 1 [177920/697932 (25%)]\tLoss: 3.170840\n",
      "Train Epoch: 1 [178560/697932 (26%)]\tLoss: 3.174346\n",
      "Train Epoch: 1 [179200/697932 (26%)]\tLoss: 3.227174\n",
      "Train Epoch: 1 [179840/697932 (26%)]\tLoss: 3.149034\n",
      "Train Epoch: 1 [180480/697932 (26%)]\tLoss: 3.159657\n",
      "Train Epoch: 1 [181120/697932 (26%)]\tLoss: 3.159636\n",
      "Train Epoch: 1 [181760/697932 (26%)]\tLoss: 3.167040\n",
      "Train Epoch: 1 [182400/697932 (26%)]\tLoss: 3.139628\n",
      "Train Epoch: 1 [183040/697932 (26%)]\tLoss: 3.194512\n",
      "Train Epoch: 1 [183680/697932 (26%)]\tLoss: 3.192712\n",
      "Train Epoch: 1 [184320/697932 (26%)]\tLoss: 3.213901\n",
      "Train Epoch: 1 [184960/697932 (26%)]\tLoss: 3.165762\n",
      "Train Epoch: 1 [185600/697932 (27%)]\tLoss: 3.176494\n",
      "Train Epoch: 1 [186240/697932 (27%)]\tLoss: 3.163759\n",
      "Train Epoch: 1 [186880/697932 (27%)]\tLoss: 3.180044\n",
      "Train Epoch: 1 [187520/697932 (27%)]\tLoss: 3.201186\n",
      "Train Epoch: 1 [188160/697932 (27%)]\tLoss: 3.176390\n",
      "Train Epoch: 1 [188800/697932 (27%)]\tLoss: 3.142130\n",
      "Train Epoch: 1 [189440/697932 (27%)]\tLoss: 3.190446\n",
      "Train Epoch: 1 [190080/697932 (27%)]\tLoss: 3.150403\n",
      "Train Epoch: 1 [190720/697932 (27%)]\tLoss: 3.173497\n",
      "Train Epoch: 1 [191360/697932 (27%)]\tLoss: 3.143214\n",
      "Train Epoch: 1 [192000/697932 (28%)]\tLoss: 3.148983\n",
      "Train Epoch: 1 [192640/697932 (28%)]\tLoss: 3.173838\n",
      "Train Epoch: 1 [193280/697932 (28%)]\tLoss: 3.176368\n",
      "Train Epoch: 1 [193920/697932 (28%)]\tLoss: 3.162428\n",
      "Train Epoch: 1 [194560/697932 (28%)]\tLoss: 3.180486\n",
      "Train Epoch: 1 [195200/697932 (28%)]\tLoss: 3.146785\n",
      "Train Epoch: 1 [195840/697932 (28%)]\tLoss: 3.158659\n",
      "Train Epoch: 1 [196480/697932 (28%)]\tLoss: 3.179453\n",
      "Train Epoch: 1 [197120/697932 (28%)]\tLoss: 3.165547\n",
      "Train Epoch: 1 [197760/697932 (28%)]\tLoss: 3.174281\n",
      "Train Epoch: 1 [198400/697932 (28%)]\tLoss: 3.201366\n",
      "Train Epoch: 1 [199040/697932 (29%)]\tLoss: 3.173689\n",
      "Train Epoch: 1 [199680/697932 (29%)]\tLoss: 3.193205\n",
      "Train Epoch: 1 [200320/697932 (29%)]\tLoss: 3.159582\n",
      "Train Epoch: 1 [200960/697932 (29%)]\tLoss: 3.173670\n",
      "Train Epoch: 1 [201600/697932 (29%)]\tLoss: 3.154876\n",
      "Train Epoch: 1 [202240/697932 (29%)]\tLoss: 3.155905\n",
      "Train Epoch: 1 [202880/697932 (29%)]\tLoss: 3.178309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [203520/697932 (29%)]\tLoss: 3.148177\n",
      "Train Epoch: 1 [204160/697932 (29%)]\tLoss: 3.200797\n",
      "Train Epoch: 1 [204800/697932 (29%)]\tLoss: 3.182302\n",
      "Train Epoch: 1 [205440/697932 (29%)]\tLoss: 3.119110\n",
      "Train Epoch: 1 [206080/697932 (30%)]\tLoss: 3.179600\n",
      "Train Epoch: 1 [206720/697932 (30%)]\tLoss: 3.174635\n",
      "Train Epoch: 1 [207360/697932 (30%)]\tLoss: 3.190008\n",
      "Train Epoch: 1 [208000/697932 (30%)]\tLoss: 3.169673\n",
      "Train Epoch: 1 [208640/697932 (30%)]\tLoss: 3.177439\n",
      "Train Epoch: 1 [209280/697932 (30%)]\tLoss: 3.134780\n",
      "Train Epoch: 1 [209920/697932 (30%)]\tLoss: 3.184019\n",
      "Train Epoch: 1 [210560/697932 (30%)]\tLoss: 3.145991\n",
      "Train Epoch: 1 [211200/697932 (30%)]\tLoss: 3.165009\n",
      "Train Epoch: 1 [211840/697932 (30%)]\tLoss: 3.182403\n",
      "Train Epoch: 1 [212480/697932 (30%)]\tLoss: 3.182500\n",
      "Train Epoch: 1 [213120/697932 (31%)]\tLoss: 3.166100\n",
      "Train Epoch: 1 [213760/697932 (31%)]\tLoss: 3.171268\n",
      "Train Epoch: 1 [214400/697932 (31%)]\tLoss: 3.180191\n",
      "Train Epoch: 1 [215040/697932 (31%)]\tLoss: 3.164236\n",
      "Train Epoch: 1 [215680/697932 (31%)]\tLoss: 3.201428\n",
      "Train Epoch: 1 [216320/697932 (31%)]\tLoss: 3.162912\n",
      "Train Epoch: 1 [216960/697932 (31%)]\tLoss: 3.175815\n",
      "Train Epoch: 1 [217600/697932 (31%)]\tLoss: 3.168000\n",
      "Train Epoch: 1 [218240/697932 (31%)]\tLoss: 3.145246\n",
      "Train Epoch: 1 [218880/697932 (31%)]\tLoss: 3.190702\n",
      "Train Epoch: 1 [219520/697932 (31%)]\tLoss: 3.160399\n",
      "Train Epoch: 1 [220160/697932 (32%)]\tLoss: 3.132444\n",
      "Train Epoch: 1 [220800/697932 (32%)]\tLoss: 3.179406\n",
      "Train Epoch: 1 [221440/697932 (32%)]\tLoss: 3.154361\n",
      "Train Epoch: 1 [222080/697932 (32%)]\tLoss: 3.193595\n",
      "Train Epoch: 1 [222720/697932 (32%)]\tLoss: 3.183678\n",
      "Train Epoch: 1 [223360/697932 (32%)]\tLoss: 3.187901\n",
      "Train Epoch: 1 [224000/697932 (32%)]\tLoss: 3.182507\n",
      "Train Epoch: 1 [224640/697932 (32%)]\tLoss: 3.191040\n",
      "Train Epoch: 1 [225280/697932 (32%)]\tLoss: 3.185130\n",
      "Train Epoch: 1 [225920/697932 (32%)]\tLoss: 3.168138\n",
      "Train Epoch: 1 [226560/697932 (32%)]\tLoss: 3.196387\n",
      "Train Epoch: 1 [227200/697932 (33%)]\tLoss: 3.151995\n",
      "Train Epoch: 1 [227840/697932 (33%)]\tLoss: 3.148959\n",
      "Train Epoch: 1 [228480/697932 (33%)]\tLoss: 3.211960\n",
      "Train Epoch: 1 [229120/697932 (33%)]\tLoss: 3.145226\n",
      "Train Epoch: 1 [229760/697932 (33%)]\tLoss: 3.197155\n",
      "Train Epoch: 1 [230400/697932 (33%)]\tLoss: 3.168427\n",
      "Train Epoch: 1 [231040/697932 (33%)]\tLoss: 3.160504\n",
      "Train Epoch: 1 [231680/697932 (33%)]\tLoss: 3.159679\n",
      "Train Epoch: 1 [232320/697932 (33%)]\tLoss: 3.177053\n",
      "Train Epoch: 1 [232960/697932 (33%)]\tLoss: 3.200903\n",
      "Train Epoch: 1 [233600/697932 (33%)]\tLoss: 3.159063\n",
      "Train Epoch: 1 [234240/697932 (34%)]\tLoss: 3.174490\n",
      "Train Epoch: 1 [234880/697932 (34%)]\tLoss: 3.144279\n",
      "Train Epoch: 1 [235520/697932 (34%)]\tLoss: 3.155051\n",
      "Train Epoch: 1 [236160/697932 (34%)]\tLoss: 3.164642\n",
      "Train Epoch: 1 [236800/697932 (34%)]\tLoss: 3.159779\n",
      "Train Epoch: 1 [237440/697932 (34%)]\tLoss: 3.161539\n",
      "Train Epoch: 1 [238080/697932 (34%)]\tLoss: 3.150835\n",
      "Train Epoch: 1 [238720/697932 (34%)]\tLoss: 3.150167\n",
      "Train Epoch: 1 [239360/697932 (34%)]\tLoss: 3.175238\n",
      "Train Epoch: 1 [240000/697932 (34%)]\tLoss: 3.175844\n",
      "Train Epoch: 1 [240640/697932 (34%)]\tLoss: 3.197604\n",
      "Train Epoch: 1 [241280/697932 (35%)]\tLoss: 3.180020\n",
      "Train Epoch: 1 [241920/697932 (35%)]\tLoss: 3.205425\n",
      "Train Epoch: 1 [242560/697932 (35%)]\tLoss: 3.195355\n",
      "Train Epoch: 1 [243200/697932 (35%)]\tLoss: 3.188966\n",
      "Train Epoch: 1 [243840/697932 (35%)]\tLoss: 3.166720\n",
      "Train Epoch: 1 [244480/697932 (35%)]\tLoss: 3.171726\n",
      "Train Epoch: 1 [245120/697932 (35%)]\tLoss: 3.177248\n",
      "Train Epoch: 1 [245760/697932 (35%)]\tLoss: 3.175983\n",
      "Train Epoch: 1 [246400/697932 (35%)]\tLoss: 3.181840\n",
      "Train Epoch: 1 [247040/697932 (35%)]\tLoss: 3.180311\n",
      "Train Epoch: 1 [247680/697932 (35%)]\tLoss: 3.163121\n",
      "Train Epoch: 1 [248320/697932 (36%)]\tLoss: 3.143485\n",
      "Train Epoch: 1 [248960/697932 (36%)]\tLoss: 3.132067\n",
      "Train Epoch: 1 [249600/697932 (36%)]\tLoss: 3.157677\n",
      "Train Epoch: 1 [250240/697932 (36%)]\tLoss: 3.170274\n",
      "Train Epoch: 1 [250880/697932 (36%)]\tLoss: 3.192221\n",
      "Train Epoch: 1 [251520/697932 (36%)]\tLoss: 3.172915\n",
      "Train Epoch: 1 [252160/697932 (36%)]\tLoss: 3.211918\n",
      "Train Epoch: 1 [252800/697932 (36%)]\tLoss: 3.145461\n",
      "Train Epoch: 1 [253440/697932 (36%)]\tLoss: 3.170445\n",
      "Train Epoch: 1 [254080/697932 (36%)]\tLoss: 3.156982\n",
      "Train Epoch: 1 [254720/697932 (36%)]\tLoss: 3.136343\n",
      "Train Epoch: 1 [255360/697932 (37%)]\tLoss: 3.159358\n",
      "Train Epoch: 1 [256000/697932 (37%)]\tLoss: 3.181814\n",
      "Train Epoch: 1 [256640/697932 (37%)]\tLoss: 3.175078\n",
      "Train Epoch: 1 [257280/697932 (37%)]\tLoss: 3.175093\n",
      "Train Epoch: 1 [257920/697932 (37%)]\tLoss: 3.200536\n",
      "Train Epoch: 1 [258560/697932 (37%)]\tLoss: 3.190536\n",
      "Train Epoch: 1 [259200/697932 (37%)]\tLoss: 3.201272\n",
      "Train Epoch: 1 [259840/697932 (37%)]\tLoss: 3.196117\n",
      "Train Epoch: 1 [260480/697932 (37%)]\tLoss: 3.165463\n",
      "Train Epoch: 1 [261120/697932 (37%)]\tLoss: 3.149433\n",
      "Train Epoch: 1 [261760/697932 (38%)]\tLoss: 3.155269\n",
      "Train Epoch: 1 [262400/697932 (38%)]\tLoss: 3.179017\n",
      "Train Epoch: 1 [263040/697932 (38%)]\tLoss: 3.197933\n",
      "Train Epoch: 1 [263680/697932 (38%)]\tLoss: 3.162618\n",
      "Train Epoch: 1 [264320/697932 (38%)]\tLoss: 3.157062\n",
      "Train Epoch: 1 [264960/697932 (38%)]\tLoss: 3.184978\n",
      "Train Epoch: 1 [265600/697932 (38%)]\tLoss: 3.186873\n",
      "Train Epoch: 1 [266240/697932 (38%)]\tLoss: 3.160408\n",
      "Train Epoch: 1 [266880/697932 (38%)]\tLoss: 3.172297\n",
      "Train Epoch: 1 [267520/697932 (38%)]\tLoss: 3.155436\n",
      "Train Epoch: 1 [268160/697932 (38%)]\tLoss: 3.172954\n",
      "Train Epoch: 1 [268800/697932 (39%)]\tLoss: 3.202532\n",
      "Train Epoch: 1 [269440/697932 (39%)]\tLoss: 3.168929\n",
      "Train Epoch: 1 [270080/697932 (39%)]\tLoss: 3.193308\n",
      "Train Epoch: 1 [270720/697932 (39%)]\tLoss: 3.179924\n",
      "Train Epoch: 1 [271360/697932 (39%)]\tLoss: 3.180295\n",
      "Train Epoch: 1 [272000/697932 (39%)]\tLoss: 3.163721\n",
      "Train Epoch: 1 [272640/697932 (39%)]\tLoss: 3.165863\n",
      "Train Epoch: 1 [273280/697932 (39%)]\tLoss: 3.164674\n",
      "Train Epoch: 1 [273920/697932 (39%)]\tLoss: 3.176827\n",
      "Train Epoch: 1 [274560/697932 (39%)]\tLoss: 3.158545\n",
      "Train Epoch: 1 [275200/697932 (39%)]\tLoss: 3.191641\n",
      "Train Epoch: 1 [275840/697932 (40%)]\tLoss: 3.168181\n",
      "Train Epoch: 1 [276480/697932 (40%)]\tLoss: 3.169819\n",
      "Train Epoch: 1 [277120/697932 (40%)]\tLoss: 3.184436\n",
      "Train Epoch: 1 [277760/697932 (40%)]\tLoss: 3.175280\n",
      "Train Epoch: 1 [278400/697932 (40%)]\tLoss: 3.166273\n",
      "Train Epoch: 1 [279040/697932 (40%)]\tLoss: 3.161331\n",
      "Train Epoch: 1 [279680/697932 (40%)]\tLoss: 3.145908\n",
      "Train Epoch: 1 [280320/697932 (40%)]\tLoss: 3.207159\n",
      "Train Epoch: 1 [280960/697932 (40%)]\tLoss: 3.161168\n",
      "Train Epoch: 1 [281600/697932 (40%)]\tLoss: 3.189356\n",
      "Train Epoch: 1 [282240/697932 (40%)]\tLoss: 3.156118\n",
      "Train Epoch: 1 [282880/697932 (41%)]\tLoss: 3.170411\n",
      "Train Epoch: 1 [283520/697932 (41%)]\tLoss: 3.181298\n",
      "Train Epoch: 1 [284160/697932 (41%)]\tLoss: 3.170773\n",
      "Train Epoch: 1 [284800/697932 (41%)]\tLoss: 3.188828\n",
      "Train Epoch: 1 [285440/697932 (41%)]\tLoss: 3.194917\n",
      "Train Epoch: 1 [286080/697932 (41%)]\tLoss: 3.160102\n",
      "Train Epoch: 1 [286720/697932 (41%)]\tLoss: 3.180030\n",
      "Train Epoch: 1 [287360/697932 (41%)]\tLoss: 3.178651\n",
      "Train Epoch: 1 [288000/697932 (41%)]\tLoss: 3.174258\n",
      "Train Epoch: 1 [288640/697932 (41%)]\tLoss: 3.150611\n",
      "Train Epoch: 1 [289280/697932 (41%)]\tLoss: 3.147272\n",
      "Train Epoch: 1 [289920/697932 (42%)]\tLoss: 3.178617\n",
      "Train Epoch: 1 [290560/697932 (42%)]\tLoss: 3.170942\n",
      "Train Epoch: 1 [291200/697932 (42%)]\tLoss: 3.139705\n",
      "Train Epoch: 1 [291840/697932 (42%)]\tLoss: 3.185198\n",
      "Train Epoch: 1 [292480/697932 (42%)]\tLoss: 3.150527\n",
      "Train Epoch: 1 [293120/697932 (42%)]\tLoss: 3.194187\n",
      "Train Epoch: 1 [293760/697932 (42%)]\tLoss: 3.191156\n",
      "Train Epoch: 1 [294400/697932 (42%)]\tLoss: 3.191889\n",
      "Train Epoch: 1 [295040/697932 (42%)]\tLoss: 3.195074\n",
      "Train Epoch: 1 [295680/697932 (42%)]\tLoss: 3.192753\n",
      "Train Epoch: 1 [296320/697932 (42%)]\tLoss: 3.157639\n",
      "Train Epoch: 1 [296960/697932 (43%)]\tLoss: 3.184449\n",
      "Train Epoch: 1 [297600/697932 (43%)]\tLoss: 3.153173\n",
      "Train Epoch: 1 [298240/697932 (43%)]\tLoss: 3.146052\n",
      "Train Epoch: 1 [298880/697932 (43%)]\tLoss: 3.180776\n",
      "Train Epoch: 1 [299520/697932 (43%)]\tLoss: 3.140211\n",
      "Train Epoch: 1 [300160/697932 (43%)]\tLoss: 3.157287\n",
      "Train Epoch: 1 [300800/697932 (43%)]\tLoss: 3.187560\n",
      "Train Epoch: 1 [301440/697932 (43%)]\tLoss: 3.164534\n",
      "Train Epoch: 1 [302080/697932 (43%)]\tLoss: 3.171734\n",
      "Train Epoch: 1 [302720/697932 (43%)]\tLoss: 3.172378\n",
      "Train Epoch: 1 [303360/697932 (43%)]\tLoss: 3.188921\n",
      "Train Epoch: 1 [304000/697932 (44%)]\tLoss: 3.171493\n",
      "Train Epoch: 1 [304640/697932 (44%)]\tLoss: 3.175830\n",
      "Train Epoch: 1 [305280/697932 (44%)]\tLoss: 3.188559\n",
      "Train Epoch: 1 [305920/697932 (44%)]\tLoss: 3.143116\n",
      "Train Epoch: 1 [306560/697932 (44%)]\tLoss: 3.187406\n",
      "Train Epoch: 1 [307200/697932 (44%)]\tLoss: 3.150545\n",
      "Train Epoch: 1 [307840/697932 (44%)]\tLoss: 3.171521\n",
      "Train Epoch: 1 [308480/697932 (44%)]\tLoss: 3.188813\n",
      "Train Epoch: 1 [309120/697932 (44%)]\tLoss: 3.161432\n",
      "Train Epoch: 1 [309760/697932 (44%)]\tLoss: 3.152751\n",
      "Train Epoch: 1 [310400/697932 (44%)]\tLoss: 3.191748\n",
      "Train Epoch: 1 [311040/697932 (45%)]\tLoss: 3.209575\n",
      "Train Epoch: 1 [311680/697932 (45%)]\tLoss: 3.150535\n",
      "Train Epoch: 1 [312320/697932 (45%)]\tLoss: 3.189804\n",
      "Train Epoch: 1 [312960/697932 (45%)]\tLoss: 3.168590\n",
      "Train Epoch: 1 [313600/697932 (45%)]\tLoss: 3.155772\n",
      "Train Epoch: 1 [314240/697932 (45%)]\tLoss: 3.176165\n",
      "Train Epoch: 1 [314880/697932 (45%)]\tLoss: 3.173083\n",
      "Train Epoch: 1 [315520/697932 (45%)]\tLoss: 3.172775\n",
      "Train Epoch: 1 [316160/697932 (45%)]\tLoss: 3.174271\n",
      "Train Epoch: 1 [316800/697932 (45%)]\tLoss: 3.193244\n",
      "Train Epoch: 1 [317440/697932 (45%)]\tLoss: 3.159798\n",
      "Train Epoch: 1 [318080/697932 (46%)]\tLoss: 3.193511\n",
      "Train Epoch: 1 [318720/697932 (46%)]\tLoss: 3.181679\n",
      "Train Epoch: 1 [319360/697932 (46%)]\tLoss: 3.161525\n",
      "Train Epoch: 1 [320000/697932 (46%)]\tLoss: 3.191324\n",
      "Train Epoch: 1 [320640/697932 (46%)]\tLoss: 3.148468\n",
      "Train Epoch: 1 [321280/697932 (46%)]\tLoss: 3.172245\n",
      "Train Epoch: 1 [321920/697932 (46%)]\tLoss: 3.193528\n",
      "Train Epoch: 1 [322560/697932 (46%)]\tLoss: 3.185103\n",
      "Train Epoch: 1 [323200/697932 (46%)]\tLoss: 3.162217\n",
      "Train Epoch: 1 [323840/697932 (46%)]\tLoss: 3.160874\n",
      "Train Epoch: 1 [324480/697932 (46%)]\tLoss: 3.190326\n",
      "Train Epoch: 1 [325120/697932 (47%)]\tLoss: 3.167338\n",
      "Train Epoch: 1 [325760/697932 (47%)]\tLoss: 3.183881\n",
      "Train Epoch: 1 [326400/697932 (47%)]\tLoss: 3.181489\n",
      "Train Epoch: 1 [327040/697932 (47%)]\tLoss: 3.187646\n",
      "Train Epoch: 1 [327680/697932 (47%)]\tLoss: 3.165828\n",
      "Train Epoch: 1 [328320/697932 (47%)]\tLoss: 3.177135\n",
      "Train Epoch: 1 [328960/697932 (47%)]\tLoss: 3.167359\n",
      "Train Epoch: 1 [329600/697932 (47%)]\tLoss: 3.176902\n",
      "Train Epoch: 1 [330240/697932 (47%)]\tLoss: 3.161052\n",
      "Train Epoch: 1 [330880/697932 (47%)]\tLoss: 3.179383\n",
      "Train Epoch: 1 [331520/697932 (47%)]\tLoss: 3.185500\n",
      "Train Epoch: 1 [332160/697932 (48%)]\tLoss: 3.186368\n",
      "Train Epoch: 1 [332800/697932 (48%)]\tLoss: 3.176971\n",
      "Train Epoch: 1 [333440/697932 (48%)]\tLoss: 3.199865\n",
      "Train Epoch: 1 [334080/697932 (48%)]\tLoss: 3.193350\n",
      "Train Epoch: 1 [334720/697932 (48%)]\tLoss: 3.141472\n",
      "Train Epoch: 1 [335360/697932 (48%)]\tLoss: 3.184889\n",
      "Train Epoch: 1 [336000/697932 (48%)]\tLoss: 3.160836\n",
      "Train Epoch: 1 [336640/697932 (48%)]\tLoss: 3.162763\n",
      "Train Epoch: 1 [337280/697932 (48%)]\tLoss: 3.155774\n",
      "Train Epoch: 1 [337920/697932 (48%)]\tLoss: 3.193377\n",
      "Train Epoch: 1 [338560/697932 (49%)]\tLoss: 3.183637\n",
      "Train Epoch: 1 [339200/697932 (49%)]\tLoss: 3.168863\n",
      "Train Epoch: 1 [339840/697932 (49%)]\tLoss: 3.178057\n",
      "Train Epoch: 1 [340480/697932 (49%)]\tLoss: 3.146096\n",
      "Train Epoch: 1 [341120/697932 (49%)]\tLoss: 3.158301\n",
      "Train Epoch: 1 [341760/697932 (49%)]\tLoss: 3.187756\n",
      "Train Epoch: 1 [342400/697932 (49%)]\tLoss: 3.141336\n",
      "Train Epoch: 1 [343040/697932 (49%)]\tLoss: 3.173835\n",
      "Train Epoch: 1 [343680/697932 (49%)]\tLoss: 3.164466\n",
      "Train Epoch: 1 [344320/697932 (49%)]\tLoss: 3.193575\n",
      "Train Epoch: 1 [344960/697932 (49%)]\tLoss: 3.175148\n",
      "Train Epoch: 1 [345600/697932 (50%)]\tLoss: 3.193815\n",
      "Train Epoch: 1 [346240/697932 (50%)]\tLoss: 3.203390\n",
      "Train Epoch: 1 [346880/697932 (50%)]\tLoss: 3.225807\n",
      "Train Epoch: 1 [347520/697932 (50%)]\tLoss: 3.179025\n",
      "Train Epoch: 1 [348160/697932 (50%)]\tLoss: 3.223229\n",
      "Train Epoch: 1 [348800/697932 (50%)]\tLoss: 3.174901\n",
      "Train Epoch: 1 [349440/697932 (50%)]\tLoss: 3.207338\n",
      "Train Epoch: 1 [350080/697932 (50%)]\tLoss: 3.164169\n",
      "Train Epoch: 1 [350720/697932 (50%)]\tLoss: 3.168097\n",
      "Train Epoch: 1 [351360/697932 (50%)]\tLoss: 3.174723\n",
      "Train Epoch: 1 [352000/697932 (50%)]\tLoss: 3.171559\n",
      "Train Epoch: 1 [352640/697932 (51%)]\tLoss: 3.184959\n",
      "Train Epoch: 1 [353280/697932 (51%)]\tLoss: 3.185893\n",
      "Train Epoch: 1 [353920/697932 (51%)]\tLoss: 3.201274\n",
      "Train Epoch: 1 [354560/697932 (51%)]\tLoss: 3.157161\n",
      "Train Epoch: 1 [355200/697932 (51%)]\tLoss: 3.168329\n",
      "Train Epoch: 1 [355840/697932 (51%)]\tLoss: 3.192815\n",
      "Train Epoch: 1 [356480/697932 (51%)]\tLoss: 3.162622\n",
      "Train Epoch: 1 [357120/697932 (51%)]\tLoss: 3.167399\n",
      "Train Epoch: 1 [357760/697932 (51%)]\tLoss: 3.176583\n",
      "Train Epoch: 1 [358400/697932 (51%)]\tLoss: 3.161015\n",
      "Train Epoch: 1 [359040/697932 (51%)]\tLoss: 3.189899\n",
      "Train Epoch: 1 [359680/697932 (52%)]\tLoss: 3.186778\n",
      "Train Epoch: 1 [360320/697932 (52%)]\tLoss: 3.164554\n",
      "Train Epoch: 1 [360960/697932 (52%)]\tLoss: 3.134961\n",
      "Train Epoch: 1 [361600/697932 (52%)]\tLoss: 3.168305\n",
      "Train Epoch: 1 [362240/697932 (52%)]\tLoss: 3.166262\n",
      "Train Epoch: 1 [362880/697932 (52%)]\tLoss: 3.192963\n",
      "Train Epoch: 1 [363520/697932 (52%)]\tLoss: 3.177557\n",
      "Train Epoch: 1 [364160/697932 (52%)]\tLoss: 3.175308\n",
      "Train Epoch: 1 [364800/697932 (52%)]\tLoss: 3.187081\n",
      "Train Epoch: 1 [365440/697932 (52%)]\tLoss: 3.170692\n",
      "Train Epoch: 1 [366080/697932 (52%)]\tLoss: 3.185850\n",
      "Train Epoch: 1 [366720/697932 (53%)]\tLoss: 3.153388\n",
      "Train Epoch: 1 [367360/697932 (53%)]\tLoss: 3.184039\n",
      "Train Epoch: 1 [368000/697932 (53%)]\tLoss: 3.191880\n",
      "Train Epoch: 1 [368640/697932 (53%)]\tLoss: 3.179965\n",
      "Train Epoch: 1 [369280/697932 (53%)]\tLoss: 3.174111\n",
      "Train Epoch: 1 [369920/697932 (53%)]\tLoss: 3.159649\n",
      "Train Epoch: 1 [370560/697932 (53%)]\tLoss: 3.139282\n",
      "Train Epoch: 1 [371200/697932 (53%)]\tLoss: 3.160568\n",
      "Train Epoch: 1 [371840/697932 (53%)]\tLoss: 3.159412\n",
      "Train Epoch: 1 [372480/697932 (53%)]\tLoss: 3.185627\n",
      "Train Epoch: 1 [373120/697932 (53%)]\tLoss: 3.186447\n",
      "Train Epoch: 1 [373760/697932 (54%)]\tLoss: 3.173302\n",
      "Train Epoch: 1 [374400/697932 (54%)]\tLoss: 3.169002\n",
      "Train Epoch: 1 [375040/697932 (54%)]\tLoss: 3.158070\n",
      "Train Epoch: 1 [375680/697932 (54%)]\tLoss: 3.175254\n",
      "Train Epoch: 1 [376320/697932 (54%)]\tLoss: 3.173519\n",
      "Train Epoch: 1 [376960/697932 (54%)]\tLoss: 3.145580\n",
      "Train Epoch: 1 [377600/697932 (54%)]\tLoss: 3.166674\n",
      "Train Epoch: 1 [378240/697932 (54%)]\tLoss: 3.185976\n",
      "Train Epoch: 1 [378880/697932 (54%)]\tLoss: 3.157136\n",
      "Train Epoch: 1 [379520/697932 (54%)]\tLoss: 3.193271\n",
      "Train Epoch: 1 [380160/697932 (54%)]\tLoss: 3.167795\n",
      "Train Epoch: 1 [380800/697932 (55%)]\tLoss: 3.185692\n",
      "Train Epoch: 1 [381440/697932 (55%)]\tLoss: 3.172501\n",
      "Train Epoch: 1 [382080/697932 (55%)]\tLoss: 3.204963\n",
      "Train Epoch: 1 [382720/697932 (55%)]\tLoss: 3.167211\n",
      "Train Epoch: 1 [383360/697932 (55%)]\tLoss: 3.168719\n",
      "Train Epoch: 1 [384000/697932 (55%)]\tLoss: 3.187714\n",
      "Train Epoch: 1 [384640/697932 (55%)]\tLoss: 3.173886\n",
      "Train Epoch: 1 [385280/697932 (55%)]\tLoss: 3.168603\n",
      "Train Epoch: 1 [385920/697932 (55%)]\tLoss: 3.142004\n",
      "Train Epoch: 1 [386560/697932 (55%)]\tLoss: 3.163324\n",
      "Train Epoch: 1 [387200/697932 (55%)]\tLoss: 3.166342\n",
      "Train Epoch: 1 [387840/697932 (56%)]\tLoss: 3.175455\n",
      "Train Epoch: 1 [388480/697932 (56%)]\tLoss: 3.140566\n",
      "Train Epoch: 1 [389120/697932 (56%)]\tLoss: 3.204179\n",
      "Train Epoch: 1 [389760/697932 (56%)]\tLoss: 3.182775\n",
      "Train Epoch: 1 [390400/697932 (56%)]\tLoss: 3.173221\n",
      "Train Epoch: 1 [391040/697932 (56%)]\tLoss: 3.202722\n",
      "Train Epoch: 1 [391680/697932 (56%)]\tLoss: 3.146695\n",
      "Train Epoch: 1 [392320/697932 (56%)]\tLoss: 3.177865\n",
      "Train Epoch: 1 [392960/697932 (56%)]\tLoss: 3.168428\n",
      "Train Epoch: 1 [393600/697932 (56%)]\tLoss: 3.165855\n",
      "Train Epoch: 1 [394240/697932 (56%)]\tLoss: 3.169747\n",
      "Train Epoch: 1 [394880/697932 (57%)]\tLoss: 3.176833\n",
      "Train Epoch: 1 [395520/697932 (57%)]\tLoss: 3.146280\n",
      "Train Epoch: 1 [396160/697932 (57%)]\tLoss: 3.180037\n",
      "Train Epoch: 1 [396800/697932 (57%)]\tLoss: 3.165865\n",
      "Train Epoch: 1 [397440/697932 (57%)]\tLoss: 3.192583\n",
      "Train Epoch: 1 [398080/697932 (57%)]\tLoss: 3.197764\n",
      "Train Epoch: 1 [398720/697932 (57%)]\tLoss: 3.181551\n",
      "Train Epoch: 1 [399360/697932 (57%)]\tLoss: 3.175842\n",
      "Train Epoch: 1 [400000/697932 (57%)]\tLoss: 3.153653\n",
      "Train Epoch: 1 [400640/697932 (57%)]\tLoss: 3.190808\n",
      "Train Epoch: 1 [401280/697932 (57%)]\tLoss: 3.138747\n",
      "Train Epoch: 1 [401920/697932 (58%)]\tLoss: 3.116943\n",
      "Train Epoch: 1 [402560/697932 (58%)]\tLoss: 3.158803\n",
      "Train Epoch: 1 [403200/697932 (58%)]\tLoss: 3.153956\n",
      "Train Epoch: 1 [403840/697932 (58%)]\tLoss: 3.194926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [404480/697932 (58%)]\tLoss: 3.190885\n",
      "Train Epoch: 1 [405120/697932 (58%)]\tLoss: 3.189243\n",
      "Train Epoch: 1 [405760/697932 (58%)]\tLoss: 3.193747\n",
      "Train Epoch: 1 [406400/697932 (58%)]\tLoss: 3.205098\n",
      "Train Epoch: 1 [407040/697932 (58%)]\tLoss: 3.177249\n",
      "Train Epoch: 1 [407680/697932 (58%)]\tLoss: 3.196660\n",
      "Train Epoch: 1 [408320/697932 (58%)]\tLoss: 3.186465\n",
      "Train Epoch: 1 [408960/697932 (59%)]\tLoss: 3.160031\n",
      "Train Epoch: 1 [409600/697932 (59%)]\tLoss: 3.167909\n",
      "Train Epoch: 1 [410240/697932 (59%)]\tLoss: 3.157070\n",
      "Train Epoch: 1 [410880/697932 (59%)]\tLoss: 3.172404\n",
      "Train Epoch: 1 [411520/697932 (59%)]\tLoss: 3.137408\n",
      "Train Epoch: 1 [412160/697932 (59%)]\tLoss: 3.176448\n",
      "Train Epoch: 1 [412800/697932 (59%)]\tLoss: 3.194457\n",
      "Train Epoch: 1 [413440/697932 (59%)]\tLoss: 3.197342\n",
      "Train Epoch: 1 [414080/697932 (59%)]\tLoss: 3.195680\n",
      "Train Epoch: 1 [414720/697932 (59%)]\tLoss: 3.179683\n",
      "Train Epoch: 1 [415360/697932 (60%)]\tLoss: 3.152589\n",
      "Train Epoch: 1 [416000/697932 (60%)]\tLoss: 3.130476\n",
      "Train Epoch: 1 [416640/697932 (60%)]\tLoss: 3.161174\n",
      "Train Epoch: 1 [417280/697932 (60%)]\tLoss: 3.129378\n",
      "Train Epoch: 1 [417920/697932 (60%)]\tLoss: 3.168520\n",
      "Train Epoch: 1 [418560/697932 (60%)]\tLoss: 3.151581\n",
      "Train Epoch: 1 [419200/697932 (60%)]\tLoss: 3.171396\n",
      "Train Epoch: 1 [419840/697932 (60%)]\tLoss: 3.219675\n",
      "Train Epoch: 1 [420480/697932 (60%)]\tLoss: 3.167078\n",
      "Train Epoch: 1 [421120/697932 (60%)]\tLoss: 3.212664\n",
      "Train Epoch: 1 [421760/697932 (60%)]\tLoss: 3.160165\n",
      "Train Epoch: 1 [422400/697932 (61%)]\tLoss: 3.158445\n",
      "Train Epoch: 1 [423040/697932 (61%)]\tLoss: 3.192416\n",
      "Train Epoch: 1 [423680/697932 (61%)]\tLoss: 3.167717\n",
      "Train Epoch: 1 [424320/697932 (61%)]\tLoss: 3.158624\n",
      "Train Epoch: 1 [424960/697932 (61%)]\tLoss: 3.204483\n",
      "Train Epoch: 1 [425600/697932 (61%)]\tLoss: 3.155283\n",
      "Train Epoch: 1 [426240/697932 (61%)]\tLoss: 3.203645\n",
      "Train Epoch: 1 [426880/697932 (61%)]\tLoss: 3.182480\n",
      "Train Epoch: 1 [427520/697932 (61%)]\tLoss: 3.180851\n",
      "Train Epoch: 1 [428160/697932 (61%)]\tLoss: 3.173043\n",
      "Train Epoch: 1 [428800/697932 (61%)]\tLoss: 3.165334\n",
      "Train Epoch: 1 [429440/697932 (62%)]\tLoss: 3.192815\n",
      "Train Epoch: 1 [430080/697932 (62%)]\tLoss: 3.173096\n",
      "Train Epoch: 1 [430720/697932 (62%)]\tLoss: 3.164470\n",
      "Train Epoch: 1 [431360/697932 (62%)]\tLoss: 3.165275\n",
      "Train Epoch: 1 [432000/697932 (62%)]\tLoss: 3.172595\n",
      "Train Epoch: 1 [432640/697932 (62%)]\tLoss: 3.173153\n",
      "Train Epoch: 1 [433280/697932 (62%)]\tLoss: 3.183181\n",
      "Train Epoch: 1 [433920/697932 (62%)]\tLoss: 3.169259\n",
      "Train Epoch: 1 [434560/697932 (62%)]\tLoss: 3.178291\n",
      "Train Epoch: 1 [435200/697932 (62%)]\tLoss: 3.201770\n",
      "Train Epoch: 1 [435840/697932 (62%)]\tLoss: 3.139109\n",
      "Train Epoch: 1 [436480/697932 (63%)]\tLoss: 3.131377\n",
      "Train Epoch: 1 [437120/697932 (63%)]\tLoss: 3.188153\n",
      "Train Epoch: 1 [437760/697932 (63%)]\tLoss: 3.205017\n",
      "Train Epoch: 1 [438400/697932 (63%)]\tLoss: 3.175000\n",
      "Train Epoch: 1 [439040/697932 (63%)]\tLoss: 3.190260\n",
      "Train Epoch: 1 [439680/697932 (63%)]\tLoss: 3.175228\n",
      "Train Epoch: 1 [440320/697932 (63%)]\tLoss: 3.200284\n",
      "Train Epoch: 1 [440960/697932 (63%)]\tLoss: 3.162412\n",
      "Train Epoch: 1 [441600/697932 (63%)]\tLoss: 3.165144\n",
      "Train Epoch: 1 [442240/697932 (63%)]\tLoss: 3.183957\n",
      "Train Epoch: 1 [442880/697932 (63%)]\tLoss: 3.156543\n",
      "Train Epoch: 1 [443520/697932 (64%)]\tLoss: 3.150114\n",
      "Train Epoch: 1 [444160/697932 (64%)]\tLoss: 3.153918\n",
      "Train Epoch: 1 [444800/697932 (64%)]\tLoss: 3.190370\n",
      "Train Epoch: 1 [445440/697932 (64%)]\tLoss: 3.202495\n",
      "Train Epoch: 1 [446080/697932 (64%)]\tLoss: 3.182802\n",
      "Train Epoch: 1 [446720/697932 (64%)]\tLoss: 3.203395\n",
      "Train Epoch: 1 [447360/697932 (64%)]\tLoss: 3.180925\n",
      "Train Epoch: 1 [448000/697932 (64%)]\tLoss: 3.143487\n",
      "Train Epoch: 1 [448640/697932 (64%)]\tLoss: 3.156532\n",
      "Train Epoch: 1 [449280/697932 (64%)]\tLoss: 3.182121\n",
      "Train Epoch: 1 [449920/697932 (64%)]\tLoss: 3.183505\n",
      "Train Epoch: 1 [450560/697932 (65%)]\tLoss: 3.170101\n",
      "Train Epoch: 1 [451200/697932 (65%)]\tLoss: 3.159050\n",
      "Train Epoch: 1 [451840/697932 (65%)]\tLoss: 3.173567\n",
      "Train Epoch: 1 [452480/697932 (65%)]\tLoss: 3.166224\n",
      "Train Epoch: 1 [453120/697932 (65%)]\tLoss: 3.177540\n",
      "Train Epoch: 1 [453760/697932 (65%)]\tLoss: 3.170207\n",
      "Train Epoch: 1 [454400/697932 (65%)]\tLoss: 3.166566\n",
      "Train Epoch: 1 [455040/697932 (65%)]\tLoss: 3.208352\n",
      "Train Epoch: 1 [455680/697932 (65%)]\tLoss: 3.184415\n",
      "Train Epoch: 1 [456320/697932 (65%)]\tLoss: 3.159895\n",
      "Train Epoch: 1 [456960/697932 (65%)]\tLoss: 3.183260\n",
      "Train Epoch: 1 [457600/697932 (66%)]\tLoss: 3.182791\n",
      "Train Epoch: 1 [458240/697932 (66%)]\tLoss: 3.139210\n",
      "Train Epoch: 1 [458880/697932 (66%)]\tLoss: 3.176159\n",
      "Train Epoch: 1 [459520/697932 (66%)]\tLoss: 3.175296\n",
      "Train Epoch: 1 [460160/697932 (66%)]\tLoss: 3.178406\n",
      "Train Epoch: 1 [460800/697932 (66%)]\tLoss: 3.172166\n",
      "Train Epoch: 1 [461440/697932 (66%)]\tLoss: 3.159882\n",
      "Train Epoch: 1 [462080/697932 (66%)]\tLoss: 3.175887\n",
      "Train Epoch: 1 [462720/697932 (66%)]\tLoss: 3.191864\n",
      "Train Epoch: 1 [463360/697932 (66%)]\tLoss: 3.172164\n",
      "Train Epoch: 1 [464000/697932 (66%)]\tLoss: 3.149769\n",
      "Train Epoch: 1 [464640/697932 (67%)]\tLoss: 3.165294\n",
      "Train Epoch: 1 [465280/697932 (67%)]\tLoss: 3.182775\n",
      "Train Epoch: 1 [465920/697932 (67%)]\tLoss: 3.176152\n",
      "Train Epoch: 1 [466560/697932 (67%)]\tLoss: 3.167169\n",
      "Train Epoch: 1 [467200/697932 (67%)]\tLoss: 3.177618\n",
      "Train Epoch: 1 [467840/697932 (67%)]\tLoss: 3.166275\n",
      "Train Epoch: 1 [468480/697932 (67%)]\tLoss: 3.186106\n",
      "Train Epoch: 1 [469120/697932 (67%)]\tLoss: 3.158444\n",
      "Train Epoch: 1 [469760/697932 (67%)]\tLoss: 3.191143\n",
      "Train Epoch: 1 [470400/697932 (67%)]\tLoss: 3.151952\n",
      "Train Epoch: 1 [471040/697932 (67%)]\tLoss: 3.151306\n",
      "Train Epoch: 1 [471680/697932 (68%)]\tLoss: 3.162879\n",
      "Train Epoch: 1 [472320/697932 (68%)]\tLoss: 3.195173\n",
      "Train Epoch: 1 [472960/697932 (68%)]\tLoss: 3.160184\n",
      "Train Epoch: 1 [473600/697932 (68%)]\tLoss: 3.199986\n",
      "Train Epoch: 1 [474240/697932 (68%)]\tLoss: 3.176601\n",
      "Train Epoch: 1 [474880/697932 (68%)]\tLoss: 3.148092\n",
      "Train Epoch: 1 [475520/697932 (68%)]\tLoss: 3.192473\n",
      "Train Epoch: 1 [476160/697932 (68%)]\tLoss: 3.171848\n",
      "Train Epoch: 1 [476800/697932 (68%)]\tLoss: 3.145507\n",
      "Train Epoch: 1 [477440/697932 (68%)]\tLoss: 3.175799\n",
      "Train Epoch: 1 [478080/697932 (68%)]\tLoss: 3.174198\n",
      "Train Epoch: 1 [478720/697932 (69%)]\tLoss: 3.184029\n",
      "Train Epoch: 1 [479360/697932 (69%)]\tLoss: 3.212181\n",
      "Train Epoch: 1 [480000/697932 (69%)]\tLoss: 3.165014\n",
      "Train Epoch: 1 [480640/697932 (69%)]\tLoss: 3.166494\n",
      "Train Epoch: 1 [481280/697932 (69%)]\tLoss: 3.170620\n",
      "Train Epoch: 1 [481920/697932 (69%)]\tLoss: 3.169268\n",
      "Train Epoch: 1 [482560/697932 (69%)]\tLoss: 3.195708\n",
      "Train Epoch: 1 [483200/697932 (69%)]\tLoss: 3.186976\n",
      "Train Epoch: 1 [483840/697932 (69%)]\tLoss: 3.161435\n",
      "Train Epoch: 1 [484480/697932 (69%)]\tLoss: 3.233378\n",
      "Train Epoch: 1 [485120/697932 (70%)]\tLoss: 3.159550\n",
      "Train Epoch: 1 [485760/697932 (70%)]\tLoss: 3.184253\n",
      "Train Epoch: 1 [486400/697932 (70%)]\tLoss: 3.158319\n",
      "Train Epoch: 1 [487040/697932 (70%)]\tLoss: 3.155137\n",
      "Train Epoch: 1 [487680/697932 (70%)]\tLoss: 3.148334\n",
      "Train Epoch: 1 [488320/697932 (70%)]\tLoss: 3.184931\n",
      "Train Epoch: 1 [488960/697932 (70%)]\tLoss: 3.181627\n",
      "Train Epoch: 1 [489600/697932 (70%)]\tLoss: 3.200109\n",
      "Train Epoch: 1 [490240/697932 (70%)]\tLoss: 3.160620\n",
      "Train Epoch: 1 [490880/697932 (70%)]\tLoss: 3.157457\n",
      "Train Epoch: 1 [491520/697932 (70%)]\tLoss: 3.164783\n",
      "Train Epoch: 1 [492160/697932 (71%)]\tLoss: 3.141037\n",
      "Train Epoch: 1 [492800/697932 (71%)]\tLoss: 3.202015\n",
      "Train Epoch: 1 [493440/697932 (71%)]\tLoss: 3.142539\n",
      "Train Epoch: 1 [494080/697932 (71%)]\tLoss: 3.178997\n",
      "Train Epoch: 1 [494720/697932 (71%)]\tLoss: 3.182317\n",
      "Train Epoch: 1 [495360/697932 (71%)]\tLoss: 3.159166\n",
      "Train Epoch: 1 [496000/697932 (71%)]\tLoss: 3.182264\n",
      "Train Epoch: 1 [496640/697932 (71%)]\tLoss: 3.156676\n",
      "Train Epoch: 1 [497280/697932 (71%)]\tLoss: 3.153779\n",
      "Train Epoch: 1 [497920/697932 (71%)]\tLoss: 3.165232\n",
      "Train Epoch: 1 [498560/697932 (71%)]\tLoss: 3.173719\n",
      "Train Epoch: 1 [499200/697932 (72%)]\tLoss: 3.164915\n",
      "Train Epoch: 1 [499840/697932 (72%)]\tLoss: 3.194090\n",
      "Train Epoch: 1 [500480/697932 (72%)]\tLoss: 3.167736\n",
      "Train Epoch: 1 [501120/697932 (72%)]\tLoss: 3.202613\n",
      "Train Epoch: 1 [501760/697932 (72%)]\tLoss: 3.145956\n",
      "Train Epoch: 1 [502400/697932 (72%)]\tLoss: 3.168213\n",
      "Train Epoch: 1 [503040/697932 (72%)]\tLoss: 3.186810\n",
      "Train Epoch: 1 [503680/697932 (72%)]\tLoss: 3.190785\n",
      "Train Epoch: 1 [504320/697932 (72%)]\tLoss: 3.177567\n",
      "Train Epoch: 1 [504960/697932 (72%)]\tLoss: 3.156414\n",
      "Train Epoch: 1 [505600/697932 (72%)]\tLoss: 3.180339\n",
      "Train Epoch: 1 [506240/697932 (73%)]\tLoss: 3.136242\n",
      "Train Epoch: 1 [506880/697932 (73%)]\tLoss: 3.182865\n",
      "Train Epoch: 1 [507520/697932 (73%)]\tLoss: 3.178998\n",
      "Train Epoch: 1 [508160/697932 (73%)]\tLoss: 3.153081\n",
      "Train Epoch: 1 [508800/697932 (73%)]\tLoss: 3.188893\n",
      "Train Epoch: 1 [509440/697932 (73%)]\tLoss: 3.146195\n",
      "Train Epoch: 1 [510080/697932 (73%)]\tLoss: 3.193898\n",
      "Train Epoch: 1 [510720/697932 (73%)]\tLoss: 3.186752\n",
      "Train Epoch: 1 [511360/697932 (73%)]\tLoss: 3.208683\n",
      "Train Epoch: 1 [512000/697932 (73%)]\tLoss: 3.213495\n",
      "Train Epoch: 1 [512640/697932 (73%)]\tLoss: 3.170415\n",
      "Train Epoch: 1 [513280/697932 (74%)]\tLoss: 3.179507\n",
      "Train Epoch: 1 [513920/697932 (74%)]\tLoss: 3.196789\n",
      "Train Epoch: 1 [514560/697932 (74%)]\tLoss: 3.152687\n",
      "Train Epoch: 1 [515200/697932 (74%)]\tLoss: 3.120017\n",
      "Train Epoch: 1 [515840/697932 (74%)]\tLoss: 3.168035\n",
      "Train Epoch: 1 [516480/697932 (74%)]\tLoss: 3.146713\n",
      "Train Epoch: 1 [517120/697932 (74%)]\tLoss: 3.147757\n",
      "Train Epoch: 1 [517760/697932 (74%)]\tLoss: 3.167958\n",
      "Train Epoch: 1 [518400/697932 (74%)]\tLoss: 3.184344\n",
      "Train Epoch: 1 [519040/697932 (74%)]\tLoss: 3.192036\n",
      "Train Epoch: 1 [519680/697932 (74%)]\tLoss: 3.157357\n",
      "Train Epoch: 1 [520320/697932 (75%)]\tLoss: 3.168707\n",
      "Train Epoch: 1 [520960/697932 (75%)]\tLoss: 3.186692\n",
      "Train Epoch: 1 [521600/697932 (75%)]\tLoss: 3.185010\n",
      "Train Epoch: 1 [522240/697932 (75%)]\tLoss: 3.156327\n",
      "Train Epoch: 1 [522880/697932 (75%)]\tLoss: 3.189919\n",
      "Train Epoch: 1 [523520/697932 (75%)]\tLoss: 3.136736\n",
      "Train Epoch: 1 [524160/697932 (75%)]\tLoss: 3.186749\n",
      "Train Epoch: 1 [524800/697932 (75%)]\tLoss: 3.171310\n",
      "Train Epoch: 1 [525440/697932 (75%)]\tLoss: 3.190259\n",
      "Train Epoch: 1 [526080/697932 (75%)]\tLoss: 3.189327\n",
      "Train Epoch: 1 [526720/697932 (75%)]\tLoss: 3.189772\n",
      "Train Epoch: 1 [527360/697932 (76%)]\tLoss: 3.163496\n",
      "Train Epoch: 1 [528000/697932 (76%)]\tLoss: 3.210315\n",
      "Train Epoch: 1 [528640/697932 (76%)]\tLoss: 3.183741\n",
      "Train Epoch: 1 [529280/697932 (76%)]\tLoss: 3.148742\n",
      "Train Epoch: 1 [529920/697932 (76%)]\tLoss: 3.197304\n",
      "Train Epoch: 1 [530560/697932 (76%)]\tLoss: 3.147547\n",
      "Train Epoch: 1 [531200/697932 (76%)]\tLoss: 3.178117\n",
      "Train Epoch: 1 [531840/697932 (76%)]\tLoss: 3.173549\n",
      "Train Epoch: 1 [532480/697932 (76%)]\tLoss: 3.156906\n",
      "Train Epoch: 1 [533120/697932 (76%)]\tLoss: 3.182245\n",
      "Train Epoch: 1 [533760/697932 (76%)]\tLoss: 3.202815\n",
      "Train Epoch: 1 [534400/697932 (77%)]\tLoss: 3.197458\n",
      "Train Epoch: 1 [535040/697932 (77%)]\tLoss: 3.161740\n",
      "Train Epoch: 1 [535680/697932 (77%)]\tLoss: 3.165719\n",
      "Train Epoch: 1 [536320/697932 (77%)]\tLoss: 3.177268\n",
      "Train Epoch: 1 [536960/697932 (77%)]\tLoss: 3.176206\n",
      "Train Epoch: 1 [537600/697932 (77%)]\tLoss: 3.175438\n",
      "Train Epoch: 1 [538240/697932 (77%)]\tLoss: 3.159949\n",
      "Train Epoch: 1 [538880/697932 (77%)]\tLoss: 3.174204\n",
      "Train Epoch: 1 [539520/697932 (77%)]\tLoss: 3.200858\n",
      "Train Epoch: 1 [540160/697932 (77%)]\tLoss: 3.170352\n",
      "Train Epoch: 1 [540800/697932 (77%)]\tLoss: 3.166870\n",
      "Train Epoch: 1 [541440/697932 (78%)]\tLoss: 3.172898\n",
      "Train Epoch: 1 [542080/697932 (78%)]\tLoss: 3.171031\n",
      "Train Epoch: 1 [542720/697932 (78%)]\tLoss: 3.162193\n",
      "Train Epoch: 1 [543360/697932 (78%)]\tLoss: 3.193213\n",
      "Train Epoch: 1 [544000/697932 (78%)]\tLoss: 3.195287\n",
      "Train Epoch: 1 [544640/697932 (78%)]\tLoss: 3.196620\n",
      "Train Epoch: 1 [545280/697932 (78%)]\tLoss: 3.180769\n",
      "Train Epoch: 1 [545920/697932 (78%)]\tLoss: 3.195936\n",
      "Train Epoch: 1 [546560/697932 (78%)]\tLoss: 3.201078\n",
      "Train Epoch: 1 [547200/697932 (78%)]\tLoss: 3.143178\n",
      "Train Epoch: 1 [547840/697932 (78%)]\tLoss: 3.156736\n",
      "Train Epoch: 1 [548480/697932 (79%)]\tLoss: 3.177331\n",
      "Train Epoch: 1 [549120/697932 (79%)]\tLoss: 3.179672\n",
      "Train Epoch: 1 [549760/697932 (79%)]\tLoss: 3.179198\n",
      "Train Epoch: 1 [550400/697932 (79%)]\tLoss: 3.166095\n",
      "Train Epoch: 1 [551040/697932 (79%)]\tLoss: 3.198667\n",
      "Train Epoch: 1 [551680/697932 (79%)]\tLoss: 3.171252\n",
      "Train Epoch: 1 [552320/697932 (79%)]\tLoss: 3.161843\n",
      "Train Epoch: 1 [552960/697932 (79%)]\tLoss: 3.181142\n",
      "Train Epoch: 1 [553600/697932 (79%)]\tLoss: 3.156758\n",
      "Train Epoch: 1 [554240/697932 (79%)]\tLoss: 3.150326\n",
      "Train Epoch: 1 [554880/697932 (79%)]\tLoss: 3.192673\n",
      "Train Epoch: 1 [555520/697932 (80%)]\tLoss: 3.169291\n",
      "Train Epoch: 1 [556160/697932 (80%)]\tLoss: 3.196501\n",
      "Train Epoch: 1 [556800/697932 (80%)]\tLoss: 3.148330\n",
      "Train Epoch: 1 [557440/697932 (80%)]\tLoss: 3.163731\n",
      "Train Epoch: 1 [558080/697932 (80%)]\tLoss: 3.137971\n",
      "Train Epoch: 1 [558720/697932 (80%)]\tLoss: 3.163015\n",
      "Train Epoch: 1 [559360/697932 (80%)]\tLoss: 3.144306\n",
      "Train Epoch: 1 [560000/697932 (80%)]\tLoss: 3.160928\n",
      "Train Epoch: 1 [560640/697932 (80%)]\tLoss: 3.180429\n",
      "Train Epoch: 1 [561280/697932 (80%)]\tLoss: 3.195709\n",
      "Train Epoch: 1 [561920/697932 (81%)]\tLoss: 3.152626\n",
      "Train Epoch: 1 [562560/697932 (81%)]\tLoss: 3.180426\n",
      "Train Epoch: 1 [563200/697932 (81%)]\tLoss: 3.127909\n",
      "Train Epoch: 1 [563840/697932 (81%)]\tLoss: 3.159432\n",
      "Train Epoch: 1 [564480/697932 (81%)]\tLoss: 3.155883\n",
      "Train Epoch: 1 [565120/697932 (81%)]\tLoss: 3.216978\n",
      "Train Epoch: 1 [565760/697932 (81%)]\tLoss: 3.201844\n",
      "Train Epoch: 1 [566400/697932 (81%)]\tLoss: 3.179147\n",
      "Train Epoch: 1 [567040/697932 (81%)]\tLoss: 3.124712\n",
      "Train Epoch: 1 [567680/697932 (81%)]\tLoss: 3.173098\n",
      "Train Epoch: 1 [568320/697932 (81%)]\tLoss: 3.172191\n",
      "Train Epoch: 1 [568960/697932 (82%)]\tLoss: 3.173599\n",
      "Train Epoch: 1 [569600/697932 (82%)]\tLoss: 3.166454\n",
      "Train Epoch: 1 [570240/697932 (82%)]\tLoss: 3.191634\n",
      "Train Epoch: 1 [570880/697932 (82%)]\tLoss: 3.155590\n",
      "Train Epoch: 1 [571520/697932 (82%)]\tLoss: 3.197255\n",
      "Train Epoch: 1 [572160/697932 (82%)]\tLoss: 3.198621\n",
      "Train Epoch: 1 [572800/697932 (82%)]\tLoss: 3.181641\n",
      "Train Epoch: 1 [573440/697932 (82%)]\tLoss: 3.161723\n",
      "Train Epoch: 1 [574080/697932 (82%)]\tLoss: 3.189983\n",
      "Train Epoch: 1 [574720/697932 (82%)]\tLoss: 3.175427\n",
      "Train Epoch: 1 [575360/697932 (82%)]\tLoss: 3.132230\n",
      "Train Epoch: 1 [576000/697932 (83%)]\tLoss: 3.173826\n",
      "Train Epoch: 1 [576640/697932 (83%)]\tLoss: 3.183896\n",
      "Train Epoch: 1 [577280/697932 (83%)]\tLoss: 3.146841\n",
      "Train Epoch: 1 [577920/697932 (83%)]\tLoss: 3.168406\n",
      "Train Epoch: 1 [578560/697932 (83%)]\tLoss: 3.164276\n",
      "Train Epoch: 1 [579200/697932 (83%)]\tLoss: 3.193320\n",
      "Train Epoch: 1 [579840/697932 (83%)]\tLoss: 3.168215\n",
      "Train Epoch: 1 [580480/697932 (83%)]\tLoss: 3.159053\n",
      "Train Epoch: 1 [581120/697932 (83%)]\tLoss: 3.187716\n",
      "Train Epoch: 1 [581760/697932 (83%)]\tLoss: 3.174155\n",
      "Train Epoch: 1 [582400/697932 (83%)]\tLoss: 3.177887\n",
      "Train Epoch: 1 [583040/697932 (84%)]\tLoss: 3.135372\n",
      "Train Epoch: 1 [583680/697932 (84%)]\tLoss: 3.200329\n",
      "Train Epoch: 1 [584320/697932 (84%)]\tLoss: 3.169244\n",
      "Train Epoch: 1 [584960/697932 (84%)]\tLoss: 3.174698\n",
      "Train Epoch: 1 [585600/697932 (84%)]\tLoss: 3.170124\n",
      "Train Epoch: 1 [586240/697932 (84%)]\tLoss: 3.176836\n",
      "Train Epoch: 1 [586880/697932 (84%)]\tLoss: 3.183984\n",
      "Train Epoch: 1 [587520/697932 (84%)]\tLoss: 3.181747\n",
      "Train Epoch: 1 [588160/697932 (84%)]\tLoss: 3.156545\n",
      "Train Epoch: 1 [588800/697932 (84%)]\tLoss: 3.170772\n",
      "Train Epoch: 1 [589440/697932 (84%)]\tLoss: 3.159499\n",
      "Train Epoch: 1 [590080/697932 (85%)]\tLoss: 3.207810\n",
      "Train Epoch: 1 [590720/697932 (85%)]\tLoss: 3.168401\n",
      "Train Epoch: 1 [591360/697932 (85%)]\tLoss: 3.172758\n",
      "Train Epoch: 1 [592000/697932 (85%)]\tLoss: 3.201161\n",
      "Train Epoch: 1 [592640/697932 (85%)]\tLoss: 3.183434\n",
      "Train Epoch: 1 [593280/697932 (85%)]\tLoss: 3.208563\n",
      "Train Epoch: 1 [593920/697932 (85%)]\tLoss: 3.168908\n",
      "Train Epoch: 1 [594560/697932 (85%)]\tLoss: 3.170079\n",
      "Train Epoch: 1 [595200/697932 (85%)]\tLoss: 3.142883\n",
      "Train Epoch: 1 [595840/697932 (85%)]\tLoss: 3.145343\n",
      "Train Epoch: 1 [596480/697932 (85%)]\tLoss: 3.186471\n",
      "Train Epoch: 1 [597120/697932 (86%)]\tLoss: 3.151257\n",
      "Train Epoch: 1 [597760/697932 (86%)]\tLoss: 3.165479\n",
      "Train Epoch: 1 [598400/697932 (86%)]\tLoss: 3.159124\n",
      "Train Epoch: 1 [599040/697932 (86%)]\tLoss: 3.169772\n",
      "Train Epoch: 1 [599680/697932 (86%)]\tLoss: 3.188839\n",
      "Train Epoch: 1 [600320/697932 (86%)]\tLoss: 3.163696\n",
      "Train Epoch: 1 [600960/697932 (86%)]\tLoss: 3.160006\n",
      "Train Epoch: 1 [601600/697932 (86%)]\tLoss: 3.152030\n",
      "Train Epoch: 1 [602240/697932 (86%)]\tLoss: 3.165890\n",
      "Train Epoch: 1 [602880/697932 (86%)]\tLoss: 3.200897\n",
      "Train Epoch: 1 [603520/697932 (86%)]\tLoss: 3.167131\n",
      "Train Epoch: 1 [604160/697932 (87%)]\tLoss: 3.170169\n",
      "Train Epoch: 1 [604800/697932 (87%)]\tLoss: 3.169955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [605440/697932 (87%)]\tLoss: 3.158267\n",
      "Train Epoch: 1 [606080/697932 (87%)]\tLoss: 3.147986\n",
      "Train Epoch: 1 [606720/697932 (87%)]\tLoss: 3.159916\n",
      "Train Epoch: 1 [607360/697932 (87%)]\tLoss: 3.166767\n",
      "Train Epoch: 1 [608000/697932 (87%)]\tLoss: 3.162641\n",
      "Train Epoch: 1 [608640/697932 (87%)]\tLoss: 3.169606\n",
      "Train Epoch: 1 [609280/697932 (87%)]\tLoss: 3.216661\n",
      "Train Epoch: 1 [609920/697932 (87%)]\tLoss: 3.170066\n",
      "Train Epoch: 1 [610560/697932 (87%)]\tLoss: 3.196182\n",
      "Train Epoch: 1 [611200/697932 (88%)]\tLoss: 3.192017\n",
      "Train Epoch: 1 [611840/697932 (88%)]\tLoss: 3.182238\n",
      "Train Epoch: 1 [612480/697932 (88%)]\tLoss: 3.189987\n",
      "Train Epoch: 1 [613120/697932 (88%)]\tLoss: 3.150673\n",
      "Train Epoch: 1 [613760/697932 (88%)]\tLoss: 3.163319\n",
      "Train Epoch: 1 [614400/697932 (88%)]\tLoss: 3.156418\n",
      "Train Epoch: 1 [615040/697932 (88%)]\tLoss: 3.171753\n",
      "Train Epoch: 1 [615680/697932 (88%)]\tLoss: 3.165099\n",
      "Train Epoch: 1 [616320/697932 (88%)]\tLoss: 3.212290\n",
      "Train Epoch: 1 [616960/697932 (88%)]\tLoss: 3.143507\n",
      "Train Epoch: 1 [617600/697932 (88%)]\tLoss: 3.163975\n",
      "Train Epoch: 1 [618240/697932 (89%)]\tLoss: 3.205698\n",
      "Train Epoch: 1 [618880/697932 (89%)]\tLoss: 3.179008\n",
      "Train Epoch: 1 [619520/697932 (89%)]\tLoss: 3.167938\n",
      "Train Epoch: 1 [620160/697932 (89%)]\tLoss: 3.140658\n",
      "Train Epoch: 1 [620800/697932 (89%)]\tLoss: 3.172724\n",
      "Train Epoch: 1 [621440/697932 (89%)]\tLoss: 3.189375\n",
      "Train Epoch: 1 [622080/697932 (89%)]\tLoss: 3.206267\n",
      "Train Epoch: 1 [622720/697932 (89%)]\tLoss: 3.184233\n",
      "Train Epoch: 1 [623360/697932 (89%)]\tLoss: 3.153260\n",
      "Train Epoch: 1 [624000/697932 (89%)]\tLoss: 3.180265\n",
      "Train Epoch: 1 [624640/697932 (89%)]\tLoss: 3.181621\n",
      "Train Epoch: 1 [625280/697932 (90%)]\tLoss: 3.189150\n",
      "Train Epoch: 1 [625920/697932 (90%)]\tLoss: 3.179616\n",
      "Train Epoch: 1 [626560/697932 (90%)]\tLoss: 3.171954\n",
      "Train Epoch: 1 [627200/697932 (90%)]\tLoss: 3.161387\n",
      "Train Epoch: 1 [627840/697932 (90%)]\tLoss: 3.202952\n",
      "Train Epoch: 1 [628480/697932 (90%)]\tLoss: 3.162432\n",
      "Train Epoch: 1 [629120/697932 (90%)]\tLoss: 3.167953\n",
      "Train Epoch: 1 [629760/697932 (90%)]\tLoss: 3.175144\n",
      "Train Epoch: 1 [630400/697932 (90%)]\tLoss: 3.154150\n",
      "Train Epoch: 1 [631040/697932 (90%)]\tLoss: 3.192121\n",
      "Train Epoch: 1 [631680/697932 (91%)]\tLoss: 3.145063\n",
      "Train Epoch: 1 [632320/697932 (91%)]\tLoss: 3.150854\n",
      "Train Epoch: 1 [632960/697932 (91%)]\tLoss: 3.166375\n",
      "Train Epoch: 1 [633600/697932 (91%)]\tLoss: 3.189370\n",
      "Train Epoch: 1 [634240/697932 (91%)]\tLoss: 3.216838\n",
      "Train Epoch: 1 [634880/697932 (91%)]\tLoss: 3.183419\n",
      "Train Epoch: 1 [635520/697932 (91%)]\tLoss: 3.173012\n",
      "Train Epoch: 1 [636160/697932 (91%)]\tLoss: 3.145133\n",
      "Train Epoch: 1 [636800/697932 (91%)]\tLoss: 3.176976\n",
      "Train Epoch: 1 [637440/697932 (91%)]\tLoss: 3.163209\n",
      "Train Epoch: 1 [638080/697932 (91%)]\tLoss: 3.203911\n",
      "Train Epoch: 1 [638720/697932 (92%)]\tLoss: 3.157097\n",
      "Train Epoch: 1 [639360/697932 (92%)]\tLoss: 3.172303\n",
      "Train Epoch: 1 [640000/697932 (92%)]\tLoss: 3.182205\n",
      "Train Epoch: 1 [640640/697932 (92%)]\tLoss: 3.206865\n",
      "Train Epoch: 1 [641280/697932 (92%)]\tLoss: 3.181204\n",
      "Train Epoch: 1 [641920/697932 (92%)]\tLoss: 3.175963\n",
      "Train Epoch: 1 [642560/697932 (92%)]\tLoss: 3.168240\n",
      "Train Epoch: 1 [643200/697932 (92%)]\tLoss: 3.187640\n",
      "Train Epoch: 1 [643840/697932 (92%)]\tLoss: 3.169354\n",
      "Train Epoch: 1 [644480/697932 (92%)]\tLoss: 3.151522\n",
      "Train Epoch: 1 [645120/697932 (92%)]\tLoss: 3.179837\n",
      "Train Epoch: 1 [645760/697932 (93%)]\tLoss: 3.187687\n",
      "Train Epoch: 1 [646400/697932 (93%)]\tLoss: 3.181866\n",
      "Train Epoch: 1 [647040/697932 (93%)]\tLoss: 3.188013\n",
      "Train Epoch: 1 [647680/697932 (93%)]\tLoss: 3.160475\n",
      "Train Epoch: 1 [648320/697932 (93%)]\tLoss: 3.193197\n",
      "Train Epoch: 1 [648960/697932 (93%)]\tLoss: 3.187141\n",
      "Train Epoch: 1 [649600/697932 (93%)]\tLoss: 3.176121\n",
      "Train Epoch: 1 [650240/697932 (93%)]\tLoss: 3.181117\n",
      "Train Epoch: 1 [650880/697932 (93%)]\tLoss: 3.152678\n",
      "Train Epoch: 1 [651520/697932 (93%)]\tLoss: 3.177647\n",
      "Train Epoch: 1 [652160/697932 (93%)]\tLoss: 3.185639\n",
      "Train Epoch: 1 [652800/697932 (94%)]\tLoss: 3.169449\n",
      "Train Epoch: 1 [653440/697932 (94%)]\tLoss: 3.176028\n",
      "Train Epoch: 1 [654080/697932 (94%)]\tLoss: 3.210359\n",
      "Train Epoch: 1 [654720/697932 (94%)]\tLoss: 3.163947\n",
      "Train Epoch: 1 [655360/697932 (94%)]\tLoss: 3.153966\n",
      "Train Epoch: 1 [656000/697932 (94%)]\tLoss: 3.173200\n",
      "Train Epoch: 1 [656640/697932 (94%)]\tLoss: 3.140963\n",
      "Train Epoch: 1 [657280/697932 (94%)]\tLoss: 3.146796\n",
      "Train Epoch: 1 [657920/697932 (94%)]\tLoss: 3.150071\n",
      "Train Epoch: 1 [658560/697932 (94%)]\tLoss: 3.163689\n",
      "Train Epoch: 1 [659200/697932 (94%)]\tLoss: 3.144915\n",
      "Train Epoch: 1 [659840/697932 (95%)]\tLoss: 3.174515\n",
      "Train Epoch: 1 [660480/697932 (95%)]\tLoss: 3.159886\n",
      "Train Epoch: 1 [661120/697932 (95%)]\tLoss: 3.142884\n",
      "Train Epoch: 1 [661760/697932 (95%)]\tLoss: 3.148778\n",
      "Train Epoch: 1 [662400/697932 (95%)]\tLoss: 3.175651\n",
      "Train Epoch: 1 [663040/697932 (95%)]\tLoss: 3.182279\n",
      "Train Epoch: 1 [663680/697932 (95%)]\tLoss: 3.175889\n",
      "Train Epoch: 1 [664320/697932 (95%)]\tLoss: 3.181544\n",
      "Train Epoch: 1 [664960/697932 (95%)]\tLoss: 3.176392\n",
      "Train Epoch: 1 [665600/697932 (95%)]\tLoss: 3.174984\n",
      "Train Epoch: 1 [666240/697932 (95%)]\tLoss: 3.151867\n",
      "Train Epoch: 1 [666880/697932 (96%)]\tLoss: 3.192676\n",
      "Train Epoch: 1 [667520/697932 (96%)]\tLoss: 3.170881\n",
      "Train Epoch: 1 [668160/697932 (96%)]\tLoss: 3.178172\n",
      "Train Epoch: 1 [668800/697932 (96%)]\tLoss: 3.164148\n",
      "Train Epoch: 1 [669440/697932 (96%)]\tLoss: 3.175621\n",
      "Train Epoch: 1 [670080/697932 (96%)]\tLoss: 3.159053\n",
      "Train Epoch: 1 [670720/697932 (96%)]\tLoss: 3.136912\n",
      "Train Epoch: 1 [671360/697932 (96%)]\tLoss: 3.170755\n",
      "Train Epoch: 1 [672000/697932 (96%)]\tLoss: 3.189236\n",
      "Train Epoch: 1 [672640/697932 (96%)]\tLoss: 3.212672\n",
      "Train Epoch: 1 [673280/697932 (96%)]\tLoss: 3.179083\n",
      "Train Epoch: 1 [673920/697932 (97%)]\tLoss: 3.165439\n",
      "Train Epoch: 1 [674560/697932 (97%)]\tLoss: 3.164557\n",
      "Train Epoch: 1 [675200/697932 (97%)]\tLoss: 3.160574\n",
      "Train Epoch: 1 [675840/697932 (97%)]\tLoss: 3.199843\n",
      "Train Epoch: 1 [676480/697932 (97%)]\tLoss: 3.168863\n",
      "Train Epoch: 1 [677120/697932 (97%)]\tLoss: 3.172240\n",
      "Train Epoch: 1 [677760/697932 (97%)]\tLoss: 3.175903\n",
      "Train Epoch: 1 [678400/697932 (97%)]\tLoss: 3.167430\n",
      "Train Epoch: 1 [679040/697932 (97%)]\tLoss: 3.177815\n",
      "Train Epoch: 1 [679680/697932 (97%)]\tLoss: 3.150675\n",
      "Train Epoch: 1 [680320/697932 (97%)]\tLoss: 3.164790\n",
      "Train Epoch: 1 [680960/697932 (98%)]\tLoss: 3.169068\n",
      "Train Epoch: 1 [681600/697932 (98%)]\tLoss: 3.168254\n",
      "Train Epoch: 1 [682240/697932 (98%)]\tLoss: 3.190942\n",
      "Train Epoch: 1 [682880/697932 (98%)]\tLoss: 3.172380\n",
      "Train Epoch: 1 [683520/697932 (98%)]\tLoss: 3.153688\n",
      "Train Epoch: 1 [684160/697932 (98%)]\tLoss: 3.144058\n",
      "Train Epoch: 1 [684800/697932 (98%)]\tLoss: 3.168151\n",
      "Train Epoch: 1 [685440/697932 (98%)]\tLoss: 3.192538\n",
      "Train Epoch: 1 [686080/697932 (98%)]\tLoss: 3.194529\n",
      "Train Epoch: 1 [686720/697932 (98%)]\tLoss: 3.188991\n",
      "Train Epoch: 1 [687360/697932 (98%)]\tLoss: 3.178846\n",
      "Train Epoch: 1 [688000/697932 (99%)]\tLoss: 3.175526\n",
      "Train Epoch: 1 [688640/697932 (99%)]\tLoss: 3.193652\n",
      "Train Epoch: 1 [689280/697932 (99%)]\tLoss: 3.154835\n",
      "Train Epoch: 1 [689920/697932 (99%)]\tLoss: 3.214194\n",
      "Train Epoch: 1 [690560/697932 (99%)]\tLoss: 3.185207\n",
      "Train Epoch: 1 [691200/697932 (99%)]\tLoss: 3.176842\n",
      "Train Epoch: 1 [691840/697932 (99%)]\tLoss: 3.167315\n",
      "Train Epoch: 1 [692480/697932 (99%)]\tLoss: 3.165043\n",
      "Train Epoch: 1 [693120/697932 (99%)]\tLoss: 3.150679\n",
      "Train Epoch: 1 [693760/697932 (99%)]\tLoss: 3.178284\n",
      "Train Epoch: 1 [694400/697932 (99%)]\tLoss: 3.156507\n",
      "Train Epoch: 1 [695040/697932 (100%)]\tLoss: 3.150701\n",
      "Train Epoch: 1 [695680/697932 (100%)]\tLoss: 3.170821\n",
      "Train Epoch: 1 [696320/697932 (100%)]\tLoss: 3.172052\n",
      "Train Epoch: 1 [696960/697932 (100%)]\tLoss: 3.172755\n",
      "Train Epoch: 1 [697600/697932 (100%)]\tLoss: 3.165750\n",
      "\n",
      "Test set: Avg. loss: 0.0044, Accuracy: 38/116323 (0%)\n",
      "\n",
      "Train Epoch: 2 [0/697932 (0%)]\tLoss: 3.188798\n",
      "Train Epoch: 2 [640/697932 (0%)]\tLoss: 3.142486\n",
      "Train Epoch: 2 [1280/697932 (0%)]\tLoss: 3.167789\n",
      "Train Epoch: 2 [1920/697932 (0%)]\tLoss: 3.150190\n",
      "Train Epoch: 2 [2560/697932 (0%)]\tLoss: 3.168230\n",
      "Train Epoch: 2 [3200/697932 (0%)]\tLoss: 3.171563\n",
      "Train Epoch: 2 [3840/697932 (1%)]\tLoss: 3.198528\n",
      "Train Epoch: 2 [4480/697932 (1%)]\tLoss: 3.182014\n",
      "Train Epoch: 2 [5120/697932 (1%)]\tLoss: 3.177460\n",
      "Train Epoch: 2 [5760/697932 (1%)]\tLoss: 3.172775\n",
      "Train Epoch: 2 [6400/697932 (1%)]\tLoss: 3.140871\n",
      "Train Epoch: 2 [7040/697932 (1%)]\tLoss: 3.168627\n",
      "Train Epoch: 2 [7680/697932 (1%)]\tLoss: 3.150665\n",
      "Train Epoch: 2 [8320/697932 (1%)]\tLoss: 3.189983\n",
      "Train Epoch: 2 [8960/697932 (1%)]\tLoss: 3.143693\n",
      "Train Epoch: 2 [9600/697932 (1%)]\tLoss: 3.200406\n",
      "Train Epoch: 2 [10240/697932 (1%)]\tLoss: 3.186409\n",
      "Train Epoch: 2 [10880/697932 (2%)]\tLoss: 3.152780\n",
      "Train Epoch: 2 [11520/697932 (2%)]\tLoss: 3.165614\n",
      "Train Epoch: 2 [12160/697932 (2%)]\tLoss: 3.153282\n",
      "Train Epoch: 2 [12800/697932 (2%)]\tLoss: 3.171605\n",
      "Train Epoch: 2 [13440/697932 (2%)]\tLoss: 3.168106\n",
      "Train Epoch: 2 [14080/697932 (2%)]\tLoss: 3.159470\n",
      "Train Epoch: 2 [14720/697932 (2%)]\tLoss: 3.157685\n",
      "Train Epoch: 2 [15360/697932 (2%)]\tLoss: 3.184549\n",
      "Train Epoch: 2 [16000/697932 (2%)]\tLoss: 3.202261\n",
      "Train Epoch: 2 [16640/697932 (2%)]\tLoss: 3.193684\n",
      "Train Epoch: 2 [17280/697932 (2%)]\tLoss: 3.140405\n",
      "Train Epoch: 2 [17920/697932 (3%)]\tLoss: 3.171825\n",
      "Train Epoch: 2 [18560/697932 (3%)]\tLoss: 3.181567\n",
      "Train Epoch: 2 [19200/697932 (3%)]\tLoss: 3.172083\n",
      "Train Epoch: 2 [19840/697932 (3%)]\tLoss: 3.171024\n",
      "Train Epoch: 2 [20480/697932 (3%)]\tLoss: 3.147704\n",
      "Train Epoch: 2 [21120/697932 (3%)]\tLoss: 3.141780\n",
      "Train Epoch: 2 [21760/697932 (3%)]\tLoss: 3.181095\n",
      "Train Epoch: 2 [22400/697932 (3%)]\tLoss: 3.198401\n",
      "Train Epoch: 2 [23040/697932 (3%)]\tLoss: 3.158091\n",
      "Train Epoch: 2 [23680/697932 (3%)]\tLoss: 3.167158\n",
      "Train Epoch: 2 [24320/697932 (3%)]\tLoss: 3.159773\n",
      "Train Epoch: 2 [24960/697932 (4%)]\tLoss: 3.179120\n",
      "Train Epoch: 2 [25600/697932 (4%)]\tLoss: 3.153217\n",
      "Train Epoch: 2 [26240/697932 (4%)]\tLoss: 3.179994\n",
      "Train Epoch: 2 [26880/697932 (4%)]\tLoss: 3.218660\n",
      "Train Epoch: 2 [27520/697932 (4%)]\tLoss: 3.175574\n",
      "Train Epoch: 2 [28160/697932 (4%)]\tLoss: 3.154385\n",
      "Train Epoch: 2 [28800/697932 (4%)]\tLoss: 3.198473\n",
      "Train Epoch: 2 [29440/697932 (4%)]\tLoss: 3.192217\n",
      "Train Epoch: 2 [30080/697932 (4%)]\tLoss: 3.233598\n",
      "Train Epoch: 2 [30720/697932 (4%)]\tLoss: 3.180925\n",
      "Train Epoch: 2 [31360/697932 (4%)]\tLoss: 3.158703\n",
      "Train Epoch: 2 [32000/697932 (5%)]\tLoss: 3.145722\n",
      "Train Epoch: 2 [32640/697932 (5%)]\tLoss: 3.192363\n",
      "Train Epoch: 2 [33280/697932 (5%)]\tLoss: 3.126662\n",
      "Train Epoch: 2 [33920/697932 (5%)]\tLoss: 3.175860\n",
      "Train Epoch: 2 [34560/697932 (5%)]\tLoss: 3.183056\n",
      "Train Epoch: 2 [35200/697932 (5%)]\tLoss: 3.152240\n",
      "Train Epoch: 2 [35840/697932 (5%)]\tLoss: 3.144192\n",
      "Train Epoch: 2 [36480/697932 (5%)]\tLoss: 3.149766\n",
      "Train Epoch: 2 [37120/697932 (5%)]\tLoss: 3.147669\n",
      "Train Epoch: 2 [37760/697932 (5%)]\tLoss: 3.162978\n",
      "Train Epoch: 2 [38400/697932 (6%)]\tLoss: 3.186990\n",
      "Train Epoch: 2 [39040/697932 (6%)]\tLoss: 3.181892\n",
      "Train Epoch: 2 [39680/697932 (6%)]\tLoss: 3.178372\n",
      "Train Epoch: 2 [40320/697932 (6%)]\tLoss: 3.158617\n",
      "Train Epoch: 2 [40960/697932 (6%)]\tLoss: 3.200051\n",
      "Train Epoch: 2 [41600/697932 (6%)]\tLoss: 3.164037\n",
      "Train Epoch: 2 [42240/697932 (6%)]\tLoss: 3.150234\n",
      "Train Epoch: 2 [42880/697932 (6%)]\tLoss: 3.170657\n",
      "Train Epoch: 2 [43520/697932 (6%)]\tLoss: 3.188028\n",
      "Train Epoch: 2 [44160/697932 (6%)]\tLoss: 3.171823\n",
      "Train Epoch: 2 [44800/697932 (6%)]\tLoss: 3.183162\n",
      "Train Epoch: 2 [45440/697932 (7%)]\tLoss: 3.156157\n",
      "Train Epoch: 2 [46080/697932 (7%)]\tLoss: 3.148616\n",
      "Train Epoch: 2 [46720/697932 (7%)]\tLoss: 3.177789\n",
      "Train Epoch: 2 [47360/697932 (7%)]\tLoss: 3.194968\n",
      "Train Epoch: 2 [48000/697932 (7%)]\tLoss: 3.173699\n",
      "Train Epoch: 2 [48640/697932 (7%)]\tLoss: 3.162136\n",
      "Train Epoch: 2 [49280/697932 (7%)]\tLoss: 3.152070\n",
      "Train Epoch: 2 [49920/697932 (7%)]\tLoss: 3.155470\n",
      "Train Epoch: 2 [50560/697932 (7%)]\tLoss: 3.195455\n",
      "Train Epoch: 2 [51200/697932 (7%)]\tLoss: 3.146710\n",
      "Train Epoch: 2 [51840/697932 (7%)]\tLoss: 3.172845\n",
      "Train Epoch: 2 [52480/697932 (8%)]\tLoss: 3.157420\n",
      "Train Epoch: 2 [53120/697932 (8%)]\tLoss: 3.182888\n",
      "Train Epoch: 2 [53760/697932 (8%)]\tLoss: 3.169804\n",
      "Train Epoch: 2 [54400/697932 (8%)]\tLoss: 3.175235\n",
      "Train Epoch: 2 [55040/697932 (8%)]\tLoss: 3.213789\n",
      "Train Epoch: 2 [55680/697932 (8%)]\tLoss: 3.171104\n",
      "Train Epoch: 2 [56320/697932 (8%)]\tLoss: 3.168672\n",
      "Train Epoch: 2 [56960/697932 (8%)]\tLoss: 3.197338\n",
      "Train Epoch: 2 [57600/697932 (8%)]\tLoss: 3.176800\n",
      "Train Epoch: 2 [58240/697932 (8%)]\tLoss: 3.197881\n",
      "Train Epoch: 2 [58880/697932 (8%)]\tLoss: 3.176629\n",
      "Train Epoch: 2 [59520/697932 (9%)]\tLoss: 3.168579\n",
      "Train Epoch: 2 [60160/697932 (9%)]\tLoss: 3.170424\n",
      "Train Epoch: 2 [60800/697932 (9%)]\tLoss: 3.171744\n",
      "Train Epoch: 2 [61440/697932 (9%)]\tLoss: 3.209929\n",
      "Train Epoch: 2 [62080/697932 (9%)]\tLoss: 3.175064\n",
      "Train Epoch: 2 [62720/697932 (9%)]\tLoss: 3.178826\n",
      "Train Epoch: 2 [63360/697932 (9%)]\tLoss: 3.168781\n",
      "Train Epoch: 2 [64000/697932 (9%)]\tLoss: 3.191663\n",
      "Train Epoch: 2 [64640/697932 (9%)]\tLoss: 3.188864\n",
      "Train Epoch: 2 [65280/697932 (9%)]\tLoss: 3.205766\n",
      "Train Epoch: 2 [65920/697932 (9%)]\tLoss: 3.151879\n",
      "Train Epoch: 2 [66560/697932 (10%)]\tLoss: 3.182828\n",
      "Train Epoch: 2 [67200/697932 (10%)]\tLoss: 3.168239\n",
      "Train Epoch: 2 [67840/697932 (10%)]\tLoss: 3.162720\n",
      "Train Epoch: 2 [68480/697932 (10%)]\tLoss: 3.190258\n",
      "Train Epoch: 2 [69120/697932 (10%)]\tLoss: 3.177272\n",
      "Train Epoch: 2 [69760/697932 (10%)]\tLoss: 3.156299\n",
      "Train Epoch: 2 [70400/697932 (10%)]\tLoss: 3.168309\n",
      "Train Epoch: 2 [71040/697932 (10%)]\tLoss: 3.165507\n",
      "Train Epoch: 2 [71680/697932 (10%)]\tLoss: 3.166447\n",
      "Train Epoch: 2 [72320/697932 (10%)]\tLoss: 3.200315\n",
      "Train Epoch: 2 [72960/697932 (10%)]\tLoss: 3.144932\n",
      "Train Epoch: 2 [73600/697932 (11%)]\tLoss: 3.171490\n",
      "Train Epoch: 2 [74240/697932 (11%)]\tLoss: 3.179605\n",
      "Train Epoch: 2 [74880/697932 (11%)]\tLoss: 3.185026\n",
      "Train Epoch: 2 [75520/697932 (11%)]\tLoss: 3.164885\n",
      "Train Epoch: 2 [76160/697932 (11%)]\tLoss: 3.206665\n",
      "Train Epoch: 2 [76800/697932 (11%)]\tLoss: 3.171175\n",
      "Train Epoch: 2 [77440/697932 (11%)]\tLoss: 3.164819\n",
      "Train Epoch: 2 [78080/697932 (11%)]\tLoss: 3.148475\n",
      "Train Epoch: 2 [78720/697932 (11%)]\tLoss: 3.159425\n",
      "Train Epoch: 2 [79360/697932 (11%)]\tLoss: 3.154202\n",
      "Train Epoch: 2 [80000/697932 (11%)]\tLoss: 3.174672\n",
      "Train Epoch: 2 [80640/697932 (12%)]\tLoss: 3.166330\n",
      "Train Epoch: 2 [81280/697932 (12%)]\tLoss: 3.187858\n",
      "Train Epoch: 2 [81920/697932 (12%)]\tLoss: 3.156791\n",
      "Train Epoch: 2 [82560/697932 (12%)]\tLoss: 3.155336\n",
      "Train Epoch: 2 [83200/697932 (12%)]\tLoss: 3.168318\n",
      "Train Epoch: 2 [83840/697932 (12%)]\tLoss: 3.149918\n",
      "Train Epoch: 2 [84480/697932 (12%)]\tLoss: 3.178649\n",
      "Train Epoch: 2 [85120/697932 (12%)]\tLoss: 3.191099\n",
      "Train Epoch: 2 [85760/697932 (12%)]\tLoss: 3.177761\n",
      "Train Epoch: 2 [86400/697932 (12%)]\tLoss: 3.141483\n",
      "Train Epoch: 2 [87040/697932 (12%)]\tLoss: 3.140851\n",
      "Train Epoch: 2 [87680/697932 (13%)]\tLoss: 3.151623\n",
      "Train Epoch: 2 [88320/697932 (13%)]\tLoss: 3.174350\n",
      "Train Epoch: 2 [88960/697932 (13%)]\tLoss: 3.182643\n",
      "Train Epoch: 2 [89600/697932 (13%)]\tLoss: 3.173426\n",
      "Train Epoch: 2 [90240/697932 (13%)]\tLoss: 3.192649\n",
      "Train Epoch: 2 [90880/697932 (13%)]\tLoss: 3.162908\n",
      "Train Epoch: 2 [91520/697932 (13%)]\tLoss: 3.163541\n",
      "Train Epoch: 2 [92160/697932 (13%)]\tLoss: 3.181319\n",
      "Train Epoch: 2 [92800/697932 (13%)]\tLoss: 3.208240\n",
      "Train Epoch: 2 [93440/697932 (13%)]\tLoss: 3.194595\n",
      "Train Epoch: 2 [94080/697932 (13%)]\tLoss: 3.183156\n",
      "Train Epoch: 2 [94720/697932 (14%)]\tLoss: 3.154651\n",
      "Train Epoch: 2 [95360/697932 (14%)]\tLoss: 3.186641\n",
      "Train Epoch: 2 [96000/697932 (14%)]\tLoss: 3.158065\n",
      "Train Epoch: 2 [96640/697932 (14%)]\tLoss: 3.163348\n",
      "Train Epoch: 2 [97280/697932 (14%)]\tLoss: 3.160815\n",
      "Train Epoch: 2 [97920/697932 (14%)]\tLoss: 3.184293\n",
      "Train Epoch: 2 [98560/697932 (14%)]\tLoss: 3.156962\n",
      "Train Epoch: 2 [99200/697932 (14%)]\tLoss: 3.178765\n",
      "Train Epoch: 2 [99840/697932 (14%)]\tLoss: 3.154614\n",
      "Train Epoch: 2 [100480/697932 (14%)]\tLoss: 3.175972\n",
      "Train Epoch: 2 [101120/697932 (14%)]\tLoss: 3.148841\n",
      "Train Epoch: 2 [101760/697932 (15%)]\tLoss: 3.157214\n",
      "Train Epoch: 2 [102400/697932 (15%)]\tLoss: 3.179247\n",
      "Train Epoch: 2 [103040/697932 (15%)]\tLoss: 3.177445\n",
      "Train Epoch: 2 [103680/697932 (15%)]\tLoss: 3.146058\n",
      "Train Epoch: 2 [104320/697932 (15%)]\tLoss: 3.203637\n",
      "Train Epoch: 2 [104960/697932 (15%)]\tLoss: 3.167379\n",
      "Train Epoch: 2 [105600/697932 (15%)]\tLoss: 3.173167\n",
      "Train Epoch: 2 [106240/697932 (15%)]\tLoss: 3.196475\n",
      "Train Epoch: 2 [106880/697932 (15%)]\tLoss: 3.167310\n",
      "Train Epoch: 2 [107520/697932 (15%)]\tLoss: 3.165686\n",
      "Train Epoch: 2 [108160/697932 (15%)]\tLoss: 3.174298\n",
      "Train Epoch: 2 [108800/697932 (16%)]\tLoss: 3.182383\n",
      "Train Epoch: 2 [109440/697932 (16%)]\tLoss: 3.193871\n",
      "Train Epoch: 2 [110080/697932 (16%)]\tLoss: 3.168157\n",
      "Train Epoch: 2 [110720/697932 (16%)]\tLoss: 3.183892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [111360/697932 (16%)]\tLoss: 3.157065\n",
      "Train Epoch: 2 [112000/697932 (16%)]\tLoss: 3.166143\n",
      "Train Epoch: 2 [112640/697932 (16%)]\tLoss: 3.200470\n",
      "Train Epoch: 2 [113280/697932 (16%)]\tLoss: 3.174883\n",
      "Train Epoch: 2 [113920/697932 (16%)]\tLoss: 3.169187\n",
      "Train Epoch: 2 [114560/697932 (16%)]\tLoss: 3.144397\n",
      "Train Epoch: 2 [115200/697932 (17%)]\tLoss: 3.169550\n",
      "Train Epoch: 2 [115840/697932 (17%)]\tLoss: 3.195999\n",
      "Train Epoch: 2 [116480/697932 (17%)]\tLoss: 3.124669\n",
      "Train Epoch: 2 [117120/697932 (17%)]\tLoss: 3.156953\n",
      "Train Epoch: 2 [117760/697932 (17%)]\tLoss: 3.183585\n",
      "Train Epoch: 2 [118400/697932 (17%)]\tLoss: 3.161720\n",
      "Train Epoch: 2 [119040/697932 (17%)]\tLoss: 3.188570\n",
      "Train Epoch: 2 [119680/697932 (17%)]\tLoss: 3.188340\n",
      "Train Epoch: 2 [120320/697932 (17%)]\tLoss: 3.204633\n",
      "Train Epoch: 2 [120960/697932 (17%)]\tLoss: 3.196086\n",
      "Train Epoch: 2 [121600/697932 (17%)]\tLoss: 3.164710\n",
      "Train Epoch: 2 [122240/697932 (18%)]\tLoss: 3.144659\n",
      "Train Epoch: 2 [122880/697932 (18%)]\tLoss: 3.185458\n",
      "Train Epoch: 2 [123520/697932 (18%)]\tLoss: 3.156316\n",
      "Train Epoch: 2 [124160/697932 (18%)]\tLoss: 3.166517\n",
      "Train Epoch: 2 [124800/697932 (18%)]\tLoss: 3.181416\n",
      "Train Epoch: 2 [125440/697932 (18%)]\tLoss: 3.141466\n",
      "Train Epoch: 2 [126080/697932 (18%)]\tLoss: 3.165866\n",
      "Train Epoch: 2 [126720/697932 (18%)]\tLoss: 3.170910\n",
      "Train Epoch: 2 [127360/697932 (18%)]\tLoss: 3.171307\n",
      "Train Epoch: 2 [128000/697932 (18%)]\tLoss: 3.169981\n",
      "Train Epoch: 2 [128640/697932 (18%)]\tLoss: 3.161017\n",
      "Train Epoch: 2 [129280/697932 (19%)]\tLoss: 3.156588\n",
      "Train Epoch: 2 [129920/697932 (19%)]\tLoss: 3.159498\n",
      "Train Epoch: 2 [130560/697932 (19%)]\tLoss: 3.217143\n",
      "Train Epoch: 2 [131200/697932 (19%)]\tLoss: 3.173826\n",
      "Train Epoch: 2 [131840/697932 (19%)]\tLoss: 3.175750\n",
      "Train Epoch: 2 [132480/697932 (19%)]\tLoss: 3.178136\n",
      "Train Epoch: 2 [133120/697932 (19%)]\tLoss: 3.158143\n",
      "Train Epoch: 2 [133760/697932 (19%)]\tLoss: 3.136906\n",
      "Train Epoch: 2 [134400/697932 (19%)]\tLoss: 3.179120\n",
      "Train Epoch: 2 [135040/697932 (19%)]\tLoss: 3.162852\n",
      "Train Epoch: 2 [135680/697932 (19%)]\tLoss: 3.158379\n",
      "Train Epoch: 2 [136320/697932 (20%)]\tLoss: 3.204571\n",
      "Train Epoch: 2 [136960/697932 (20%)]\tLoss: 3.148531\n",
      "Train Epoch: 2 [137600/697932 (20%)]\tLoss: 3.138681\n",
      "Train Epoch: 2 [138240/697932 (20%)]\tLoss: 3.158184\n",
      "Train Epoch: 2 [138880/697932 (20%)]\tLoss: 3.164608\n",
      "Train Epoch: 2 [139520/697932 (20%)]\tLoss: 3.189777\n",
      "Train Epoch: 2 [140160/697932 (20%)]\tLoss: 3.166266\n",
      "Train Epoch: 2 [140800/697932 (20%)]\tLoss: 3.160990\n",
      "Train Epoch: 2 [141440/697932 (20%)]\tLoss: 3.182796\n",
      "Train Epoch: 2 [142080/697932 (20%)]\tLoss: 3.177213\n",
      "Train Epoch: 2 [142720/697932 (20%)]\tLoss: 3.174747\n",
      "Train Epoch: 2 [143360/697932 (21%)]\tLoss: 3.186209\n",
      "Train Epoch: 2 [144000/697932 (21%)]\tLoss: 3.157238\n",
      "Train Epoch: 2 [144640/697932 (21%)]\tLoss: 3.153152\n",
      "Train Epoch: 2 [145280/697932 (21%)]\tLoss: 3.191012\n",
      "Train Epoch: 2 [145920/697932 (21%)]\tLoss: 3.196908\n",
      "Train Epoch: 2 [146560/697932 (21%)]\tLoss: 3.188329\n",
      "Train Epoch: 2 [147200/697932 (21%)]\tLoss: 3.180656\n",
      "Train Epoch: 2 [147840/697932 (21%)]\tLoss: 3.168372\n",
      "Train Epoch: 2 [148480/697932 (21%)]\tLoss: 3.143234\n",
      "Train Epoch: 2 [149120/697932 (21%)]\tLoss: 3.183151\n",
      "Train Epoch: 2 [149760/697932 (21%)]\tLoss: 3.146479\n",
      "Train Epoch: 2 [150400/697932 (22%)]\tLoss: 3.156910\n",
      "Train Epoch: 2 [151040/697932 (22%)]\tLoss: 3.162211\n",
      "Train Epoch: 2 [151680/697932 (22%)]\tLoss: 3.179299\n",
      "Train Epoch: 2 [152320/697932 (22%)]\tLoss: 3.124915\n",
      "Train Epoch: 2 [152960/697932 (22%)]\tLoss: 3.171108\n",
      "Train Epoch: 2 [153600/697932 (22%)]\tLoss: 3.184128\n",
      "Train Epoch: 2 [154240/697932 (22%)]\tLoss: 3.168312\n",
      "Train Epoch: 2 [154880/697932 (22%)]\tLoss: 3.165373\n",
      "Train Epoch: 2 [155520/697932 (22%)]\tLoss: 3.174759\n",
      "Train Epoch: 2 [156160/697932 (22%)]\tLoss: 3.167740\n",
      "Train Epoch: 2 [156800/697932 (22%)]\tLoss: 3.171308\n",
      "Train Epoch: 2 [157440/697932 (23%)]\tLoss: 3.184280\n",
      "Train Epoch: 2 [158080/697932 (23%)]\tLoss: 3.201322\n",
      "Train Epoch: 2 [158720/697932 (23%)]\tLoss: 3.199050\n",
      "Train Epoch: 2 [159360/697932 (23%)]\tLoss: 3.203319\n",
      "Train Epoch: 2 [160000/697932 (23%)]\tLoss: 3.143949\n",
      "Train Epoch: 2 [160640/697932 (23%)]\tLoss: 3.165434\n",
      "Train Epoch: 2 [161280/697932 (23%)]\tLoss: 3.151272\n",
      "Train Epoch: 2 [161920/697932 (23%)]\tLoss: 3.166578\n",
      "Train Epoch: 2 [162560/697932 (23%)]\tLoss: 3.143270\n",
      "Train Epoch: 2 [163200/697932 (23%)]\tLoss: 3.164044\n",
      "Train Epoch: 2 [163840/697932 (23%)]\tLoss: 3.133396\n",
      "Train Epoch: 2 [164480/697932 (24%)]\tLoss: 3.170072\n",
      "Train Epoch: 2 [165120/697932 (24%)]\tLoss: 3.178444\n",
      "Train Epoch: 2 [165760/697932 (24%)]\tLoss: 3.200730\n",
      "Train Epoch: 2 [166400/697932 (24%)]\tLoss: 3.194166\n",
      "Train Epoch: 2 [167040/697932 (24%)]\tLoss: 3.182692\n",
      "Train Epoch: 2 [167680/697932 (24%)]\tLoss: 3.171695\n",
      "Train Epoch: 2 [168320/697932 (24%)]\tLoss: 3.177989\n",
      "Train Epoch: 2 [168960/697932 (24%)]\tLoss: 3.146693\n",
      "Train Epoch: 2 [169600/697932 (24%)]\tLoss: 3.180873\n",
      "Train Epoch: 2 [170240/697932 (24%)]\tLoss: 3.210742\n",
      "Train Epoch: 2 [170880/697932 (24%)]\tLoss: 3.153543\n",
      "Train Epoch: 2 [171520/697932 (25%)]\tLoss: 3.149984\n",
      "Train Epoch: 2 [172160/697932 (25%)]\tLoss: 3.225390\n",
      "Train Epoch: 2 [172800/697932 (25%)]\tLoss: 3.193466\n",
      "Train Epoch: 2 [173440/697932 (25%)]\tLoss: 3.163553\n",
      "Train Epoch: 2 [174080/697932 (25%)]\tLoss: 3.160737\n",
      "Train Epoch: 2 [174720/697932 (25%)]\tLoss: 3.173236\n",
      "Train Epoch: 2 [175360/697932 (25%)]\tLoss: 3.182497\n",
      "Train Epoch: 2 [176000/697932 (25%)]\tLoss: 3.154089\n",
      "Train Epoch: 2 [176640/697932 (25%)]\tLoss: 3.222572\n",
      "Train Epoch: 2 [177280/697932 (25%)]\tLoss: 3.206622\n",
      "Train Epoch: 2 [177920/697932 (25%)]\tLoss: 3.179133\n",
      "Train Epoch: 2 [178560/697932 (26%)]\tLoss: 3.167781\n",
      "Train Epoch: 2 [179200/697932 (26%)]\tLoss: 3.160213\n",
      "Train Epoch: 2 [179840/697932 (26%)]\tLoss: 3.166031\n",
      "Train Epoch: 2 [180480/697932 (26%)]\tLoss: 3.163006\n",
      "Train Epoch: 2 [181120/697932 (26%)]\tLoss: 3.149044\n",
      "Train Epoch: 2 [181760/697932 (26%)]\tLoss: 3.139199\n",
      "Train Epoch: 2 [182400/697932 (26%)]\tLoss: 3.155961\n",
      "Train Epoch: 2 [183040/697932 (26%)]\tLoss: 3.188042\n",
      "Train Epoch: 2 [183680/697932 (26%)]\tLoss: 3.191987\n",
      "Train Epoch: 2 [184320/697932 (26%)]\tLoss: 3.166885\n",
      "Train Epoch: 2 [184960/697932 (26%)]\tLoss: 3.177667\n",
      "Train Epoch: 2 [185600/697932 (27%)]\tLoss: 3.170439\n",
      "Train Epoch: 2 [186240/697932 (27%)]\tLoss: 3.184202\n",
      "Train Epoch: 2 [186880/697932 (27%)]\tLoss: 3.153492\n",
      "Train Epoch: 2 [187520/697932 (27%)]\tLoss: 3.162054\n",
      "Train Epoch: 2 [188160/697932 (27%)]\tLoss: 3.197987\n",
      "Train Epoch: 2 [188800/697932 (27%)]\tLoss: 3.173386\n",
      "Train Epoch: 2 [189440/697932 (27%)]\tLoss: 3.179787\n",
      "Train Epoch: 2 [190080/697932 (27%)]\tLoss: 3.155799\n",
      "Train Epoch: 2 [190720/697932 (27%)]\tLoss: 3.206946\n",
      "Train Epoch: 2 [191360/697932 (27%)]\tLoss: 3.149731\n",
      "Train Epoch: 2 [192000/697932 (28%)]\tLoss: 3.177505\n",
      "Train Epoch: 2 [192640/697932 (28%)]\tLoss: 3.157616\n",
      "Train Epoch: 2 [193280/697932 (28%)]\tLoss: 3.182855\n",
      "Train Epoch: 2 [193920/697932 (28%)]\tLoss: 3.190239\n",
      "Train Epoch: 2 [194560/697932 (28%)]\tLoss: 3.149271\n",
      "Train Epoch: 2 [195200/697932 (28%)]\tLoss: 3.165057\n",
      "Train Epoch: 2 [195840/697932 (28%)]\tLoss: 3.170719\n",
      "Train Epoch: 2 [196480/697932 (28%)]\tLoss: 3.161812\n",
      "Train Epoch: 2 [197120/697932 (28%)]\tLoss: 3.150532\n",
      "Train Epoch: 2 [197760/697932 (28%)]\tLoss: 3.146045\n",
      "Train Epoch: 2 [198400/697932 (28%)]\tLoss: 3.147723\n",
      "Train Epoch: 2 [199040/697932 (29%)]\tLoss: 3.173912\n",
      "Train Epoch: 2 [199680/697932 (29%)]\tLoss: 3.207569\n",
      "Train Epoch: 2 [200320/697932 (29%)]\tLoss: 3.134639\n",
      "Train Epoch: 2 [200960/697932 (29%)]\tLoss: 3.176097\n",
      "Train Epoch: 2 [201600/697932 (29%)]\tLoss: 3.187650\n",
      "Train Epoch: 2 [202240/697932 (29%)]\tLoss: 3.147908\n",
      "Train Epoch: 2 [202880/697932 (29%)]\tLoss: 3.166955\n",
      "Train Epoch: 2 [203520/697932 (29%)]\tLoss: 3.154096\n",
      "Train Epoch: 2 [204160/697932 (29%)]\tLoss: 3.162012\n",
      "Train Epoch: 2 [204800/697932 (29%)]\tLoss: 3.221993\n",
      "Train Epoch: 2 [205440/697932 (29%)]\tLoss: 3.179609\n",
      "Train Epoch: 2 [206080/697932 (30%)]\tLoss: 3.146411\n",
      "Train Epoch: 2 [206720/697932 (30%)]\tLoss: 3.151204\n",
      "Train Epoch: 2 [207360/697932 (30%)]\tLoss: 3.152737\n",
      "Train Epoch: 2 [208000/697932 (30%)]\tLoss: 3.157874\n",
      "Train Epoch: 2 [208640/697932 (30%)]\tLoss: 3.159227\n",
      "Train Epoch: 2 [209280/697932 (30%)]\tLoss: 3.178845\n",
      "Train Epoch: 2 [209920/697932 (30%)]\tLoss: 3.175420\n",
      "Train Epoch: 2 [210560/697932 (30%)]\tLoss: 3.173569\n",
      "Train Epoch: 2 [211200/697932 (30%)]\tLoss: 3.167910\n",
      "Train Epoch: 2 [211840/697932 (30%)]\tLoss: 3.157224\n",
      "Train Epoch: 2 [212480/697932 (30%)]\tLoss: 3.183802\n",
      "Train Epoch: 2 [213120/697932 (31%)]\tLoss: 3.193722\n",
      "Train Epoch: 2 [213760/697932 (31%)]\tLoss: 3.175784\n",
      "Train Epoch: 2 [214400/697932 (31%)]\tLoss: 3.187867\n",
      "Train Epoch: 2 [215040/697932 (31%)]\tLoss: 3.167280\n",
      "Train Epoch: 2 [215680/697932 (31%)]\tLoss: 3.175520\n",
      "Train Epoch: 2 [216320/697932 (31%)]\tLoss: 3.194007\n",
      "Train Epoch: 2 [216960/697932 (31%)]\tLoss: 3.133460\n",
      "Train Epoch: 2 [217600/697932 (31%)]\tLoss: 3.151300\n",
      "Train Epoch: 2 [218240/697932 (31%)]\tLoss: 3.175662\n",
      "Train Epoch: 2 [218880/697932 (31%)]\tLoss: 3.217819\n",
      "Train Epoch: 2 [219520/697932 (31%)]\tLoss: 3.132902\n",
      "Train Epoch: 2 [220160/697932 (32%)]\tLoss: 3.177088\n",
      "Train Epoch: 2 [220800/697932 (32%)]\tLoss: 3.157783\n",
      "Train Epoch: 2 [221440/697932 (32%)]\tLoss: 3.190729\n",
      "Train Epoch: 2 [222080/697932 (32%)]\tLoss: 3.162566\n",
      "Train Epoch: 2 [222720/697932 (32%)]\tLoss: 3.179799\n",
      "Train Epoch: 2 [223360/697932 (32%)]\tLoss: 3.170025\n",
      "Train Epoch: 2 [224000/697932 (32%)]\tLoss: 3.183687\n",
      "Train Epoch: 2 [224640/697932 (32%)]\tLoss: 3.159875\n",
      "Train Epoch: 2 [225280/697932 (32%)]\tLoss: 3.151111\n",
      "Train Epoch: 2 [225920/697932 (32%)]\tLoss: 3.175429\n",
      "Train Epoch: 2 [226560/697932 (32%)]\tLoss: 3.188184\n",
      "Train Epoch: 2 [227200/697932 (33%)]\tLoss: 3.154067\n",
      "Train Epoch: 2 [227840/697932 (33%)]\tLoss: 3.164350\n",
      "Train Epoch: 2 [228480/697932 (33%)]\tLoss: 3.189280\n",
      "Train Epoch: 2 [229120/697932 (33%)]\tLoss: 3.176223\n",
      "Train Epoch: 2 [229760/697932 (33%)]\tLoss: 3.183454\n",
      "Train Epoch: 2 [230400/697932 (33%)]\tLoss: 3.164770\n",
      "Train Epoch: 2 [231040/697932 (33%)]\tLoss: 3.180336\n",
      "Train Epoch: 2 [231680/697932 (33%)]\tLoss: 3.165465\n",
      "Train Epoch: 2 [232320/697932 (33%)]\tLoss: 3.143083\n",
      "Train Epoch: 2 [232960/697932 (33%)]\tLoss: 3.184759\n",
      "Train Epoch: 2 [233600/697932 (33%)]\tLoss: 3.186736\n",
      "Train Epoch: 2 [234240/697932 (34%)]\tLoss: 3.152658\n",
      "Train Epoch: 2 [234880/697932 (34%)]\tLoss: 3.164870\n",
      "Train Epoch: 2 [235520/697932 (34%)]\tLoss: 3.161453\n",
      "Train Epoch: 2 [236160/697932 (34%)]\tLoss: 3.172072\n",
      "Train Epoch: 2 [236800/697932 (34%)]\tLoss: 3.164361\n",
      "Train Epoch: 2 [237440/697932 (34%)]\tLoss: 3.164798\n",
      "Train Epoch: 2 [238080/697932 (34%)]\tLoss: 3.182678\n",
      "Train Epoch: 2 [238720/697932 (34%)]\tLoss: 3.183023\n",
      "Train Epoch: 2 [239360/697932 (34%)]\tLoss: 3.170116\n",
      "Train Epoch: 2 [240000/697932 (34%)]\tLoss: 3.193332\n",
      "Train Epoch: 2 [240640/697932 (34%)]\tLoss: 3.169610\n",
      "Train Epoch: 2 [241280/697932 (35%)]\tLoss: 3.189638\n",
      "Train Epoch: 2 [241920/697932 (35%)]\tLoss: 3.178223\n",
      "Train Epoch: 2 [242560/697932 (35%)]\tLoss: 3.179659\n",
      "Train Epoch: 2 [243200/697932 (35%)]\tLoss: 3.147166\n",
      "Train Epoch: 2 [243840/697932 (35%)]\tLoss: 3.198701\n",
      "Train Epoch: 2 [244480/697932 (35%)]\tLoss: 3.193159\n",
      "Train Epoch: 2 [245120/697932 (35%)]\tLoss: 3.171769\n",
      "Train Epoch: 2 [245760/697932 (35%)]\tLoss: 3.144721\n",
      "Train Epoch: 2 [246400/697932 (35%)]\tLoss: 3.173352\n",
      "Train Epoch: 2 [247040/697932 (35%)]\tLoss: 3.201236\n",
      "Train Epoch: 2 [247680/697932 (35%)]\tLoss: 3.178240\n",
      "Train Epoch: 2 [248320/697932 (36%)]\tLoss: 3.195142\n",
      "Train Epoch: 2 [248960/697932 (36%)]\tLoss: 3.145839\n",
      "Train Epoch: 2 [249600/697932 (36%)]\tLoss: 3.163980\n",
      "Train Epoch: 2 [250240/697932 (36%)]\tLoss: 3.170705\n",
      "Train Epoch: 2 [250880/697932 (36%)]\tLoss: 3.147873\n",
      "Train Epoch: 2 [251520/697932 (36%)]\tLoss: 3.197078\n",
      "Train Epoch: 2 [252160/697932 (36%)]\tLoss: 3.174682\n",
      "Train Epoch: 2 [252800/697932 (36%)]\tLoss: 3.162293\n",
      "Train Epoch: 2 [253440/697932 (36%)]\tLoss: 3.194022\n",
      "Train Epoch: 2 [254080/697932 (36%)]\tLoss: 3.138044\n",
      "Train Epoch: 2 [254720/697932 (36%)]\tLoss: 3.170779\n",
      "Train Epoch: 2 [255360/697932 (37%)]\tLoss: 3.193196\n",
      "Train Epoch: 2 [256000/697932 (37%)]\tLoss: 3.169588\n",
      "Train Epoch: 2 [256640/697932 (37%)]\tLoss: 3.165812\n",
      "Train Epoch: 2 [257280/697932 (37%)]\tLoss: 3.178029\n",
      "Train Epoch: 2 [257920/697932 (37%)]\tLoss: 3.197723\n",
      "Train Epoch: 2 [258560/697932 (37%)]\tLoss: 3.155533\n",
      "Train Epoch: 2 [259200/697932 (37%)]\tLoss: 3.188160\n",
      "Train Epoch: 2 [259840/697932 (37%)]\tLoss: 3.201524\n",
      "Train Epoch: 2 [260480/697932 (37%)]\tLoss: 3.216454\n",
      "Train Epoch: 2 [261120/697932 (37%)]\tLoss: 3.168744\n",
      "Train Epoch: 2 [261760/697932 (38%)]\tLoss: 3.163154\n",
      "Train Epoch: 2 [262400/697932 (38%)]\tLoss: 3.167504\n",
      "Train Epoch: 2 [263040/697932 (38%)]\tLoss: 3.175557\n",
      "Train Epoch: 2 [263680/697932 (38%)]\tLoss: 3.167294\n",
      "Train Epoch: 2 [264320/697932 (38%)]\tLoss: 3.174593\n",
      "Train Epoch: 2 [264960/697932 (38%)]\tLoss: 3.159329\n",
      "Train Epoch: 2 [265600/697932 (38%)]\tLoss: 3.151565\n",
      "Train Epoch: 2 [266240/697932 (38%)]\tLoss: 3.149898\n",
      "Train Epoch: 2 [266880/697932 (38%)]\tLoss: 3.177172\n",
      "Train Epoch: 2 [267520/697932 (38%)]\tLoss: 3.173692\n",
      "Train Epoch: 2 [268160/697932 (38%)]\tLoss: 3.156546\n",
      "Train Epoch: 2 [268800/697932 (39%)]\tLoss: 3.166787\n",
      "Train Epoch: 2 [269440/697932 (39%)]\tLoss: 3.203767\n",
      "Train Epoch: 2 [270080/697932 (39%)]\tLoss: 3.187401\n",
      "Train Epoch: 2 [270720/697932 (39%)]\tLoss: 3.150433\n",
      "Train Epoch: 2 [271360/697932 (39%)]\tLoss: 3.147353\n",
      "Train Epoch: 2 [272000/697932 (39%)]\tLoss: 3.160215\n",
      "Train Epoch: 2 [272640/697932 (39%)]\tLoss: 3.177150\n",
      "Train Epoch: 2 [273280/697932 (39%)]\tLoss: 3.210281\n",
      "Train Epoch: 2 [273920/697932 (39%)]\tLoss: 3.160174\n",
      "Train Epoch: 2 [274560/697932 (39%)]\tLoss: 3.196012\n",
      "Train Epoch: 2 [275200/697932 (39%)]\tLoss: 3.181085\n",
      "Train Epoch: 2 [275840/697932 (40%)]\tLoss: 3.178712\n",
      "Train Epoch: 2 [276480/697932 (40%)]\tLoss: 3.175221\n",
      "Train Epoch: 2 [277120/697932 (40%)]\tLoss: 3.175232\n",
      "Train Epoch: 2 [277760/697932 (40%)]\tLoss: 3.193080\n",
      "Train Epoch: 2 [278400/697932 (40%)]\tLoss: 3.126312\n",
      "Train Epoch: 2 [279040/697932 (40%)]\tLoss: 3.188761\n",
      "Train Epoch: 2 [279680/697932 (40%)]\tLoss: 3.195925\n",
      "Train Epoch: 2 [280320/697932 (40%)]\tLoss: 3.160838\n",
      "Train Epoch: 2 [280960/697932 (40%)]\tLoss: 3.167964\n",
      "Train Epoch: 2 [281600/697932 (40%)]\tLoss: 3.150535\n",
      "Train Epoch: 2 [282240/697932 (40%)]\tLoss: 3.194831\n",
      "Train Epoch: 2 [282880/697932 (41%)]\tLoss: 3.163661\n",
      "Train Epoch: 2 [283520/697932 (41%)]\tLoss: 3.161835\n",
      "Train Epoch: 2 [284160/697932 (41%)]\tLoss: 3.151563\n",
      "Train Epoch: 2 [284800/697932 (41%)]\tLoss: 3.166888\n",
      "Train Epoch: 2 [285440/697932 (41%)]\tLoss: 3.140042\n",
      "Train Epoch: 2 [286080/697932 (41%)]\tLoss: 3.154811\n",
      "Train Epoch: 2 [286720/697932 (41%)]\tLoss: 3.195178\n",
      "Train Epoch: 2 [287360/697932 (41%)]\tLoss: 3.162164\n",
      "Train Epoch: 2 [288000/697932 (41%)]\tLoss: 3.166625\n",
      "Train Epoch: 2 [288640/697932 (41%)]\tLoss: 3.205172\n",
      "Train Epoch: 2 [289280/697932 (41%)]\tLoss: 3.173234\n",
      "Train Epoch: 2 [289920/697932 (42%)]\tLoss: 3.196947\n",
      "Train Epoch: 2 [290560/697932 (42%)]\tLoss: 3.156872\n",
      "Train Epoch: 2 [291200/697932 (42%)]\tLoss: 3.162629\n",
      "Train Epoch: 2 [291840/697932 (42%)]\tLoss: 3.199370\n",
      "Train Epoch: 2 [292480/697932 (42%)]\tLoss: 3.165785\n",
      "Train Epoch: 2 [293120/697932 (42%)]\tLoss: 3.176112\n",
      "Train Epoch: 2 [293760/697932 (42%)]\tLoss: 3.168042\n",
      "Train Epoch: 2 [294400/697932 (42%)]\tLoss: 3.151858\n",
      "Train Epoch: 2 [295040/697932 (42%)]\tLoss: 3.165793\n",
      "Train Epoch: 2 [295680/697932 (42%)]\tLoss: 3.162481\n",
      "Train Epoch: 2 [296320/697932 (42%)]\tLoss: 3.155477\n",
      "Train Epoch: 2 [296960/697932 (43%)]\tLoss: 3.196685\n",
      "Train Epoch: 2 [297600/697932 (43%)]\tLoss: 3.191565\n",
      "Train Epoch: 2 [298240/697932 (43%)]\tLoss: 3.171800\n",
      "Train Epoch: 2 [298880/697932 (43%)]\tLoss: 3.172326\n",
      "Train Epoch: 2 [299520/697932 (43%)]\tLoss: 3.168290\n",
      "Train Epoch: 2 [300160/697932 (43%)]\tLoss: 3.171035\n",
      "Train Epoch: 2 [300800/697932 (43%)]\tLoss: 3.154352\n",
      "Train Epoch: 2 [301440/697932 (43%)]\tLoss: 3.144714\n",
      "Train Epoch: 2 [302080/697932 (43%)]\tLoss: 3.150403\n",
      "Train Epoch: 2 [302720/697932 (43%)]\tLoss: 3.177969\n",
      "Train Epoch: 2 [303360/697932 (43%)]\tLoss: 3.167075\n",
      "Train Epoch: 2 [304000/697932 (44%)]\tLoss: 3.180870\n",
      "Train Epoch: 2 [304640/697932 (44%)]\tLoss: 3.171273\n",
      "Train Epoch: 2 [305280/697932 (44%)]\tLoss: 3.194669\n",
      "Train Epoch: 2 [305920/697932 (44%)]\tLoss: 3.180764\n",
      "Train Epoch: 2 [306560/697932 (44%)]\tLoss: 3.156656\n",
      "Train Epoch: 2 [307200/697932 (44%)]\tLoss: 3.155470\n",
      "Train Epoch: 2 [307840/697932 (44%)]\tLoss: 3.188308\n",
      "Train Epoch: 2 [308480/697932 (44%)]\tLoss: 3.163217\n",
      "Train Epoch: 2 [309120/697932 (44%)]\tLoss: 3.199940\n",
      "Train Epoch: 2 [309760/697932 (44%)]\tLoss: 3.197325\n",
      "Train Epoch: 2 [310400/697932 (44%)]\tLoss: 3.169965\n",
      "Train Epoch: 2 [311040/697932 (45%)]\tLoss: 3.170327\n",
      "Train Epoch: 2 [311680/697932 (45%)]\tLoss: 3.181451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [312320/697932 (45%)]\tLoss: 3.157350\n",
      "Train Epoch: 2 [312960/697932 (45%)]\tLoss: 3.162228\n",
      "Train Epoch: 2 [313600/697932 (45%)]\tLoss: 3.150485\n",
      "Train Epoch: 2 [314240/697932 (45%)]\tLoss: 3.190041\n",
      "Train Epoch: 2 [314880/697932 (45%)]\tLoss: 3.170954\n",
      "Train Epoch: 2 [315520/697932 (45%)]\tLoss: 3.181173\n",
      "Train Epoch: 2 [316160/697932 (45%)]\tLoss: 3.189748\n",
      "Train Epoch: 2 [316800/697932 (45%)]\tLoss: 3.160177\n",
      "Train Epoch: 2 [317440/697932 (45%)]\tLoss: 3.190267\n",
      "Train Epoch: 2 [318080/697932 (46%)]\tLoss: 3.150235\n",
      "Train Epoch: 2 [318720/697932 (46%)]\tLoss: 3.166656\n",
      "Train Epoch: 2 [319360/697932 (46%)]\tLoss: 3.181972\n",
      "Train Epoch: 2 [320000/697932 (46%)]\tLoss: 3.176471\n",
      "Train Epoch: 2 [320640/697932 (46%)]\tLoss: 3.188976\n",
      "Train Epoch: 2 [321280/697932 (46%)]\tLoss: 3.150952\n",
      "Train Epoch: 2 [321920/697932 (46%)]\tLoss: 3.157936\n",
      "Train Epoch: 2 [322560/697932 (46%)]\tLoss: 3.161459\n",
      "Train Epoch: 2 [323200/697932 (46%)]\tLoss: 3.157900\n",
      "Train Epoch: 2 [323840/697932 (46%)]\tLoss: 3.168734\n",
      "Train Epoch: 2 [324480/697932 (46%)]\tLoss: 3.173707\n",
      "Train Epoch: 2 [325120/697932 (47%)]\tLoss: 3.176780\n",
      "Train Epoch: 2 [325760/697932 (47%)]\tLoss: 3.175385\n",
      "Train Epoch: 2 [326400/697932 (47%)]\tLoss: 3.204290\n",
      "Train Epoch: 2 [327040/697932 (47%)]\tLoss: 3.170840\n",
      "Train Epoch: 2 [327680/697932 (47%)]\tLoss: 3.191264\n",
      "Train Epoch: 2 [328320/697932 (47%)]\tLoss: 3.202309\n",
      "Train Epoch: 2 [328960/697932 (47%)]\tLoss: 3.156906\n",
      "Train Epoch: 2 [329600/697932 (47%)]\tLoss: 3.153397\n",
      "Train Epoch: 2 [330240/697932 (47%)]\tLoss: 3.215667\n",
      "Train Epoch: 2 [330880/697932 (47%)]\tLoss: 3.158086\n",
      "Train Epoch: 2 [331520/697932 (47%)]\tLoss: 3.177208\n",
      "Train Epoch: 2 [332160/697932 (48%)]\tLoss: 3.170516\n",
      "Train Epoch: 2 [332800/697932 (48%)]\tLoss: 3.172047\n",
      "Train Epoch: 2 [333440/697932 (48%)]\tLoss: 3.197492\n",
      "Train Epoch: 2 [334080/697932 (48%)]\tLoss: 3.173716\n",
      "Train Epoch: 2 [334720/697932 (48%)]\tLoss: 3.158986\n",
      "Train Epoch: 2 [335360/697932 (48%)]\tLoss: 3.160743\n",
      "Train Epoch: 2 [336000/697932 (48%)]\tLoss: 3.164479\n",
      "Train Epoch: 2 [336640/697932 (48%)]\tLoss: 3.152256\n",
      "Train Epoch: 2 [337280/697932 (48%)]\tLoss: 3.206599\n",
      "Train Epoch: 2 [337920/697932 (48%)]\tLoss: 3.162847\n",
      "Train Epoch: 2 [338560/697932 (49%)]\tLoss: 3.201904\n",
      "Train Epoch: 2 [339200/697932 (49%)]\tLoss: 3.167447\n",
      "Train Epoch: 2 [339840/697932 (49%)]\tLoss: 3.153793\n",
      "Train Epoch: 2 [340480/697932 (49%)]\tLoss: 3.170948\n",
      "Train Epoch: 2 [341120/697932 (49%)]\tLoss: 3.154990\n",
      "Train Epoch: 2 [341760/697932 (49%)]\tLoss: 3.199636\n",
      "Train Epoch: 2 [342400/697932 (49%)]\tLoss: 3.165393\n",
      "Train Epoch: 2 [343040/697932 (49%)]\tLoss: 3.175905\n",
      "Train Epoch: 2 [343680/697932 (49%)]\tLoss: 3.147871\n",
      "Train Epoch: 2 [344320/697932 (49%)]\tLoss: 3.174815\n",
      "Train Epoch: 2 [344960/697932 (49%)]\tLoss: 3.153148\n",
      "Train Epoch: 2 [345600/697932 (50%)]\tLoss: 3.201457\n",
      "Train Epoch: 2 [346240/697932 (50%)]\tLoss: 3.167262\n",
      "Train Epoch: 2 [346880/697932 (50%)]\tLoss: 3.161422\n",
      "Train Epoch: 2 [347520/697932 (50%)]\tLoss: 3.148591\n",
      "Train Epoch: 2 [348160/697932 (50%)]\tLoss: 3.175901\n",
      "Train Epoch: 2 [348800/697932 (50%)]\tLoss: 3.195992\n",
      "Train Epoch: 2 [349440/697932 (50%)]\tLoss: 3.139221\n",
      "Train Epoch: 2 [350080/697932 (50%)]\tLoss: 3.173479\n",
      "Train Epoch: 2 [350720/697932 (50%)]\tLoss: 3.159777\n",
      "Train Epoch: 2 [351360/697932 (50%)]\tLoss: 3.153636\n",
      "Train Epoch: 2 [352000/697932 (50%)]\tLoss: 3.159608\n",
      "Train Epoch: 2 [352640/697932 (51%)]\tLoss: 3.184143\n",
      "Train Epoch: 2 [353280/697932 (51%)]\tLoss: 3.140987\n",
      "Train Epoch: 2 [353920/697932 (51%)]\tLoss: 3.132339\n",
      "Train Epoch: 2 [354560/697932 (51%)]\tLoss: 3.141571\n",
      "Train Epoch: 2 [355200/697932 (51%)]\tLoss: 3.155111\n",
      "Train Epoch: 2 [355840/697932 (51%)]\tLoss: 3.159045\n",
      "Train Epoch: 2 [356480/697932 (51%)]\tLoss: 3.207314\n",
      "Train Epoch: 2 [357120/697932 (51%)]\tLoss: 3.217281\n",
      "Train Epoch: 2 [357760/697932 (51%)]\tLoss: 3.207187\n",
      "Train Epoch: 2 [358400/697932 (51%)]\tLoss: 3.182302\n",
      "Train Epoch: 2 [359040/697932 (51%)]\tLoss: 3.183260\n",
      "Train Epoch: 2 [359680/697932 (52%)]\tLoss: 3.159676\n",
      "Train Epoch: 2 [360320/697932 (52%)]\tLoss: 3.147405\n",
      "Train Epoch: 2 [360960/697932 (52%)]\tLoss: 3.175325\n",
      "Train Epoch: 2 [361600/697932 (52%)]\tLoss: 3.188317\n",
      "Train Epoch: 2 [362240/697932 (52%)]\tLoss: 3.178550\n",
      "Train Epoch: 2 [362880/697932 (52%)]\tLoss: 3.182876\n",
      "Train Epoch: 2 [363520/697932 (52%)]\tLoss: 3.167095\n",
      "Train Epoch: 2 [364160/697932 (52%)]\tLoss: 3.151822\n",
      "Train Epoch: 2 [364800/697932 (52%)]\tLoss: 3.206350\n",
      "Train Epoch: 2 [365440/697932 (52%)]\tLoss: 3.179897\n",
      "Train Epoch: 2 [366080/697932 (52%)]\tLoss: 3.191610\n",
      "Train Epoch: 2 [366720/697932 (53%)]\tLoss: 3.162594\n",
      "Train Epoch: 2 [367360/697932 (53%)]\tLoss: 3.178749\n",
      "Train Epoch: 2 [368000/697932 (53%)]\tLoss: 3.188508\n",
      "Train Epoch: 2 [368640/697932 (53%)]\tLoss: 3.179594\n",
      "Train Epoch: 2 [369280/697932 (53%)]\tLoss: 3.179575\n",
      "Train Epoch: 2 [369920/697932 (53%)]\tLoss: 3.167883\n",
      "Train Epoch: 2 [370560/697932 (53%)]\tLoss: 3.157169\n",
      "Train Epoch: 2 [371200/697932 (53%)]\tLoss: 3.170503\n",
      "Train Epoch: 2 [371840/697932 (53%)]\tLoss: 3.166298\n",
      "Train Epoch: 2 [372480/697932 (53%)]\tLoss: 3.170758\n",
      "Train Epoch: 2 [373120/697932 (53%)]\tLoss: 3.192056\n",
      "Train Epoch: 2 [373760/697932 (54%)]\tLoss: 3.191455\n",
      "Train Epoch: 2 [374400/697932 (54%)]\tLoss: 3.147635\n",
      "Train Epoch: 2 [375040/697932 (54%)]\tLoss: 3.178025\n",
      "Train Epoch: 2 [375680/697932 (54%)]\tLoss: 3.174618\n",
      "Train Epoch: 2 [376320/697932 (54%)]\tLoss: 3.166431\n",
      "Train Epoch: 2 [376960/697932 (54%)]\tLoss: 3.161391\n",
      "Train Epoch: 2 [377600/697932 (54%)]\tLoss: 3.187485\n",
      "Train Epoch: 2 [378240/697932 (54%)]\tLoss: 3.204759\n",
      "Train Epoch: 2 [378880/697932 (54%)]\tLoss: 3.176408\n",
      "Train Epoch: 2 [379520/697932 (54%)]\tLoss: 3.132344\n",
      "Train Epoch: 2 [380160/697932 (54%)]\tLoss: 3.162382\n",
      "Train Epoch: 2 [380800/697932 (55%)]\tLoss: 3.164997\n",
      "Train Epoch: 2 [381440/697932 (55%)]\tLoss: 3.174600\n",
      "Train Epoch: 2 [382080/697932 (55%)]\tLoss: 3.147526\n",
      "Train Epoch: 2 [382720/697932 (55%)]\tLoss: 3.170801\n",
      "Train Epoch: 2 [383360/697932 (55%)]\tLoss: 3.147958\n",
      "Train Epoch: 2 [384000/697932 (55%)]\tLoss: 3.137277\n",
      "Train Epoch: 2 [384640/697932 (55%)]\tLoss: 3.170902\n",
      "Train Epoch: 2 [385280/697932 (55%)]\tLoss: 3.180701\n",
      "Train Epoch: 2 [385920/697932 (55%)]\tLoss: 3.168386\n",
      "Train Epoch: 2 [386560/697932 (55%)]\tLoss: 3.155051\n",
      "Train Epoch: 2 [387200/697932 (55%)]\tLoss: 3.158817\n",
      "Train Epoch: 2 [387840/697932 (56%)]\tLoss: 3.170599\n",
      "Train Epoch: 2 [388480/697932 (56%)]\tLoss: 3.180291\n",
      "Train Epoch: 2 [389120/697932 (56%)]\tLoss: 3.217395\n",
      "Train Epoch: 2 [389760/697932 (56%)]\tLoss: 3.138197\n",
      "Train Epoch: 2 [390400/697932 (56%)]\tLoss: 3.159256\n",
      "Train Epoch: 2 [391040/697932 (56%)]\tLoss: 3.167729\n",
      "Train Epoch: 2 [391680/697932 (56%)]\tLoss: 3.156715\n",
      "Train Epoch: 2 [392320/697932 (56%)]\tLoss: 3.173977\n",
      "Train Epoch: 2 [392960/697932 (56%)]\tLoss: 3.192194\n",
      "Train Epoch: 2 [393600/697932 (56%)]\tLoss: 3.173787\n",
      "Train Epoch: 2 [394240/697932 (56%)]\tLoss: 3.192454\n",
      "Train Epoch: 2 [394880/697932 (57%)]\tLoss: 3.182439\n",
      "Train Epoch: 2 [395520/697932 (57%)]\tLoss: 3.143773\n",
      "Train Epoch: 2 [396160/697932 (57%)]\tLoss: 3.165449\n",
      "Train Epoch: 2 [396800/697932 (57%)]\tLoss: 3.190296\n",
      "Train Epoch: 2 [397440/697932 (57%)]\tLoss: 3.143064\n",
      "Train Epoch: 2 [398080/697932 (57%)]\tLoss: 3.147090\n",
      "Train Epoch: 2 [398720/697932 (57%)]\tLoss: 3.169786\n",
      "Train Epoch: 2 [399360/697932 (57%)]\tLoss: 3.138842\n",
      "Train Epoch: 2 [400000/697932 (57%)]\tLoss: 3.192865\n",
      "Train Epoch: 2 [400640/697932 (57%)]\tLoss: 3.157269\n",
      "Train Epoch: 2 [401280/697932 (57%)]\tLoss: 3.149092\n",
      "Train Epoch: 2 [401920/697932 (58%)]\tLoss: 3.204772\n",
      "Train Epoch: 2 [402560/697932 (58%)]\tLoss: 3.202470\n",
      "Train Epoch: 2 [403200/697932 (58%)]\tLoss: 3.182367\n",
      "Train Epoch: 2 [403840/697932 (58%)]\tLoss: 3.168463\n",
      "Train Epoch: 2 [404480/697932 (58%)]\tLoss: 3.173718\n",
      "Train Epoch: 2 [405120/697932 (58%)]\tLoss: 3.142915\n",
      "Train Epoch: 2 [405760/697932 (58%)]\tLoss: 3.190442\n",
      "Train Epoch: 2 [406400/697932 (58%)]\tLoss: 3.177516\n",
      "Train Epoch: 2 [407040/697932 (58%)]\tLoss: 3.166478\n",
      "Train Epoch: 2 [407680/697932 (58%)]\tLoss: 3.185987\n",
      "Train Epoch: 2 [408320/697932 (58%)]\tLoss: 3.137584\n",
      "Train Epoch: 2 [408960/697932 (59%)]\tLoss: 3.145978\n",
      "Train Epoch: 2 [409600/697932 (59%)]\tLoss: 3.162144\n",
      "Train Epoch: 2 [410240/697932 (59%)]\tLoss: 3.193606\n",
      "Train Epoch: 2 [410880/697932 (59%)]\tLoss: 3.166799\n",
      "Train Epoch: 2 [411520/697932 (59%)]\tLoss: 3.189346\n",
      "Train Epoch: 2 [412160/697932 (59%)]\tLoss: 3.147430\n",
      "Train Epoch: 2 [412800/697932 (59%)]\tLoss: 3.180443\n",
      "Train Epoch: 2 [413440/697932 (59%)]\tLoss: 3.165563\n",
      "Train Epoch: 2 [414080/697932 (59%)]\tLoss: 3.192856\n",
      "Train Epoch: 2 [414720/697932 (59%)]\tLoss: 3.169195\n",
      "Train Epoch: 2 [415360/697932 (60%)]\tLoss: 3.174484\n",
      "Train Epoch: 2 [416000/697932 (60%)]\tLoss: 3.173588\n",
      "Train Epoch: 2 [416640/697932 (60%)]\tLoss: 3.170856\n",
      "Train Epoch: 2 [417280/697932 (60%)]\tLoss: 3.169752\n",
      "Train Epoch: 2 [417920/697932 (60%)]\tLoss: 3.198220\n",
      "Train Epoch: 2 [418560/697932 (60%)]\tLoss: 3.172630\n",
      "Train Epoch: 2 [419200/697932 (60%)]\tLoss: 3.154172\n",
      "Train Epoch: 2 [419840/697932 (60%)]\tLoss: 3.180223\n",
      "Train Epoch: 2 [420480/697932 (60%)]\tLoss: 3.170177\n",
      "Train Epoch: 2 [421120/697932 (60%)]\tLoss: 3.173675\n",
      "Train Epoch: 2 [421760/697932 (60%)]\tLoss: 3.179393\n",
      "Train Epoch: 2 [422400/697932 (61%)]\tLoss: 3.162803\n",
      "Train Epoch: 2 [423040/697932 (61%)]\tLoss: 3.125101\n",
      "Train Epoch: 2 [423680/697932 (61%)]\tLoss: 3.170661\n",
      "Train Epoch: 2 [424320/697932 (61%)]\tLoss: 3.178781\n",
      "Train Epoch: 2 [424960/697932 (61%)]\tLoss: 3.166734\n",
      "Train Epoch: 2 [425600/697932 (61%)]\tLoss: 3.185054\n",
      "Train Epoch: 2 [426240/697932 (61%)]\tLoss: 3.167515\n",
      "Train Epoch: 2 [426880/697932 (61%)]\tLoss: 3.174109\n",
      "Train Epoch: 2 [427520/697932 (61%)]\tLoss: 3.195520\n",
      "Train Epoch: 2 [428160/697932 (61%)]\tLoss: 3.173599\n",
      "Train Epoch: 2 [428800/697932 (61%)]\tLoss: 3.178845\n",
      "Train Epoch: 2 [429440/697932 (62%)]\tLoss: 3.179107\n",
      "Train Epoch: 2 [430080/697932 (62%)]\tLoss: 3.189853\n",
      "Train Epoch: 2 [430720/697932 (62%)]\tLoss: 3.188256\n",
      "Train Epoch: 2 [431360/697932 (62%)]\tLoss: 3.189917\n",
      "Train Epoch: 2 [432000/697932 (62%)]\tLoss: 3.184542\n",
      "Train Epoch: 2 [432640/697932 (62%)]\tLoss: 3.152719\n",
      "Train Epoch: 2 [433280/697932 (62%)]\tLoss: 3.151379\n",
      "Train Epoch: 2 [433920/697932 (62%)]\tLoss: 3.162509\n",
      "Train Epoch: 2 [434560/697932 (62%)]\tLoss: 3.185739\n",
      "Train Epoch: 2 [435200/697932 (62%)]\tLoss: 3.157022\n",
      "Train Epoch: 2 [435840/697932 (62%)]\tLoss: 3.170276\n",
      "Train Epoch: 2 [436480/697932 (63%)]\tLoss: 3.143188\n",
      "Train Epoch: 2 [437120/697932 (63%)]\tLoss: 3.150199\n",
      "Train Epoch: 2 [437760/697932 (63%)]\tLoss: 3.181677\n",
      "Train Epoch: 2 [438400/697932 (63%)]\tLoss: 3.188985\n",
      "Train Epoch: 2 [439040/697932 (63%)]\tLoss: 3.183602\n",
      "Train Epoch: 2 [439680/697932 (63%)]\tLoss: 3.173531\n",
      "Train Epoch: 2 [440320/697932 (63%)]\tLoss: 3.156370\n",
      "Train Epoch: 2 [440960/697932 (63%)]\tLoss: 3.172673\n",
      "Train Epoch: 2 [441600/697932 (63%)]\tLoss: 3.156514\n",
      "Train Epoch: 2 [442240/697932 (63%)]\tLoss: 3.167223\n",
      "Train Epoch: 2 [442880/697932 (63%)]\tLoss: 3.199959\n",
      "Train Epoch: 2 [443520/697932 (64%)]\tLoss: 3.185757\n",
      "Train Epoch: 2 [444160/697932 (64%)]\tLoss: 3.174120\n",
      "Train Epoch: 2 [444800/697932 (64%)]\tLoss: 3.168684\n",
      "Train Epoch: 2 [445440/697932 (64%)]\tLoss: 3.191202\n",
      "Train Epoch: 2 [446080/697932 (64%)]\tLoss: 3.192226\n",
      "Train Epoch: 2 [446720/697932 (64%)]\tLoss: 3.174238\n",
      "Train Epoch: 2 [447360/697932 (64%)]\tLoss: 3.120492\n",
      "Train Epoch: 2 [448000/697932 (64%)]\tLoss: 3.168298\n",
      "Train Epoch: 2 [448640/697932 (64%)]\tLoss: 3.176871\n",
      "Train Epoch: 2 [449280/697932 (64%)]\tLoss: 3.179746\n",
      "Train Epoch: 2 [449920/697932 (64%)]\tLoss: 3.191853\n",
      "Train Epoch: 2 [450560/697932 (65%)]\tLoss: 3.156649\n",
      "Train Epoch: 2 [451200/697932 (65%)]\tLoss: 3.179785\n",
      "Train Epoch: 2 [451840/697932 (65%)]\tLoss: 3.173052\n",
      "Train Epoch: 2 [452480/697932 (65%)]\tLoss: 3.170165\n",
      "Train Epoch: 2 [453120/697932 (65%)]\tLoss: 3.147380\n",
      "Train Epoch: 2 [453760/697932 (65%)]\tLoss: 3.197620\n",
      "Train Epoch: 2 [454400/697932 (65%)]\tLoss: 3.188207\n",
      "Train Epoch: 2 [455040/697932 (65%)]\tLoss: 3.160378\n",
      "Train Epoch: 2 [455680/697932 (65%)]\tLoss: 3.153525\n",
      "Train Epoch: 2 [456320/697932 (65%)]\tLoss: 3.206934\n",
      "Train Epoch: 2 [456960/697932 (65%)]\tLoss: 3.180231\n",
      "Train Epoch: 2 [457600/697932 (66%)]\tLoss: 3.180440\n",
      "Train Epoch: 2 [458240/697932 (66%)]\tLoss: 3.177628\n",
      "Train Epoch: 2 [458880/697932 (66%)]\tLoss: 3.159920\n",
      "Train Epoch: 2 [459520/697932 (66%)]\tLoss: 3.179477\n",
      "Train Epoch: 2 [460160/697932 (66%)]\tLoss: 3.191632\n",
      "Train Epoch: 2 [460800/697932 (66%)]\tLoss: 3.162523\n",
      "Train Epoch: 2 [461440/697932 (66%)]\tLoss: 3.139449\n",
      "Train Epoch: 2 [462080/697932 (66%)]\tLoss: 3.177740\n",
      "Train Epoch: 2 [462720/697932 (66%)]\tLoss: 3.180252\n",
      "Train Epoch: 2 [463360/697932 (66%)]\tLoss: 3.161629\n",
      "Train Epoch: 2 [464000/697932 (66%)]\tLoss: 3.146346\n",
      "Train Epoch: 2 [464640/697932 (67%)]\tLoss: 3.164356\n",
      "Train Epoch: 2 [465280/697932 (67%)]\tLoss: 3.185766\n",
      "Train Epoch: 2 [465920/697932 (67%)]\tLoss: 3.158047\n",
      "Train Epoch: 2 [466560/697932 (67%)]\tLoss: 3.143689\n",
      "Train Epoch: 2 [467200/697932 (67%)]\tLoss: 3.193359\n",
      "Train Epoch: 2 [467840/697932 (67%)]\tLoss: 3.157760\n",
      "Train Epoch: 2 [468480/697932 (67%)]\tLoss: 3.162095\n",
      "Train Epoch: 2 [469120/697932 (67%)]\tLoss: 3.166912\n",
      "Train Epoch: 2 [469760/697932 (67%)]\tLoss: 3.192903\n",
      "Train Epoch: 2 [470400/697932 (67%)]\tLoss: 3.201720\n",
      "Train Epoch: 2 [471040/697932 (67%)]\tLoss: 3.194458\n",
      "Train Epoch: 2 [471680/697932 (68%)]\tLoss: 3.167463\n",
      "Train Epoch: 2 [472320/697932 (68%)]\tLoss: 3.191668\n",
      "Train Epoch: 2 [472960/697932 (68%)]\tLoss: 3.170542\n",
      "Train Epoch: 2 [473600/697932 (68%)]\tLoss: 3.188877\n",
      "Train Epoch: 2 [474240/697932 (68%)]\tLoss: 3.166280\n",
      "Train Epoch: 2 [474880/697932 (68%)]\tLoss: 3.155893\n",
      "Train Epoch: 2 [475520/697932 (68%)]\tLoss: 3.187534\n",
      "Train Epoch: 2 [476160/697932 (68%)]\tLoss: 3.163717\n",
      "Train Epoch: 2 [476800/697932 (68%)]\tLoss: 3.177958\n",
      "Train Epoch: 2 [477440/697932 (68%)]\tLoss: 3.204137\n",
      "Train Epoch: 2 [478080/697932 (68%)]\tLoss: 3.175931\n",
      "Train Epoch: 2 [478720/697932 (69%)]\tLoss: 3.167651\n",
      "Train Epoch: 2 [479360/697932 (69%)]\tLoss: 3.172322\n",
      "Train Epoch: 2 [480000/697932 (69%)]\tLoss: 3.155783\n",
      "Train Epoch: 2 [480640/697932 (69%)]\tLoss: 3.165323\n",
      "Train Epoch: 2 [481280/697932 (69%)]\tLoss: 3.150895\n",
      "Train Epoch: 2 [481920/697932 (69%)]\tLoss: 3.156908\n",
      "Train Epoch: 2 [482560/697932 (69%)]\tLoss: 3.204867\n",
      "Train Epoch: 2 [483200/697932 (69%)]\tLoss: 3.172753\n",
      "Train Epoch: 2 [483840/697932 (69%)]\tLoss: 3.154647\n",
      "Train Epoch: 2 [484480/697932 (69%)]\tLoss: 3.158956\n",
      "Train Epoch: 2 [485120/697932 (70%)]\tLoss: 3.187867\n",
      "Train Epoch: 2 [485760/697932 (70%)]\tLoss: 3.162867\n",
      "Train Epoch: 2 [486400/697932 (70%)]\tLoss: 3.168031\n",
      "Train Epoch: 2 [487040/697932 (70%)]\tLoss: 3.161609\n",
      "Train Epoch: 2 [487680/697932 (70%)]\tLoss: 3.161777\n",
      "Train Epoch: 2 [488320/697932 (70%)]\tLoss: 3.149730\n",
      "Train Epoch: 2 [488960/697932 (70%)]\tLoss: 3.184931\n",
      "Train Epoch: 2 [489600/697932 (70%)]\tLoss: 3.152399\n",
      "Train Epoch: 2 [490240/697932 (70%)]\tLoss: 3.181507\n",
      "Train Epoch: 2 [490880/697932 (70%)]\tLoss: 3.155769\n",
      "Train Epoch: 2 [491520/697932 (70%)]\tLoss: 3.156685\n",
      "Train Epoch: 2 [492160/697932 (71%)]\tLoss: 3.144461\n",
      "Train Epoch: 2 [492800/697932 (71%)]\tLoss: 3.162514\n",
      "Train Epoch: 2 [493440/697932 (71%)]\tLoss: 3.181957\n",
      "Train Epoch: 2 [494080/697932 (71%)]\tLoss: 3.175016\n",
      "Train Epoch: 2 [494720/697932 (71%)]\tLoss: 3.182168\n",
      "Train Epoch: 2 [495360/697932 (71%)]\tLoss: 3.177840\n",
      "Train Epoch: 2 [496000/697932 (71%)]\tLoss: 3.176012\n",
      "Train Epoch: 2 [496640/697932 (71%)]\tLoss: 3.188049\n",
      "Train Epoch: 2 [497280/697932 (71%)]\tLoss: 3.142971\n",
      "Train Epoch: 2 [497920/697932 (71%)]\tLoss: 3.190305\n",
      "Train Epoch: 2 [498560/697932 (71%)]\tLoss: 3.193201\n",
      "Train Epoch: 2 [499200/697932 (72%)]\tLoss: 3.186447\n",
      "Train Epoch: 2 [499840/697932 (72%)]\tLoss: 3.199847\n",
      "Train Epoch: 2 [500480/697932 (72%)]\tLoss: 3.188340\n",
      "Train Epoch: 2 [501120/697932 (72%)]\tLoss: 3.145090\n",
      "Train Epoch: 2 [501760/697932 (72%)]\tLoss: 3.171824\n",
      "Train Epoch: 2 [502400/697932 (72%)]\tLoss: 3.159894\n",
      "Train Epoch: 2 [503040/697932 (72%)]\tLoss: 3.181847\n",
      "Train Epoch: 2 [503680/697932 (72%)]\tLoss: 3.149672\n",
      "Train Epoch: 2 [504320/697932 (72%)]\tLoss: 3.185456\n",
      "Train Epoch: 2 [504960/697932 (72%)]\tLoss: 3.191921\n",
      "Train Epoch: 2 [505600/697932 (72%)]\tLoss: 3.153759\n",
      "Train Epoch: 2 [506240/697932 (73%)]\tLoss: 3.175976\n",
      "Train Epoch: 2 [506880/697932 (73%)]\tLoss: 3.132145\n",
      "Train Epoch: 2 [507520/697932 (73%)]\tLoss: 3.164579\n",
      "Train Epoch: 2 [508160/697932 (73%)]\tLoss: 3.160082\n",
      "Train Epoch: 2 [508800/697932 (73%)]\tLoss: 3.173408\n",
      "Train Epoch: 2 [509440/697932 (73%)]\tLoss: 3.164101\n",
      "Train Epoch: 2 [510080/697932 (73%)]\tLoss: 3.187829\n",
      "Train Epoch: 2 [510720/697932 (73%)]\tLoss: 3.180473\n",
      "Train Epoch: 2 [511360/697932 (73%)]\tLoss: 3.163501\n",
      "Train Epoch: 2 [512000/697932 (73%)]\tLoss: 3.146647\n",
      "Train Epoch: 2 [512640/697932 (73%)]\tLoss: 3.221843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [513280/697932 (74%)]\tLoss: 3.155460\n",
      "Train Epoch: 2 [513920/697932 (74%)]\tLoss: 3.165991\n",
      "Train Epoch: 2 [514560/697932 (74%)]\tLoss: 3.168532\n",
      "Train Epoch: 2 [515200/697932 (74%)]\tLoss: 3.176906\n",
      "Train Epoch: 2 [515840/697932 (74%)]\tLoss: 3.140669\n",
      "Train Epoch: 2 [516480/697932 (74%)]\tLoss: 3.183961\n",
      "Train Epoch: 2 [517120/697932 (74%)]\tLoss: 3.169542\n",
      "Train Epoch: 2 [517760/697932 (74%)]\tLoss: 3.191928\n",
      "Train Epoch: 2 [518400/697932 (74%)]\tLoss: 3.171710\n",
      "Train Epoch: 2 [519040/697932 (74%)]\tLoss: 3.169624\n",
      "Train Epoch: 2 [519680/697932 (74%)]\tLoss: 3.171837\n",
      "Train Epoch: 2 [520320/697932 (75%)]\tLoss: 3.160015\n",
      "Train Epoch: 2 [520960/697932 (75%)]\tLoss: 3.184085\n",
      "Train Epoch: 2 [521600/697932 (75%)]\tLoss: 3.200703\n",
      "Train Epoch: 2 [522240/697932 (75%)]\tLoss: 3.171869\n",
      "Train Epoch: 2 [522880/697932 (75%)]\tLoss: 3.194216\n",
      "Train Epoch: 2 [523520/697932 (75%)]\tLoss: 3.197062\n",
      "Train Epoch: 2 [524160/697932 (75%)]\tLoss: 3.156112\n",
      "Train Epoch: 2 [524800/697932 (75%)]\tLoss: 3.176495\n",
      "Train Epoch: 2 [525440/697932 (75%)]\tLoss: 3.176705\n",
      "Train Epoch: 2 [526080/697932 (75%)]\tLoss: 3.143812\n",
      "Train Epoch: 2 [526720/697932 (75%)]\tLoss: 3.156171\n",
      "Train Epoch: 2 [527360/697932 (76%)]\tLoss: 3.145646\n",
      "Train Epoch: 2 [528000/697932 (76%)]\tLoss: 3.151241\n",
      "Train Epoch: 2 [528640/697932 (76%)]\tLoss: 3.191787\n",
      "Train Epoch: 2 [529280/697932 (76%)]\tLoss: 3.178795\n",
      "Train Epoch: 2 [529920/697932 (76%)]\tLoss: 3.207700\n",
      "Train Epoch: 2 [530560/697932 (76%)]\tLoss: 3.164558\n",
      "Train Epoch: 2 [531200/697932 (76%)]\tLoss: 3.182757\n",
      "Train Epoch: 2 [531840/697932 (76%)]\tLoss: 3.184376\n",
      "Train Epoch: 2 [532480/697932 (76%)]\tLoss: 3.157958\n",
      "Train Epoch: 2 [533120/697932 (76%)]\tLoss: 3.143801\n",
      "Train Epoch: 2 [533760/697932 (76%)]\tLoss: 3.166351\n",
      "Train Epoch: 2 [534400/697932 (77%)]\tLoss: 3.171274\n",
      "Train Epoch: 2 [535040/697932 (77%)]\tLoss: 3.198642\n",
      "Train Epoch: 2 [535680/697932 (77%)]\tLoss: 3.133106\n",
      "Train Epoch: 2 [536320/697932 (77%)]\tLoss: 3.215956\n",
      "Train Epoch: 2 [536960/697932 (77%)]\tLoss: 3.159396\n",
      "Train Epoch: 2 [537600/697932 (77%)]\tLoss: 3.191549\n",
      "Train Epoch: 2 [538240/697932 (77%)]\tLoss: 3.173148\n",
      "Train Epoch: 2 [538880/697932 (77%)]\tLoss: 3.158685\n",
      "Train Epoch: 2 [539520/697932 (77%)]\tLoss: 3.167793\n",
      "Train Epoch: 2 [540160/697932 (77%)]\tLoss: 3.188206\n",
      "Train Epoch: 2 [540800/697932 (77%)]\tLoss: 3.189251\n",
      "Train Epoch: 2 [541440/697932 (78%)]\tLoss: 3.207565\n",
      "Train Epoch: 2 [542080/697932 (78%)]\tLoss: 3.145813\n",
      "Train Epoch: 2 [542720/697932 (78%)]\tLoss: 3.194630\n",
      "Train Epoch: 2 [543360/697932 (78%)]\tLoss: 3.188971\n",
      "Train Epoch: 2 [544000/697932 (78%)]\tLoss: 3.143431\n",
      "Train Epoch: 2 [544640/697932 (78%)]\tLoss: 3.194133\n",
      "Train Epoch: 2 [545280/697932 (78%)]\tLoss: 3.175860\n",
      "Train Epoch: 2 [545920/697932 (78%)]\tLoss: 3.199057\n",
      "Train Epoch: 2 [546560/697932 (78%)]\tLoss: 3.191059\n",
      "Train Epoch: 2 [547200/697932 (78%)]\tLoss: 3.196376\n",
      "Train Epoch: 2 [547840/697932 (78%)]\tLoss: 3.173387\n",
      "Train Epoch: 2 [548480/697932 (79%)]\tLoss: 3.199172\n",
      "Train Epoch: 2 [549120/697932 (79%)]\tLoss: 3.180591\n",
      "Train Epoch: 2 [549760/697932 (79%)]\tLoss: 3.189403\n",
      "Train Epoch: 2 [550400/697932 (79%)]\tLoss: 3.191908\n",
      "Train Epoch: 2 [551040/697932 (79%)]\tLoss: 3.167706\n",
      "Train Epoch: 2 [551680/697932 (79%)]\tLoss: 3.192063\n",
      "Train Epoch: 2 [552320/697932 (79%)]\tLoss: 3.150706\n",
      "Train Epoch: 2 [552960/697932 (79%)]\tLoss: 3.165583\n",
      "Train Epoch: 2 [553600/697932 (79%)]\tLoss: 3.190844\n",
      "Train Epoch: 2 [554240/697932 (79%)]\tLoss: 3.189902\n",
      "Train Epoch: 2 [554880/697932 (79%)]\tLoss: 3.162758\n",
      "Train Epoch: 2 [555520/697932 (80%)]\tLoss: 3.157360\n",
      "Train Epoch: 2 [556160/697932 (80%)]\tLoss: 3.203326\n",
      "Train Epoch: 2 [556800/697932 (80%)]\tLoss: 3.164609\n",
      "Train Epoch: 2 [557440/697932 (80%)]\tLoss: 3.170884\n",
      "Train Epoch: 2 [558080/697932 (80%)]\tLoss: 3.170987\n",
      "Train Epoch: 2 [558720/697932 (80%)]\tLoss: 3.159670\n",
      "Train Epoch: 2 [559360/697932 (80%)]\tLoss: 3.156621\n",
      "Train Epoch: 2 [560000/697932 (80%)]\tLoss: 3.198164\n",
      "Train Epoch: 2 [560640/697932 (80%)]\tLoss: 3.148094\n",
      "Train Epoch: 2 [561280/697932 (80%)]\tLoss: 3.160698\n",
      "Train Epoch: 2 [561920/697932 (81%)]\tLoss: 3.166278\n",
      "Train Epoch: 2 [562560/697932 (81%)]\tLoss: 3.188175\n",
      "Train Epoch: 2 [563200/697932 (81%)]\tLoss: 3.176736\n",
      "Train Epoch: 2 [563840/697932 (81%)]\tLoss: 3.167445\n",
      "Train Epoch: 2 [564480/697932 (81%)]\tLoss: 3.188980\n",
      "Train Epoch: 2 [565120/697932 (81%)]\tLoss: 3.173563\n",
      "Train Epoch: 2 [565760/697932 (81%)]\tLoss: 3.150995\n",
      "Train Epoch: 2 [566400/697932 (81%)]\tLoss: 3.179980\n",
      "Train Epoch: 2 [567040/697932 (81%)]\tLoss: 3.157996\n",
      "Train Epoch: 2 [567680/697932 (81%)]\tLoss: 3.189966\n",
      "Train Epoch: 2 [568320/697932 (81%)]\tLoss: 3.182075\n",
      "Train Epoch: 2 [568960/697932 (82%)]\tLoss: 3.198392\n",
      "Train Epoch: 2 [569600/697932 (82%)]\tLoss: 3.168989\n",
      "Train Epoch: 2 [570240/697932 (82%)]\tLoss: 3.175262\n",
      "Train Epoch: 2 [570880/697932 (82%)]\tLoss: 3.187709\n",
      "Train Epoch: 2 [571520/697932 (82%)]\tLoss: 3.172931\n",
      "Train Epoch: 2 [572160/697932 (82%)]\tLoss: 3.192475\n",
      "Train Epoch: 2 [572800/697932 (82%)]\tLoss: 3.171115\n",
      "Train Epoch: 2 [573440/697932 (82%)]\tLoss: 3.176967\n",
      "Train Epoch: 2 [574080/697932 (82%)]\tLoss: 3.148695\n",
      "Train Epoch: 2 [574720/697932 (82%)]\tLoss: 3.161381\n",
      "Train Epoch: 2 [575360/697932 (82%)]\tLoss: 3.146335\n",
      "Train Epoch: 2 [576000/697932 (83%)]\tLoss: 3.190429\n",
      "Train Epoch: 2 [576640/697932 (83%)]\tLoss: 3.158761\n",
      "Train Epoch: 2 [577280/697932 (83%)]\tLoss: 3.199554\n",
      "Train Epoch: 2 [577920/697932 (83%)]\tLoss: 3.189788\n",
      "Train Epoch: 2 [578560/697932 (83%)]\tLoss: 3.145281\n",
      "Train Epoch: 2 [579200/697932 (83%)]\tLoss: 3.185797\n",
      "Train Epoch: 2 [579840/697932 (83%)]\tLoss: 3.162766\n",
      "Train Epoch: 2 [580480/697932 (83%)]\tLoss: 3.182346\n",
      "Train Epoch: 2 [581120/697932 (83%)]\tLoss: 3.157575\n",
      "Train Epoch: 2 [581760/697932 (83%)]\tLoss: 3.166361\n",
      "Train Epoch: 2 [582400/697932 (83%)]\tLoss: 3.191949\n",
      "Train Epoch: 2 [583040/697932 (84%)]\tLoss: 3.200660\n",
      "Train Epoch: 2 [583680/697932 (84%)]\tLoss: 3.163095\n",
      "Train Epoch: 2 [584320/697932 (84%)]\tLoss: 3.128927\n",
      "Train Epoch: 2 [584960/697932 (84%)]\tLoss: 3.192727\n",
      "Train Epoch: 2 [585600/697932 (84%)]\tLoss: 3.151239\n",
      "Train Epoch: 2 [586240/697932 (84%)]\tLoss: 3.168554\n",
      "Train Epoch: 2 [586880/697932 (84%)]\tLoss: 3.158883\n",
      "Train Epoch: 2 [587520/697932 (84%)]\tLoss: 3.159546\n",
      "Train Epoch: 2 [588160/697932 (84%)]\tLoss: 3.194353\n",
      "Train Epoch: 2 [588800/697932 (84%)]\tLoss: 3.179213\n",
      "Train Epoch: 2 [589440/697932 (84%)]\tLoss: 3.160786\n",
      "Train Epoch: 2 [590080/697932 (85%)]\tLoss: 3.161294\n",
      "Train Epoch: 2 [590720/697932 (85%)]\tLoss: 3.163049\n",
      "Train Epoch: 2 [591360/697932 (85%)]\tLoss: 3.141027\n",
      "Train Epoch: 2 [592000/697932 (85%)]\tLoss: 3.185002\n",
      "Train Epoch: 2 [592640/697932 (85%)]\tLoss: 3.185400\n",
      "Train Epoch: 2 [593280/697932 (85%)]\tLoss: 3.205967\n",
      "Train Epoch: 2 [593920/697932 (85%)]\tLoss: 3.206975\n",
      "Train Epoch: 2 [594560/697932 (85%)]\tLoss: 3.162999\n",
      "Train Epoch: 2 [595200/697932 (85%)]\tLoss: 3.175037\n",
      "Train Epoch: 2 [595840/697932 (85%)]\tLoss: 3.146222\n",
      "Train Epoch: 2 [596480/697932 (85%)]\tLoss: 3.169540\n",
      "Train Epoch: 2 [597120/697932 (86%)]\tLoss: 3.184570\n",
      "Train Epoch: 2 [597760/697932 (86%)]\tLoss: 3.155869\n",
      "Train Epoch: 2 [598400/697932 (86%)]\tLoss: 3.191530\n",
      "Train Epoch: 2 [599040/697932 (86%)]\tLoss: 3.145313\n",
      "Train Epoch: 2 [599680/697932 (86%)]\tLoss: 3.166114\n",
      "Train Epoch: 2 [600320/697932 (86%)]\tLoss: 3.150958\n",
      "Train Epoch: 2 [600960/697932 (86%)]\tLoss: 3.169262\n",
      "Train Epoch: 2 [601600/697932 (86%)]\tLoss: 3.170690\n",
      "Train Epoch: 2 [602240/697932 (86%)]\tLoss: 3.156876\n",
      "Train Epoch: 2 [602880/697932 (86%)]\tLoss: 3.157954\n",
      "Train Epoch: 2 [603520/697932 (86%)]\tLoss: 3.189003\n",
      "Train Epoch: 2 [604160/697932 (87%)]\tLoss: 3.161328\n",
      "Train Epoch: 2 [604800/697932 (87%)]\tLoss: 3.184579\n",
      "Train Epoch: 2 [605440/697932 (87%)]\tLoss: 3.166320\n",
      "Train Epoch: 2 [606080/697932 (87%)]\tLoss: 3.165809\n",
      "Train Epoch: 2 [606720/697932 (87%)]\tLoss: 3.153749\n",
      "Train Epoch: 2 [607360/697932 (87%)]\tLoss: 3.216692\n",
      "Train Epoch: 2 [608000/697932 (87%)]\tLoss: 3.203867\n",
      "Train Epoch: 2 [608640/697932 (87%)]\tLoss: 3.176281\n",
      "Train Epoch: 2 [609280/697932 (87%)]\tLoss: 3.187948\n",
      "Train Epoch: 2 [609920/697932 (87%)]\tLoss: 3.165833\n",
      "Train Epoch: 2 [610560/697932 (87%)]\tLoss: 3.163033\n",
      "Train Epoch: 2 [611200/697932 (88%)]\tLoss: 3.188707\n",
      "Train Epoch: 2 [611840/697932 (88%)]\tLoss: 3.197782\n",
      "Train Epoch: 2 [612480/697932 (88%)]\tLoss: 3.176107\n",
      "Train Epoch: 2 [613120/697932 (88%)]\tLoss: 3.157334\n",
      "Train Epoch: 2 [613760/697932 (88%)]\tLoss: 3.177763\n",
      "Train Epoch: 2 [614400/697932 (88%)]\tLoss: 3.208785\n",
      "Train Epoch: 2 [615040/697932 (88%)]\tLoss: 3.135840\n",
      "Train Epoch: 2 [615680/697932 (88%)]\tLoss: 3.185084\n",
      "Train Epoch: 2 [616320/697932 (88%)]\tLoss: 3.155268\n",
      "Train Epoch: 2 [616960/697932 (88%)]\tLoss: 3.189888\n",
      "Train Epoch: 2 [617600/697932 (88%)]\tLoss: 3.174119\n",
      "Train Epoch: 2 [618240/697932 (89%)]\tLoss: 3.163632\n",
      "Train Epoch: 2 [618880/697932 (89%)]\tLoss: 3.166803\n",
      "Train Epoch: 2 [619520/697932 (89%)]\tLoss: 3.152747\n",
      "Train Epoch: 2 [620160/697932 (89%)]\tLoss: 3.164871\n",
      "Train Epoch: 2 [620800/697932 (89%)]\tLoss: 3.199928\n",
      "Train Epoch: 2 [621440/697932 (89%)]\tLoss: 3.155444\n",
      "Train Epoch: 2 [622080/697932 (89%)]\tLoss: 3.174364\n",
      "Train Epoch: 2 [622720/697932 (89%)]\tLoss: 3.172386\n",
      "Train Epoch: 2 [623360/697932 (89%)]\tLoss: 3.176862\n",
      "Train Epoch: 2 [624000/697932 (89%)]\tLoss: 3.146325\n",
      "Train Epoch: 2 [624640/697932 (89%)]\tLoss: 3.171765\n",
      "Train Epoch: 2 [625280/697932 (90%)]\tLoss: 3.192688\n",
      "Train Epoch: 2 [625920/697932 (90%)]\tLoss: 3.192915\n",
      "Train Epoch: 2 [626560/697932 (90%)]\tLoss: 3.176718\n",
      "Train Epoch: 2 [627200/697932 (90%)]\tLoss: 3.168367\n",
      "Train Epoch: 2 [627840/697932 (90%)]\tLoss: 3.187947\n",
      "Train Epoch: 2 [628480/697932 (90%)]\tLoss: 3.187803\n",
      "Train Epoch: 2 [629120/697932 (90%)]\tLoss: 3.167182\n",
      "Train Epoch: 2 [629760/697932 (90%)]\tLoss: 3.175270\n",
      "Train Epoch: 2 [630400/697932 (90%)]\tLoss: 3.188128\n",
      "Train Epoch: 2 [631040/697932 (90%)]\tLoss: 3.179108\n",
      "Train Epoch: 2 [631680/697932 (91%)]\tLoss: 3.196573\n",
      "Train Epoch: 2 [632320/697932 (91%)]\tLoss: 3.170331\n",
      "Train Epoch: 2 [632960/697932 (91%)]\tLoss: 3.150280\n",
      "Train Epoch: 2 [633600/697932 (91%)]\tLoss: 3.146708\n",
      "Train Epoch: 2 [634240/697932 (91%)]\tLoss: 3.167068\n",
      "Train Epoch: 2 [634880/697932 (91%)]\tLoss: 3.180630\n",
      "Train Epoch: 2 [635520/697932 (91%)]\tLoss: 3.152037\n",
      "Train Epoch: 2 [636160/697932 (91%)]\tLoss: 3.175711\n",
      "Train Epoch: 2 [636800/697932 (91%)]\tLoss: 3.176261\n",
      "Train Epoch: 2 [637440/697932 (91%)]\tLoss: 3.195863\n",
      "Train Epoch: 2 [638080/697932 (91%)]\tLoss: 3.133584\n",
      "Train Epoch: 2 [638720/697932 (92%)]\tLoss: 3.202692\n",
      "Train Epoch: 2 [639360/697932 (92%)]\tLoss: 3.174085\n",
      "Train Epoch: 2 [640000/697932 (92%)]\tLoss: 3.185235\n",
      "Train Epoch: 2 [640640/697932 (92%)]\tLoss: 3.150358\n",
      "Train Epoch: 2 [641280/697932 (92%)]\tLoss: 3.167598\n",
      "Train Epoch: 2 [641920/697932 (92%)]\tLoss: 3.172580\n",
      "Train Epoch: 2 [642560/697932 (92%)]\tLoss: 3.195886\n",
      "Train Epoch: 2 [643200/697932 (92%)]\tLoss: 3.129205\n",
      "Train Epoch: 2 [643840/697932 (92%)]\tLoss: 3.142675\n",
      "Train Epoch: 2 [644480/697932 (92%)]\tLoss: 3.190016\n",
      "Train Epoch: 2 [645120/697932 (92%)]\tLoss: 3.163023\n",
      "Train Epoch: 2 [645760/697932 (93%)]\tLoss: 3.203722\n",
      "Train Epoch: 2 [646400/697932 (93%)]\tLoss: 3.189237\n",
      "Train Epoch: 2 [647040/697932 (93%)]\tLoss: 3.175402\n",
      "Train Epoch: 2 [647680/697932 (93%)]\tLoss: 3.162774\n",
      "Train Epoch: 2 [648320/697932 (93%)]\tLoss: 3.190520\n",
      "Train Epoch: 2 [648960/697932 (93%)]\tLoss: 3.160146\n",
      "Train Epoch: 2 [649600/697932 (93%)]\tLoss: 3.154672\n",
      "Train Epoch: 2 [650240/697932 (93%)]\tLoss: 3.177583\n",
      "Train Epoch: 2 [650880/697932 (93%)]\tLoss: 3.173090\n",
      "Train Epoch: 2 [651520/697932 (93%)]\tLoss: 3.180418\n",
      "Train Epoch: 2 [652160/697932 (93%)]\tLoss: 3.164577\n",
      "Train Epoch: 2 [652800/697932 (94%)]\tLoss: 3.160265\n",
      "Train Epoch: 2 [653440/697932 (94%)]\tLoss: 3.173862\n",
      "Train Epoch: 2 [654080/697932 (94%)]\tLoss: 3.202687\n",
      "Train Epoch: 2 [654720/697932 (94%)]\tLoss: 3.172513\n",
      "Train Epoch: 2 [655360/697932 (94%)]\tLoss: 3.150021\n",
      "Train Epoch: 2 [656000/697932 (94%)]\tLoss: 3.181548\n",
      "Train Epoch: 2 [656640/697932 (94%)]\tLoss: 3.164281\n",
      "Train Epoch: 2 [657280/697932 (94%)]\tLoss: 3.163497\n",
      "Train Epoch: 2 [657920/697932 (94%)]\tLoss: 3.155717\n",
      "Train Epoch: 2 [658560/697932 (94%)]\tLoss: 3.190262\n",
      "Train Epoch: 2 [659200/697932 (94%)]\tLoss: 3.174248\n",
      "Train Epoch: 2 [659840/697932 (95%)]\tLoss: 3.184696\n",
      "Train Epoch: 2 [660480/697932 (95%)]\tLoss: 3.163755\n",
      "Train Epoch: 2 [661120/697932 (95%)]\tLoss: 3.199878\n",
      "Train Epoch: 2 [661760/697932 (95%)]\tLoss: 3.162362\n",
      "Train Epoch: 2 [662400/697932 (95%)]\tLoss: 3.163894\n",
      "Train Epoch: 2 [663040/697932 (95%)]\tLoss: 3.185381\n",
      "Train Epoch: 2 [663680/697932 (95%)]\tLoss: 3.160631\n",
      "Train Epoch: 2 [664320/697932 (95%)]\tLoss: 3.162807\n",
      "Train Epoch: 2 [664960/697932 (95%)]\tLoss: 3.160588\n",
      "Train Epoch: 2 [665600/697932 (95%)]\tLoss: 3.135623\n",
      "Train Epoch: 2 [666240/697932 (95%)]\tLoss: 3.167212\n",
      "Train Epoch: 2 [666880/697932 (96%)]\tLoss: 3.141603\n",
      "Train Epoch: 2 [667520/697932 (96%)]\tLoss: 3.184174\n",
      "Train Epoch: 2 [668160/697932 (96%)]\tLoss: 3.201664\n",
      "Train Epoch: 2 [668800/697932 (96%)]\tLoss: 3.151976\n",
      "Train Epoch: 2 [669440/697932 (96%)]\tLoss: 3.200973\n",
      "Train Epoch: 2 [670080/697932 (96%)]\tLoss: 3.161192\n",
      "Train Epoch: 2 [670720/697932 (96%)]\tLoss: 3.175719\n",
      "Train Epoch: 2 [671360/697932 (96%)]\tLoss: 3.147659\n",
      "Train Epoch: 2 [672000/697932 (96%)]\tLoss: 3.157312\n",
      "Train Epoch: 2 [672640/697932 (96%)]\tLoss: 3.184086\n",
      "Train Epoch: 2 [673280/697932 (96%)]\tLoss: 3.164579\n",
      "Train Epoch: 2 [673920/697932 (97%)]\tLoss: 3.170682\n",
      "Train Epoch: 2 [674560/697932 (97%)]\tLoss: 3.141732\n",
      "Train Epoch: 2 [675200/697932 (97%)]\tLoss: 3.201905\n",
      "Train Epoch: 2 [675840/697932 (97%)]\tLoss: 3.163650\n",
      "Train Epoch: 2 [676480/697932 (97%)]\tLoss: 3.145182\n",
      "Train Epoch: 2 [677120/697932 (97%)]\tLoss: 3.171389\n",
      "Train Epoch: 2 [677760/697932 (97%)]\tLoss: 3.186932\n",
      "Train Epoch: 2 [678400/697932 (97%)]\tLoss: 3.157568\n",
      "Train Epoch: 2 [679040/697932 (97%)]\tLoss: 3.167409\n",
      "Train Epoch: 2 [679680/697932 (97%)]\tLoss: 3.140767\n",
      "Train Epoch: 2 [680320/697932 (97%)]\tLoss: 3.163604\n",
      "Train Epoch: 2 [680960/697932 (98%)]\tLoss: 3.165668\n",
      "Train Epoch: 2 [681600/697932 (98%)]\tLoss: 3.190823\n",
      "Train Epoch: 2 [682240/697932 (98%)]\tLoss: 3.171341\n",
      "Train Epoch: 2 [682880/697932 (98%)]\tLoss: 3.156600\n",
      "Train Epoch: 2 [683520/697932 (98%)]\tLoss: 3.152521\n",
      "Train Epoch: 2 [684160/697932 (98%)]\tLoss: 3.163318\n",
      "Train Epoch: 2 [684800/697932 (98%)]\tLoss: 3.136654\n",
      "Train Epoch: 2 [685440/697932 (98%)]\tLoss: 3.191243\n",
      "Train Epoch: 2 [686080/697932 (98%)]\tLoss: 3.143535\n",
      "Train Epoch: 2 [686720/697932 (98%)]\tLoss: 3.147173\n",
      "Train Epoch: 2 [687360/697932 (98%)]\tLoss: 3.156798\n",
      "Train Epoch: 2 [688000/697932 (99%)]\tLoss: 3.148499\n",
      "Train Epoch: 2 [688640/697932 (99%)]\tLoss: 3.164384\n",
      "Train Epoch: 2 [689280/697932 (99%)]\tLoss: 3.194666\n",
      "Train Epoch: 2 [689920/697932 (99%)]\tLoss: 3.187915\n",
      "Train Epoch: 2 [690560/697932 (99%)]\tLoss: 3.121854\n",
      "Train Epoch: 2 [691200/697932 (99%)]\tLoss: 3.189587\n",
      "Train Epoch: 2 [691840/697932 (99%)]\tLoss: 3.193574\n",
      "Train Epoch: 2 [692480/697932 (99%)]\tLoss: 3.181761\n",
      "Train Epoch: 2 [693120/697932 (99%)]\tLoss: 3.194116\n",
      "Train Epoch: 2 [693760/697932 (99%)]\tLoss: 3.166112\n",
      "Train Epoch: 2 [694400/697932 (99%)]\tLoss: 3.192575\n",
      "Train Epoch: 2 [695040/697932 (100%)]\tLoss: 3.179753\n",
      "Train Epoch: 2 [695680/697932 (100%)]\tLoss: 3.150412\n",
      "Train Epoch: 2 [696320/697932 (100%)]\tLoss: 3.176040\n",
      "Train Epoch: 2 [696960/697932 (100%)]\tLoss: 3.166089\n",
      "Train Epoch: 2 [697600/697932 (100%)]\tLoss: 3.177776\n",
      "\n",
      "Test set: Avg. loss: 0.0045, Accuracy: 38/116323 (0%)\n",
      "\n",
      "Train Epoch: 3 [0/697932 (0%)]\tLoss: 3.170643\n",
      "Train Epoch: 3 [640/697932 (0%)]\tLoss: 3.161540\n",
      "Train Epoch: 3 [1280/697932 (0%)]\tLoss: 3.148738\n",
      "Train Epoch: 3 [1920/697932 (0%)]\tLoss: 3.127823\n",
      "Train Epoch: 3 [2560/697932 (0%)]\tLoss: 3.162179\n",
      "Train Epoch: 3 [3200/697932 (0%)]\tLoss: 3.170155\n",
      "Train Epoch: 3 [3840/697932 (1%)]\tLoss: 3.135699\n",
      "Train Epoch: 3 [4480/697932 (1%)]\tLoss: 3.199428\n",
      "Train Epoch: 3 [5120/697932 (1%)]\tLoss: 3.185697\n",
      "Train Epoch: 3 [5760/697932 (1%)]\tLoss: 3.172560\n",
      "Train Epoch: 3 [6400/697932 (1%)]\tLoss: 3.190346\n",
      "Train Epoch: 3 [7040/697932 (1%)]\tLoss: 3.190379\n",
      "Train Epoch: 3 [7680/697932 (1%)]\tLoss: 3.182658\n",
      "Train Epoch: 3 [8320/697932 (1%)]\tLoss: 3.172836\n",
      "Train Epoch: 3 [8960/697932 (1%)]\tLoss: 3.186289\n",
      "Train Epoch: 3 [9600/697932 (1%)]\tLoss: 3.171880\n",
      "Train Epoch: 3 [10240/697932 (1%)]\tLoss: 3.198459\n",
      "Train Epoch: 3 [10880/697932 (2%)]\tLoss: 3.189980\n",
      "Train Epoch: 3 [11520/697932 (2%)]\tLoss: 3.150969\n",
      "Train Epoch: 3 [12160/697932 (2%)]\tLoss: 3.170017\n",
      "Train Epoch: 3 [12800/697932 (2%)]\tLoss: 3.199200\n",
      "Train Epoch: 3 [13440/697932 (2%)]\tLoss: 3.181677\n",
      "Train Epoch: 3 [14080/697932 (2%)]\tLoss: 3.147549\n",
      "Train Epoch: 3 [14720/697932 (2%)]\tLoss: 3.189973\n",
      "Train Epoch: 3 [15360/697932 (2%)]\tLoss: 3.186563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [16000/697932 (2%)]\tLoss: 3.176080\n",
      "Train Epoch: 3 [16640/697932 (2%)]\tLoss: 3.183551\n",
      "Train Epoch: 3 [17280/697932 (2%)]\tLoss: 3.144691\n",
      "Train Epoch: 3 [17920/697932 (3%)]\tLoss: 3.186635\n",
      "Train Epoch: 3 [18560/697932 (3%)]\tLoss: 3.173613\n",
      "Train Epoch: 3 [19200/697932 (3%)]\tLoss: 3.198173\n",
      "Train Epoch: 3 [19840/697932 (3%)]\tLoss: 3.173639\n",
      "Train Epoch: 3 [20480/697932 (3%)]\tLoss: 3.145507\n",
      "Train Epoch: 3 [21120/697932 (3%)]\tLoss: 3.141220\n",
      "Train Epoch: 3 [21760/697932 (3%)]\tLoss: 3.162975\n",
      "Train Epoch: 3 [22400/697932 (3%)]\tLoss: 3.154841\n",
      "Train Epoch: 3 [23040/697932 (3%)]\tLoss: 3.192234\n",
      "Train Epoch: 3 [23680/697932 (3%)]\tLoss: 3.169644\n",
      "Train Epoch: 3 [24320/697932 (3%)]\tLoss: 3.145095\n",
      "Train Epoch: 3 [24960/697932 (4%)]\tLoss: 3.187584\n",
      "Train Epoch: 3 [25600/697932 (4%)]\tLoss: 3.180219\n",
      "Train Epoch: 3 [26240/697932 (4%)]\tLoss: 3.192141\n",
      "Train Epoch: 3 [26880/697932 (4%)]\tLoss: 3.163056\n",
      "Train Epoch: 3 [27520/697932 (4%)]\tLoss: 3.209426\n",
      "Train Epoch: 3 [28160/697932 (4%)]\tLoss: 3.207161\n",
      "Train Epoch: 3 [28800/697932 (4%)]\tLoss: 3.197037\n",
      "Train Epoch: 3 [29440/697932 (4%)]\tLoss: 3.184288\n",
      "Train Epoch: 3 [30080/697932 (4%)]\tLoss: 3.158461\n",
      "Train Epoch: 3 [30720/697932 (4%)]\tLoss: 3.173172\n",
      "Train Epoch: 3 [31360/697932 (4%)]\tLoss: 3.180362\n",
      "Train Epoch: 3 [32000/697932 (5%)]\tLoss: 3.156849\n",
      "Train Epoch: 3 [32640/697932 (5%)]\tLoss: 3.156773\n",
      "Train Epoch: 3 [33280/697932 (5%)]\tLoss: 3.175003\n",
      "Train Epoch: 3 [33920/697932 (5%)]\tLoss: 3.186712\n",
      "Train Epoch: 3 [34560/697932 (5%)]\tLoss: 3.172840\n",
      "Train Epoch: 3 [35200/697932 (5%)]\tLoss: 3.180922\n",
      "Train Epoch: 3 [35840/697932 (5%)]\tLoss: 3.147473\n",
      "Train Epoch: 3 [36480/697932 (5%)]\tLoss: 3.159168\n",
      "Train Epoch: 3 [37120/697932 (5%)]\tLoss: 3.217158\n",
      "Train Epoch: 3 [37760/697932 (5%)]\tLoss: 3.186701\n",
      "Train Epoch: 3 [38400/697932 (6%)]\tLoss: 3.191120\n",
      "Train Epoch: 3 [39040/697932 (6%)]\tLoss: 3.175946\n",
      "Train Epoch: 3 [39680/697932 (6%)]\tLoss: 3.183126\n",
      "Train Epoch: 3 [40320/697932 (6%)]\tLoss: 3.170707\n",
      "Train Epoch: 3 [40960/697932 (6%)]\tLoss: 3.166098\n",
      "Train Epoch: 3 [41600/697932 (6%)]\tLoss: 3.155757\n",
      "Train Epoch: 3 [42240/697932 (6%)]\tLoss: 3.174862\n",
      "Train Epoch: 3 [42880/697932 (6%)]\tLoss: 3.158041\n",
      "Train Epoch: 3 [43520/697932 (6%)]\tLoss: 3.179615\n",
      "Train Epoch: 3 [44160/697932 (6%)]\tLoss: 3.178628\n",
      "Train Epoch: 3 [44800/697932 (6%)]\tLoss: 3.212039\n",
      "Train Epoch: 3 [45440/697932 (7%)]\tLoss: 3.157919\n",
      "Train Epoch: 3 [46080/697932 (7%)]\tLoss: 3.207136\n",
      "Train Epoch: 3 [46720/697932 (7%)]\tLoss: 3.161060\n",
      "Train Epoch: 3 [47360/697932 (7%)]\tLoss: 3.174013\n",
      "Train Epoch: 3 [48000/697932 (7%)]\tLoss: 3.148853\n",
      "Train Epoch: 3 [48640/697932 (7%)]\tLoss: 3.155280\n",
      "Train Epoch: 3 [49280/697932 (7%)]\tLoss: 3.206409\n",
      "Train Epoch: 3 [49920/697932 (7%)]\tLoss: 3.194499\n",
      "Train Epoch: 3 [50560/697932 (7%)]\tLoss: 3.168049\n",
      "Train Epoch: 3 [51200/697932 (7%)]\tLoss: 3.191354\n",
      "Train Epoch: 3 [51840/697932 (7%)]\tLoss: 3.157523\n",
      "Train Epoch: 3 [52480/697932 (8%)]\tLoss: 3.198065\n",
      "Train Epoch: 3 [53120/697932 (8%)]\tLoss: 3.190356\n",
      "Train Epoch: 3 [53760/697932 (8%)]\tLoss: 3.195679\n",
      "Train Epoch: 3 [54400/697932 (8%)]\tLoss: 3.175436\n",
      "Train Epoch: 3 [55040/697932 (8%)]\tLoss: 3.173173\n",
      "Train Epoch: 3 [55680/697932 (8%)]\tLoss: 3.172206\n",
      "Train Epoch: 3 [56320/697932 (8%)]\tLoss: 3.151153\n",
      "Train Epoch: 3 [56960/697932 (8%)]\tLoss: 3.169045\n",
      "Train Epoch: 3 [57600/697932 (8%)]\tLoss: 3.196111\n",
      "Train Epoch: 3 [58240/697932 (8%)]\tLoss: 3.164475\n",
      "Train Epoch: 3 [58880/697932 (8%)]\tLoss: 3.189249\n",
      "Train Epoch: 3 [59520/697932 (9%)]\tLoss: 3.177690\n",
      "Train Epoch: 3 [60160/697932 (9%)]\tLoss: 3.164664\n",
      "Train Epoch: 3 [60800/697932 (9%)]\tLoss: 3.171581\n",
      "Train Epoch: 3 [61440/697932 (9%)]\tLoss: 3.138536\n",
      "Train Epoch: 3 [62080/697932 (9%)]\tLoss: 3.179177\n",
      "Train Epoch: 3 [62720/697932 (9%)]\tLoss: 3.190996\n",
      "Train Epoch: 3 [63360/697932 (9%)]\tLoss: 3.182266\n",
      "Train Epoch: 3 [64000/697932 (9%)]\tLoss: 3.163278\n",
      "Train Epoch: 3 [64640/697932 (9%)]\tLoss: 3.168121\n",
      "Train Epoch: 3 [65280/697932 (9%)]\tLoss: 3.156307\n",
      "Train Epoch: 3 [65920/697932 (9%)]\tLoss: 3.126749\n",
      "Train Epoch: 3 [66560/697932 (10%)]\tLoss: 3.139248\n",
      "Train Epoch: 3 [67200/697932 (10%)]\tLoss: 3.158334\n",
      "Train Epoch: 3 [67840/697932 (10%)]\tLoss: 3.150728\n",
      "Train Epoch: 3 [68480/697932 (10%)]\tLoss: 3.161298\n",
      "Train Epoch: 3 [69120/697932 (10%)]\tLoss: 3.147210\n",
      "Train Epoch: 3 [69760/697932 (10%)]\tLoss: 3.158638\n",
      "Train Epoch: 3 [70400/697932 (10%)]\tLoss: 3.172069\n",
      "Train Epoch: 3 [71040/697932 (10%)]\tLoss: 3.175681\n",
      "Train Epoch: 3 [71680/697932 (10%)]\tLoss: 3.155390\n",
      "Train Epoch: 3 [72320/697932 (10%)]\tLoss: 3.150061\n",
      "Train Epoch: 3 [72960/697932 (10%)]\tLoss: 3.168150\n",
      "Train Epoch: 3 [73600/697932 (11%)]\tLoss: 3.190631\n",
      "Train Epoch: 3 [74240/697932 (11%)]\tLoss: 3.169419\n",
      "Train Epoch: 3 [74880/697932 (11%)]\tLoss: 3.157218\n",
      "Train Epoch: 3 [75520/697932 (11%)]\tLoss: 3.190376\n",
      "Train Epoch: 3 [76160/697932 (11%)]\tLoss: 3.195536\n",
      "Train Epoch: 3 [76800/697932 (11%)]\tLoss: 3.145270\n",
      "Train Epoch: 3 [77440/697932 (11%)]\tLoss: 3.166284\n",
      "Train Epoch: 3 [78080/697932 (11%)]\tLoss: 3.165925\n",
      "Train Epoch: 3 [78720/697932 (11%)]\tLoss: 3.164509\n",
      "Train Epoch: 3 [79360/697932 (11%)]\tLoss: 3.148177\n",
      "Train Epoch: 3 [80000/697932 (11%)]\tLoss: 3.151464\n",
      "Train Epoch: 3 [80640/697932 (12%)]\tLoss: 3.205028\n",
      "Train Epoch: 3 [81280/697932 (12%)]\tLoss: 3.171078\n",
      "Train Epoch: 3 [81920/697932 (12%)]\tLoss: 3.199978\n",
      "Train Epoch: 3 [82560/697932 (12%)]\tLoss: 3.154147\n",
      "Train Epoch: 3 [83200/697932 (12%)]\tLoss: 3.179837\n",
      "Train Epoch: 3 [83840/697932 (12%)]\tLoss: 3.170392\n",
      "Train Epoch: 3 [84480/697932 (12%)]\tLoss: 3.169780\n",
      "Train Epoch: 3 [85120/697932 (12%)]\tLoss: 3.159015\n",
      "Train Epoch: 3 [85760/697932 (12%)]\tLoss: 3.164937\n",
      "Train Epoch: 3 [86400/697932 (12%)]\tLoss: 3.197930\n",
      "Train Epoch: 3 [87040/697932 (12%)]\tLoss: 3.174350\n",
      "Train Epoch: 3 [87680/697932 (13%)]\tLoss: 3.229980\n",
      "Train Epoch: 3 [88320/697932 (13%)]\tLoss: 3.177719\n",
      "Train Epoch: 3 [88960/697932 (13%)]\tLoss: 3.154592\n",
      "Train Epoch: 3 [89600/697932 (13%)]\tLoss: 3.184917\n",
      "Train Epoch: 3 [90240/697932 (13%)]\tLoss: 3.167527\n",
      "Train Epoch: 3 [90880/697932 (13%)]\tLoss: 3.179498\n",
      "Train Epoch: 3 [91520/697932 (13%)]\tLoss: 3.163063\n",
      "Train Epoch: 3 [92160/697932 (13%)]\tLoss: 3.169167\n",
      "Train Epoch: 3 [92800/697932 (13%)]\tLoss: 3.173847\n",
      "Train Epoch: 3 [93440/697932 (13%)]\tLoss: 3.203821\n",
      "Train Epoch: 3 [94080/697932 (13%)]\tLoss: 3.149313\n",
      "Train Epoch: 3 [94720/697932 (14%)]\tLoss: 3.181719\n",
      "Train Epoch: 3 [95360/697932 (14%)]\tLoss: 3.201600\n",
      "Train Epoch: 3 [96000/697932 (14%)]\tLoss: 3.166192\n",
      "Train Epoch: 3 [96640/697932 (14%)]\tLoss: 3.156764\n",
      "Train Epoch: 3 [97280/697932 (14%)]\tLoss: 3.174347\n",
      "Train Epoch: 3 [97920/697932 (14%)]\tLoss: 3.166804\n",
      "Train Epoch: 3 [98560/697932 (14%)]\tLoss: 3.155287\n",
      "Train Epoch: 3 [99200/697932 (14%)]\tLoss: 3.139420\n",
      "Train Epoch: 3 [99840/697932 (14%)]\tLoss: 3.168381\n",
      "Train Epoch: 3 [100480/697932 (14%)]\tLoss: 3.139930\n",
      "Train Epoch: 3 [101120/697932 (14%)]\tLoss: 3.162375\n",
      "Train Epoch: 3 [101760/697932 (15%)]\tLoss: 3.147546\n",
      "Train Epoch: 3 [102400/697932 (15%)]\tLoss: 3.173428\n",
      "Train Epoch: 3 [103040/697932 (15%)]\tLoss: 3.189226\n",
      "Train Epoch: 3 [103680/697932 (15%)]\tLoss: 3.187500\n",
      "Train Epoch: 3 [104320/697932 (15%)]\tLoss: 3.177380\n",
      "Train Epoch: 3 [104960/697932 (15%)]\tLoss: 3.141114\n",
      "Train Epoch: 3 [105600/697932 (15%)]\tLoss: 3.176872\n",
      "Train Epoch: 3 [106240/697932 (15%)]\tLoss: 3.134638\n",
      "Train Epoch: 3 [106880/697932 (15%)]\tLoss: 3.173914\n",
      "Train Epoch: 3 [107520/697932 (15%)]\tLoss: 3.169599\n",
      "Train Epoch: 3 [108160/697932 (15%)]\tLoss: 3.179969\n",
      "Train Epoch: 3 [108800/697932 (16%)]\tLoss: 3.186316\n",
      "Train Epoch: 3 [109440/697932 (16%)]\tLoss: 3.165624\n",
      "Train Epoch: 3 [110080/697932 (16%)]\tLoss: 3.124389\n",
      "Train Epoch: 3 [110720/697932 (16%)]\tLoss: 3.150520\n",
      "Train Epoch: 3 [111360/697932 (16%)]\tLoss: 3.170093\n",
      "Train Epoch: 3 [112000/697932 (16%)]\tLoss: 3.191649\n",
      "Train Epoch: 3 [112640/697932 (16%)]\tLoss: 3.172685\n",
      "Train Epoch: 3 [113280/697932 (16%)]\tLoss: 3.194964\n",
      "Train Epoch: 3 [113920/697932 (16%)]\tLoss: 3.200033\n",
      "Train Epoch: 3 [114560/697932 (16%)]\tLoss: 3.174302\n",
      "Train Epoch: 3 [115200/697932 (17%)]\tLoss: 3.173717\n",
      "Train Epoch: 3 [115840/697932 (17%)]\tLoss: 3.190082\n",
      "Train Epoch: 3 [116480/697932 (17%)]\tLoss: 3.219572\n",
      "Train Epoch: 3 [117120/697932 (17%)]\tLoss: 3.153390\n",
      "Train Epoch: 3 [117760/697932 (17%)]\tLoss: 3.165588\n",
      "Train Epoch: 3 [118400/697932 (17%)]\tLoss: 3.136424\n",
      "Train Epoch: 3 [119040/697932 (17%)]\tLoss: 3.153826\n",
      "Train Epoch: 3 [119680/697932 (17%)]\tLoss: 3.179838\n",
      "Train Epoch: 3 [120320/697932 (17%)]\tLoss: 3.184520\n",
      "Train Epoch: 3 [120960/697932 (17%)]\tLoss: 3.164851\n",
      "Train Epoch: 3 [121600/697932 (17%)]\tLoss: 3.146351\n",
      "Train Epoch: 3 [122240/697932 (18%)]\tLoss: 3.155137\n",
      "Train Epoch: 3 [122880/697932 (18%)]\tLoss: 3.185374\n",
      "Train Epoch: 3 [123520/697932 (18%)]\tLoss: 3.198156\n",
      "Train Epoch: 3 [124160/697932 (18%)]\tLoss: 3.170957\n",
      "Train Epoch: 3 [124800/697932 (18%)]\tLoss: 3.172569\n",
      "Train Epoch: 3 [125440/697932 (18%)]\tLoss: 3.169733\n",
      "Train Epoch: 3 [126080/697932 (18%)]\tLoss: 3.154353\n",
      "Train Epoch: 3 [126720/697932 (18%)]\tLoss: 3.187942\n",
      "Train Epoch: 3 [127360/697932 (18%)]\tLoss: 3.134323\n",
      "Train Epoch: 3 [128000/697932 (18%)]\tLoss: 3.213646\n",
      "Train Epoch: 3 [128640/697932 (18%)]\tLoss: 3.159785\n",
      "Train Epoch: 3 [129280/697932 (19%)]\tLoss: 3.172988\n",
      "Train Epoch: 3 [129920/697932 (19%)]\tLoss: 3.193618\n",
      "Train Epoch: 3 [130560/697932 (19%)]\tLoss: 3.200307\n",
      "Train Epoch: 3 [131200/697932 (19%)]\tLoss: 3.170746\n",
      "Train Epoch: 3 [131840/697932 (19%)]\tLoss: 3.157192\n",
      "Train Epoch: 3 [132480/697932 (19%)]\tLoss: 3.167374\n",
      "Train Epoch: 3 [133120/697932 (19%)]\tLoss: 3.204996\n",
      "Train Epoch: 3 [133760/697932 (19%)]\tLoss: 3.175945\n",
      "Train Epoch: 3 [134400/697932 (19%)]\tLoss: 3.170977\n",
      "Train Epoch: 3 [135040/697932 (19%)]\tLoss: 3.175574\n",
      "Train Epoch: 3 [135680/697932 (19%)]\tLoss: 3.204355\n",
      "Train Epoch: 3 [136320/697932 (20%)]\tLoss: 3.185002\n",
      "Train Epoch: 3 [136960/697932 (20%)]\tLoss: 3.176563\n",
      "Train Epoch: 3 [137600/697932 (20%)]\tLoss: 3.185689\n",
      "Train Epoch: 3 [138240/697932 (20%)]\tLoss: 3.188881\n",
      "Train Epoch: 3 [138880/697932 (20%)]\tLoss: 3.190034\n",
      "Train Epoch: 3 [139520/697932 (20%)]\tLoss: 3.201395\n",
      "Train Epoch: 3 [140160/697932 (20%)]\tLoss: 3.147478\n",
      "Train Epoch: 3 [140800/697932 (20%)]\tLoss: 3.162392\n",
      "Train Epoch: 3 [141440/697932 (20%)]\tLoss: 3.164239\n",
      "Train Epoch: 3 [142080/697932 (20%)]\tLoss: 3.141309\n",
      "Train Epoch: 3 [142720/697932 (20%)]\tLoss: 3.170953\n",
      "Train Epoch: 3 [143360/697932 (21%)]\tLoss: 3.181353\n",
      "Train Epoch: 3 [144000/697932 (21%)]\tLoss: 3.171103\n",
      "Train Epoch: 3 [144640/697932 (21%)]\tLoss: 3.176984\n",
      "Train Epoch: 3 [145280/697932 (21%)]\tLoss: 3.147513\n",
      "Train Epoch: 3 [145920/697932 (21%)]\tLoss: 3.196582\n",
      "Train Epoch: 3 [146560/697932 (21%)]\tLoss: 3.177215\n",
      "Train Epoch: 3 [147200/697932 (21%)]\tLoss: 3.175211\n",
      "Train Epoch: 3 [147840/697932 (21%)]\tLoss: 3.159947\n",
      "Train Epoch: 3 [148480/697932 (21%)]\tLoss: 3.175894\n",
      "Train Epoch: 3 [149120/697932 (21%)]\tLoss: 3.185319\n",
      "Train Epoch: 3 [149760/697932 (21%)]\tLoss: 3.165566\n",
      "Train Epoch: 3 [150400/697932 (22%)]\tLoss: 3.220776\n",
      "Train Epoch: 3 [151040/697932 (22%)]\tLoss: 3.157704\n",
      "Train Epoch: 3 [151680/697932 (22%)]\tLoss: 3.152835\n",
      "Train Epoch: 3 [152320/697932 (22%)]\tLoss: 3.160608\n",
      "Train Epoch: 3 [152960/697932 (22%)]\tLoss: 3.213000\n",
      "Train Epoch: 3 [153600/697932 (22%)]\tLoss: 3.172800\n",
      "Train Epoch: 3 [154240/697932 (22%)]\tLoss: 3.176589\n",
      "Train Epoch: 3 [154880/697932 (22%)]\tLoss: 3.204061\n",
      "Train Epoch: 3 [155520/697932 (22%)]\tLoss: 3.172390\n",
      "Train Epoch: 3 [156160/697932 (22%)]\tLoss: 3.147684\n",
      "Train Epoch: 3 [156800/697932 (22%)]\tLoss: 3.184254\n",
      "Train Epoch: 3 [157440/697932 (23%)]\tLoss: 3.156955\n",
      "Train Epoch: 3 [158080/697932 (23%)]\tLoss: 3.138623\n",
      "Train Epoch: 3 [158720/697932 (23%)]\tLoss: 3.146478\n",
      "Train Epoch: 3 [159360/697932 (23%)]\tLoss: 3.187476\n",
      "Train Epoch: 3 [160000/697932 (23%)]\tLoss: 3.226050\n",
      "Train Epoch: 3 [160640/697932 (23%)]\tLoss: 3.172315\n",
      "Train Epoch: 3 [161280/697932 (23%)]\tLoss: 3.174263\n",
      "Train Epoch: 3 [161920/697932 (23%)]\tLoss: 3.165605\n",
      "Train Epoch: 3 [162560/697932 (23%)]\tLoss: 3.194355\n",
      "Train Epoch: 3 [163200/697932 (23%)]\tLoss: 3.195846\n",
      "Train Epoch: 3 [163840/697932 (23%)]\tLoss: 3.172887\n",
      "Train Epoch: 3 [164480/697932 (24%)]\tLoss: 3.137851\n",
      "Train Epoch: 3 [165120/697932 (24%)]\tLoss: 3.139588\n",
      "Train Epoch: 3 [165760/697932 (24%)]\tLoss: 3.178687\n",
      "Train Epoch: 3 [166400/697932 (24%)]\tLoss: 3.169109\n",
      "Train Epoch: 3 [167040/697932 (24%)]\tLoss: 3.188241\n",
      "Train Epoch: 3 [167680/697932 (24%)]\tLoss: 3.174423\n",
      "Train Epoch: 3 [168320/697932 (24%)]\tLoss: 3.169872\n",
      "Train Epoch: 3 [168960/697932 (24%)]\tLoss: 3.176961\n",
      "Train Epoch: 3 [169600/697932 (24%)]\tLoss: 3.148239\n",
      "Train Epoch: 3 [170240/697932 (24%)]\tLoss: 3.149521\n",
      "Train Epoch: 3 [170880/697932 (24%)]\tLoss: 3.182730\n",
      "Train Epoch: 3 [171520/697932 (25%)]\tLoss: 3.212456\n",
      "Train Epoch: 3 [172160/697932 (25%)]\tLoss: 3.149969\n",
      "Train Epoch: 3 [172800/697932 (25%)]\tLoss: 3.203017\n",
      "Train Epoch: 3 [173440/697932 (25%)]\tLoss: 3.164918\n",
      "Train Epoch: 3 [174080/697932 (25%)]\tLoss: 3.171051\n",
      "Train Epoch: 3 [174720/697932 (25%)]\tLoss: 3.184778\n",
      "Train Epoch: 3 [175360/697932 (25%)]\tLoss: 3.186736\n",
      "Train Epoch: 3 [176000/697932 (25%)]\tLoss: 3.184837\n",
      "Train Epoch: 3 [176640/697932 (25%)]\tLoss: 3.173793\n",
      "Train Epoch: 3 [177280/697932 (25%)]\tLoss: 3.162480\n",
      "Train Epoch: 3 [177920/697932 (25%)]\tLoss: 3.203616\n",
      "Train Epoch: 3 [178560/697932 (26%)]\tLoss: 3.191656\n",
      "Train Epoch: 3 [179200/697932 (26%)]\tLoss: 3.190746\n",
      "Train Epoch: 3 [179840/697932 (26%)]\tLoss: 3.144594\n",
      "Train Epoch: 3 [180480/697932 (26%)]\tLoss: 3.164713\n",
      "Train Epoch: 3 [181120/697932 (26%)]\tLoss: 3.170304\n",
      "Train Epoch: 3 [181760/697932 (26%)]\tLoss: 3.173845\n",
      "Train Epoch: 3 [182400/697932 (26%)]\tLoss: 3.155803\n",
      "Train Epoch: 3 [183040/697932 (26%)]\tLoss: 3.169827\n",
      "Train Epoch: 3 [183680/697932 (26%)]\tLoss: 3.189805\n",
      "Train Epoch: 3 [184320/697932 (26%)]\tLoss: 3.154585\n",
      "Train Epoch: 3 [184960/697932 (26%)]\tLoss: 3.180102\n",
      "Train Epoch: 3 [185600/697932 (27%)]\tLoss: 3.174712\n",
      "Train Epoch: 3 [186240/697932 (27%)]\tLoss: 3.168555\n",
      "Train Epoch: 3 [186880/697932 (27%)]\tLoss: 3.180928\n",
      "Train Epoch: 3 [187520/697932 (27%)]\tLoss: 3.179315\n",
      "Train Epoch: 3 [188160/697932 (27%)]\tLoss: 3.197994\n",
      "Train Epoch: 3 [188800/697932 (27%)]\tLoss: 3.199679\n",
      "Train Epoch: 3 [189440/697932 (27%)]\tLoss: 3.175226\n",
      "Train Epoch: 3 [190080/697932 (27%)]\tLoss: 3.170961\n",
      "Train Epoch: 3 [190720/697932 (27%)]\tLoss: 3.162134\n",
      "Train Epoch: 3 [191360/697932 (27%)]\tLoss: 3.158323\n",
      "Train Epoch: 3 [192000/697932 (28%)]\tLoss: 3.160421\n",
      "Train Epoch: 3 [192640/697932 (28%)]\tLoss: 3.185322\n",
      "Train Epoch: 3 [193280/697932 (28%)]\tLoss: 3.182067\n",
      "Train Epoch: 3 [193920/697932 (28%)]\tLoss: 3.158803\n",
      "Train Epoch: 3 [194560/697932 (28%)]\tLoss: 3.171832\n",
      "Train Epoch: 3 [195200/697932 (28%)]\tLoss: 3.177217\n",
      "Train Epoch: 3 [195840/697932 (28%)]\tLoss: 3.197164\n",
      "Train Epoch: 3 [196480/697932 (28%)]\tLoss: 3.182422\n",
      "Train Epoch: 3 [197120/697932 (28%)]\tLoss: 3.189530\n",
      "Train Epoch: 3 [197760/697932 (28%)]\tLoss: 3.164461\n",
      "Train Epoch: 3 [198400/697932 (28%)]\tLoss: 3.176212\n",
      "Train Epoch: 3 [199040/697932 (29%)]\tLoss: 3.209253\n",
      "Train Epoch: 3 [199680/697932 (29%)]\tLoss: 3.171058\n",
      "Train Epoch: 3 [200320/697932 (29%)]\tLoss: 3.180601\n",
      "Train Epoch: 3 [200960/697932 (29%)]\tLoss: 3.167368\n",
      "Train Epoch: 3 [201600/697932 (29%)]\tLoss: 3.176705\n",
      "Train Epoch: 3 [202240/697932 (29%)]\tLoss: 3.175652\n",
      "Train Epoch: 3 [202880/697932 (29%)]\tLoss: 3.206757\n",
      "Train Epoch: 3 [203520/697932 (29%)]\tLoss: 3.169230\n",
      "Train Epoch: 3 [204160/697932 (29%)]\tLoss: 3.182875\n",
      "Train Epoch: 3 [204800/697932 (29%)]\tLoss: 3.162267\n",
      "Train Epoch: 3 [205440/697932 (29%)]\tLoss: 3.200317\n",
      "Train Epoch: 3 [206080/697932 (30%)]\tLoss: 3.145465\n",
      "Train Epoch: 3 [206720/697932 (30%)]\tLoss: 3.165514\n",
      "Train Epoch: 3 [207360/697932 (30%)]\tLoss: 3.161300\n",
      "Train Epoch: 3 [208000/697932 (30%)]\tLoss: 3.194228\n",
      "Train Epoch: 3 [208640/697932 (30%)]\tLoss: 3.180501\n",
      "Train Epoch: 3 [209280/697932 (30%)]\tLoss: 3.162329\n",
      "Train Epoch: 3 [209920/697932 (30%)]\tLoss: 3.191868\n",
      "Train Epoch: 3 [210560/697932 (30%)]\tLoss: 3.182534\n",
      "Train Epoch: 3 [211200/697932 (30%)]\tLoss: 3.197869\n",
      "Train Epoch: 3 [211840/697932 (30%)]\tLoss: 3.180330\n",
      "Train Epoch: 3 [212480/697932 (30%)]\tLoss: 3.187762\n",
      "Train Epoch: 3 [213120/697932 (31%)]\tLoss: 3.166247\n",
      "Train Epoch: 3 [213760/697932 (31%)]\tLoss: 3.177384\n",
      "Train Epoch: 3 [214400/697932 (31%)]\tLoss: 3.179128\n",
      "Train Epoch: 3 [215040/697932 (31%)]\tLoss: 3.170099\n",
      "Train Epoch: 3 [215680/697932 (31%)]\tLoss: 3.162356\n",
      "Train Epoch: 3 [216320/697932 (31%)]\tLoss: 3.163454\n",
      "Train Epoch: 3 [216960/697932 (31%)]\tLoss: 3.202134\n",
      "Train Epoch: 3 [217600/697932 (31%)]\tLoss: 3.188242\n",
      "Train Epoch: 3 [218240/697932 (31%)]\tLoss: 3.162974\n",
      "Train Epoch: 3 [218880/697932 (31%)]\tLoss: 3.176964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [219520/697932 (31%)]\tLoss: 3.169384\n",
      "Train Epoch: 3 [220160/697932 (32%)]\tLoss: 3.146386\n",
      "Train Epoch: 3 [220800/697932 (32%)]\tLoss: 3.183294\n",
      "Train Epoch: 3 [221440/697932 (32%)]\tLoss: 3.145016\n",
      "Train Epoch: 3 [222080/697932 (32%)]\tLoss: 3.166521\n",
      "Train Epoch: 3 [222720/697932 (32%)]\tLoss: 3.157807\n",
      "Train Epoch: 3 [223360/697932 (32%)]\tLoss: 3.175220\n",
      "Train Epoch: 3 [224000/697932 (32%)]\tLoss: 3.142601\n",
      "Train Epoch: 3 [224640/697932 (32%)]\tLoss: 3.144443\n",
      "Train Epoch: 3 [225280/697932 (32%)]\tLoss: 3.191180\n",
      "Train Epoch: 3 [225920/697932 (32%)]\tLoss: 3.148804\n",
      "Train Epoch: 3 [226560/697932 (32%)]\tLoss: 3.171518\n",
      "Train Epoch: 3 [227200/697932 (33%)]\tLoss: 3.175808\n",
      "Train Epoch: 3 [227840/697932 (33%)]\tLoss: 3.165977\n",
      "Train Epoch: 3 [228480/697932 (33%)]\tLoss: 3.148774\n",
      "Train Epoch: 3 [229120/697932 (33%)]\tLoss: 3.194666\n",
      "Train Epoch: 3 [229760/697932 (33%)]\tLoss: 3.160662\n",
      "Train Epoch: 3 [230400/697932 (33%)]\tLoss: 3.154939\n",
      "Train Epoch: 3 [231040/697932 (33%)]\tLoss: 3.142444\n",
      "Train Epoch: 3 [231680/697932 (33%)]\tLoss: 3.155869\n",
      "Train Epoch: 3 [232320/697932 (33%)]\tLoss: 3.175279\n",
      "Train Epoch: 3 [232960/697932 (33%)]\tLoss: 3.190811\n",
      "Train Epoch: 3 [233600/697932 (33%)]\tLoss: 3.179647\n",
      "Train Epoch: 3 [234240/697932 (34%)]\tLoss: 3.181345\n",
      "Train Epoch: 3 [234880/697932 (34%)]\tLoss: 3.173521\n",
      "Train Epoch: 3 [235520/697932 (34%)]\tLoss: 3.157242\n",
      "Train Epoch: 3 [236160/697932 (34%)]\tLoss: 3.160201\n",
      "Train Epoch: 3 [236800/697932 (34%)]\tLoss: 3.174594\n",
      "Train Epoch: 3 [237440/697932 (34%)]\tLoss: 3.156885\n",
      "Train Epoch: 3 [238080/697932 (34%)]\tLoss: 3.139251\n",
      "Train Epoch: 3 [238720/697932 (34%)]\tLoss: 3.186533\n",
      "Train Epoch: 3 [239360/697932 (34%)]\tLoss: 3.180151\n",
      "Train Epoch: 3 [240000/697932 (34%)]\tLoss: 3.169769\n",
      "Train Epoch: 3 [240640/697932 (34%)]\tLoss: 3.146630\n",
      "Train Epoch: 3 [241280/697932 (35%)]\tLoss: 3.164948\n",
      "Train Epoch: 3 [241920/697932 (35%)]\tLoss: 3.158190\n",
      "Train Epoch: 3 [242560/697932 (35%)]\tLoss: 3.167249\n",
      "Train Epoch: 3 [243200/697932 (35%)]\tLoss: 3.171491\n",
      "Train Epoch: 3 [243840/697932 (35%)]\tLoss: 3.167850\n",
      "Train Epoch: 3 [244480/697932 (35%)]\tLoss: 3.154626\n",
      "Train Epoch: 3 [245120/697932 (35%)]\tLoss: 3.140690\n",
      "Train Epoch: 3 [245760/697932 (35%)]\tLoss: 3.187077\n",
      "Train Epoch: 3 [246400/697932 (35%)]\tLoss: 3.170624\n",
      "Train Epoch: 3 [247040/697932 (35%)]\tLoss: 3.199465\n",
      "Train Epoch: 3 [247680/697932 (35%)]\tLoss: 3.156544\n",
      "Train Epoch: 3 [248320/697932 (36%)]\tLoss: 3.180502\n",
      "Train Epoch: 3 [248960/697932 (36%)]\tLoss: 3.202061\n",
      "Train Epoch: 3 [249600/697932 (36%)]\tLoss: 3.168559\n",
      "Train Epoch: 3 [250240/697932 (36%)]\tLoss: 3.170338\n",
      "Train Epoch: 3 [250880/697932 (36%)]\tLoss: 3.172030\n",
      "Train Epoch: 3 [251520/697932 (36%)]\tLoss: 3.143404\n",
      "Train Epoch: 3 [252160/697932 (36%)]\tLoss: 3.187934\n",
      "Train Epoch: 3 [252800/697932 (36%)]\tLoss: 3.167469\n",
      "Train Epoch: 3 [253440/697932 (36%)]\tLoss: 3.186929\n",
      "Train Epoch: 3 [254080/697932 (36%)]\tLoss: 3.170720\n",
      "Train Epoch: 3 [254720/697932 (36%)]\tLoss: 3.165177\n",
      "Train Epoch: 3 [255360/697932 (37%)]\tLoss: 3.181341\n",
      "Train Epoch: 3 [256000/697932 (37%)]\tLoss: 3.211334\n",
      "Train Epoch: 3 [256640/697932 (37%)]\tLoss: 3.173076\n",
      "Train Epoch: 3 [257280/697932 (37%)]\tLoss: 3.191304\n",
      "Train Epoch: 3 [257920/697932 (37%)]\tLoss: 3.153986\n",
      "Train Epoch: 3 [258560/697932 (37%)]\tLoss: 3.216008\n",
      "Train Epoch: 3 [259200/697932 (37%)]\tLoss: 3.203943\n",
      "Train Epoch: 3 [259840/697932 (37%)]\tLoss: 3.158689\n",
      "Train Epoch: 3 [260480/697932 (37%)]\tLoss: 3.162885\n",
      "Train Epoch: 3 [261120/697932 (37%)]\tLoss: 3.184711\n",
      "Train Epoch: 3 [261760/697932 (38%)]\tLoss: 3.152797\n",
      "Train Epoch: 3 [262400/697932 (38%)]\tLoss: 3.186656\n",
      "Train Epoch: 3 [263040/697932 (38%)]\tLoss: 3.202118\n",
      "Train Epoch: 3 [263680/697932 (38%)]\tLoss: 3.160063\n",
      "Train Epoch: 3 [264320/697932 (38%)]\tLoss: 3.164302\n",
      "Train Epoch: 3 [264960/697932 (38%)]\tLoss: 3.195509\n",
      "Train Epoch: 3 [265600/697932 (38%)]\tLoss: 3.149736\n",
      "Train Epoch: 3 [266240/697932 (38%)]\tLoss: 3.154482\n",
      "Train Epoch: 3 [266880/697932 (38%)]\tLoss: 3.186907\n",
      "Train Epoch: 3 [267520/697932 (38%)]\tLoss: 3.199317\n",
      "Train Epoch: 3 [268160/697932 (38%)]\tLoss: 3.169809\n",
      "Train Epoch: 3 [268800/697932 (39%)]\tLoss: 3.183539\n",
      "Train Epoch: 3 [269440/697932 (39%)]\tLoss: 3.168481\n",
      "Train Epoch: 3 [270080/697932 (39%)]\tLoss: 3.168387\n",
      "Train Epoch: 3 [270720/697932 (39%)]\tLoss: 3.139504\n",
      "Train Epoch: 3 [271360/697932 (39%)]\tLoss: 3.203065\n",
      "Train Epoch: 3 [272000/697932 (39%)]\tLoss: 3.140349\n",
      "Train Epoch: 3 [272640/697932 (39%)]\tLoss: 3.166082\n",
      "Train Epoch: 3 [273280/697932 (39%)]\tLoss: 3.176487\n",
      "Train Epoch: 3 [273920/697932 (39%)]\tLoss: 3.165745\n",
      "Train Epoch: 3 [274560/697932 (39%)]\tLoss: 3.177182\n",
      "Train Epoch: 3 [275200/697932 (39%)]\tLoss: 3.138994\n",
      "Train Epoch: 3 [275840/697932 (40%)]\tLoss: 3.134707\n",
      "Train Epoch: 3 [276480/697932 (40%)]\tLoss: 3.162242\n",
      "Train Epoch: 3 [277120/697932 (40%)]\tLoss: 3.155990\n",
      "Train Epoch: 3 [277760/697932 (40%)]\tLoss: 3.183790\n",
      "Train Epoch: 3 [278400/697932 (40%)]\tLoss: 3.164626\n",
      "Train Epoch: 3 [279040/697932 (40%)]\tLoss: 3.163657\n",
      "Train Epoch: 3 [279680/697932 (40%)]\tLoss: 3.187156\n",
      "Train Epoch: 3 [280320/697932 (40%)]\tLoss: 3.159585\n",
      "Train Epoch: 3 [280960/697932 (40%)]\tLoss: 3.197576\n",
      "Train Epoch: 3 [281600/697932 (40%)]\tLoss: 3.144843\n",
      "Train Epoch: 3 [282240/697932 (40%)]\tLoss: 3.162919\n",
      "Train Epoch: 3 [282880/697932 (41%)]\tLoss: 3.195435\n",
      "Train Epoch: 3 [283520/697932 (41%)]\tLoss: 3.168197\n",
      "Train Epoch: 3 [284160/697932 (41%)]\tLoss: 3.156952\n",
      "Train Epoch: 3 [284800/697932 (41%)]\tLoss: 3.188742\n",
      "Train Epoch: 3 [285440/697932 (41%)]\tLoss: 3.164929\n",
      "Train Epoch: 3 [286080/697932 (41%)]\tLoss: 3.163114\n",
      "Train Epoch: 3 [286720/697932 (41%)]\tLoss: 3.157862\n",
      "Train Epoch: 3 [287360/697932 (41%)]\tLoss: 3.151073\n",
      "Train Epoch: 3 [288000/697932 (41%)]\tLoss: 3.172245\n",
      "Train Epoch: 3 [288640/697932 (41%)]\tLoss: 3.168504\n",
      "Train Epoch: 3 [289280/697932 (41%)]\tLoss: 3.159909\n",
      "Train Epoch: 3 [289920/697932 (42%)]\tLoss: 3.177539\n",
      "Train Epoch: 3 [290560/697932 (42%)]\tLoss: 3.169358\n",
      "Train Epoch: 3 [291200/697932 (42%)]\tLoss: 3.169995\n",
      "Train Epoch: 3 [291840/697932 (42%)]\tLoss: 3.185734\n",
      "Train Epoch: 3 [292480/697932 (42%)]\tLoss: 3.159822\n",
      "Train Epoch: 3 [293120/697932 (42%)]\tLoss: 3.165937\n",
      "Train Epoch: 3 [293760/697932 (42%)]\tLoss: 3.184706\n",
      "Train Epoch: 3 [294400/697932 (42%)]\tLoss: 3.176187\n",
      "Train Epoch: 3 [295040/697932 (42%)]\tLoss: 3.187710\n",
      "Train Epoch: 3 [295680/697932 (42%)]\tLoss: 3.164207\n",
      "Train Epoch: 3 [296320/697932 (42%)]\tLoss: 3.140611\n",
      "Train Epoch: 3 [296960/697932 (43%)]\tLoss: 3.184077\n",
      "Train Epoch: 3 [297600/697932 (43%)]\tLoss: 3.166702\n",
      "Train Epoch: 3 [298240/697932 (43%)]\tLoss: 3.160130\n",
      "Train Epoch: 3 [298880/697932 (43%)]\tLoss: 3.159833\n",
      "Train Epoch: 3 [299520/697932 (43%)]\tLoss: 3.168839\n",
      "Train Epoch: 3 [300160/697932 (43%)]\tLoss: 3.165239\n",
      "Train Epoch: 3 [300800/697932 (43%)]\tLoss: 3.164942\n",
      "Train Epoch: 3 [301440/697932 (43%)]\tLoss: 3.148552\n",
      "Train Epoch: 3 [302080/697932 (43%)]\tLoss: 3.114618\n",
      "Train Epoch: 3 [302720/697932 (43%)]\tLoss: 3.172671\n",
      "Train Epoch: 3 [303360/697932 (43%)]\tLoss: 3.184953\n",
      "Train Epoch: 3 [304000/697932 (44%)]\tLoss: 3.176569\n",
      "Train Epoch: 3 [304640/697932 (44%)]\tLoss: 3.171354\n",
      "Train Epoch: 3 [305280/697932 (44%)]\tLoss: 3.164546\n",
      "Train Epoch: 3 [305920/697932 (44%)]\tLoss: 3.165925\n",
      "Train Epoch: 3 [306560/697932 (44%)]\tLoss: 3.145568\n",
      "Train Epoch: 3 [307200/697932 (44%)]\tLoss: 3.169598\n",
      "Train Epoch: 3 [307840/697932 (44%)]\tLoss: 3.176582\n",
      "Train Epoch: 3 [308480/697932 (44%)]\tLoss: 3.146013\n",
      "Train Epoch: 3 [309120/697932 (44%)]\tLoss: 3.164224\n",
      "Train Epoch: 3 [309760/697932 (44%)]\tLoss: 3.142774\n",
      "Train Epoch: 3 [310400/697932 (44%)]\tLoss: 3.156170\n",
      "Train Epoch: 3 [311040/697932 (45%)]\tLoss: 3.179285\n",
      "Train Epoch: 3 [311680/697932 (45%)]\tLoss: 3.182356\n",
      "Train Epoch: 3 [312320/697932 (45%)]\tLoss: 3.169611\n",
      "Train Epoch: 3 [312960/697932 (45%)]\tLoss: 3.144917\n",
      "Train Epoch: 3 [313600/697932 (45%)]\tLoss: 3.181077\n",
      "Train Epoch: 3 [314240/697932 (45%)]\tLoss: 3.148626\n",
      "Train Epoch: 3 [314880/697932 (45%)]\tLoss: 3.162798\n",
      "Train Epoch: 3 [315520/697932 (45%)]\tLoss: 3.168846\n",
      "Train Epoch: 3 [316160/697932 (45%)]\tLoss: 3.200872\n",
      "Train Epoch: 3 [316800/697932 (45%)]\tLoss: 3.193100\n",
      "Train Epoch: 3 [317440/697932 (45%)]\tLoss: 3.161714\n",
      "Train Epoch: 3 [318080/697932 (46%)]\tLoss: 3.188503\n",
      "Train Epoch: 3 [318720/697932 (46%)]\tLoss: 3.157693\n",
      "Train Epoch: 3 [319360/697932 (46%)]\tLoss: 3.167798\n",
      "Train Epoch: 3 [320000/697932 (46%)]\tLoss: 3.176279\n",
      "Train Epoch: 3 [320640/697932 (46%)]\tLoss: 3.183638\n",
      "Train Epoch: 3 [321280/697932 (46%)]\tLoss: 3.182810\n",
      "Train Epoch: 3 [321920/697932 (46%)]\tLoss: 3.176230\n",
      "Train Epoch: 3 [322560/697932 (46%)]\tLoss: 3.181616\n",
      "Train Epoch: 3 [323200/697932 (46%)]\tLoss: 3.140445\n",
      "Train Epoch: 3 [323840/697932 (46%)]\tLoss: 3.163630\n",
      "Train Epoch: 3 [324480/697932 (46%)]\tLoss: 3.166793\n",
      "Train Epoch: 3 [325120/697932 (47%)]\tLoss: 3.175439\n",
      "Train Epoch: 3 [325760/697932 (47%)]\tLoss: 3.153870\n",
      "Train Epoch: 3 [326400/697932 (47%)]\tLoss: 3.173563\n",
      "Train Epoch: 3 [327040/697932 (47%)]\tLoss: 3.143050\n",
      "Train Epoch: 3 [327680/697932 (47%)]\tLoss: 3.166564\n",
      "Train Epoch: 3 [328320/697932 (47%)]\tLoss: 3.209193\n",
      "Train Epoch: 3 [328960/697932 (47%)]\tLoss: 3.159247\n",
      "Train Epoch: 3 [329600/697932 (47%)]\tLoss: 3.153318\n",
      "Train Epoch: 3 [330240/697932 (47%)]\tLoss: 3.144662\n",
      "Train Epoch: 3 [330880/697932 (47%)]\tLoss: 3.175285\n",
      "Train Epoch: 3 [331520/697932 (47%)]\tLoss: 3.170000\n",
      "Train Epoch: 3 [332160/697932 (48%)]\tLoss: 3.162046\n",
      "Train Epoch: 3 [332800/697932 (48%)]\tLoss: 3.142614\n",
      "Train Epoch: 3 [333440/697932 (48%)]\tLoss: 3.175457\n",
      "Train Epoch: 3 [334080/697932 (48%)]\tLoss: 3.162385\n",
      "Train Epoch: 3 [334720/697932 (48%)]\tLoss: 3.171803\n",
      "Train Epoch: 3 [335360/697932 (48%)]\tLoss: 3.168870\n",
      "Train Epoch: 3 [336000/697932 (48%)]\tLoss: 3.174050\n",
      "Train Epoch: 3 [336640/697932 (48%)]\tLoss: 3.178432\n",
      "Train Epoch: 3 [337280/697932 (48%)]\tLoss: 3.172330\n",
      "Train Epoch: 3 [337920/697932 (48%)]\tLoss: 3.184071\n",
      "Train Epoch: 3 [338560/697932 (49%)]\tLoss: 3.164986\n",
      "Train Epoch: 3 [339200/697932 (49%)]\tLoss: 3.183750\n",
      "Train Epoch: 3 [339840/697932 (49%)]\tLoss: 3.151872\n",
      "Train Epoch: 3 [340480/697932 (49%)]\tLoss: 3.164120\n",
      "Train Epoch: 3 [341120/697932 (49%)]\tLoss: 3.157682\n",
      "Train Epoch: 3 [341760/697932 (49%)]\tLoss: 3.177687\n",
      "Train Epoch: 3 [342400/697932 (49%)]\tLoss: 3.170285\n",
      "Train Epoch: 3 [343040/697932 (49%)]\tLoss: 3.173578\n",
      "Train Epoch: 3 [343680/697932 (49%)]\tLoss: 3.170509\n",
      "Train Epoch: 3 [344320/697932 (49%)]\tLoss: 3.181695\n",
      "Train Epoch: 3 [344960/697932 (49%)]\tLoss: 3.161564\n",
      "Train Epoch: 3 [345600/697932 (50%)]\tLoss: 3.150118\n",
      "Train Epoch: 3 [346240/697932 (50%)]\tLoss: 3.187087\n",
      "Train Epoch: 3 [346880/697932 (50%)]\tLoss: 3.167785\n",
      "Train Epoch: 3 [347520/697932 (50%)]\tLoss: 3.146597\n",
      "Train Epoch: 3 [348160/697932 (50%)]\tLoss: 3.193992\n",
      "Train Epoch: 3 [348800/697932 (50%)]\tLoss: 3.175211\n",
      "Train Epoch: 3 [349440/697932 (50%)]\tLoss: 3.161114\n",
      "Train Epoch: 3 [350080/697932 (50%)]\tLoss: 3.160460\n",
      "Train Epoch: 3 [350720/697932 (50%)]\tLoss: 3.202275\n",
      "Train Epoch: 3 [351360/697932 (50%)]\tLoss: 3.171366\n",
      "Train Epoch: 3 [352000/697932 (50%)]\tLoss: 3.197908\n",
      "Train Epoch: 3 [352640/697932 (51%)]\tLoss: 3.209055\n",
      "Train Epoch: 3 [353280/697932 (51%)]\tLoss: 3.134351\n",
      "Train Epoch: 3 [353920/697932 (51%)]\tLoss: 3.143079\n",
      "Train Epoch: 3 [354560/697932 (51%)]\tLoss: 3.160335\n",
      "Train Epoch: 3 [355200/697932 (51%)]\tLoss: 3.186161\n",
      "Train Epoch: 3 [355840/697932 (51%)]\tLoss: 3.170011\n",
      "Train Epoch: 3 [356480/697932 (51%)]\tLoss: 3.195736\n",
      "Train Epoch: 3 [357120/697932 (51%)]\tLoss: 3.140352\n",
      "Train Epoch: 3 [357760/697932 (51%)]\tLoss: 3.154210\n",
      "Train Epoch: 3 [358400/697932 (51%)]\tLoss: 3.158214\n",
      "Train Epoch: 3 [359040/697932 (51%)]\tLoss: 3.171597\n",
      "Train Epoch: 3 [359680/697932 (52%)]\tLoss: 3.157935\n",
      "Train Epoch: 3 [360320/697932 (52%)]\tLoss: 3.178884\n",
      "Train Epoch: 3 [360960/697932 (52%)]\tLoss: 3.169510\n",
      "Train Epoch: 3 [361600/697932 (52%)]\tLoss: 3.143534\n",
      "Train Epoch: 3 [362240/697932 (52%)]\tLoss: 3.164940\n",
      "Train Epoch: 3 [362880/697932 (52%)]\tLoss: 3.158205\n",
      "Train Epoch: 3 [363520/697932 (52%)]\tLoss: 3.153555\n",
      "Train Epoch: 3 [364160/697932 (52%)]\tLoss: 3.164019\n",
      "Train Epoch: 3 [364800/697932 (52%)]\tLoss: 3.183209\n",
      "Train Epoch: 3 [365440/697932 (52%)]\tLoss: 3.141386\n",
      "Train Epoch: 3 [366080/697932 (52%)]\tLoss: 3.168124\n",
      "Train Epoch: 3 [366720/697932 (53%)]\tLoss: 3.190689\n",
      "Train Epoch: 3 [367360/697932 (53%)]\tLoss: 3.170142\n",
      "Train Epoch: 3 [368000/697932 (53%)]\tLoss: 3.155766\n",
      "Train Epoch: 3 [368640/697932 (53%)]\tLoss: 3.133639\n",
      "Train Epoch: 3 [369280/697932 (53%)]\tLoss: 3.199476\n",
      "Train Epoch: 3 [369920/697932 (53%)]\tLoss: 3.171133\n",
      "Train Epoch: 3 [370560/697932 (53%)]\tLoss: 3.179411\n",
      "Train Epoch: 3 [371200/697932 (53%)]\tLoss: 3.162000\n",
      "Train Epoch: 3 [371840/697932 (53%)]\tLoss: 3.181371\n",
      "Train Epoch: 3 [372480/697932 (53%)]\tLoss: 3.117723\n",
      "Train Epoch: 3 [373120/697932 (53%)]\tLoss: 3.168147\n",
      "Train Epoch: 3 [373760/697932 (54%)]\tLoss: 3.188474\n",
      "Train Epoch: 3 [374400/697932 (54%)]\tLoss: 3.204583\n",
      "Train Epoch: 3 [375040/697932 (54%)]\tLoss: 3.189751\n",
      "Train Epoch: 3 [375680/697932 (54%)]\tLoss: 3.185274\n",
      "Train Epoch: 3 [376320/697932 (54%)]\tLoss: 3.146322\n",
      "Train Epoch: 3 [376960/697932 (54%)]\tLoss: 3.160161\n",
      "Train Epoch: 3 [377600/697932 (54%)]\tLoss: 3.218496\n",
      "Train Epoch: 3 [378240/697932 (54%)]\tLoss: 3.185656\n",
      "Train Epoch: 3 [378880/697932 (54%)]\tLoss: 3.166091\n",
      "Train Epoch: 3 [379520/697932 (54%)]\tLoss: 3.175070\n",
      "Train Epoch: 3 [380160/697932 (54%)]\tLoss: 3.164464\n",
      "Train Epoch: 3 [380800/697932 (55%)]\tLoss: 3.163210\n",
      "Train Epoch: 3 [381440/697932 (55%)]\tLoss: 3.181497\n",
      "Train Epoch: 3 [382080/697932 (55%)]\tLoss: 3.172207\n",
      "Train Epoch: 3 [382720/697932 (55%)]\tLoss: 3.168281\n",
      "Train Epoch: 3 [383360/697932 (55%)]\tLoss: 3.142255\n",
      "Train Epoch: 3 [384000/697932 (55%)]\tLoss: 3.169353\n",
      "Train Epoch: 3 [384640/697932 (55%)]\tLoss: 3.173460\n",
      "Train Epoch: 3 [385280/697932 (55%)]\tLoss: 3.174659\n",
      "Train Epoch: 3 [385920/697932 (55%)]\tLoss: 3.160591\n",
      "Train Epoch: 3 [386560/697932 (55%)]\tLoss: 3.157038\n",
      "Train Epoch: 3 [387200/697932 (55%)]\tLoss: 3.168797\n",
      "Train Epoch: 3 [387840/697932 (56%)]\tLoss: 3.179261\n",
      "Train Epoch: 3 [388480/697932 (56%)]\tLoss: 3.165810\n",
      "Train Epoch: 3 [389120/697932 (56%)]\tLoss: 3.171739\n",
      "Train Epoch: 3 [389760/697932 (56%)]\tLoss: 3.182231\n",
      "Train Epoch: 3 [390400/697932 (56%)]\tLoss: 3.132133\n",
      "Train Epoch: 3 [391040/697932 (56%)]\tLoss: 3.173442\n",
      "Train Epoch: 3 [391680/697932 (56%)]\tLoss: 3.165035\n",
      "Train Epoch: 3 [392320/697932 (56%)]\tLoss: 3.200740\n",
      "Train Epoch: 3 [392960/697932 (56%)]\tLoss: 3.181205\n",
      "Train Epoch: 3 [393600/697932 (56%)]\tLoss: 3.142594\n",
      "Train Epoch: 3 [394240/697932 (56%)]\tLoss: 3.190222\n",
      "Train Epoch: 3 [394880/697932 (57%)]\tLoss: 3.153222\n",
      "Train Epoch: 3 [395520/697932 (57%)]\tLoss: 3.194491\n",
      "Train Epoch: 3 [396160/697932 (57%)]\tLoss: 3.185720\n",
      "Train Epoch: 3 [396800/697932 (57%)]\tLoss: 3.216786\n",
      "Train Epoch: 3 [397440/697932 (57%)]\tLoss: 3.165244\n",
      "Train Epoch: 3 [398080/697932 (57%)]\tLoss: 3.181391\n",
      "Train Epoch: 3 [398720/697932 (57%)]\tLoss: 3.181781\n",
      "Train Epoch: 3 [399360/697932 (57%)]\tLoss: 3.192619\n",
      "Train Epoch: 3 [400000/697932 (57%)]\tLoss: 3.195282\n",
      "Train Epoch: 3 [400640/697932 (57%)]\tLoss: 3.173284\n",
      "Train Epoch: 3 [401280/697932 (57%)]\tLoss: 3.173384\n",
      "Train Epoch: 3 [401920/697932 (58%)]\tLoss: 3.197371\n",
      "Train Epoch: 3 [402560/697932 (58%)]\tLoss: 3.156112\n",
      "Train Epoch: 3 [403200/697932 (58%)]\tLoss: 3.144552\n",
      "Train Epoch: 3 [403840/697932 (58%)]\tLoss: 3.136008\n",
      "Train Epoch: 3 [404480/697932 (58%)]\tLoss: 3.152265\n",
      "Train Epoch: 3 [405120/697932 (58%)]\tLoss: 3.185416\n",
      "Train Epoch: 3 [405760/697932 (58%)]\tLoss: 3.153840\n",
      "Train Epoch: 3 [406400/697932 (58%)]\tLoss: 3.174529\n",
      "Train Epoch: 3 [407040/697932 (58%)]\tLoss: 3.156579\n",
      "Train Epoch: 3 [407680/697932 (58%)]\tLoss: 3.148682\n",
      "Train Epoch: 3 [408320/697932 (58%)]\tLoss: 3.154474\n",
      "Train Epoch: 3 [408960/697932 (59%)]\tLoss: 3.164069\n",
      "Train Epoch: 3 [409600/697932 (59%)]\tLoss: 3.139147\n",
      "Train Epoch: 3 [410240/697932 (59%)]\tLoss: 3.188684\n",
      "Train Epoch: 3 [410880/697932 (59%)]\tLoss: 3.223451\n",
      "Train Epoch: 3 [411520/697932 (59%)]\tLoss: 3.156648\n",
      "Train Epoch: 3 [412160/697932 (59%)]\tLoss: 3.163924\n",
      "Train Epoch: 3 [412800/697932 (59%)]\tLoss: 3.168554\n",
      "Train Epoch: 3 [413440/697932 (59%)]\tLoss: 3.190663\n",
      "Train Epoch: 3 [414080/697932 (59%)]\tLoss: 3.159278\n",
      "Train Epoch: 3 [414720/697932 (59%)]\tLoss: 3.177006\n",
      "Train Epoch: 3 [415360/697932 (60%)]\tLoss: 3.176153\n",
      "Train Epoch: 3 [416000/697932 (60%)]\tLoss: 3.157304\n",
      "Train Epoch: 3 [416640/697932 (60%)]\tLoss: 3.162023\n",
      "Train Epoch: 3 [417280/697932 (60%)]\tLoss: 3.159458\n",
      "Train Epoch: 3 [417920/697932 (60%)]\tLoss: 3.173620\n",
      "Train Epoch: 3 [418560/697932 (60%)]\tLoss: 3.166323\n",
      "Train Epoch: 3 [419200/697932 (60%)]\tLoss: 3.208590\n",
      "Train Epoch: 3 [419840/697932 (60%)]\tLoss: 3.168232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [420480/697932 (60%)]\tLoss: 3.165266\n",
      "Train Epoch: 3 [421120/697932 (60%)]\tLoss: 3.193018\n",
      "Train Epoch: 3 [421760/697932 (60%)]\tLoss: 3.176629\n",
      "Train Epoch: 3 [422400/697932 (61%)]\tLoss: 3.172321\n",
      "Train Epoch: 3 [423040/697932 (61%)]\tLoss: 3.145997\n",
      "Train Epoch: 3 [423680/697932 (61%)]\tLoss: 3.137609\n",
      "Train Epoch: 3 [424320/697932 (61%)]\tLoss: 3.145157\n",
      "Train Epoch: 3 [424960/697932 (61%)]\tLoss: 3.194621\n",
      "Train Epoch: 3 [425600/697932 (61%)]\tLoss: 3.202763\n",
      "Train Epoch: 3 [426240/697932 (61%)]\tLoss: 3.146434\n",
      "Train Epoch: 3 [426880/697932 (61%)]\tLoss: 3.170730\n",
      "Train Epoch: 3 [427520/697932 (61%)]\tLoss: 3.198298\n",
      "Train Epoch: 3 [428160/697932 (61%)]\tLoss: 3.189724\n",
      "Train Epoch: 3 [428800/697932 (61%)]\tLoss: 3.185110\n",
      "Train Epoch: 3 [429440/697932 (62%)]\tLoss: 3.143118\n",
      "Train Epoch: 3 [430080/697932 (62%)]\tLoss: 3.184456\n",
      "Train Epoch: 3 [430720/697932 (62%)]\tLoss: 3.208333\n",
      "Train Epoch: 3 [431360/697932 (62%)]\tLoss: 3.177222\n",
      "Train Epoch: 3 [432000/697932 (62%)]\tLoss: 3.174193\n",
      "Train Epoch: 3 [432640/697932 (62%)]\tLoss: 3.170010\n",
      "Train Epoch: 3 [433280/697932 (62%)]\tLoss: 3.172316\n",
      "Train Epoch: 3 [433920/697932 (62%)]\tLoss: 3.156000\n",
      "Train Epoch: 3 [434560/697932 (62%)]\tLoss: 3.183729\n",
      "Train Epoch: 3 [435200/697932 (62%)]\tLoss: 3.155348\n",
      "Train Epoch: 3 [435840/697932 (62%)]\tLoss: 3.187097\n",
      "Train Epoch: 3 [436480/697932 (63%)]\tLoss: 3.198201\n",
      "Train Epoch: 3 [437120/697932 (63%)]\tLoss: 3.141870\n",
      "Train Epoch: 3 [437760/697932 (63%)]\tLoss: 3.191890\n",
      "Train Epoch: 3 [438400/697932 (63%)]\tLoss: 3.155772\n",
      "Train Epoch: 3 [439040/697932 (63%)]\tLoss: 3.167172\n",
      "Train Epoch: 3 [439680/697932 (63%)]\tLoss: 3.173664\n",
      "Train Epoch: 3 [440320/697932 (63%)]\tLoss: 3.162563\n",
      "Train Epoch: 3 [440960/697932 (63%)]\tLoss: 3.163469\n",
      "Train Epoch: 3 [441600/697932 (63%)]\tLoss: 3.187127\n",
      "Train Epoch: 3 [442240/697932 (63%)]\tLoss: 3.170339\n",
      "Train Epoch: 3 [442880/697932 (63%)]\tLoss: 3.189717\n",
      "Train Epoch: 3 [443520/697932 (64%)]\tLoss: 3.200305\n",
      "Train Epoch: 3 [444160/697932 (64%)]\tLoss: 3.175946\n",
      "Train Epoch: 3 [444800/697932 (64%)]\tLoss: 3.190440\n",
      "Train Epoch: 3 [445440/697932 (64%)]\tLoss: 3.145313\n",
      "Train Epoch: 3 [446080/697932 (64%)]\tLoss: 3.160826\n",
      "Train Epoch: 3 [446720/697932 (64%)]\tLoss: 3.171737\n",
      "Train Epoch: 3 [447360/697932 (64%)]\tLoss: 3.189894\n",
      "Train Epoch: 3 [448000/697932 (64%)]\tLoss: 3.187829\n",
      "Train Epoch: 3 [448640/697932 (64%)]\tLoss: 3.176211\n",
      "Train Epoch: 3 [449280/697932 (64%)]\tLoss: 3.175418\n",
      "Train Epoch: 3 [449920/697932 (64%)]\tLoss: 3.168061\n",
      "Train Epoch: 3 [450560/697932 (65%)]\tLoss: 3.166616\n",
      "Train Epoch: 3 [451200/697932 (65%)]\tLoss: 3.175303\n",
      "Train Epoch: 3 [451840/697932 (65%)]\tLoss: 3.212269\n",
      "Train Epoch: 3 [452480/697932 (65%)]\tLoss: 3.203896\n",
      "Train Epoch: 3 [453120/697932 (65%)]\tLoss: 3.175615\n",
      "Train Epoch: 3 [453760/697932 (65%)]\tLoss: 3.178303\n",
      "Train Epoch: 3 [454400/697932 (65%)]\tLoss: 3.196976\n",
      "Train Epoch: 3 [455040/697932 (65%)]\tLoss: 3.193186\n",
      "Train Epoch: 3 [455680/697932 (65%)]\tLoss: 3.159947\n",
      "Train Epoch: 3 [456320/697932 (65%)]\tLoss: 3.190899\n",
      "Train Epoch: 3 [456960/697932 (65%)]\tLoss: 3.150489\n",
      "Train Epoch: 3 [457600/697932 (66%)]\tLoss: 3.154839\n",
      "Train Epoch: 3 [458240/697932 (66%)]\tLoss: 3.148095\n",
      "Train Epoch: 3 [458880/697932 (66%)]\tLoss: 3.175846\n",
      "Train Epoch: 3 [459520/697932 (66%)]\tLoss: 3.160579\n",
      "Train Epoch: 3 [460160/697932 (66%)]\tLoss: 3.168763\n",
      "Train Epoch: 3 [460800/697932 (66%)]\tLoss: 3.189842\n",
      "Train Epoch: 3 [461440/697932 (66%)]\tLoss: 3.163530\n",
      "Train Epoch: 3 [462080/697932 (66%)]\tLoss: 3.154052\n",
      "Train Epoch: 3 [462720/697932 (66%)]\tLoss: 3.160634\n",
      "Train Epoch: 3 [463360/697932 (66%)]\tLoss: 3.191002\n",
      "Train Epoch: 3 [464000/697932 (66%)]\tLoss: 3.179606\n",
      "Train Epoch: 3 [464640/697932 (67%)]\tLoss: 3.167938\n",
      "Train Epoch: 3 [465280/697932 (67%)]\tLoss: 3.172397\n",
      "Train Epoch: 3 [465920/697932 (67%)]\tLoss: 3.193892\n",
      "Train Epoch: 3 [466560/697932 (67%)]\tLoss: 3.181405\n",
      "Train Epoch: 3 [467200/697932 (67%)]\tLoss: 3.170496\n",
      "Train Epoch: 3 [467840/697932 (67%)]\tLoss: 3.173186\n",
      "Train Epoch: 3 [468480/697932 (67%)]\tLoss: 3.201262\n",
      "Train Epoch: 3 [469120/697932 (67%)]\tLoss: 3.204299\n",
      "Train Epoch: 3 [469760/697932 (67%)]\tLoss: 3.174046\n",
      "Train Epoch: 3 [470400/697932 (67%)]\tLoss: 3.161695\n",
      "Train Epoch: 3 [471040/697932 (67%)]\tLoss: 3.163443\n",
      "Train Epoch: 3 [471680/697932 (68%)]\tLoss: 3.160784\n",
      "Train Epoch: 3 [472320/697932 (68%)]\tLoss: 3.161988\n",
      "Train Epoch: 3 [472960/697932 (68%)]\tLoss: 3.138945\n",
      "Train Epoch: 3 [473600/697932 (68%)]\tLoss: 3.189091\n",
      "Train Epoch: 3 [474240/697932 (68%)]\tLoss: 3.145149\n",
      "Train Epoch: 3 [474880/697932 (68%)]\tLoss: 3.182104\n",
      "Train Epoch: 3 [475520/697932 (68%)]\tLoss: 3.162992\n",
      "Train Epoch: 3 [476160/697932 (68%)]\tLoss: 3.187610\n",
      "Train Epoch: 3 [476800/697932 (68%)]\tLoss: 3.143379\n",
      "Train Epoch: 3 [477440/697932 (68%)]\tLoss: 3.187287\n",
      "Train Epoch: 3 [478080/697932 (68%)]\tLoss: 3.221596\n",
      "Train Epoch: 3 [478720/697932 (69%)]\tLoss: 3.186499\n",
      "Train Epoch: 3 [479360/697932 (69%)]\tLoss: 3.167043\n",
      "Train Epoch: 3 [480000/697932 (69%)]\tLoss: 3.162270\n",
      "Train Epoch: 3 [480640/697932 (69%)]\tLoss: 3.172215\n",
      "Train Epoch: 3 [481280/697932 (69%)]\tLoss: 3.168802\n",
      "Train Epoch: 3 [481920/697932 (69%)]\tLoss: 3.195677\n",
      "Train Epoch: 3 [482560/697932 (69%)]\tLoss: 3.157284\n",
      "Train Epoch: 3 [483200/697932 (69%)]\tLoss: 3.170724\n",
      "Train Epoch: 3 [483840/697932 (69%)]\tLoss: 3.153047\n",
      "Train Epoch: 3 [484480/697932 (69%)]\tLoss: 3.146415\n",
      "Train Epoch: 3 [485120/697932 (70%)]\tLoss: 3.156026\n",
      "Train Epoch: 3 [485760/697932 (70%)]\tLoss: 3.152081\n",
      "Train Epoch: 3 [486400/697932 (70%)]\tLoss: 3.160652\n",
      "Train Epoch: 3 [487040/697932 (70%)]\tLoss: 3.156991\n",
      "Train Epoch: 3 [487680/697932 (70%)]\tLoss: 3.184605\n",
      "Train Epoch: 3 [488320/697932 (70%)]\tLoss: 3.187727\n",
      "Train Epoch: 3 [488960/697932 (70%)]\tLoss: 3.173532\n",
      "Train Epoch: 3 [489600/697932 (70%)]\tLoss: 3.166861\n",
      "Train Epoch: 3 [490240/697932 (70%)]\tLoss: 3.196501\n",
      "Train Epoch: 3 [490880/697932 (70%)]\tLoss: 3.167352\n",
      "Train Epoch: 3 [491520/697932 (70%)]\tLoss: 3.159420\n",
      "Train Epoch: 3 [492160/697932 (71%)]\tLoss: 3.177381\n",
      "Train Epoch: 3 [492800/697932 (71%)]\tLoss: 3.194443\n",
      "Train Epoch: 3 [493440/697932 (71%)]\tLoss: 3.185250\n",
      "Train Epoch: 3 [494080/697932 (71%)]\tLoss: 3.184586\n",
      "Train Epoch: 3 [494720/697932 (71%)]\tLoss: 3.147882\n",
      "Train Epoch: 3 [495360/697932 (71%)]\tLoss: 3.171295\n",
      "Train Epoch: 3 [496000/697932 (71%)]\tLoss: 3.211783\n",
      "Train Epoch: 3 [496640/697932 (71%)]\tLoss: 3.151003\n",
      "Train Epoch: 3 [497280/697932 (71%)]\tLoss: 3.156250\n",
      "Train Epoch: 3 [497920/697932 (71%)]\tLoss: 3.163528\n",
      "Train Epoch: 3 [498560/697932 (71%)]\tLoss: 3.153376\n",
      "Train Epoch: 3 [499200/697932 (72%)]\tLoss: 3.163211\n",
      "Train Epoch: 3 [499840/697932 (72%)]\tLoss: 3.193042\n",
      "Train Epoch: 3 [500480/697932 (72%)]\tLoss: 3.185787\n",
      "Train Epoch: 3 [501120/697932 (72%)]\tLoss: 3.162061\n",
      "Train Epoch: 3 [501760/697932 (72%)]\tLoss: 3.164871\n",
      "Train Epoch: 3 [502400/697932 (72%)]\tLoss: 3.144971\n",
      "Train Epoch: 3 [503040/697932 (72%)]\tLoss: 3.160954\n",
      "Train Epoch: 3 [503680/697932 (72%)]\tLoss: 3.162516\n",
      "Train Epoch: 3 [504320/697932 (72%)]\tLoss: 3.179494\n",
      "Train Epoch: 3 [504960/697932 (72%)]\tLoss: 3.141101\n",
      "Train Epoch: 3 [505600/697932 (72%)]\tLoss: 3.130973\n",
      "Train Epoch: 3 [506240/697932 (73%)]\tLoss: 3.191567\n",
      "Train Epoch: 3 [506880/697932 (73%)]\tLoss: 3.156515\n",
      "Train Epoch: 3 [507520/697932 (73%)]\tLoss: 3.181921\n",
      "Train Epoch: 3 [508160/697932 (73%)]\tLoss: 3.164759\n",
      "Train Epoch: 3 [508800/697932 (73%)]\tLoss: 3.178661\n",
      "Train Epoch: 3 [509440/697932 (73%)]\tLoss: 3.132735\n",
      "Train Epoch: 3 [510080/697932 (73%)]\tLoss: 3.183362\n",
      "Train Epoch: 3 [510720/697932 (73%)]\tLoss: 3.190789\n",
      "Train Epoch: 3 [511360/697932 (73%)]\tLoss: 3.163081\n",
      "Train Epoch: 3 [512000/697932 (73%)]\tLoss: 3.158112\n",
      "Train Epoch: 3 [512640/697932 (73%)]\tLoss: 3.185485\n",
      "Train Epoch: 3 [513280/697932 (74%)]\tLoss: 3.196645\n",
      "Train Epoch: 3 [513920/697932 (74%)]\tLoss: 3.152783\n",
      "Train Epoch: 3 [514560/697932 (74%)]\tLoss: 3.171766\n",
      "Train Epoch: 3 [515200/697932 (74%)]\tLoss: 3.159153\n",
      "Train Epoch: 3 [515840/697932 (74%)]\tLoss: 3.146849\n",
      "Train Epoch: 3 [516480/697932 (74%)]\tLoss: 3.202257\n",
      "Train Epoch: 3 [517120/697932 (74%)]\tLoss: 3.189464\n",
      "Train Epoch: 3 [517760/697932 (74%)]\tLoss: 3.150701\n",
      "Train Epoch: 3 [518400/697932 (74%)]\tLoss: 3.179977\n",
      "Train Epoch: 3 [519040/697932 (74%)]\tLoss: 3.149909\n",
      "Train Epoch: 3 [519680/697932 (74%)]\tLoss: 3.173300\n",
      "Train Epoch: 3 [520320/697932 (75%)]\tLoss: 3.141104\n",
      "Train Epoch: 3 [520960/697932 (75%)]\tLoss: 3.172358\n",
      "Train Epoch: 3 [521600/697932 (75%)]\tLoss: 3.165812\n",
      "Train Epoch: 3 [522240/697932 (75%)]\tLoss: 3.192899\n",
      "Train Epoch: 3 [522880/697932 (75%)]\tLoss: 3.165810\n",
      "Train Epoch: 3 [523520/697932 (75%)]\tLoss: 3.132821\n",
      "Train Epoch: 3 [524160/697932 (75%)]\tLoss: 3.164072\n",
      "Train Epoch: 3 [524800/697932 (75%)]\tLoss: 3.183823\n",
      "Train Epoch: 3 [525440/697932 (75%)]\tLoss: 3.147231\n",
      "Train Epoch: 3 [526080/697932 (75%)]\tLoss: 3.147732\n",
      "Train Epoch: 3 [526720/697932 (75%)]\tLoss: 3.190525\n",
      "Train Epoch: 3 [527360/697932 (76%)]\tLoss: 3.210291\n",
      "Train Epoch: 3 [528000/697932 (76%)]\tLoss: 3.122603\n",
      "Train Epoch: 3 [528640/697932 (76%)]\tLoss: 3.153035\n",
      "Train Epoch: 3 [529280/697932 (76%)]\tLoss: 3.166589\n",
      "Train Epoch: 3 [529920/697932 (76%)]\tLoss: 3.167045\n",
      "Train Epoch: 3 [530560/697932 (76%)]\tLoss: 3.205267\n",
      "Train Epoch: 3 [531200/697932 (76%)]\tLoss: 3.189328\n",
      "Train Epoch: 3 [531840/697932 (76%)]\tLoss: 3.168142\n",
      "Train Epoch: 3 [532480/697932 (76%)]\tLoss: 3.173106\n",
      "Train Epoch: 3 [533120/697932 (76%)]\tLoss: 3.179370\n",
      "Train Epoch: 3 [533760/697932 (76%)]\tLoss: 3.201461\n",
      "Train Epoch: 3 [534400/697932 (77%)]\tLoss: 3.154585\n",
      "Train Epoch: 3 [535040/697932 (77%)]\tLoss: 3.179146\n",
      "Train Epoch: 3 [535680/697932 (77%)]\tLoss: 3.162538\n",
      "Train Epoch: 3 [536320/697932 (77%)]\tLoss: 3.196512\n",
      "Train Epoch: 3 [536960/697932 (77%)]\tLoss: 3.185538\n",
      "Train Epoch: 3 [537600/697932 (77%)]\tLoss: 3.163029\n",
      "Train Epoch: 3 [538240/697932 (77%)]\tLoss: 3.128289\n",
      "Train Epoch: 3 [538880/697932 (77%)]\tLoss: 3.177137\n",
      "Train Epoch: 3 [539520/697932 (77%)]\tLoss: 3.154399\n",
      "Train Epoch: 3 [540160/697932 (77%)]\tLoss: 3.177750\n",
      "Train Epoch: 3 [540800/697932 (77%)]\tLoss: 3.154399\n",
      "Train Epoch: 3 [541440/697932 (78%)]\tLoss: 3.168515\n",
      "Train Epoch: 3 [542080/697932 (78%)]\tLoss: 3.197714\n",
      "Train Epoch: 3 [542720/697932 (78%)]\tLoss: 3.183492\n",
      "Train Epoch: 3 [543360/697932 (78%)]\tLoss: 3.186661\n",
      "Train Epoch: 3 [544000/697932 (78%)]\tLoss: 3.181462\n",
      "Train Epoch: 3 [544640/697932 (78%)]\tLoss: 3.167752\n",
      "Train Epoch: 3 [545280/697932 (78%)]\tLoss: 3.162493\n",
      "Train Epoch: 3 [545920/697932 (78%)]\tLoss: 3.173203\n",
      "Train Epoch: 3 [546560/697932 (78%)]\tLoss: 3.158372\n",
      "Train Epoch: 3 [547200/697932 (78%)]\tLoss: 3.162694\n",
      "Train Epoch: 3 [547840/697932 (78%)]\tLoss: 3.191983\n",
      "Train Epoch: 3 [548480/697932 (79%)]\tLoss: 3.137743\n",
      "Train Epoch: 3 [549120/697932 (79%)]\tLoss: 3.167236\n",
      "Train Epoch: 3 [549760/697932 (79%)]\tLoss: 3.184669\n",
      "Train Epoch: 3 [550400/697932 (79%)]\tLoss: 3.165620\n",
      "Train Epoch: 3 [551040/697932 (79%)]\tLoss: 3.171966\n",
      "Train Epoch: 3 [551680/697932 (79%)]\tLoss: 3.145842\n",
      "Train Epoch: 3 [552320/697932 (79%)]\tLoss: 3.187647\n",
      "Train Epoch: 3 [552960/697932 (79%)]\tLoss: 3.186717\n",
      "Train Epoch: 3 [553600/697932 (79%)]\tLoss: 3.188406\n",
      "Train Epoch: 3 [554240/697932 (79%)]\tLoss: 3.179493\n",
      "Train Epoch: 3 [554880/697932 (79%)]\tLoss: 3.154083\n",
      "Train Epoch: 3 [555520/697932 (80%)]\tLoss: 3.192620\n",
      "Train Epoch: 3 [556160/697932 (80%)]\tLoss: 3.170813\n",
      "Train Epoch: 3 [556800/697932 (80%)]\tLoss: 3.160330\n",
      "Train Epoch: 3 [557440/697932 (80%)]\tLoss: 3.166963\n",
      "Train Epoch: 3 [558080/697932 (80%)]\tLoss: 3.162623\n",
      "Train Epoch: 3 [558720/697932 (80%)]\tLoss: 3.154286\n",
      "Train Epoch: 3 [559360/697932 (80%)]\tLoss: 3.158786\n",
      "Train Epoch: 3 [560000/697932 (80%)]\tLoss: 3.178741\n",
      "Train Epoch: 3 [560640/697932 (80%)]\tLoss: 3.144956\n",
      "Train Epoch: 3 [561280/697932 (80%)]\tLoss: 3.174664\n",
      "Train Epoch: 3 [561920/697932 (81%)]\tLoss: 3.158364\n",
      "Train Epoch: 3 [562560/697932 (81%)]\tLoss: 3.185389\n",
      "Train Epoch: 3 [563200/697932 (81%)]\tLoss: 3.140806\n",
      "Train Epoch: 3 [563840/697932 (81%)]\tLoss: 3.167670\n",
      "Train Epoch: 3 [564480/697932 (81%)]\tLoss: 3.171113\n",
      "Train Epoch: 3 [565120/697932 (81%)]\tLoss: 3.178904\n",
      "Train Epoch: 3 [565760/697932 (81%)]\tLoss: 3.147716\n",
      "Train Epoch: 3 [566400/697932 (81%)]\tLoss: 3.158876\n",
      "Train Epoch: 3 [567040/697932 (81%)]\tLoss: 3.175186\n",
      "Train Epoch: 3 [567680/697932 (81%)]\tLoss: 3.184866\n",
      "Train Epoch: 3 [568320/697932 (81%)]\tLoss: 3.159922\n",
      "Train Epoch: 3 [568960/697932 (82%)]\tLoss: 3.175908\n",
      "Train Epoch: 3 [569600/697932 (82%)]\tLoss: 3.153580\n",
      "Train Epoch: 3 [570240/697932 (82%)]\tLoss: 3.178297\n",
      "Train Epoch: 3 [570880/697932 (82%)]\tLoss: 3.167294\n",
      "Train Epoch: 3 [571520/697932 (82%)]\tLoss: 3.180499\n",
      "Train Epoch: 3 [572160/697932 (82%)]\tLoss: 3.145762\n",
      "Train Epoch: 3 [572800/697932 (82%)]\tLoss: 3.154807\n",
      "Train Epoch: 3 [573440/697932 (82%)]\tLoss: 3.155354\n",
      "Train Epoch: 3 [574080/697932 (82%)]\tLoss: 3.146879\n",
      "Train Epoch: 3 [574720/697932 (82%)]\tLoss: 3.156708\n",
      "Train Epoch: 3 [575360/697932 (82%)]\tLoss: 3.150066\n",
      "Train Epoch: 3 [576000/697932 (83%)]\tLoss: 3.199432\n",
      "Train Epoch: 3 [576640/697932 (83%)]\tLoss: 3.193066\n",
      "Train Epoch: 3 [577280/697932 (83%)]\tLoss: 3.158171\n",
      "Train Epoch: 3 [577920/697932 (83%)]\tLoss: 3.182155\n",
      "Train Epoch: 3 [578560/697932 (83%)]\tLoss: 3.188830\n",
      "Train Epoch: 3 [579200/697932 (83%)]\tLoss: 3.162508\n",
      "Train Epoch: 3 [579840/697932 (83%)]\tLoss: 3.192916\n",
      "Train Epoch: 3 [580480/697932 (83%)]\tLoss: 3.164930\n",
      "Train Epoch: 3 [581120/697932 (83%)]\tLoss: 3.196465\n",
      "Train Epoch: 3 [581760/697932 (83%)]\tLoss: 3.168835\n",
      "Train Epoch: 3 [582400/697932 (83%)]\tLoss: 3.148767\n",
      "Train Epoch: 3 [583040/697932 (84%)]\tLoss: 3.160734\n",
      "Train Epoch: 3 [583680/697932 (84%)]\tLoss: 3.190708\n",
      "Train Epoch: 3 [584320/697932 (84%)]\tLoss: 3.156803\n",
      "Train Epoch: 3 [584960/697932 (84%)]\tLoss: 3.182775\n",
      "Train Epoch: 3 [585600/697932 (84%)]\tLoss: 3.186528\n",
      "Train Epoch: 3 [586240/697932 (84%)]\tLoss: 3.162949\n",
      "Train Epoch: 3 [586880/697932 (84%)]\tLoss: 3.160980\n",
      "Train Epoch: 3 [587520/697932 (84%)]\tLoss: 3.204418\n",
      "Train Epoch: 3 [588160/697932 (84%)]\tLoss: 3.192141\n",
      "Train Epoch: 3 [588800/697932 (84%)]\tLoss: 3.163831\n",
      "Train Epoch: 3 [589440/697932 (84%)]\tLoss: 3.206228\n",
      "Train Epoch: 3 [590080/697932 (85%)]\tLoss: 3.185139\n",
      "Train Epoch: 3 [590720/697932 (85%)]\tLoss: 3.174435\n",
      "Train Epoch: 3 [591360/697932 (85%)]\tLoss: 3.179846\n",
      "Train Epoch: 3 [592000/697932 (85%)]\tLoss: 3.173737\n",
      "Train Epoch: 3 [592640/697932 (85%)]\tLoss: 3.150052\n",
      "Train Epoch: 3 [593280/697932 (85%)]\tLoss: 3.177885\n",
      "Train Epoch: 3 [593920/697932 (85%)]\tLoss: 3.139279\n",
      "Train Epoch: 3 [594560/697932 (85%)]\tLoss: 3.158328\n",
      "Train Epoch: 3 [595200/697932 (85%)]\tLoss: 3.179718\n",
      "Train Epoch: 3 [595840/697932 (85%)]\tLoss: 3.182112\n",
      "Train Epoch: 3 [596480/697932 (85%)]\tLoss: 3.171065\n",
      "Train Epoch: 3 [597120/697932 (86%)]\tLoss: 3.163549\n",
      "Train Epoch: 3 [597760/697932 (86%)]\tLoss: 3.189167\n",
      "Train Epoch: 3 [598400/697932 (86%)]\tLoss: 3.186416\n",
      "Train Epoch: 3 [599040/697932 (86%)]\tLoss: 3.191559\n",
      "Train Epoch: 3 [599680/697932 (86%)]\tLoss: 3.147871\n",
      "Train Epoch: 3 [600320/697932 (86%)]\tLoss: 3.168080\n",
      "Train Epoch: 3 [600960/697932 (86%)]\tLoss: 3.162198\n",
      "Train Epoch: 3 [601600/697932 (86%)]\tLoss: 3.166509\n",
      "Train Epoch: 3 [602240/697932 (86%)]\tLoss: 3.158207\n",
      "Train Epoch: 3 [602880/697932 (86%)]\tLoss: 3.167512\n",
      "Train Epoch: 3 [603520/697932 (86%)]\tLoss: 3.180182\n",
      "Train Epoch: 3 [604160/697932 (87%)]\tLoss: 3.155480\n",
      "Train Epoch: 3 [604800/697932 (87%)]\tLoss: 3.149715\n",
      "Train Epoch: 3 [605440/697932 (87%)]\tLoss: 3.169624\n",
      "Train Epoch: 3 [606080/697932 (87%)]\tLoss: 3.151085\n",
      "Train Epoch: 3 [606720/697932 (87%)]\tLoss: 3.153879\n",
      "Train Epoch: 3 [607360/697932 (87%)]\tLoss: 3.181080\n",
      "Train Epoch: 3 [608000/697932 (87%)]\tLoss: 3.174288\n",
      "Train Epoch: 3 [608640/697932 (87%)]\tLoss: 3.151037\n",
      "Train Epoch: 3 [609280/697932 (87%)]\tLoss: 3.177619\n",
      "Train Epoch: 3 [609920/697932 (87%)]\tLoss: 3.164874\n",
      "Train Epoch: 3 [610560/697932 (87%)]\tLoss: 3.184955\n",
      "Train Epoch: 3 [611200/697932 (88%)]\tLoss: 3.173555\n",
      "Train Epoch: 3 [611840/697932 (88%)]\tLoss: 3.210513\n",
      "Train Epoch: 3 [612480/697932 (88%)]\tLoss: 3.182545\n",
      "Train Epoch: 3 [613120/697932 (88%)]\tLoss: 3.169542\n",
      "Train Epoch: 3 [613760/697932 (88%)]\tLoss: 3.159436\n",
      "Train Epoch: 3 [614400/697932 (88%)]\tLoss: 3.152701\n",
      "Train Epoch: 3 [615040/697932 (88%)]\tLoss: 3.152508\n",
      "Train Epoch: 3 [615680/697932 (88%)]\tLoss: 3.151765\n",
      "Train Epoch: 3 [616320/697932 (88%)]\tLoss: 3.161987\n",
      "Train Epoch: 3 [616960/697932 (88%)]\tLoss: 3.183643\n",
      "Train Epoch: 3 [617600/697932 (88%)]\tLoss: 3.178123\n",
      "Train Epoch: 3 [618240/697932 (89%)]\tLoss: 3.186074\n",
      "Train Epoch: 3 [618880/697932 (89%)]\tLoss: 3.166178\n",
      "Train Epoch: 3 [619520/697932 (89%)]\tLoss: 3.145112\n",
      "Train Epoch: 3 [620160/697932 (89%)]\tLoss: 3.183390\n",
      "Train Epoch: 3 [620800/697932 (89%)]\tLoss: 3.178271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [621440/697932 (89%)]\tLoss: 3.164624\n",
      "Train Epoch: 3 [622080/697932 (89%)]\tLoss: 3.138999\n",
      "Train Epoch: 3 [622720/697932 (89%)]\tLoss: 3.201707\n",
      "Train Epoch: 3 [623360/697932 (89%)]\tLoss: 3.149357\n",
      "Train Epoch: 3 [624000/697932 (89%)]\tLoss: 3.194814\n",
      "Train Epoch: 3 [624640/697932 (89%)]\tLoss: 3.163908\n",
      "Train Epoch: 3 [625280/697932 (90%)]\tLoss: 3.172203\n",
      "Train Epoch: 3 [625920/697932 (90%)]\tLoss: 3.173263\n",
      "Train Epoch: 3 [626560/697932 (90%)]\tLoss: 3.164699\n",
      "Train Epoch: 3 [627200/697932 (90%)]\tLoss: 3.173307\n",
      "Train Epoch: 3 [627840/697932 (90%)]\tLoss: 3.175707\n",
      "Train Epoch: 3 [628480/697932 (90%)]\tLoss: 3.163965\n",
      "Train Epoch: 3 [629120/697932 (90%)]\tLoss: 3.163958\n",
      "Train Epoch: 3 [629760/697932 (90%)]\tLoss: 3.191050\n",
      "Train Epoch: 3 [630400/697932 (90%)]\tLoss: 3.200509\n",
      "Train Epoch: 3 [631040/697932 (90%)]\tLoss: 3.155652\n",
      "Train Epoch: 3 [631680/697932 (91%)]\tLoss: 3.192058\n",
      "Train Epoch: 3 [632320/697932 (91%)]\tLoss: 3.158082\n",
      "Train Epoch: 3 [632960/697932 (91%)]\tLoss: 3.186592\n",
      "Train Epoch: 3 [633600/697932 (91%)]\tLoss: 3.189240\n",
      "Train Epoch: 3 [634240/697932 (91%)]\tLoss: 3.156093\n",
      "Train Epoch: 3 [634880/697932 (91%)]\tLoss: 3.154090\n",
      "Train Epoch: 3 [635520/697932 (91%)]\tLoss: 3.183917\n",
      "Train Epoch: 3 [636160/697932 (91%)]\tLoss: 3.177453\n",
      "Train Epoch: 3 [636800/697932 (91%)]\tLoss: 3.174344\n",
      "Train Epoch: 3 [637440/697932 (91%)]\tLoss: 3.178054\n",
      "Train Epoch: 3 [638080/697932 (91%)]\tLoss: 3.174594\n",
      "Train Epoch: 3 [638720/697932 (92%)]\tLoss: 3.184544\n",
      "Train Epoch: 3 [639360/697932 (92%)]\tLoss: 3.174093\n",
      "Train Epoch: 3 [640000/697932 (92%)]\tLoss: 3.194834\n",
      "Train Epoch: 3 [640640/697932 (92%)]\tLoss: 3.150913\n",
      "Train Epoch: 3 [641280/697932 (92%)]\tLoss: 3.163978\n",
      "Train Epoch: 3 [641920/697932 (92%)]\tLoss: 3.217340\n",
      "Train Epoch: 3 [642560/697932 (92%)]\tLoss: 3.202906\n",
      "Train Epoch: 3 [643200/697932 (92%)]\tLoss: 3.166971\n",
      "Train Epoch: 3 [643840/697932 (92%)]\tLoss: 3.177655\n",
      "Train Epoch: 3 [644480/697932 (92%)]\tLoss: 3.140367\n",
      "Train Epoch: 3 [645120/697932 (92%)]\tLoss: 3.164286\n",
      "Train Epoch: 3 [645760/697932 (93%)]\tLoss: 3.183792\n",
      "Train Epoch: 3 [646400/697932 (93%)]\tLoss: 3.171243\n",
      "Train Epoch: 3 [647040/697932 (93%)]\tLoss: 3.139367\n",
      "Train Epoch: 3 [647680/697932 (93%)]\tLoss: 3.188548\n",
      "Train Epoch: 3 [648320/697932 (93%)]\tLoss: 3.185926\n",
      "Train Epoch: 3 [648960/697932 (93%)]\tLoss: 3.180323\n",
      "Train Epoch: 3 [649600/697932 (93%)]\tLoss: 3.157889\n",
      "Train Epoch: 3 [650240/697932 (93%)]\tLoss: 3.175267\n",
      "Train Epoch: 3 [650880/697932 (93%)]\tLoss: 3.165932\n",
      "Train Epoch: 3 [651520/697932 (93%)]\tLoss: 3.154960\n",
      "Train Epoch: 3 [652160/697932 (93%)]\tLoss: 3.196092\n",
      "Train Epoch: 3 [652800/697932 (94%)]\tLoss: 3.202401\n",
      "Train Epoch: 3 [653440/697932 (94%)]\tLoss: 3.224795\n",
      "Train Epoch: 3 [654080/697932 (94%)]\tLoss: 3.164841\n",
      "Train Epoch: 3 [654720/697932 (94%)]\tLoss: 3.169834\n",
      "Train Epoch: 3 [655360/697932 (94%)]\tLoss: 3.180333\n",
      "Train Epoch: 3 [656000/697932 (94%)]\tLoss: 3.195705\n",
      "Train Epoch: 3 [656640/697932 (94%)]\tLoss: 3.173251\n",
      "Train Epoch: 3 [657280/697932 (94%)]\tLoss: 3.171395\n",
      "Train Epoch: 3 [657920/697932 (94%)]\tLoss: 3.159260\n",
      "Train Epoch: 3 [658560/697932 (94%)]\tLoss: 3.178455\n",
      "Train Epoch: 3 [659200/697932 (94%)]\tLoss: 3.183491\n",
      "Train Epoch: 3 [659840/697932 (95%)]\tLoss: 3.166702\n",
      "Train Epoch: 3 [660480/697932 (95%)]\tLoss: 3.204720\n",
      "Train Epoch: 3 [661120/697932 (95%)]\tLoss: 3.176849\n",
      "Train Epoch: 3 [661760/697932 (95%)]\tLoss: 3.171880\n",
      "Train Epoch: 3 [662400/697932 (95%)]\tLoss: 3.175017\n",
      "Train Epoch: 3 [663040/697932 (95%)]\tLoss: 3.160510\n",
      "Train Epoch: 3 [663680/697932 (95%)]\tLoss: 3.155366\n",
      "Train Epoch: 3 [664320/697932 (95%)]\tLoss: 3.176584\n",
      "Train Epoch: 3 [664960/697932 (95%)]\tLoss: 3.158649\n",
      "Train Epoch: 3 [665600/697932 (95%)]\tLoss: 3.179912\n",
      "Train Epoch: 3 [666240/697932 (95%)]\tLoss: 3.121603\n",
      "Train Epoch: 3 [666880/697932 (96%)]\tLoss: 3.141813\n",
      "Train Epoch: 3 [667520/697932 (96%)]\tLoss: 3.184415\n",
      "Train Epoch: 3 [668160/697932 (96%)]\tLoss: 3.196055\n",
      "Train Epoch: 3 [668800/697932 (96%)]\tLoss: 3.185703\n",
      "Train Epoch: 3 [669440/697932 (96%)]\tLoss: 3.154900\n",
      "Train Epoch: 3 [670080/697932 (96%)]\tLoss: 3.146051\n",
      "Train Epoch: 3 [670720/697932 (96%)]\tLoss: 3.161085\n",
      "Train Epoch: 3 [671360/697932 (96%)]\tLoss: 3.164356\n",
      "Train Epoch: 3 [672000/697932 (96%)]\tLoss: 3.180469\n",
      "Train Epoch: 3 [672640/697932 (96%)]\tLoss: 3.168097\n",
      "Train Epoch: 3 [673280/697932 (96%)]\tLoss: 3.177234\n",
      "Train Epoch: 3 [673920/697932 (97%)]\tLoss: 3.193299\n",
      "Train Epoch: 3 [674560/697932 (97%)]\tLoss: 3.148384\n",
      "Train Epoch: 3 [675200/697932 (97%)]\tLoss: 3.182648\n",
      "Train Epoch: 3 [675840/697932 (97%)]\tLoss: 3.138076\n",
      "Train Epoch: 3 [676480/697932 (97%)]\tLoss: 3.184684\n",
      "Train Epoch: 3 [677120/697932 (97%)]\tLoss: 3.167965\n",
      "Train Epoch: 3 [677760/697932 (97%)]\tLoss: 3.160791\n",
      "Train Epoch: 3 [678400/697932 (97%)]\tLoss: 3.139302\n",
      "Train Epoch: 3 [679040/697932 (97%)]\tLoss: 3.176092\n",
      "Train Epoch: 3 [679680/697932 (97%)]\tLoss: 3.182765\n",
      "Train Epoch: 3 [680320/697932 (97%)]\tLoss: 3.160175\n",
      "Train Epoch: 3 [680960/697932 (98%)]\tLoss: 3.160561\n",
      "Train Epoch: 3 [681600/697932 (98%)]\tLoss: 3.173321\n",
      "Train Epoch: 3 [682240/697932 (98%)]\tLoss: 3.158902\n",
      "Train Epoch: 3 [682880/697932 (98%)]\tLoss: 3.163297\n",
      "Train Epoch: 3 [683520/697932 (98%)]\tLoss: 3.168187\n",
      "Train Epoch: 3 [684160/697932 (98%)]\tLoss: 3.169763\n",
      "Train Epoch: 3 [684800/697932 (98%)]\tLoss: 3.159878\n",
      "Train Epoch: 3 [685440/697932 (98%)]\tLoss: 3.197281\n",
      "Train Epoch: 3 [686080/697932 (98%)]\tLoss: 3.153425\n",
      "Train Epoch: 3 [686720/697932 (98%)]\tLoss: 3.147632\n",
      "Train Epoch: 3 [687360/697932 (98%)]\tLoss: 3.197670\n",
      "Train Epoch: 3 [688000/697932 (99%)]\tLoss: 3.165578\n",
      "Train Epoch: 3 [688640/697932 (99%)]\tLoss: 3.160771\n",
      "Train Epoch: 3 [689280/697932 (99%)]\tLoss: 3.172961\n",
      "Train Epoch: 3 [689920/697932 (99%)]\tLoss: 3.159852\n",
      "Train Epoch: 3 [690560/697932 (99%)]\tLoss: 3.176796\n",
      "Train Epoch: 3 [691200/697932 (99%)]\tLoss: 3.152232\n",
      "Train Epoch: 3 [691840/697932 (99%)]\tLoss: 3.162861\n",
      "Train Epoch: 3 [692480/697932 (99%)]\tLoss: 3.171845\n",
      "Train Epoch: 3 [693120/697932 (99%)]\tLoss: 3.153779\n",
      "Train Epoch: 3 [693760/697932 (99%)]\tLoss: 3.175018\n",
      "Train Epoch: 3 [694400/697932 (99%)]\tLoss: 3.171897\n",
      "Train Epoch: 3 [695040/697932 (100%)]\tLoss: 3.177928\n",
      "Train Epoch: 3 [695680/697932 (100%)]\tLoss: 3.163633\n",
      "Train Epoch: 3 [696320/697932 (100%)]\tLoss: 3.133833\n",
      "Train Epoch: 3 [696960/697932 (100%)]\tLoss: 3.157805\n",
      "Train Epoch: 3 [697600/697932 (100%)]\tLoss: 3.127556\n",
      "\n",
      "Test set: Avg. loss: 0.0043, Accuracy: 38/116323 (0%)\n",
      "\n",
      "Train Epoch: 4 [0/697932 (0%)]\tLoss: 3.163776\n",
      "Train Epoch: 4 [640/697932 (0%)]\tLoss: 3.145556\n",
      "Train Epoch: 4 [1280/697932 (0%)]\tLoss: 3.185005\n",
      "Train Epoch: 4 [1920/697932 (0%)]\tLoss: 3.173593\n",
      "Train Epoch: 4 [2560/697932 (0%)]\tLoss: 3.180819\n",
      "Train Epoch: 4 [3200/697932 (0%)]\tLoss: 3.150755\n",
      "Train Epoch: 4 [3840/697932 (1%)]\tLoss: 3.147604\n",
      "Train Epoch: 4 [4480/697932 (1%)]\tLoss: 3.169105\n",
      "Train Epoch: 4 [5120/697932 (1%)]\tLoss: 3.175175\n",
      "Train Epoch: 4 [5760/697932 (1%)]\tLoss: 3.171030\n",
      "Train Epoch: 4 [6400/697932 (1%)]\tLoss: 3.156041\n",
      "Train Epoch: 4 [7040/697932 (1%)]\tLoss: 3.179579\n",
      "Train Epoch: 4 [7680/697932 (1%)]\tLoss: 3.154963\n",
      "Train Epoch: 4 [8320/697932 (1%)]\tLoss: 3.188708\n",
      "Train Epoch: 4 [8960/697932 (1%)]\tLoss: 3.171004\n",
      "Train Epoch: 4 [9600/697932 (1%)]\tLoss: 3.173416\n",
      "Train Epoch: 4 [10240/697932 (1%)]\tLoss: 3.184275\n",
      "Train Epoch: 4 [10880/697932 (2%)]\tLoss: 3.179164\n",
      "Train Epoch: 4 [11520/697932 (2%)]\tLoss: 3.196046\n",
      "Train Epoch: 4 [12160/697932 (2%)]\tLoss: 3.167871\n",
      "Train Epoch: 4 [12800/697932 (2%)]\tLoss: 3.142914\n",
      "Train Epoch: 4 [13440/697932 (2%)]\tLoss: 3.187791\n",
      "Train Epoch: 4 [14080/697932 (2%)]\tLoss: 3.183381\n",
      "Train Epoch: 4 [14720/697932 (2%)]\tLoss: 3.176506\n",
      "Train Epoch: 4 [15360/697932 (2%)]\tLoss: 3.160877\n",
      "Train Epoch: 4 [16000/697932 (2%)]\tLoss: 3.192974\n",
      "Train Epoch: 4 [16640/697932 (2%)]\tLoss: 3.189782\n",
      "Train Epoch: 4 [17280/697932 (2%)]\tLoss: 3.181724\n",
      "Train Epoch: 4 [17920/697932 (3%)]\tLoss: 3.180111\n",
      "Train Epoch: 4 [18560/697932 (3%)]\tLoss: 3.167609\n",
      "Train Epoch: 4 [19200/697932 (3%)]\tLoss: 3.176564\n",
      "Train Epoch: 4 [19840/697932 (3%)]\tLoss: 3.166582\n",
      "Train Epoch: 4 [20480/697932 (3%)]\tLoss: 3.195180\n",
      "Train Epoch: 4 [21120/697932 (3%)]\tLoss: 3.149458\n",
      "Train Epoch: 4 [21760/697932 (3%)]\tLoss: 3.136184\n",
      "Train Epoch: 4 [22400/697932 (3%)]\tLoss: 3.136869\n",
      "Train Epoch: 4 [23040/697932 (3%)]\tLoss: 3.196709\n",
      "Train Epoch: 4 [23680/697932 (3%)]\tLoss: 3.186883\n",
      "Train Epoch: 4 [24320/697932 (3%)]\tLoss: 3.173512\n",
      "Train Epoch: 4 [24960/697932 (4%)]\tLoss: 3.162336\n",
      "Train Epoch: 4 [25600/697932 (4%)]\tLoss: 3.152353\n",
      "Train Epoch: 4 [26240/697932 (4%)]\tLoss: 3.162746\n",
      "Train Epoch: 4 [26880/697932 (4%)]\tLoss: 3.182446\n",
      "Train Epoch: 4 [27520/697932 (4%)]\tLoss: 3.209639\n",
      "Train Epoch: 4 [28160/697932 (4%)]\tLoss: 3.157826\n",
      "Train Epoch: 4 [28800/697932 (4%)]\tLoss: 3.158896\n",
      "Train Epoch: 4 [29440/697932 (4%)]\tLoss: 3.182184\n",
      "Train Epoch: 4 [30080/697932 (4%)]\tLoss: 3.172585\n",
      "Train Epoch: 4 [30720/697932 (4%)]\tLoss: 3.207698\n",
      "Train Epoch: 4 [31360/697932 (4%)]\tLoss: 3.171034\n",
      "Train Epoch: 4 [32000/697932 (5%)]\tLoss: 3.172514\n",
      "Train Epoch: 4 [32640/697932 (5%)]\tLoss: 3.153560\n",
      "Train Epoch: 4 [33280/697932 (5%)]\tLoss: 3.160878\n",
      "Train Epoch: 4 [33920/697932 (5%)]\tLoss: 3.174054\n",
      "Train Epoch: 4 [34560/697932 (5%)]\tLoss: 3.174735\n",
      "Train Epoch: 4 [35200/697932 (5%)]\tLoss: 3.158801\n",
      "Train Epoch: 4 [35840/697932 (5%)]\tLoss: 3.184356\n",
      "Train Epoch: 4 [36480/697932 (5%)]\tLoss: 3.194283\n",
      "Train Epoch: 4 [37120/697932 (5%)]\tLoss: 3.173512\n",
      "Train Epoch: 4 [37760/697932 (5%)]\tLoss: 3.151594\n",
      "Train Epoch: 4 [38400/697932 (6%)]\tLoss: 3.169029\n",
      "Train Epoch: 4 [39040/697932 (6%)]\tLoss: 3.152168\n",
      "Train Epoch: 4 [39680/697932 (6%)]\tLoss: 3.151798\n",
      "Train Epoch: 4 [40320/697932 (6%)]\tLoss: 3.206634\n",
      "Train Epoch: 4 [40960/697932 (6%)]\tLoss: 3.180881\n",
      "Train Epoch: 4 [41600/697932 (6%)]\tLoss: 3.165356\n",
      "Train Epoch: 4 [42240/697932 (6%)]\tLoss: 3.177381\n",
      "Train Epoch: 4 [42880/697932 (6%)]\tLoss: 3.197117\n",
      "Train Epoch: 4 [43520/697932 (6%)]\tLoss: 3.178943\n",
      "Train Epoch: 4 [44160/697932 (6%)]\tLoss: 3.176297\n",
      "Train Epoch: 4 [44800/697932 (6%)]\tLoss: 3.178012\n",
      "Train Epoch: 4 [45440/697932 (7%)]\tLoss: 3.163334\n",
      "Train Epoch: 4 [46080/697932 (7%)]\tLoss: 3.154499\n",
      "Train Epoch: 4 [46720/697932 (7%)]\tLoss: 3.152406\n",
      "Train Epoch: 4 [47360/697932 (7%)]\tLoss: 3.172490\n",
      "Train Epoch: 4 [48000/697932 (7%)]\tLoss: 3.171061\n",
      "Train Epoch: 4 [48640/697932 (7%)]\tLoss: 3.192559\n",
      "Train Epoch: 4 [49280/697932 (7%)]\tLoss: 3.221959\n",
      "Train Epoch: 4 [49920/697932 (7%)]\tLoss: 3.187457\n",
      "Train Epoch: 4 [50560/697932 (7%)]\tLoss: 3.183769\n",
      "Train Epoch: 4 [51200/697932 (7%)]\tLoss: 3.152033\n",
      "Train Epoch: 4 [51840/697932 (7%)]\tLoss: 3.183767\n",
      "Train Epoch: 4 [52480/697932 (8%)]\tLoss: 3.178254\n",
      "Train Epoch: 4 [53120/697932 (8%)]\tLoss: 3.175064\n",
      "Train Epoch: 4 [53760/697932 (8%)]\tLoss: 3.159735\n",
      "Train Epoch: 4 [54400/697932 (8%)]\tLoss: 3.167689\n",
      "Train Epoch: 4 [55040/697932 (8%)]\tLoss: 3.173337\n",
      "Train Epoch: 4 [55680/697932 (8%)]\tLoss: 3.186728\n",
      "Train Epoch: 4 [56320/697932 (8%)]\tLoss: 3.207810\n",
      "Train Epoch: 4 [56960/697932 (8%)]\tLoss: 3.186654\n",
      "Train Epoch: 4 [57600/697932 (8%)]\tLoss: 3.167988\n",
      "Train Epoch: 4 [58240/697932 (8%)]\tLoss: 3.161135\n",
      "Train Epoch: 4 [58880/697932 (8%)]\tLoss: 3.178639\n",
      "Train Epoch: 4 [59520/697932 (9%)]\tLoss: 3.175928\n",
      "Train Epoch: 4 [60160/697932 (9%)]\tLoss: 3.178790\n",
      "Train Epoch: 4 [60800/697932 (9%)]\tLoss: 3.139298\n",
      "Train Epoch: 4 [61440/697932 (9%)]\tLoss: 3.153984\n",
      "Train Epoch: 4 [62080/697932 (9%)]\tLoss: 3.173259\n",
      "Train Epoch: 4 [62720/697932 (9%)]\tLoss: 3.148229\n",
      "Train Epoch: 4 [63360/697932 (9%)]\tLoss: 3.159905\n",
      "Train Epoch: 4 [64000/697932 (9%)]\tLoss: 3.152586\n",
      "Train Epoch: 4 [64640/697932 (9%)]\tLoss: 3.162198\n",
      "Train Epoch: 4 [65280/697932 (9%)]\tLoss: 3.179131\n",
      "Train Epoch: 4 [65920/697932 (9%)]\tLoss: 3.172517\n",
      "Train Epoch: 4 [66560/697932 (10%)]\tLoss: 3.173769\n",
      "Train Epoch: 4 [67200/697932 (10%)]\tLoss: 3.140531\n",
      "Train Epoch: 4 [67840/697932 (10%)]\tLoss: 3.161254\n",
      "Train Epoch: 4 [68480/697932 (10%)]\tLoss: 3.171009\n",
      "Train Epoch: 4 [69120/697932 (10%)]\tLoss: 3.143611\n",
      "Train Epoch: 4 [69760/697932 (10%)]\tLoss: 3.173015\n",
      "Train Epoch: 4 [70400/697932 (10%)]\tLoss: 3.159068\n",
      "Train Epoch: 4 [71040/697932 (10%)]\tLoss: 3.150508\n",
      "Train Epoch: 4 [71680/697932 (10%)]\tLoss: 3.158103\n",
      "Train Epoch: 4 [72320/697932 (10%)]\tLoss: 3.177588\n",
      "Train Epoch: 4 [72960/697932 (10%)]\tLoss: 3.141513\n",
      "Train Epoch: 4 [73600/697932 (11%)]\tLoss: 3.125796\n",
      "Train Epoch: 4 [74240/697932 (11%)]\tLoss: 3.157901\n",
      "Train Epoch: 4 [74880/697932 (11%)]\tLoss: 3.174553\n",
      "Train Epoch: 4 [75520/697932 (11%)]\tLoss: 3.193253\n",
      "Train Epoch: 4 [76160/697932 (11%)]\tLoss: 3.179806\n",
      "Train Epoch: 4 [76800/697932 (11%)]\tLoss: 3.177566\n",
      "Train Epoch: 4 [77440/697932 (11%)]\tLoss: 3.145969\n",
      "Train Epoch: 4 [78080/697932 (11%)]\tLoss: 3.176545\n",
      "Train Epoch: 4 [78720/697932 (11%)]\tLoss: 3.196157\n",
      "Train Epoch: 4 [79360/697932 (11%)]\tLoss: 3.164353\n",
      "Train Epoch: 4 [80000/697932 (11%)]\tLoss: 3.165374\n",
      "Train Epoch: 4 [80640/697932 (12%)]\tLoss: 3.178074\n",
      "Train Epoch: 4 [81280/697932 (12%)]\tLoss: 3.157394\n",
      "Train Epoch: 4 [81920/697932 (12%)]\tLoss: 3.154444\n",
      "Train Epoch: 4 [82560/697932 (12%)]\tLoss: 3.143857\n",
      "Train Epoch: 4 [83200/697932 (12%)]\tLoss: 3.175142\n",
      "Train Epoch: 4 [83840/697932 (12%)]\tLoss: 3.156733\n",
      "Train Epoch: 4 [84480/697932 (12%)]\tLoss: 3.163615\n",
      "Train Epoch: 4 [85120/697932 (12%)]\tLoss: 3.169064\n",
      "Train Epoch: 4 [85760/697932 (12%)]\tLoss: 3.163000\n",
      "Train Epoch: 4 [86400/697932 (12%)]\tLoss: 3.156475\n",
      "Train Epoch: 4 [87040/697932 (12%)]\tLoss: 3.150300\n",
      "Train Epoch: 4 [87680/697932 (13%)]\tLoss: 3.189861\n",
      "Train Epoch: 4 [88320/697932 (13%)]\tLoss: 3.176395\n",
      "Train Epoch: 4 [88960/697932 (13%)]\tLoss: 3.183019\n",
      "Train Epoch: 4 [89600/697932 (13%)]\tLoss: 3.185922\n",
      "Train Epoch: 4 [90240/697932 (13%)]\tLoss: 3.188520\n",
      "Train Epoch: 4 [90880/697932 (13%)]\tLoss: 3.166188\n",
      "Train Epoch: 4 [91520/697932 (13%)]\tLoss: 3.182667\n",
      "Train Epoch: 4 [92160/697932 (13%)]\tLoss: 3.163111\n",
      "Train Epoch: 4 [92800/697932 (13%)]\tLoss: 3.166880\n",
      "Train Epoch: 4 [93440/697932 (13%)]\tLoss: 3.168379\n",
      "Train Epoch: 4 [94080/697932 (13%)]\tLoss: 3.196042\n",
      "Train Epoch: 4 [94720/697932 (14%)]\tLoss: 3.143380\n",
      "Train Epoch: 4 [95360/697932 (14%)]\tLoss: 3.172964\n",
      "Train Epoch: 4 [96000/697932 (14%)]\tLoss: 3.167918\n",
      "Train Epoch: 4 [96640/697932 (14%)]\tLoss: 3.149504\n",
      "Train Epoch: 4 [97280/697932 (14%)]\tLoss: 3.184887\n",
      "Train Epoch: 4 [97920/697932 (14%)]\tLoss: 3.207911\n",
      "Train Epoch: 4 [98560/697932 (14%)]\tLoss: 3.172870\n",
      "Train Epoch: 4 [99200/697932 (14%)]\tLoss: 3.154812\n",
      "Train Epoch: 4 [99840/697932 (14%)]\tLoss: 3.186921\n",
      "Train Epoch: 4 [100480/697932 (14%)]\tLoss: 3.163018\n",
      "Train Epoch: 4 [101120/697932 (14%)]\tLoss: 3.156583\n",
      "Train Epoch: 4 [101760/697932 (15%)]\tLoss: 3.155958\n",
      "Train Epoch: 4 [102400/697932 (15%)]\tLoss: 3.178418\n",
      "Train Epoch: 4 [103040/697932 (15%)]\tLoss: 3.182496\n",
      "Train Epoch: 4 [103680/697932 (15%)]\tLoss: 3.204833\n",
      "Train Epoch: 4 [104320/697932 (15%)]\tLoss: 3.173068\n",
      "Train Epoch: 4 [104960/697932 (15%)]\tLoss: 3.184406\n",
      "Train Epoch: 4 [105600/697932 (15%)]\tLoss: 3.180082\n",
      "Train Epoch: 4 [106240/697932 (15%)]\tLoss: 3.162222\n",
      "Train Epoch: 4 [106880/697932 (15%)]\tLoss: 3.170492\n",
      "Train Epoch: 4 [107520/697932 (15%)]\tLoss: 3.157391\n",
      "Train Epoch: 4 [108160/697932 (15%)]\tLoss: 3.177285\n",
      "Train Epoch: 4 [108800/697932 (16%)]\tLoss: 3.181927\n",
      "Train Epoch: 4 [109440/697932 (16%)]\tLoss: 3.178039\n",
      "Train Epoch: 4 [110080/697932 (16%)]\tLoss: 3.128441\n",
      "Train Epoch: 4 [110720/697932 (16%)]\tLoss: 3.170822\n",
      "Train Epoch: 4 [111360/697932 (16%)]\tLoss: 3.194560\n",
      "Train Epoch: 4 [112000/697932 (16%)]\tLoss: 3.151656\n",
      "Train Epoch: 4 [112640/697932 (16%)]\tLoss: 3.200748\n",
      "Train Epoch: 4 [113280/697932 (16%)]\tLoss: 3.166075\n",
      "Train Epoch: 4 [113920/697932 (16%)]\tLoss: 3.175091\n",
      "Train Epoch: 4 [114560/697932 (16%)]\tLoss: 3.187727\n",
      "Train Epoch: 4 [115200/697932 (17%)]\tLoss: 3.145818\n",
      "Train Epoch: 4 [115840/697932 (17%)]\tLoss: 3.156605\n",
      "Train Epoch: 4 [116480/697932 (17%)]\tLoss: 3.155661\n",
      "Train Epoch: 4 [117120/697932 (17%)]\tLoss: 3.175447\n",
      "Train Epoch: 4 [117760/697932 (17%)]\tLoss: 3.170292\n",
      "Train Epoch: 4 [118400/697932 (17%)]\tLoss: 3.189608\n",
      "Train Epoch: 4 [119040/697932 (17%)]\tLoss: 3.180794\n",
      "Train Epoch: 4 [119680/697932 (17%)]\tLoss: 3.165877\n",
      "Train Epoch: 4 [120320/697932 (17%)]\tLoss: 3.157189\n",
      "Train Epoch: 4 [120960/697932 (17%)]\tLoss: 3.168358\n",
      "Train Epoch: 4 [121600/697932 (17%)]\tLoss: 3.154874\n",
      "Train Epoch: 4 [122240/697932 (18%)]\tLoss: 3.134771\n",
      "Train Epoch: 4 [122880/697932 (18%)]\tLoss: 3.182410\n",
      "Train Epoch: 4 [123520/697932 (18%)]\tLoss: 3.143138\n",
      "Train Epoch: 4 [124160/697932 (18%)]\tLoss: 3.136879\n",
      "Train Epoch: 4 [124800/697932 (18%)]\tLoss: 3.205283\n",
      "Train Epoch: 4 [125440/697932 (18%)]\tLoss: 3.151486\n",
      "Train Epoch: 4 [126080/697932 (18%)]\tLoss: 3.140918\n",
      "Train Epoch: 4 [126720/697932 (18%)]\tLoss: 3.137745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [127360/697932 (18%)]\tLoss: 3.190955\n",
      "Train Epoch: 4 [128000/697932 (18%)]\tLoss: 3.170207\n",
      "Train Epoch: 4 [128640/697932 (18%)]\tLoss: 3.174959\n",
      "Train Epoch: 4 [129280/697932 (19%)]\tLoss: 3.196658\n",
      "Train Epoch: 4 [129920/697932 (19%)]\tLoss: 3.185355\n",
      "Train Epoch: 4 [130560/697932 (19%)]\tLoss: 3.166313\n",
      "Train Epoch: 4 [131200/697932 (19%)]\tLoss: 3.150208\n",
      "Train Epoch: 4 [131840/697932 (19%)]\tLoss: 3.167816\n",
      "Train Epoch: 4 [132480/697932 (19%)]\tLoss: 3.188951\n",
      "Train Epoch: 4 [133120/697932 (19%)]\tLoss: 3.171136\n",
      "Train Epoch: 4 [133760/697932 (19%)]\tLoss: 3.183133\n",
      "Train Epoch: 4 [134400/697932 (19%)]\tLoss: 3.128621\n",
      "Train Epoch: 4 [135040/697932 (19%)]\tLoss: 3.163517\n",
      "Train Epoch: 4 [135680/697932 (19%)]\tLoss: 3.175866\n",
      "Train Epoch: 4 [136320/697932 (20%)]\tLoss: 3.173957\n",
      "Train Epoch: 4 [136960/697932 (20%)]\tLoss: 3.201047\n",
      "Train Epoch: 4 [137600/697932 (20%)]\tLoss: 3.162867\n",
      "Train Epoch: 4 [138240/697932 (20%)]\tLoss: 3.184168\n",
      "Train Epoch: 4 [138880/697932 (20%)]\tLoss: 3.171186\n",
      "Train Epoch: 4 [139520/697932 (20%)]\tLoss: 3.177776\n",
      "Train Epoch: 4 [140160/697932 (20%)]\tLoss: 3.175299\n",
      "Train Epoch: 4 [140800/697932 (20%)]\tLoss: 3.136228\n",
      "Train Epoch: 4 [141440/697932 (20%)]\tLoss: 3.156272\n",
      "Train Epoch: 4 [142080/697932 (20%)]\tLoss: 3.152394\n",
      "Train Epoch: 4 [142720/697932 (20%)]\tLoss: 3.171992\n",
      "Train Epoch: 4 [143360/697932 (21%)]\tLoss: 3.185330\n",
      "Train Epoch: 4 [144000/697932 (21%)]\tLoss: 3.177542\n",
      "Train Epoch: 4 [144640/697932 (21%)]\tLoss: 3.149194\n",
      "Train Epoch: 4 [145280/697932 (21%)]\tLoss: 3.173213\n",
      "Train Epoch: 4 [145920/697932 (21%)]\tLoss: 3.198447\n",
      "Train Epoch: 4 [146560/697932 (21%)]\tLoss: 3.129062\n",
      "Train Epoch: 4 [147200/697932 (21%)]\tLoss: 3.160857\n",
      "Train Epoch: 4 [147840/697932 (21%)]\tLoss: 3.185372\n",
      "Train Epoch: 4 [148480/697932 (21%)]\tLoss: 3.165976\n",
      "Train Epoch: 4 [149120/697932 (21%)]\tLoss: 3.180701\n",
      "Train Epoch: 4 [149760/697932 (21%)]\tLoss: 3.137985\n",
      "Train Epoch: 4 [150400/697932 (22%)]\tLoss: 3.157143\n",
      "Train Epoch: 4 [151040/697932 (22%)]\tLoss: 3.155249\n",
      "Train Epoch: 4 [151680/697932 (22%)]\tLoss: 3.191384\n",
      "Train Epoch: 4 [152320/697932 (22%)]\tLoss: 3.209410\n",
      "Train Epoch: 4 [152960/697932 (22%)]\tLoss: 3.192922\n",
      "Train Epoch: 4 [153600/697932 (22%)]\tLoss: 3.178067\n",
      "Train Epoch: 4 [154240/697932 (22%)]\tLoss: 3.149823\n",
      "Train Epoch: 4 [154880/697932 (22%)]\tLoss: 3.179909\n",
      "Train Epoch: 4 [155520/697932 (22%)]\tLoss: 3.189687\n",
      "Train Epoch: 4 [156160/697932 (22%)]\tLoss: 3.167144\n",
      "Train Epoch: 4 [156800/697932 (22%)]\tLoss: 3.182599\n",
      "Train Epoch: 4 [157440/697932 (23%)]\tLoss: 3.176244\n",
      "Train Epoch: 4 [158080/697932 (23%)]\tLoss: 3.204192\n",
      "Train Epoch: 4 [158720/697932 (23%)]\tLoss: 3.191597\n",
      "Train Epoch: 4 [159360/697932 (23%)]\tLoss: 3.194579\n",
      "Train Epoch: 4 [160000/697932 (23%)]\tLoss: 3.197740\n",
      "Train Epoch: 4 [160640/697932 (23%)]\tLoss: 3.189921\n",
      "Train Epoch: 4 [161280/697932 (23%)]\tLoss: 3.169209\n",
      "Train Epoch: 4 [161920/697932 (23%)]\tLoss: 3.169581\n",
      "Train Epoch: 4 [162560/697932 (23%)]\tLoss: 3.210952\n",
      "Train Epoch: 4 [163200/697932 (23%)]\tLoss: 3.161200\n",
      "Train Epoch: 4 [163840/697932 (23%)]\tLoss: 3.172620\n",
      "Train Epoch: 4 [164480/697932 (24%)]\tLoss: 3.183376\n",
      "Train Epoch: 4 [165120/697932 (24%)]\tLoss: 3.158906\n",
      "Train Epoch: 4 [165760/697932 (24%)]\tLoss: 3.151812\n",
      "Train Epoch: 4 [166400/697932 (24%)]\tLoss: 3.172647\n",
      "Train Epoch: 4 [167040/697932 (24%)]\tLoss: 3.159731\n",
      "Train Epoch: 4 [167680/697932 (24%)]\tLoss: 3.168165\n",
      "Train Epoch: 4 [168320/697932 (24%)]\tLoss: 3.169541\n",
      "Train Epoch: 4 [168960/697932 (24%)]\tLoss: 3.136309\n",
      "Train Epoch: 4 [169600/697932 (24%)]\tLoss: 3.169703\n",
      "Train Epoch: 4 [170240/697932 (24%)]\tLoss: 3.193501\n",
      "Train Epoch: 4 [170880/697932 (24%)]\tLoss: 3.174778\n",
      "Train Epoch: 4 [171520/697932 (25%)]\tLoss: 3.150392\n",
      "Train Epoch: 4 [172160/697932 (25%)]\tLoss: 3.164035\n",
      "Train Epoch: 4 [172800/697932 (25%)]\tLoss: 3.165674\n",
      "Train Epoch: 4 [173440/697932 (25%)]\tLoss: 3.173481\n",
      "Train Epoch: 4 [174080/697932 (25%)]\tLoss: 3.178485\n",
      "Train Epoch: 4 [174720/697932 (25%)]\tLoss: 3.145835\n",
      "Train Epoch: 4 [175360/697932 (25%)]\tLoss: 3.148421\n",
      "Train Epoch: 4 [176000/697932 (25%)]\tLoss: 3.192863\n",
      "Train Epoch: 4 [176640/697932 (25%)]\tLoss: 3.177016\n",
      "Train Epoch: 4 [177280/697932 (25%)]\tLoss: 3.147999\n",
      "Train Epoch: 4 [177920/697932 (25%)]\tLoss: 3.159276\n",
      "Train Epoch: 4 [178560/697932 (26%)]\tLoss: 3.146864\n",
      "Train Epoch: 4 [179200/697932 (26%)]\tLoss: 3.158279\n",
      "Train Epoch: 4 [179840/697932 (26%)]\tLoss: 3.165192\n",
      "Train Epoch: 4 [180480/697932 (26%)]\tLoss: 3.161901\n",
      "Train Epoch: 4 [181120/697932 (26%)]\tLoss: 3.144127\n",
      "Train Epoch: 4 [181760/697932 (26%)]\tLoss: 3.160998\n",
      "Train Epoch: 4 [182400/697932 (26%)]\tLoss: 3.141362\n",
      "Train Epoch: 4 [183040/697932 (26%)]\tLoss: 3.152854\n",
      "Train Epoch: 4 [183680/697932 (26%)]\tLoss: 3.159364\n",
      "Train Epoch: 4 [184320/697932 (26%)]\tLoss: 3.199224\n",
      "Train Epoch: 4 [184960/697932 (26%)]\tLoss: 3.156554\n",
      "Train Epoch: 4 [185600/697932 (27%)]\tLoss: 3.161885\n",
      "Train Epoch: 4 [186240/697932 (27%)]\tLoss: 3.146815\n",
      "Train Epoch: 4 [186880/697932 (27%)]\tLoss: 3.165601\n",
      "Train Epoch: 4 [187520/697932 (27%)]\tLoss: 3.170214\n",
      "Train Epoch: 4 [188160/697932 (27%)]\tLoss: 3.190321\n",
      "Train Epoch: 4 [188800/697932 (27%)]\tLoss: 3.168185\n",
      "Train Epoch: 4 [189440/697932 (27%)]\tLoss: 3.200025\n",
      "Train Epoch: 4 [190080/697932 (27%)]\tLoss: 3.157228\n",
      "Train Epoch: 4 [190720/697932 (27%)]\tLoss: 3.177519\n",
      "Train Epoch: 4 [191360/697932 (27%)]\tLoss: 3.169211\n",
      "Train Epoch: 4 [192000/697932 (28%)]\tLoss: 3.167401\n",
      "Train Epoch: 4 [192640/697932 (28%)]\tLoss: 3.146941\n",
      "Train Epoch: 4 [193280/697932 (28%)]\tLoss: 3.197714\n",
      "Train Epoch: 4 [193920/697932 (28%)]\tLoss: 3.167189\n",
      "Train Epoch: 4 [194560/697932 (28%)]\tLoss: 3.155020\n",
      "Train Epoch: 4 [195200/697932 (28%)]\tLoss: 3.158669\n",
      "Train Epoch: 4 [195840/697932 (28%)]\tLoss: 3.176464\n",
      "Train Epoch: 4 [196480/697932 (28%)]\tLoss: 3.184510\n",
      "Train Epoch: 4 [197120/697932 (28%)]\tLoss: 3.167132\n",
      "Train Epoch: 4 [197760/697932 (28%)]\tLoss: 3.216691\n",
      "Train Epoch: 4 [198400/697932 (28%)]\tLoss: 3.165704\n",
      "Train Epoch: 4 [199040/697932 (29%)]\tLoss: 3.166896\n",
      "Train Epoch: 4 [199680/697932 (29%)]\tLoss: 3.176338\n",
      "Train Epoch: 4 [200320/697932 (29%)]\tLoss: 3.158051\n",
      "Train Epoch: 4 [200960/697932 (29%)]\tLoss: 3.150238\n",
      "Train Epoch: 4 [201600/697932 (29%)]\tLoss: 3.210558\n",
      "Train Epoch: 4 [202240/697932 (29%)]\tLoss: 3.145736\n",
      "Train Epoch: 4 [202880/697932 (29%)]\tLoss: 3.162519\n",
      "Train Epoch: 4 [203520/697932 (29%)]\tLoss: 3.193657\n",
      "Train Epoch: 4 [204160/697932 (29%)]\tLoss: 3.182442\n",
      "Train Epoch: 4 [204800/697932 (29%)]\tLoss: 3.187809\n",
      "Train Epoch: 4 [205440/697932 (29%)]\tLoss: 3.185138\n",
      "Train Epoch: 4 [206080/697932 (30%)]\tLoss: 3.173270\n",
      "Train Epoch: 4 [206720/697932 (30%)]\tLoss: 3.166105\n",
      "Train Epoch: 4 [207360/697932 (30%)]\tLoss: 3.141429\n",
      "Train Epoch: 4 [208000/697932 (30%)]\tLoss: 3.169963\n",
      "Train Epoch: 4 [208640/697932 (30%)]\tLoss: 3.168573\n",
      "Train Epoch: 4 [209280/697932 (30%)]\tLoss: 3.181808\n",
      "Train Epoch: 4 [209920/697932 (30%)]\tLoss: 3.163020\n",
      "Train Epoch: 4 [210560/697932 (30%)]\tLoss: 3.152408\n",
      "Train Epoch: 4 [211200/697932 (30%)]\tLoss: 3.173073\n",
      "Train Epoch: 4 [211840/697932 (30%)]\tLoss: 3.155356\n",
      "Train Epoch: 4 [212480/697932 (30%)]\tLoss: 3.178550\n",
      "Train Epoch: 4 [213120/697932 (31%)]\tLoss: 3.175080\n",
      "Train Epoch: 4 [213760/697932 (31%)]\tLoss: 3.186186\n",
      "Train Epoch: 4 [214400/697932 (31%)]\tLoss: 3.197861\n",
      "Train Epoch: 4 [215040/697932 (31%)]\tLoss: 3.155223\n",
      "Train Epoch: 4 [215680/697932 (31%)]\tLoss: 3.158259\n",
      "Train Epoch: 4 [216320/697932 (31%)]\tLoss: 3.175506\n",
      "Train Epoch: 4 [216960/697932 (31%)]\tLoss: 3.205238\n",
      "Train Epoch: 4 [217600/697932 (31%)]\tLoss: 3.175272\n",
      "Train Epoch: 4 [218240/697932 (31%)]\tLoss: 3.189549\n",
      "Train Epoch: 4 [218880/697932 (31%)]\tLoss: 3.134412\n",
      "Train Epoch: 4 [219520/697932 (31%)]\tLoss: 3.178430\n",
      "Train Epoch: 4 [220160/697932 (32%)]\tLoss: 3.196424\n",
      "Train Epoch: 4 [220800/697932 (32%)]\tLoss: 3.179655\n",
      "Train Epoch: 4 [221440/697932 (32%)]\tLoss: 3.196009\n",
      "Train Epoch: 4 [222080/697932 (32%)]\tLoss: 3.154511\n",
      "Train Epoch: 4 [222720/697932 (32%)]\tLoss: 3.179482\n",
      "Train Epoch: 4 [223360/697932 (32%)]\tLoss: 3.127624\n",
      "Train Epoch: 4 [224000/697932 (32%)]\tLoss: 3.146070\n",
      "Train Epoch: 4 [224640/697932 (32%)]\tLoss: 3.161465\n",
      "Train Epoch: 4 [225280/697932 (32%)]\tLoss: 3.170588\n",
      "Train Epoch: 4 [225920/697932 (32%)]\tLoss: 3.193118\n",
      "Train Epoch: 4 [226560/697932 (32%)]\tLoss: 3.187726\n",
      "Train Epoch: 4 [227200/697932 (33%)]\tLoss: 3.183528\n",
      "Train Epoch: 4 [227840/697932 (33%)]\tLoss: 3.153723\n",
      "Train Epoch: 4 [228480/697932 (33%)]\tLoss: 3.166659\n",
      "Train Epoch: 4 [229120/697932 (33%)]\tLoss: 3.174538\n",
      "Train Epoch: 4 [229760/697932 (33%)]\tLoss: 3.164649\n",
      "Train Epoch: 4 [230400/697932 (33%)]\tLoss: 3.183486\n",
      "Train Epoch: 4 [231040/697932 (33%)]\tLoss: 3.159477\n",
      "Train Epoch: 4 [231680/697932 (33%)]\tLoss: 3.186863\n",
      "Train Epoch: 4 [232320/697932 (33%)]\tLoss: 3.146762\n",
      "Train Epoch: 4 [232960/697932 (33%)]\tLoss: 3.152458\n",
      "Train Epoch: 4 [233600/697932 (33%)]\tLoss: 3.155519\n",
      "Train Epoch: 4 [234240/697932 (34%)]\tLoss: 3.200099\n",
      "Train Epoch: 4 [234880/697932 (34%)]\tLoss: 3.175827\n",
      "Train Epoch: 4 [235520/697932 (34%)]\tLoss: 3.149857\n",
      "Train Epoch: 4 [236160/697932 (34%)]\tLoss: 3.194195\n",
      "Train Epoch: 4 [236800/697932 (34%)]\tLoss: 3.149529\n",
      "Train Epoch: 4 [237440/697932 (34%)]\tLoss: 3.161536\n",
      "Train Epoch: 4 [238080/697932 (34%)]\tLoss: 3.177451\n",
      "Train Epoch: 4 [238720/697932 (34%)]\tLoss: 3.198974\n",
      "Train Epoch: 4 [239360/697932 (34%)]\tLoss: 3.180927\n",
      "Train Epoch: 4 [240000/697932 (34%)]\tLoss: 3.189822\n",
      "Train Epoch: 4 [240640/697932 (34%)]\tLoss: 3.170411\n",
      "Train Epoch: 4 [241280/697932 (35%)]\tLoss: 3.152247\n",
      "Train Epoch: 4 [241920/697932 (35%)]\tLoss: 3.178805\n",
      "Train Epoch: 4 [242560/697932 (35%)]\tLoss: 3.172248\n",
      "Train Epoch: 4 [243200/697932 (35%)]\tLoss: 3.157722\n",
      "Train Epoch: 4 [243840/697932 (35%)]\tLoss: 3.172654\n",
      "Train Epoch: 4 [244480/697932 (35%)]\tLoss: 3.163092\n",
      "Train Epoch: 4 [245120/697932 (35%)]\tLoss: 3.195995\n",
      "Train Epoch: 4 [245760/697932 (35%)]\tLoss: 3.159460\n",
      "Train Epoch: 4 [246400/697932 (35%)]\tLoss: 3.192047\n",
      "Train Epoch: 4 [247040/697932 (35%)]\tLoss: 3.178722\n",
      "Train Epoch: 4 [247680/697932 (35%)]\tLoss: 3.182456\n",
      "Train Epoch: 4 [248320/697932 (36%)]\tLoss: 3.187575\n",
      "Train Epoch: 4 [248960/697932 (36%)]\tLoss: 3.155154\n",
      "Train Epoch: 4 [249600/697932 (36%)]\tLoss: 3.191365\n",
      "Train Epoch: 4 [250240/697932 (36%)]\tLoss: 3.130271\n",
      "Train Epoch: 4 [250880/697932 (36%)]\tLoss: 3.159523\n",
      "Train Epoch: 4 [251520/697932 (36%)]\tLoss: 3.141323\n",
      "Train Epoch: 4 [252160/697932 (36%)]\tLoss: 3.169372\n",
      "Train Epoch: 4 [252800/697932 (36%)]\tLoss: 3.160067\n",
      "Train Epoch: 4 [253440/697932 (36%)]\tLoss: 3.163974\n",
      "Train Epoch: 4 [254080/697932 (36%)]\tLoss: 3.160819\n",
      "Train Epoch: 4 [254720/697932 (36%)]\tLoss: 3.177749\n",
      "Train Epoch: 4 [255360/697932 (37%)]\tLoss: 3.156571\n",
      "Train Epoch: 4 [256000/697932 (37%)]\tLoss: 3.179630\n",
      "Train Epoch: 4 [256640/697932 (37%)]\tLoss: 3.146166\n",
      "Train Epoch: 4 [257280/697932 (37%)]\tLoss: 3.169173\n",
      "Train Epoch: 4 [257920/697932 (37%)]\tLoss: 3.176557\n",
      "Train Epoch: 4 [258560/697932 (37%)]\tLoss: 3.145472\n",
      "Train Epoch: 4 [259200/697932 (37%)]\tLoss: 3.155871\n",
      "Train Epoch: 4 [259840/697932 (37%)]\tLoss: 3.159731\n",
      "Train Epoch: 4 [260480/697932 (37%)]\tLoss: 3.148654\n",
      "Train Epoch: 4 [261120/697932 (37%)]\tLoss: 3.172522\n",
      "Train Epoch: 4 [261760/697932 (38%)]\tLoss: 3.179833\n",
      "Train Epoch: 4 [262400/697932 (38%)]\tLoss: 3.158087\n",
      "Train Epoch: 4 [263040/697932 (38%)]\tLoss: 3.168804\n",
      "Train Epoch: 4 [263680/697932 (38%)]\tLoss: 3.157185\n",
      "Train Epoch: 4 [264320/697932 (38%)]\tLoss: 3.147076\n",
      "Train Epoch: 4 [264960/697932 (38%)]\tLoss: 3.198365\n",
      "Train Epoch: 4 [265600/697932 (38%)]\tLoss: 3.162343\n",
      "Train Epoch: 4 [266240/697932 (38%)]\tLoss: 3.184969\n",
      "Train Epoch: 4 [266880/697932 (38%)]\tLoss: 3.187722\n",
      "Train Epoch: 4 [267520/697932 (38%)]\tLoss: 3.187326\n",
      "Train Epoch: 4 [268160/697932 (38%)]\tLoss: 3.155570\n",
      "Train Epoch: 4 [268800/697932 (39%)]\tLoss: 3.163876\n",
      "Train Epoch: 4 [269440/697932 (39%)]\tLoss: 3.192896\n",
      "Train Epoch: 4 [270080/697932 (39%)]\tLoss: 3.192121\n",
      "Train Epoch: 4 [270720/697932 (39%)]\tLoss: 3.151511\n",
      "Train Epoch: 4 [271360/697932 (39%)]\tLoss: 3.131940\n",
      "Train Epoch: 4 [272000/697932 (39%)]\tLoss: 3.184186\n",
      "Train Epoch: 4 [272640/697932 (39%)]\tLoss: 3.155806\n",
      "Train Epoch: 4 [273280/697932 (39%)]\tLoss: 3.166587\n",
      "Train Epoch: 4 [273920/697932 (39%)]\tLoss: 3.127462\n",
      "Train Epoch: 4 [274560/697932 (39%)]\tLoss: 3.171478\n",
      "Train Epoch: 4 [275200/697932 (39%)]\tLoss: 3.138187\n",
      "Train Epoch: 4 [275840/697932 (40%)]\tLoss: 3.200048\n",
      "Train Epoch: 4 [276480/697932 (40%)]\tLoss: 3.190342\n",
      "Train Epoch: 4 [277120/697932 (40%)]\tLoss: 3.172675\n",
      "Train Epoch: 4 [277760/697932 (40%)]\tLoss: 3.204899\n",
      "Train Epoch: 4 [278400/697932 (40%)]\tLoss: 3.166892\n",
      "Train Epoch: 4 [279040/697932 (40%)]\tLoss: 3.175561\n",
      "Train Epoch: 4 [279680/697932 (40%)]\tLoss: 3.175719\n",
      "Train Epoch: 4 [280320/697932 (40%)]\tLoss: 3.194090\n",
      "Train Epoch: 4 [280960/697932 (40%)]\tLoss: 3.181450\n",
      "Train Epoch: 4 [281600/697932 (40%)]\tLoss: 3.149060\n",
      "Train Epoch: 4 [282240/697932 (40%)]\tLoss: 3.184206\n",
      "Train Epoch: 4 [282880/697932 (41%)]\tLoss: 3.202073\n",
      "Train Epoch: 4 [283520/697932 (41%)]\tLoss: 3.155361\n",
      "Train Epoch: 4 [284160/697932 (41%)]\tLoss: 3.167519\n",
      "Train Epoch: 4 [284800/697932 (41%)]\tLoss: 3.185543\n",
      "Train Epoch: 4 [285440/697932 (41%)]\tLoss: 3.177224\n",
      "Train Epoch: 4 [286080/697932 (41%)]\tLoss: 3.150808\n",
      "Train Epoch: 4 [286720/697932 (41%)]\tLoss: 3.167520\n",
      "Train Epoch: 4 [287360/697932 (41%)]\tLoss: 3.175809\n",
      "Train Epoch: 4 [288000/697932 (41%)]\tLoss: 3.144885\n",
      "Train Epoch: 4 [288640/697932 (41%)]\tLoss: 3.178334\n",
      "Train Epoch: 4 [289280/697932 (41%)]\tLoss: 3.191350\n",
      "Train Epoch: 4 [289920/697932 (42%)]\tLoss: 3.149772\n",
      "Train Epoch: 4 [290560/697932 (42%)]\tLoss: 3.149744\n",
      "Train Epoch: 4 [291200/697932 (42%)]\tLoss: 3.185124\n",
      "Train Epoch: 4 [291840/697932 (42%)]\tLoss: 3.181852\n",
      "Train Epoch: 4 [292480/697932 (42%)]\tLoss: 3.159844\n",
      "Train Epoch: 4 [293120/697932 (42%)]\tLoss: 3.165488\n",
      "Train Epoch: 4 [293760/697932 (42%)]\tLoss: 3.176915\n",
      "Train Epoch: 4 [294400/697932 (42%)]\tLoss: 3.153159\n",
      "Train Epoch: 4 [295040/697932 (42%)]\tLoss: 3.152873\n",
      "Train Epoch: 4 [295680/697932 (42%)]\tLoss: 3.146105\n",
      "Train Epoch: 4 [296320/697932 (42%)]\tLoss: 3.192115\n",
      "Train Epoch: 4 [296960/697932 (43%)]\tLoss: 3.131178\n",
      "Train Epoch: 4 [297600/697932 (43%)]\tLoss: 3.175479\n",
      "Train Epoch: 4 [298240/697932 (43%)]\tLoss: 3.165944\n",
      "Train Epoch: 4 [298880/697932 (43%)]\tLoss: 3.143183\n",
      "Train Epoch: 4 [299520/697932 (43%)]\tLoss: 3.170694\n",
      "Train Epoch: 4 [300160/697932 (43%)]\tLoss: 3.126920\n",
      "Train Epoch: 4 [300800/697932 (43%)]\tLoss: 3.151146\n",
      "Train Epoch: 4 [301440/697932 (43%)]\tLoss: 3.175334\n",
      "Train Epoch: 4 [302080/697932 (43%)]\tLoss: 3.167656\n",
      "Train Epoch: 4 [302720/697932 (43%)]\tLoss: 3.205614\n",
      "Train Epoch: 4 [303360/697932 (43%)]\tLoss: 3.176205\n",
      "Train Epoch: 4 [304000/697932 (44%)]\tLoss: 3.142076\n",
      "Train Epoch: 4 [304640/697932 (44%)]\tLoss: 3.195052\n",
      "Train Epoch: 4 [305280/697932 (44%)]\tLoss: 3.133376\n",
      "Train Epoch: 4 [305920/697932 (44%)]\tLoss: 3.161587\n",
      "Train Epoch: 4 [306560/697932 (44%)]\tLoss: 3.143329\n",
      "Train Epoch: 4 [307200/697932 (44%)]\tLoss: 3.151124\n",
      "Train Epoch: 4 [307840/697932 (44%)]\tLoss: 3.165668\n",
      "Train Epoch: 4 [308480/697932 (44%)]\tLoss: 3.167429\n",
      "Train Epoch: 4 [309120/697932 (44%)]\tLoss: 3.165756\n",
      "Train Epoch: 4 [309760/697932 (44%)]\tLoss: 3.198736\n",
      "Train Epoch: 4 [310400/697932 (44%)]\tLoss: 3.195622\n",
      "Train Epoch: 4 [311040/697932 (45%)]\tLoss: 3.201471\n",
      "Train Epoch: 4 [311680/697932 (45%)]\tLoss: 3.193508\n",
      "Train Epoch: 4 [312320/697932 (45%)]\tLoss: 3.184217\n",
      "Train Epoch: 4 [312960/697932 (45%)]\tLoss: 3.145403\n",
      "Train Epoch: 4 [313600/697932 (45%)]\tLoss: 3.188320\n",
      "Train Epoch: 4 [314240/697932 (45%)]\tLoss: 3.170602\n",
      "Train Epoch: 4 [314880/697932 (45%)]\tLoss: 3.145731\n",
      "Train Epoch: 4 [315520/697932 (45%)]\tLoss: 3.175693\n",
      "Train Epoch: 4 [316160/697932 (45%)]\tLoss: 3.172228\n",
      "Train Epoch: 4 [316800/697932 (45%)]\tLoss: 3.164863\n",
      "Train Epoch: 4 [317440/697932 (45%)]\tLoss: 3.155519\n",
      "Train Epoch: 4 [318080/697932 (46%)]\tLoss: 3.135792\n",
      "Train Epoch: 4 [318720/697932 (46%)]\tLoss: 3.155075\n",
      "Train Epoch: 4 [319360/697932 (46%)]\tLoss: 3.156293\n",
      "Train Epoch: 4 [320000/697932 (46%)]\tLoss: 3.177974\n",
      "Train Epoch: 4 [320640/697932 (46%)]\tLoss: 3.176415\n",
      "Train Epoch: 4 [321280/697932 (46%)]\tLoss: 3.175629\n",
      "Train Epoch: 4 [321920/697932 (46%)]\tLoss: 3.163110\n",
      "Train Epoch: 4 [322560/697932 (46%)]\tLoss: 3.211779\n",
      "Train Epoch: 4 [323200/697932 (46%)]\tLoss: 3.163238\n",
      "Train Epoch: 4 [323840/697932 (46%)]\tLoss: 3.163555\n",
      "Train Epoch: 4 [324480/697932 (46%)]\tLoss: 3.187475\n",
      "Train Epoch: 4 [325120/697932 (47%)]\tLoss: 3.200228\n",
      "Train Epoch: 4 [325760/697932 (47%)]\tLoss: 3.188811\n",
      "Train Epoch: 4 [326400/697932 (47%)]\tLoss: 3.177602\n",
      "Train Epoch: 4 [327040/697932 (47%)]\tLoss: 3.177850\n",
      "Train Epoch: 4 [327680/697932 (47%)]\tLoss: 3.177447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [328320/697932 (47%)]\tLoss: 3.183603\n",
      "Train Epoch: 4 [328960/697932 (47%)]\tLoss: 3.175888\n",
      "Train Epoch: 4 [329600/697932 (47%)]\tLoss: 3.157922\n",
      "Train Epoch: 4 [330240/697932 (47%)]\tLoss: 3.143937\n",
      "Train Epoch: 4 [330880/697932 (47%)]\tLoss: 3.170660\n",
      "Train Epoch: 4 [331520/697932 (47%)]\tLoss: 3.179292\n",
      "Train Epoch: 4 [332160/697932 (48%)]\tLoss: 3.200797\n",
      "Train Epoch: 4 [332800/697932 (48%)]\tLoss: 3.145977\n",
      "Train Epoch: 4 [333440/697932 (48%)]\tLoss: 3.191776\n",
      "Train Epoch: 4 [334080/697932 (48%)]\tLoss: 3.175684\n",
      "Train Epoch: 4 [334720/697932 (48%)]\tLoss: 3.194141\n",
      "Train Epoch: 4 [335360/697932 (48%)]\tLoss: 3.176056\n",
      "Train Epoch: 4 [336000/697932 (48%)]\tLoss: 3.152941\n",
      "Train Epoch: 4 [336640/697932 (48%)]\tLoss: 3.176024\n",
      "Train Epoch: 4 [337280/697932 (48%)]\tLoss: 3.191787\n",
      "Train Epoch: 4 [337920/697932 (48%)]\tLoss: 3.156360\n",
      "Train Epoch: 4 [338560/697932 (49%)]\tLoss: 3.185055\n",
      "Train Epoch: 4 [339200/697932 (49%)]\tLoss: 3.165115\n",
      "Train Epoch: 4 [339840/697932 (49%)]\tLoss: 3.189066\n",
      "Train Epoch: 4 [340480/697932 (49%)]\tLoss: 3.170927\n",
      "Train Epoch: 4 [341120/697932 (49%)]\tLoss: 3.175537\n",
      "Train Epoch: 4 [341760/697932 (49%)]\tLoss: 3.174692\n",
      "Train Epoch: 4 [342400/697932 (49%)]\tLoss: 3.148576\n",
      "Train Epoch: 4 [343040/697932 (49%)]\tLoss: 3.148349\n",
      "Train Epoch: 4 [343680/697932 (49%)]\tLoss: 3.176385\n",
      "Train Epoch: 4 [344320/697932 (49%)]\tLoss: 3.147021\n",
      "Train Epoch: 4 [344960/697932 (49%)]\tLoss: 3.187403\n",
      "Train Epoch: 4 [345600/697932 (50%)]\tLoss: 3.161320\n",
      "Train Epoch: 4 [346240/697932 (50%)]\tLoss: 3.155979\n",
      "Train Epoch: 4 [346880/697932 (50%)]\tLoss: 3.158616\n",
      "Train Epoch: 4 [347520/697932 (50%)]\tLoss: 3.155580\n",
      "Train Epoch: 4 [348160/697932 (50%)]\tLoss: 3.158666\n",
      "Train Epoch: 4 [348800/697932 (50%)]\tLoss: 3.216792\n",
      "Train Epoch: 4 [349440/697932 (50%)]\tLoss: 3.151060\n",
      "Train Epoch: 4 [350080/697932 (50%)]\tLoss: 3.174204\n",
      "Train Epoch: 4 [350720/697932 (50%)]\tLoss: 3.163055\n",
      "Train Epoch: 4 [351360/697932 (50%)]\tLoss: 3.176115\n",
      "Train Epoch: 4 [352000/697932 (50%)]\tLoss: 3.193550\n",
      "Train Epoch: 4 [352640/697932 (51%)]\tLoss: 3.175799\n",
      "Train Epoch: 4 [353280/697932 (51%)]\tLoss: 3.182674\n",
      "Train Epoch: 4 [353920/697932 (51%)]\tLoss: 3.151495\n",
      "Train Epoch: 4 [354560/697932 (51%)]\tLoss: 3.165306\n",
      "Train Epoch: 4 [355200/697932 (51%)]\tLoss: 3.155366\n",
      "Train Epoch: 4 [355840/697932 (51%)]\tLoss: 3.176143\n",
      "Train Epoch: 4 [356480/697932 (51%)]\tLoss: 3.180241\n",
      "Train Epoch: 4 [357120/697932 (51%)]\tLoss: 3.165096\n",
      "Train Epoch: 4 [357760/697932 (51%)]\tLoss: 3.158937\n",
      "Train Epoch: 4 [358400/697932 (51%)]\tLoss: 3.163989\n",
      "Train Epoch: 4 [359040/697932 (51%)]\tLoss: 3.165956\n",
      "Train Epoch: 4 [359680/697932 (52%)]\tLoss: 3.191751\n",
      "Train Epoch: 4 [360320/697932 (52%)]\tLoss: 3.177983\n",
      "Train Epoch: 4 [360960/697932 (52%)]\tLoss: 3.167935\n",
      "Train Epoch: 4 [361600/697932 (52%)]\tLoss: 3.132792\n",
      "Train Epoch: 4 [362240/697932 (52%)]\tLoss: 3.177154\n",
      "Train Epoch: 4 [362880/697932 (52%)]\tLoss: 3.182679\n",
      "Train Epoch: 4 [363520/697932 (52%)]\tLoss: 3.144854\n",
      "Train Epoch: 4 [364160/697932 (52%)]\tLoss: 3.169622\n",
      "Train Epoch: 4 [364800/697932 (52%)]\tLoss: 3.155488\n",
      "Train Epoch: 4 [365440/697932 (52%)]\tLoss: 3.169979\n",
      "Train Epoch: 4 [366080/697932 (52%)]\tLoss: 3.175104\n",
      "Train Epoch: 4 [366720/697932 (53%)]\tLoss: 3.204395\n",
      "Train Epoch: 4 [367360/697932 (53%)]\tLoss: 3.175128\n",
      "Train Epoch: 4 [368000/697932 (53%)]\tLoss: 3.177755\n",
      "Train Epoch: 4 [368640/697932 (53%)]\tLoss: 3.160630\n",
      "Train Epoch: 4 [369280/697932 (53%)]\tLoss: 3.173863\n",
      "Train Epoch: 4 [369920/697932 (53%)]\tLoss: 3.173666\n",
      "Train Epoch: 4 [370560/697932 (53%)]\tLoss: 3.173146\n",
      "Train Epoch: 4 [371200/697932 (53%)]\tLoss: 3.187588\n",
      "Train Epoch: 4 [371840/697932 (53%)]\tLoss: 3.173217\n",
      "Train Epoch: 4 [372480/697932 (53%)]\tLoss: 3.148859\n",
      "Train Epoch: 4 [373120/697932 (53%)]\tLoss: 3.157873\n",
      "Train Epoch: 4 [373760/697932 (54%)]\tLoss: 3.173481\n",
      "Train Epoch: 4 [374400/697932 (54%)]\tLoss: 3.182019\n",
      "Train Epoch: 4 [375040/697932 (54%)]\tLoss: 3.173823\n",
      "Train Epoch: 4 [375680/697932 (54%)]\tLoss: 3.155066\n",
      "Train Epoch: 4 [376320/697932 (54%)]\tLoss: 3.193676\n",
      "Train Epoch: 4 [376960/697932 (54%)]\tLoss: 3.193124\n",
      "Train Epoch: 4 [377600/697932 (54%)]\tLoss: 3.166491\n",
      "Train Epoch: 4 [378240/697932 (54%)]\tLoss: 3.173177\n",
      "Train Epoch: 4 [378880/697932 (54%)]\tLoss: 3.166804\n",
      "Train Epoch: 4 [379520/697932 (54%)]\tLoss: 3.154222\n",
      "Train Epoch: 4 [380160/697932 (54%)]\tLoss: 3.195536\n",
      "Train Epoch: 4 [380800/697932 (55%)]\tLoss: 3.176007\n",
      "Train Epoch: 4 [381440/697932 (55%)]\tLoss: 3.184055\n",
      "Train Epoch: 4 [382080/697932 (55%)]\tLoss: 3.168430\n",
      "Train Epoch: 4 [382720/697932 (55%)]\tLoss: 3.153692\n",
      "Train Epoch: 4 [383360/697932 (55%)]\tLoss: 3.156469\n",
      "Train Epoch: 4 [384000/697932 (55%)]\tLoss: 3.158912\n",
      "Train Epoch: 4 [384640/697932 (55%)]\tLoss: 3.175885\n",
      "Train Epoch: 4 [385280/697932 (55%)]\tLoss: 3.158429\n",
      "Train Epoch: 4 [385920/697932 (55%)]\tLoss: 3.174364\n",
      "Train Epoch: 4 [386560/697932 (55%)]\tLoss: 3.163545\n",
      "Train Epoch: 4 [387200/697932 (55%)]\tLoss: 3.155458\n",
      "Train Epoch: 4 [387840/697932 (56%)]\tLoss: 3.177063\n",
      "Train Epoch: 4 [388480/697932 (56%)]\tLoss: 3.183344\n",
      "Train Epoch: 4 [389120/697932 (56%)]\tLoss: 3.181351\n",
      "Train Epoch: 4 [389760/697932 (56%)]\tLoss: 3.205900\n",
      "Train Epoch: 4 [390400/697932 (56%)]\tLoss: 3.166314\n",
      "Train Epoch: 4 [391040/697932 (56%)]\tLoss: 3.146494\n",
      "Train Epoch: 4 [391680/697932 (56%)]\tLoss: 3.173407\n",
      "Train Epoch: 4 [392320/697932 (56%)]\tLoss: 3.165147\n",
      "Train Epoch: 4 [392960/697932 (56%)]\tLoss: 3.177717\n",
      "Train Epoch: 4 [393600/697932 (56%)]\tLoss: 3.180257\n",
      "Train Epoch: 4 [394240/697932 (56%)]\tLoss: 3.177123\n",
      "Train Epoch: 4 [394880/697932 (57%)]\tLoss: 3.183597\n",
      "Train Epoch: 4 [395520/697932 (57%)]\tLoss: 3.169398\n",
      "Train Epoch: 4 [396160/697932 (57%)]\tLoss: 3.159147\n",
      "Train Epoch: 4 [396800/697932 (57%)]\tLoss: 3.178275\n",
      "Train Epoch: 4 [397440/697932 (57%)]\tLoss: 3.152732\n",
      "Train Epoch: 4 [398080/697932 (57%)]\tLoss: 3.157730\n",
      "Train Epoch: 4 [398720/697932 (57%)]\tLoss: 3.149955\n",
      "Train Epoch: 4 [399360/697932 (57%)]\tLoss: 3.189834\n",
      "Train Epoch: 4 [400000/697932 (57%)]\tLoss: 3.147825\n",
      "Train Epoch: 4 [400640/697932 (57%)]\tLoss: 3.165223\n",
      "Train Epoch: 4 [401280/697932 (57%)]\tLoss: 3.153144\n",
      "Train Epoch: 4 [401920/697932 (58%)]\tLoss: 3.141827\n",
      "Train Epoch: 4 [402560/697932 (58%)]\tLoss: 3.160850\n",
      "Train Epoch: 4 [403200/697932 (58%)]\tLoss: 3.171485\n",
      "Train Epoch: 4 [403840/697932 (58%)]\tLoss: 3.163166\n",
      "Train Epoch: 4 [404480/697932 (58%)]\tLoss: 3.162521\n",
      "Train Epoch: 4 [405120/697932 (58%)]\tLoss: 3.148175\n",
      "Train Epoch: 4 [405760/697932 (58%)]\tLoss: 3.162436\n",
      "Train Epoch: 4 [406400/697932 (58%)]\tLoss: 3.144086\n",
      "Train Epoch: 4 [407040/697932 (58%)]\tLoss: 3.182315\n",
      "Train Epoch: 4 [407680/697932 (58%)]\tLoss: 3.181839\n",
      "Train Epoch: 4 [408320/697932 (58%)]\tLoss: 3.171734\n",
      "Train Epoch: 4 [408960/697932 (59%)]\tLoss: 3.169792\n",
      "Train Epoch: 4 [409600/697932 (59%)]\tLoss: 3.205590\n",
      "Train Epoch: 4 [410240/697932 (59%)]\tLoss: 3.164409\n",
      "Train Epoch: 4 [410880/697932 (59%)]\tLoss: 3.154009\n",
      "Train Epoch: 4 [411520/697932 (59%)]\tLoss: 3.155662\n",
      "Train Epoch: 4 [412160/697932 (59%)]\tLoss: 3.183348\n",
      "Train Epoch: 4 [412800/697932 (59%)]\tLoss: 3.179926\n",
      "Train Epoch: 4 [413440/697932 (59%)]\tLoss: 3.175989\n",
      "Train Epoch: 4 [414080/697932 (59%)]\tLoss: 3.137448\n",
      "Train Epoch: 4 [414720/697932 (59%)]\tLoss: 3.173909\n",
      "Train Epoch: 4 [415360/697932 (60%)]\tLoss: 3.192350\n",
      "Train Epoch: 4 [416000/697932 (60%)]\tLoss: 3.162539\n",
      "Train Epoch: 4 [416640/697932 (60%)]\tLoss: 3.167920\n",
      "Train Epoch: 4 [417280/697932 (60%)]\tLoss: 3.150121\n",
      "Train Epoch: 4 [417920/697932 (60%)]\tLoss: 3.178330\n",
      "Train Epoch: 4 [418560/697932 (60%)]\tLoss: 3.172043\n",
      "Train Epoch: 4 [419200/697932 (60%)]\tLoss: 3.188782\n",
      "Train Epoch: 4 [419840/697932 (60%)]\tLoss: 3.178536\n",
      "Train Epoch: 4 [420480/697932 (60%)]\tLoss: 3.143759\n",
      "Train Epoch: 4 [421120/697932 (60%)]\tLoss: 3.163793\n",
      "Train Epoch: 4 [421760/697932 (60%)]\tLoss: 3.148221\n",
      "Train Epoch: 4 [422400/697932 (61%)]\tLoss: 3.181092\n",
      "Train Epoch: 4 [423040/697932 (61%)]\tLoss: 3.165727\n",
      "Train Epoch: 4 [423680/697932 (61%)]\tLoss: 3.175994\n",
      "Train Epoch: 4 [424320/697932 (61%)]\tLoss: 3.154888\n",
      "Train Epoch: 4 [424960/697932 (61%)]\tLoss: 3.188041\n",
      "Train Epoch: 4 [425600/697932 (61%)]\tLoss: 3.162366\n",
      "Train Epoch: 4 [426240/697932 (61%)]\tLoss: 3.191786\n",
      "Train Epoch: 4 [426880/697932 (61%)]\tLoss: 3.172912\n",
      "Train Epoch: 4 [427520/697932 (61%)]\tLoss: 3.152332\n",
      "Train Epoch: 4 [428160/697932 (61%)]\tLoss: 3.148299\n",
      "Train Epoch: 4 [428800/697932 (61%)]\tLoss: 3.168318\n",
      "Train Epoch: 4 [429440/697932 (62%)]\tLoss: 3.188172\n",
      "Train Epoch: 4 [430080/697932 (62%)]\tLoss: 3.182631\n",
      "Train Epoch: 4 [430720/697932 (62%)]\tLoss: 3.184602\n",
      "Train Epoch: 4 [431360/697932 (62%)]\tLoss: 3.152881\n",
      "Train Epoch: 4 [432000/697932 (62%)]\tLoss: 3.156679\n",
      "Train Epoch: 4 [432640/697932 (62%)]\tLoss: 3.158313\n",
      "Train Epoch: 4 [433280/697932 (62%)]\tLoss: 3.157590\n",
      "Train Epoch: 4 [433920/697932 (62%)]\tLoss: 3.146472\n",
      "Train Epoch: 4 [434560/697932 (62%)]\tLoss: 3.167652\n",
      "Train Epoch: 4 [435200/697932 (62%)]\tLoss: 3.158135\n",
      "Train Epoch: 4 [435840/697932 (62%)]\tLoss: 3.172636\n",
      "Train Epoch: 4 [436480/697932 (63%)]\tLoss: 3.151858\n",
      "Train Epoch: 4 [437120/697932 (63%)]\tLoss: 3.180654\n",
      "Train Epoch: 4 [437760/697932 (63%)]\tLoss: 3.214239\n",
      "Train Epoch: 4 [438400/697932 (63%)]\tLoss: 3.161286\n",
      "Train Epoch: 4 [439040/697932 (63%)]\tLoss: 3.175180\n",
      "Train Epoch: 4 [439680/697932 (63%)]\tLoss: 3.168601\n",
      "Train Epoch: 4 [440320/697932 (63%)]\tLoss: 3.185185\n",
      "Train Epoch: 4 [440960/697932 (63%)]\tLoss: 3.161209\n",
      "Train Epoch: 4 [441600/697932 (63%)]\tLoss: 3.205778\n",
      "Train Epoch: 4 [442240/697932 (63%)]\tLoss: 3.190609\n",
      "Train Epoch: 4 [442880/697932 (63%)]\tLoss: 3.174294\n",
      "Train Epoch: 4 [443520/697932 (64%)]\tLoss: 3.161330\n",
      "Train Epoch: 4 [444160/697932 (64%)]\tLoss: 3.167027\n",
      "Train Epoch: 4 [444800/697932 (64%)]\tLoss: 3.159311\n",
      "Train Epoch: 4 [445440/697932 (64%)]\tLoss: 3.197387\n",
      "Train Epoch: 4 [446080/697932 (64%)]\tLoss: 3.184717\n",
      "Train Epoch: 4 [446720/697932 (64%)]\tLoss: 3.169453\n",
      "Train Epoch: 4 [447360/697932 (64%)]\tLoss: 3.177463\n",
      "Train Epoch: 4 [448000/697932 (64%)]\tLoss: 3.185693\n",
      "Train Epoch: 4 [448640/697932 (64%)]\tLoss: 3.186523\n",
      "Train Epoch: 4 [449280/697932 (64%)]\tLoss: 3.168438\n",
      "Train Epoch: 4 [449920/697932 (64%)]\tLoss: 3.154554\n",
      "Train Epoch: 4 [450560/697932 (65%)]\tLoss: 3.174270\n",
      "Train Epoch: 4 [451200/697932 (65%)]\tLoss: 3.194797\n",
      "Train Epoch: 4 [451840/697932 (65%)]\tLoss: 3.187136\n",
      "Train Epoch: 4 [452480/697932 (65%)]\tLoss: 3.183546\n",
      "Train Epoch: 4 [453120/697932 (65%)]\tLoss: 3.203855\n",
      "Train Epoch: 4 [453760/697932 (65%)]\tLoss: 3.176073\n",
      "Train Epoch: 4 [454400/697932 (65%)]\tLoss: 3.159331\n",
      "Train Epoch: 4 [455040/697932 (65%)]\tLoss: 3.184879\n",
      "Train Epoch: 4 [455680/697932 (65%)]\tLoss: 3.179029\n",
      "Train Epoch: 4 [456320/697932 (65%)]\tLoss: 3.172187\n",
      "Train Epoch: 4 [456960/697932 (65%)]\tLoss: 3.143617\n",
      "Train Epoch: 4 [457600/697932 (66%)]\tLoss: 3.195635\n",
      "Train Epoch: 4 [458240/697932 (66%)]\tLoss: 3.178361\n",
      "Train Epoch: 4 [458880/697932 (66%)]\tLoss: 3.178380\n",
      "Train Epoch: 4 [459520/697932 (66%)]\tLoss: 3.157497\n",
      "Train Epoch: 4 [460160/697932 (66%)]\tLoss: 3.167166\n",
      "Train Epoch: 4 [460800/697932 (66%)]\tLoss: 3.147990\n",
      "Train Epoch: 4 [461440/697932 (66%)]\tLoss: 3.160826\n",
      "Train Epoch: 4 [462080/697932 (66%)]\tLoss: 3.176618\n",
      "Train Epoch: 4 [462720/697932 (66%)]\tLoss: 3.150775\n",
      "Train Epoch: 4 [463360/697932 (66%)]\tLoss: 3.174476\n",
      "Train Epoch: 4 [464000/697932 (66%)]\tLoss: 3.164577\n",
      "Train Epoch: 4 [464640/697932 (67%)]\tLoss: 3.157882\n",
      "Train Epoch: 4 [465280/697932 (67%)]\tLoss: 3.150221\n",
      "Train Epoch: 4 [465920/697932 (67%)]\tLoss: 3.170540\n",
      "Train Epoch: 4 [466560/697932 (67%)]\tLoss: 3.183090\n",
      "Train Epoch: 4 [467200/697932 (67%)]\tLoss: 3.196797\n",
      "Train Epoch: 4 [467840/697932 (67%)]\tLoss: 3.174480\n",
      "Train Epoch: 4 [468480/697932 (67%)]\tLoss: 3.163693\n",
      "Train Epoch: 4 [469120/697932 (67%)]\tLoss: 3.178873\n",
      "Train Epoch: 4 [469760/697932 (67%)]\tLoss: 3.146536\n",
      "Train Epoch: 4 [470400/697932 (67%)]\tLoss: 3.165232\n",
      "Train Epoch: 4 [471040/697932 (67%)]\tLoss: 3.176925\n",
      "Train Epoch: 4 [471680/697932 (68%)]\tLoss: 3.156174\n",
      "Train Epoch: 4 [472320/697932 (68%)]\tLoss: 3.150483\n",
      "Train Epoch: 4 [472960/697932 (68%)]\tLoss: 3.202379\n",
      "Train Epoch: 4 [473600/697932 (68%)]\tLoss: 3.156368\n",
      "Train Epoch: 4 [474240/697932 (68%)]\tLoss: 3.162626\n",
      "Train Epoch: 4 [474880/697932 (68%)]\tLoss: 3.171261\n",
      "Train Epoch: 4 [475520/697932 (68%)]\tLoss: 3.173095\n",
      "Train Epoch: 4 [476160/697932 (68%)]\tLoss: 3.192508\n",
      "Train Epoch: 4 [476800/697932 (68%)]\tLoss: 3.118135\n",
      "Train Epoch: 4 [477440/697932 (68%)]\tLoss: 3.186555\n",
      "Train Epoch: 4 [478080/697932 (68%)]\tLoss: 3.140303\n",
      "Train Epoch: 4 [478720/697932 (69%)]\tLoss: 3.167916\n",
      "Train Epoch: 4 [479360/697932 (69%)]\tLoss: 3.194290\n",
      "Train Epoch: 4 [480000/697932 (69%)]\tLoss: 3.197887\n",
      "Train Epoch: 4 [480640/697932 (69%)]\tLoss: 3.187643\n",
      "Train Epoch: 4 [481280/697932 (69%)]\tLoss: 3.173505\n",
      "Train Epoch: 4 [481920/697932 (69%)]\tLoss: 3.173961\n",
      "Train Epoch: 4 [482560/697932 (69%)]\tLoss: 3.166023\n",
      "Train Epoch: 4 [483200/697932 (69%)]\tLoss: 3.181039\n",
      "Train Epoch: 4 [483840/697932 (69%)]\tLoss: 3.154807\n",
      "Train Epoch: 4 [484480/697932 (69%)]\tLoss: 3.138159\n",
      "Train Epoch: 4 [485120/697932 (70%)]\tLoss: 3.189069\n",
      "Train Epoch: 4 [485760/697932 (70%)]\tLoss: 3.168804\n",
      "Train Epoch: 4 [486400/697932 (70%)]\tLoss: 3.161425\n",
      "Train Epoch: 4 [487040/697932 (70%)]\tLoss: 3.141497\n",
      "Train Epoch: 4 [487680/697932 (70%)]\tLoss: 3.161854\n",
      "Train Epoch: 4 [488320/697932 (70%)]\tLoss: 3.163944\n",
      "Train Epoch: 4 [488960/697932 (70%)]\tLoss: 3.170977\n",
      "Train Epoch: 4 [489600/697932 (70%)]\tLoss: 3.166290\n",
      "Train Epoch: 4 [490240/697932 (70%)]\tLoss: 3.178125\n",
      "Train Epoch: 4 [490880/697932 (70%)]\tLoss: 3.188454\n",
      "Train Epoch: 4 [491520/697932 (70%)]\tLoss: 3.160678\n",
      "Train Epoch: 4 [492160/697932 (71%)]\tLoss: 3.165363\n",
      "Train Epoch: 4 [492800/697932 (71%)]\tLoss: 3.159173\n",
      "Train Epoch: 4 [493440/697932 (71%)]\tLoss: 3.178236\n",
      "Train Epoch: 4 [494080/697932 (71%)]\tLoss: 3.174054\n",
      "Train Epoch: 4 [494720/697932 (71%)]\tLoss: 3.152474\n",
      "Train Epoch: 4 [495360/697932 (71%)]\tLoss: 3.166735\n",
      "Train Epoch: 4 [496000/697932 (71%)]\tLoss: 3.163615\n",
      "Train Epoch: 4 [496640/697932 (71%)]\tLoss: 3.198927\n",
      "Train Epoch: 4 [497280/697932 (71%)]\tLoss: 3.170076\n",
      "Train Epoch: 4 [497920/697932 (71%)]\tLoss: 3.178553\n",
      "Train Epoch: 4 [498560/697932 (71%)]\tLoss: 3.178513\n",
      "Train Epoch: 4 [499200/697932 (72%)]\tLoss: 3.156623\n",
      "Train Epoch: 4 [499840/697932 (72%)]\tLoss: 3.189508\n",
      "Train Epoch: 4 [500480/697932 (72%)]\tLoss: 3.198195\n",
      "Train Epoch: 4 [501120/697932 (72%)]\tLoss: 3.200103\n",
      "Train Epoch: 4 [501760/697932 (72%)]\tLoss: 3.185844\n",
      "Train Epoch: 4 [502400/697932 (72%)]\tLoss: 3.147381\n",
      "Train Epoch: 4 [503040/697932 (72%)]\tLoss: 3.135609\n",
      "Train Epoch: 4 [503680/697932 (72%)]\tLoss: 3.179148\n",
      "Train Epoch: 4 [504320/697932 (72%)]\tLoss: 3.166049\n",
      "Train Epoch: 4 [504960/697932 (72%)]\tLoss: 3.141488\n",
      "Train Epoch: 4 [505600/697932 (72%)]\tLoss: 3.148942\n",
      "Train Epoch: 4 [506240/697932 (73%)]\tLoss: 3.168493\n",
      "Train Epoch: 4 [506880/697932 (73%)]\tLoss: 3.165380\n",
      "Train Epoch: 4 [507520/697932 (73%)]\tLoss: 3.161561\n",
      "Train Epoch: 4 [508160/697932 (73%)]\tLoss: 3.185907\n",
      "Train Epoch: 4 [508800/697932 (73%)]\tLoss: 3.145802\n",
      "Train Epoch: 4 [509440/697932 (73%)]\tLoss: 3.170482\n",
      "Train Epoch: 4 [510080/697932 (73%)]\tLoss: 3.154725\n",
      "Train Epoch: 4 [510720/697932 (73%)]\tLoss: 3.165054\n",
      "Train Epoch: 4 [511360/697932 (73%)]\tLoss: 3.164346\n",
      "Train Epoch: 4 [512000/697932 (73%)]\tLoss: 3.152600\n",
      "Train Epoch: 4 [512640/697932 (73%)]\tLoss: 3.194222\n",
      "Train Epoch: 4 [513280/697932 (74%)]\tLoss: 3.183226\n",
      "Train Epoch: 4 [513920/697932 (74%)]\tLoss: 3.167317\n",
      "Train Epoch: 4 [514560/697932 (74%)]\tLoss: 3.202169\n",
      "Train Epoch: 4 [515200/697932 (74%)]\tLoss: 3.204205\n",
      "Train Epoch: 4 [515840/697932 (74%)]\tLoss: 3.165201\n",
      "Train Epoch: 4 [516480/697932 (74%)]\tLoss: 3.189029\n",
      "Train Epoch: 4 [517120/697932 (74%)]\tLoss: 3.203627\n",
      "Train Epoch: 4 [517760/697932 (74%)]\tLoss: 3.193794\n",
      "Train Epoch: 4 [518400/697932 (74%)]\tLoss: 3.162821\n",
      "Train Epoch: 4 [519040/697932 (74%)]\tLoss: 3.153323\n",
      "Train Epoch: 4 [519680/697932 (74%)]\tLoss: 3.171941\n",
      "Train Epoch: 4 [520320/697932 (75%)]\tLoss: 3.195900\n",
      "Train Epoch: 4 [520960/697932 (75%)]\tLoss: 3.151314\n",
      "Train Epoch: 4 [521600/697932 (75%)]\tLoss: 3.188041\n",
      "Train Epoch: 4 [522240/697932 (75%)]\tLoss: 3.172362\n",
      "Train Epoch: 4 [522880/697932 (75%)]\tLoss: 3.170559\n",
      "Train Epoch: 4 [523520/697932 (75%)]\tLoss: 3.189031\n",
      "Train Epoch: 4 [524160/697932 (75%)]\tLoss: 3.169790\n",
      "Train Epoch: 4 [524800/697932 (75%)]\tLoss: 3.173196\n",
      "Train Epoch: 4 [525440/697932 (75%)]\tLoss: 3.165769\n",
      "Train Epoch: 4 [526080/697932 (75%)]\tLoss: 3.177724\n",
      "Train Epoch: 4 [526720/697932 (75%)]\tLoss: 3.174458\n",
      "Train Epoch: 4 [527360/697932 (76%)]\tLoss: 3.181452\n",
      "Train Epoch: 4 [528000/697932 (76%)]\tLoss: 3.154082\n",
      "Train Epoch: 4 [528640/697932 (76%)]\tLoss: 3.189015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [529280/697932 (76%)]\tLoss: 3.198413\n",
      "Train Epoch: 4 [529920/697932 (76%)]\tLoss: 3.183088\n",
      "Train Epoch: 4 [530560/697932 (76%)]\tLoss: 3.157135\n",
      "Train Epoch: 4 [531200/697932 (76%)]\tLoss: 3.159315\n",
      "Train Epoch: 4 [531840/697932 (76%)]\tLoss: 3.164175\n",
      "Train Epoch: 4 [532480/697932 (76%)]\tLoss: 3.149601\n",
      "Train Epoch: 4 [533120/697932 (76%)]\tLoss: 3.167188\n",
      "Train Epoch: 4 [533760/697932 (76%)]\tLoss: 3.178592\n",
      "Train Epoch: 4 [534400/697932 (77%)]\tLoss: 3.158123\n",
      "Train Epoch: 4 [535040/697932 (77%)]\tLoss: 3.167181\n",
      "Train Epoch: 4 [535680/697932 (77%)]\tLoss: 3.161630\n",
      "Train Epoch: 4 [536320/697932 (77%)]\tLoss: 3.180242\n",
      "Train Epoch: 4 [536960/697932 (77%)]\tLoss: 3.161778\n",
      "Train Epoch: 4 [537600/697932 (77%)]\tLoss: 3.198126\n",
      "Train Epoch: 4 [538240/697932 (77%)]\tLoss: 3.160794\n",
      "Train Epoch: 4 [538880/697932 (77%)]\tLoss: 3.165800\n",
      "Train Epoch: 4 [539520/697932 (77%)]\tLoss: 3.169424\n",
      "Train Epoch: 4 [540160/697932 (77%)]\tLoss: 3.179105\n",
      "Train Epoch: 4 [540800/697932 (77%)]\tLoss: 3.158177\n",
      "Train Epoch: 4 [541440/697932 (78%)]\tLoss: 3.154773\n",
      "Train Epoch: 4 [542080/697932 (78%)]\tLoss: 3.167838\n",
      "Train Epoch: 4 [542720/697932 (78%)]\tLoss: 3.183562\n",
      "Train Epoch: 4 [543360/697932 (78%)]\tLoss: 3.134313\n",
      "Train Epoch: 4 [544000/697932 (78%)]\tLoss: 3.201457\n",
      "Train Epoch: 4 [544640/697932 (78%)]\tLoss: 3.180510\n",
      "Train Epoch: 4 [545280/697932 (78%)]\tLoss: 3.196942\n",
      "Train Epoch: 4 [545920/697932 (78%)]\tLoss: 3.170319\n",
      "Train Epoch: 4 [546560/697932 (78%)]\tLoss: 3.199044\n",
      "Train Epoch: 4 [547200/697932 (78%)]\tLoss: 3.193614\n",
      "Train Epoch: 4 [547840/697932 (78%)]\tLoss: 3.150016\n",
      "Train Epoch: 4 [548480/697932 (79%)]\tLoss: 3.193017\n",
      "Train Epoch: 4 [549120/697932 (79%)]\tLoss: 3.157876\n",
      "Train Epoch: 4 [549760/697932 (79%)]\tLoss: 3.162990\n",
      "Train Epoch: 4 [550400/697932 (79%)]\tLoss: 3.188074\n",
      "Train Epoch: 4 [551040/697932 (79%)]\tLoss: 3.181729\n",
      "Train Epoch: 4 [551680/697932 (79%)]\tLoss: 3.154746\n",
      "Train Epoch: 4 [552320/697932 (79%)]\tLoss: 3.172424\n",
      "Train Epoch: 4 [552960/697932 (79%)]\tLoss: 3.147449\n",
      "Train Epoch: 4 [553600/697932 (79%)]\tLoss: 3.122701\n",
      "Train Epoch: 4 [554240/697932 (79%)]\tLoss: 3.144657\n",
      "Train Epoch: 4 [554880/697932 (79%)]\tLoss: 3.171306\n",
      "Train Epoch: 4 [555520/697932 (80%)]\tLoss: 3.186511\n",
      "Train Epoch: 4 [556160/697932 (80%)]\tLoss: 3.176857\n",
      "Train Epoch: 4 [556800/697932 (80%)]\tLoss: 3.152215\n",
      "Train Epoch: 4 [557440/697932 (80%)]\tLoss: 3.159880\n",
      "Train Epoch: 4 [558080/697932 (80%)]\tLoss: 3.168809\n",
      "Train Epoch: 4 [558720/697932 (80%)]\tLoss: 3.167951\n",
      "Train Epoch: 4 [559360/697932 (80%)]\tLoss: 3.214538\n",
      "Train Epoch: 4 [560000/697932 (80%)]\tLoss: 3.192865\n",
      "Train Epoch: 4 [560640/697932 (80%)]\tLoss: 3.176152\n",
      "Train Epoch: 4 [561280/697932 (80%)]\tLoss: 3.153261\n",
      "Train Epoch: 4 [561920/697932 (81%)]\tLoss: 3.198005\n",
      "Train Epoch: 4 [562560/697932 (81%)]\tLoss: 3.183157\n",
      "Train Epoch: 4 [563200/697932 (81%)]\tLoss: 3.173852\n",
      "Train Epoch: 4 [563840/697932 (81%)]\tLoss: 3.156321\n",
      "Train Epoch: 4 [564480/697932 (81%)]\tLoss: 3.201614\n",
      "Train Epoch: 4 [565120/697932 (81%)]\tLoss: 3.192508\n",
      "Train Epoch: 4 [565760/697932 (81%)]\tLoss: 3.174101\n",
      "Train Epoch: 4 [566400/697932 (81%)]\tLoss: 3.146369\n",
      "Train Epoch: 4 [567040/697932 (81%)]\tLoss: 3.154432\n",
      "Train Epoch: 4 [567680/697932 (81%)]\tLoss: 3.170362\n",
      "Train Epoch: 4 [568320/697932 (81%)]\tLoss: 3.147964\n",
      "Train Epoch: 4 [568960/697932 (82%)]\tLoss: 3.165521\n",
      "Train Epoch: 4 [569600/697932 (82%)]\tLoss: 3.193840\n",
      "Train Epoch: 4 [570240/697932 (82%)]\tLoss: 3.177551\n",
      "Train Epoch: 4 [570880/697932 (82%)]\tLoss: 3.190042\n",
      "Train Epoch: 4 [571520/697932 (82%)]\tLoss: 3.201401\n",
      "Train Epoch: 4 [572160/697932 (82%)]\tLoss: 3.162814\n",
      "Train Epoch: 4 [572800/697932 (82%)]\tLoss: 3.166472\n",
      "Train Epoch: 4 [573440/697932 (82%)]\tLoss: 3.143651\n",
      "Train Epoch: 4 [574080/697932 (82%)]\tLoss: 3.163274\n",
      "Train Epoch: 4 [574720/697932 (82%)]\tLoss: 3.150804\n",
      "Train Epoch: 4 [575360/697932 (82%)]\tLoss: 3.171648\n",
      "Train Epoch: 4 [576000/697932 (83%)]\tLoss: 3.150125\n",
      "Train Epoch: 4 [576640/697932 (83%)]\tLoss: 3.172064\n",
      "Train Epoch: 4 [577280/697932 (83%)]\tLoss: 3.184881\n",
      "Train Epoch: 4 [577920/697932 (83%)]\tLoss: 3.149422\n",
      "Train Epoch: 4 [578560/697932 (83%)]\tLoss: 3.178109\n",
      "Train Epoch: 4 [579200/697932 (83%)]\tLoss: 3.169662\n",
      "Train Epoch: 4 [579840/697932 (83%)]\tLoss: 3.197750\n",
      "Train Epoch: 4 [580480/697932 (83%)]\tLoss: 3.178434\n",
      "Train Epoch: 4 [581120/697932 (83%)]\tLoss: 3.183417\n",
      "Train Epoch: 4 [581760/697932 (83%)]\tLoss: 3.170283\n",
      "Train Epoch: 4 [582400/697932 (83%)]\tLoss: 3.195661\n",
      "Train Epoch: 4 [583040/697932 (84%)]\tLoss: 3.158314\n",
      "Train Epoch: 4 [583680/697932 (84%)]\tLoss: 3.222233\n",
      "Train Epoch: 4 [584320/697932 (84%)]\tLoss: 3.159725\n",
      "Train Epoch: 4 [584960/697932 (84%)]\tLoss: 3.163815\n",
      "Train Epoch: 4 [585600/697932 (84%)]\tLoss: 3.175820\n",
      "Train Epoch: 4 [586240/697932 (84%)]\tLoss: 3.156115\n",
      "Train Epoch: 4 [586880/697932 (84%)]\tLoss: 3.157445\n",
      "Train Epoch: 4 [587520/697932 (84%)]\tLoss: 3.180619\n",
      "Train Epoch: 4 [588160/697932 (84%)]\tLoss: 3.154373\n",
      "Train Epoch: 4 [588800/697932 (84%)]\tLoss: 3.160007\n",
      "Train Epoch: 4 [589440/697932 (84%)]\tLoss: 3.151668\n",
      "Train Epoch: 4 [590080/697932 (85%)]\tLoss: 3.162898\n",
      "Train Epoch: 4 [590720/697932 (85%)]\tLoss: 3.164731\n",
      "Train Epoch: 4 [591360/697932 (85%)]\tLoss: 3.170102\n",
      "Train Epoch: 4 [592000/697932 (85%)]\tLoss: 3.184217\n",
      "Train Epoch: 4 [592640/697932 (85%)]\tLoss: 3.119043\n",
      "Train Epoch: 4 [593280/697932 (85%)]\tLoss: 3.160229\n",
      "Train Epoch: 4 [593920/697932 (85%)]\tLoss: 3.175957\n",
      "Train Epoch: 4 [594560/697932 (85%)]\tLoss: 3.156036\n",
      "Train Epoch: 4 [595200/697932 (85%)]\tLoss: 3.173694\n",
      "Train Epoch: 4 [595840/697932 (85%)]\tLoss: 3.184137\n",
      "Train Epoch: 4 [596480/697932 (85%)]\tLoss: 3.125717\n",
      "Train Epoch: 4 [597120/697932 (86%)]\tLoss: 3.161631\n",
      "Train Epoch: 4 [597760/697932 (86%)]\tLoss: 3.187269\n",
      "Train Epoch: 4 [598400/697932 (86%)]\tLoss: 3.174271\n",
      "Train Epoch: 4 [599040/697932 (86%)]\tLoss: 3.168720\n",
      "Train Epoch: 4 [599680/697932 (86%)]\tLoss: 3.175534\n",
      "Train Epoch: 4 [600320/697932 (86%)]\tLoss: 3.173305\n",
      "Train Epoch: 4 [600960/697932 (86%)]\tLoss: 3.182011\n",
      "Train Epoch: 4 [601600/697932 (86%)]\tLoss: 3.157382\n",
      "Train Epoch: 4 [602240/697932 (86%)]\tLoss: 3.158269\n",
      "Train Epoch: 4 [602880/697932 (86%)]\tLoss: 3.138456\n",
      "Train Epoch: 4 [603520/697932 (86%)]\tLoss: 3.195999\n",
      "Train Epoch: 4 [604160/697932 (87%)]\tLoss: 3.189139\n",
      "Train Epoch: 4 [604800/697932 (87%)]\tLoss: 3.158563\n",
      "Train Epoch: 4 [605440/697932 (87%)]\tLoss: 3.169222\n",
      "Train Epoch: 4 [606080/697932 (87%)]\tLoss: 3.145604\n",
      "Train Epoch: 4 [606720/697932 (87%)]\tLoss: 3.150911\n",
      "Train Epoch: 4 [607360/697932 (87%)]\tLoss: 3.142180\n",
      "Train Epoch: 4 [608000/697932 (87%)]\tLoss: 3.180532\n",
      "Train Epoch: 4 [608640/697932 (87%)]\tLoss: 3.122495\n",
      "Train Epoch: 4 [609280/697932 (87%)]\tLoss: 3.164110\n",
      "Train Epoch: 4 [609920/697932 (87%)]\tLoss: 3.160120\n",
      "Train Epoch: 4 [610560/697932 (87%)]\tLoss: 3.157488\n",
      "Train Epoch: 4 [611200/697932 (88%)]\tLoss: 3.193372\n",
      "Train Epoch: 4 [611840/697932 (88%)]\tLoss: 3.161082\n",
      "Train Epoch: 4 [612480/697932 (88%)]\tLoss: 3.149974\n",
      "Train Epoch: 4 [613120/697932 (88%)]\tLoss: 3.140240\n",
      "Train Epoch: 4 [613760/697932 (88%)]\tLoss: 3.178543\n",
      "Train Epoch: 4 [614400/697932 (88%)]\tLoss: 3.162450\n",
      "Train Epoch: 4 [615040/697932 (88%)]\tLoss: 3.158163\n",
      "Train Epoch: 4 [615680/697932 (88%)]\tLoss: 3.158123\n",
      "Train Epoch: 4 [616320/697932 (88%)]\tLoss: 3.167175\n",
      "Train Epoch: 4 [616960/697932 (88%)]\tLoss: 3.179190\n",
      "Train Epoch: 4 [617600/697932 (88%)]\tLoss: 3.174565\n",
      "Train Epoch: 4 [618240/697932 (89%)]\tLoss: 3.178830\n",
      "Train Epoch: 4 [618880/697932 (89%)]\tLoss: 3.185798\n",
      "Train Epoch: 4 [619520/697932 (89%)]\tLoss: 3.185999\n",
      "Train Epoch: 4 [620160/697932 (89%)]\tLoss: 3.196075\n",
      "Train Epoch: 4 [620800/697932 (89%)]\tLoss: 3.162980\n",
      "Train Epoch: 4 [621440/697932 (89%)]\tLoss: 3.210413\n",
      "Train Epoch: 4 [622080/697932 (89%)]\tLoss: 3.186235\n",
      "Train Epoch: 4 [622720/697932 (89%)]\tLoss: 3.141906\n",
      "Train Epoch: 4 [623360/697932 (89%)]\tLoss: 3.164446\n",
      "Train Epoch: 4 [624000/697932 (89%)]\tLoss: 3.163776\n",
      "Train Epoch: 4 [624640/697932 (89%)]\tLoss: 3.205837\n",
      "Train Epoch: 4 [625280/697932 (90%)]\tLoss: 3.137894\n",
      "Train Epoch: 4 [625920/697932 (90%)]\tLoss: 3.170552\n",
      "Train Epoch: 4 [626560/697932 (90%)]\tLoss: 3.165099\n",
      "Train Epoch: 4 [627200/697932 (90%)]\tLoss: 3.187103\n",
      "Train Epoch: 4 [627840/697932 (90%)]\tLoss: 3.163353\n",
      "Train Epoch: 4 [628480/697932 (90%)]\tLoss: 3.216348\n",
      "Train Epoch: 4 [629120/697932 (90%)]\tLoss: 3.186654\n",
      "Train Epoch: 4 [629760/697932 (90%)]\tLoss: 3.187454\n",
      "Train Epoch: 4 [630400/697932 (90%)]\tLoss: 3.177443\n",
      "Train Epoch: 4 [631040/697932 (90%)]\tLoss: 3.189444\n",
      "Train Epoch: 4 [631680/697932 (91%)]\tLoss: 3.159220\n",
      "Train Epoch: 4 [632320/697932 (91%)]\tLoss: 3.185721\n",
      "Train Epoch: 4 [632960/697932 (91%)]\tLoss: 3.189472\n",
      "Train Epoch: 4 [633600/697932 (91%)]\tLoss: 3.150810\n",
      "Train Epoch: 4 [634240/697932 (91%)]\tLoss: 3.178525\n",
      "Train Epoch: 4 [634880/697932 (91%)]\tLoss: 3.165127\n",
      "Train Epoch: 4 [635520/697932 (91%)]\tLoss: 3.169046\n",
      "Train Epoch: 4 [636160/697932 (91%)]\tLoss: 3.157199\n",
      "Train Epoch: 4 [636800/697932 (91%)]\tLoss: 3.166864\n",
      "Train Epoch: 4 [637440/697932 (91%)]\tLoss: 3.164649\n",
      "Train Epoch: 4 [638080/697932 (91%)]\tLoss: 3.190180\n",
      "Train Epoch: 4 [638720/697932 (92%)]\tLoss: 3.154292\n",
      "Train Epoch: 4 [639360/697932 (92%)]\tLoss: 3.153251\n",
      "Train Epoch: 4 [640000/697932 (92%)]\tLoss: 3.136523\n",
      "Train Epoch: 4 [640640/697932 (92%)]\tLoss: 3.168850\n",
      "Train Epoch: 4 [641280/697932 (92%)]\tLoss: 3.164362\n",
      "Train Epoch: 4 [641920/697932 (92%)]\tLoss: 3.156711\n",
      "Train Epoch: 4 [642560/697932 (92%)]\tLoss: 3.156616\n",
      "Train Epoch: 4 [643200/697932 (92%)]\tLoss: 3.178135\n",
      "Train Epoch: 4 [643840/697932 (92%)]\tLoss: 3.170422\n",
      "Train Epoch: 4 [644480/697932 (92%)]\tLoss: 3.171065\n",
      "Train Epoch: 4 [645120/697932 (92%)]\tLoss: 3.187038\n",
      "Train Epoch: 4 [645760/697932 (93%)]\tLoss: 3.196482\n",
      "Train Epoch: 4 [646400/697932 (93%)]\tLoss: 3.170691\n",
      "Train Epoch: 4 [647040/697932 (93%)]\tLoss: 3.160524\n",
      "Train Epoch: 4 [647680/697932 (93%)]\tLoss: 3.169868\n",
      "Train Epoch: 4 [648320/697932 (93%)]\tLoss: 3.180436\n",
      "Train Epoch: 4 [648960/697932 (93%)]\tLoss: 3.176257\n",
      "Train Epoch: 4 [649600/697932 (93%)]\tLoss: 3.184788\n",
      "Train Epoch: 4 [650240/697932 (93%)]\tLoss: 3.169678\n",
      "Train Epoch: 4 [650880/697932 (93%)]\tLoss: 3.198021\n",
      "Train Epoch: 4 [651520/697932 (93%)]\tLoss: 3.150809\n",
      "Train Epoch: 4 [652160/697932 (93%)]\tLoss: 3.181618\n",
      "Train Epoch: 4 [652800/697932 (94%)]\tLoss: 3.173046\n",
      "Train Epoch: 4 [653440/697932 (94%)]\tLoss: 3.197428\n",
      "Train Epoch: 4 [654080/697932 (94%)]\tLoss: 3.172293\n",
      "Train Epoch: 4 [654720/697932 (94%)]\tLoss: 3.180996\n",
      "Train Epoch: 4 [655360/697932 (94%)]\tLoss: 3.151910\n",
      "Train Epoch: 4 [656000/697932 (94%)]\tLoss: 3.176970\n",
      "Train Epoch: 4 [656640/697932 (94%)]\tLoss: 3.181558\n",
      "Train Epoch: 4 [657280/697932 (94%)]\tLoss: 3.184615\n",
      "Train Epoch: 4 [657920/697932 (94%)]\tLoss: 3.154177\n",
      "Train Epoch: 4 [658560/697932 (94%)]\tLoss: 3.182100\n",
      "Train Epoch: 4 [659200/697932 (94%)]\tLoss: 3.145681\n",
      "Train Epoch: 4 [659840/697932 (95%)]\tLoss: 3.158304\n",
      "Train Epoch: 4 [660480/697932 (95%)]\tLoss: 3.194162\n",
      "Train Epoch: 4 [661120/697932 (95%)]\tLoss: 3.153424\n",
      "Train Epoch: 4 [661760/697932 (95%)]\tLoss: 3.167401\n",
      "Train Epoch: 4 [662400/697932 (95%)]\tLoss: 3.160635\n",
      "Train Epoch: 4 [663040/697932 (95%)]\tLoss: 3.150505\n",
      "Train Epoch: 4 [663680/697932 (95%)]\tLoss: 3.169811\n",
      "Train Epoch: 4 [664320/697932 (95%)]\tLoss: 3.148724\n",
      "Train Epoch: 4 [664960/697932 (95%)]\tLoss: 3.164302\n",
      "Train Epoch: 4 [665600/697932 (95%)]\tLoss: 3.163746\n",
      "Train Epoch: 4 [666240/697932 (95%)]\tLoss: 3.176361\n",
      "Train Epoch: 4 [666880/697932 (96%)]\tLoss: 3.183982\n",
      "Train Epoch: 4 [667520/697932 (96%)]\tLoss: 3.140783\n",
      "Train Epoch: 4 [668160/697932 (96%)]\tLoss: 3.177575\n",
      "Train Epoch: 4 [668800/697932 (96%)]\tLoss: 3.176628\n",
      "Train Epoch: 4 [669440/697932 (96%)]\tLoss: 3.198025\n",
      "Train Epoch: 4 [670080/697932 (96%)]\tLoss: 3.146106\n",
      "Train Epoch: 4 [670720/697932 (96%)]\tLoss: 3.171445\n",
      "Train Epoch: 4 [671360/697932 (96%)]\tLoss: 3.158242\n",
      "Train Epoch: 4 [672000/697932 (96%)]\tLoss: 3.156257\n",
      "Train Epoch: 4 [672640/697932 (96%)]\tLoss: 3.164957\n",
      "Train Epoch: 4 [673280/697932 (96%)]\tLoss: 3.140778\n",
      "Train Epoch: 4 [673920/697932 (97%)]\tLoss: 3.170732\n",
      "Train Epoch: 4 [674560/697932 (97%)]\tLoss: 3.141748\n",
      "Train Epoch: 4 [675200/697932 (97%)]\tLoss: 3.143345\n",
      "Train Epoch: 4 [675840/697932 (97%)]\tLoss: 3.179247\n",
      "Train Epoch: 4 [676480/697932 (97%)]\tLoss: 3.184460\n",
      "Train Epoch: 4 [677120/697932 (97%)]\tLoss: 3.183048\n",
      "Train Epoch: 4 [677760/697932 (97%)]\tLoss: 3.174437\n",
      "Train Epoch: 4 [678400/697932 (97%)]\tLoss: 3.197542\n",
      "Train Epoch: 4 [679040/697932 (97%)]\tLoss: 3.155360\n",
      "Train Epoch: 4 [679680/697932 (97%)]\tLoss: 3.150253\n",
      "Train Epoch: 4 [680320/697932 (97%)]\tLoss: 3.153981\n",
      "Train Epoch: 4 [680960/697932 (98%)]\tLoss: 3.174811\n",
      "Train Epoch: 4 [681600/697932 (98%)]\tLoss: 3.165328\n",
      "Train Epoch: 4 [682240/697932 (98%)]\tLoss: 3.165384\n",
      "Train Epoch: 4 [682880/697932 (98%)]\tLoss: 3.143563\n",
      "Train Epoch: 4 [683520/697932 (98%)]\tLoss: 3.173243\n",
      "Train Epoch: 4 [684160/697932 (98%)]\tLoss: 3.158563\n",
      "Train Epoch: 4 [684800/697932 (98%)]\tLoss: 3.168224\n",
      "Train Epoch: 4 [685440/697932 (98%)]\tLoss: 3.179356\n",
      "Train Epoch: 4 [686080/697932 (98%)]\tLoss: 3.174335\n",
      "Train Epoch: 4 [686720/697932 (98%)]\tLoss: 3.171172\n",
      "Train Epoch: 4 [687360/697932 (98%)]\tLoss: 3.176008\n",
      "Train Epoch: 4 [688000/697932 (99%)]\tLoss: 3.204494\n",
      "Train Epoch: 4 [688640/697932 (99%)]\tLoss: 3.154102\n",
      "Train Epoch: 4 [689280/697932 (99%)]\tLoss: 3.147739\n",
      "Train Epoch: 4 [689920/697932 (99%)]\tLoss: 3.166068\n",
      "Train Epoch: 4 [690560/697932 (99%)]\tLoss: 3.141782\n",
      "Train Epoch: 4 [691200/697932 (99%)]\tLoss: 3.177364\n",
      "Train Epoch: 4 [691840/697932 (99%)]\tLoss: 3.158648\n",
      "Train Epoch: 4 [692480/697932 (99%)]\tLoss: 3.163818\n",
      "Train Epoch: 4 [693120/697932 (99%)]\tLoss: 3.181835\n",
      "Train Epoch: 4 [693760/697932 (99%)]\tLoss: 3.178082\n",
      "Train Epoch: 4 [694400/697932 (99%)]\tLoss: 3.156810\n",
      "Train Epoch: 4 [695040/697932 (100%)]\tLoss: 3.159669\n",
      "Train Epoch: 4 [695680/697932 (100%)]\tLoss: 3.155518\n",
      "Train Epoch: 4 [696320/697932 (100%)]\tLoss: 3.179571\n",
      "Train Epoch: 4 [696960/697932 (100%)]\tLoss: 3.148607\n",
      "Train Epoch: 4 [697600/697932 (100%)]\tLoss: 3.173641\n",
      "\n",
      "Test set: Avg. loss: 0.0048, Accuracy: 38/116323 (0%)\n",
      "\n",
      "Train Epoch: 5 [0/697932 (0%)]\tLoss: 3.203756\n",
      "Train Epoch: 5 [640/697932 (0%)]\tLoss: 3.170910\n",
      "Train Epoch: 5 [1280/697932 (0%)]\tLoss: 3.180547\n",
      "Train Epoch: 5 [1920/697932 (0%)]\tLoss: 3.201252\n",
      "Train Epoch: 5 [2560/697932 (0%)]\tLoss: 3.147484\n",
      "Train Epoch: 5 [3200/697932 (0%)]\tLoss: 3.181840\n",
      "Train Epoch: 5 [3840/697932 (1%)]\tLoss: 3.179666\n",
      "Train Epoch: 5 [4480/697932 (1%)]\tLoss: 3.159903\n",
      "Train Epoch: 5 [5120/697932 (1%)]\tLoss: 3.163153\n",
      "Train Epoch: 5 [5760/697932 (1%)]\tLoss: 3.187191\n",
      "Train Epoch: 5 [6400/697932 (1%)]\tLoss: 3.128162\n",
      "Train Epoch: 5 [7040/697932 (1%)]\tLoss: 3.187254\n",
      "Train Epoch: 5 [7680/697932 (1%)]\tLoss: 3.202328\n",
      "Train Epoch: 5 [8320/697932 (1%)]\tLoss: 3.170642\n",
      "Train Epoch: 5 [8960/697932 (1%)]\tLoss: 3.169784\n",
      "Train Epoch: 5 [9600/697932 (1%)]\tLoss: 3.160923\n",
      "Train Epoch: 5 [10240/697932 (1%)]\tLoss: 3.162762\n",
      "Train Epoch: 5 [10880/697932 (2%)]\tLoss: 3.147181\n",
      "Train Epoch: 5 [11520/697932 (2%)]\tLoss: 3.174576\n",
      "Train Epoch: 5 [12160/697932 (2%)]\tLoss: 3.157103\n",
      "Train Epoch: 5 [12800/697932 (2%)]\tLoss: 3.159250\n",
      "Train Epoch: 5 [13440/697932 (2%)]\tLoss: 3.194561\n",
      "Train Epoch: 5 [14080/697932 (2%)]\tLoss: 3.173363\n",
      "Train Epoch: 5 [14720/697932 (2%)]\tLoss: 3.146986\n",
      "Train Epoch: 5 [15360/697932 (2%)]\tLoss: 3.156905\n",
      "Train Epoch: 5 [16000/697932 (2%)]\tLoss: 3.155594\n",
      "Train Epoch: 5 [16640/697932 (2%)]\tLoss: 3.170171\n",
      "Train Epoch: 5 [17280/697932 (2%)]\tLoss: 3.195472\n",
      "Train Epoch: 5 [17920/697932 (3%)]\tLoss: 3.171242\n",
      "Train Epoch: 5 [18560/697932 (3%)]\tLoss: 3.164104\n",
      "Train Epoch: 5 [19200/697932 (3%)]\tLoss: 3.147048\n",
      "Train Epoch: 5 [19840/697932 (3%)]\tLoss: 3.140440\n",
      "Train Epoch: 5 [20480/697932 (3%)]\tLoss: 3.140912\n",
      "Train Epoch: 5 [21120/697932 (3%)]\tLoss: 3.133824\n",
      "Train Epoch: 5 [21760/697932 (3%)]\tLoss: 3.187627\n",
      "Train Epoch: 5 [22400/697932 (3%)]\tLoss: 3.176083\n",
      "Train Epoch: 5 [23040/697932 (3%)]\tLoss: 3.175855\n",
      "Train Epoch: 5 [23680/697932 (3%)]\tLoss: 3.132635\n",
      "Train Epoch: 5 [24320/697932 (3%)]\tLoss: 3.166097\n",
      "Train Epoch: 5 [24960/697932 (4%)]\tLoss: 3.178914\n",
      "Train Epoch: 5 [25600/697932 (4%)]\tLoss: 3.148733\n",
      "Train Epoch: 5 [26240/697932 (4%)]\tLoss: 3.166184\n",
      "Train Epoch: 5 [26880/697932 (4%)]\tLoss: 3.113414\n",
      "Train Epoch: 5 [27520/697932 (4%)]\tLoss: 3.159365\n",
      "Train Epoch: 5 [28160/697932 (4%)]\tLoss: 3.160017\n",
      "Train Epoch: 5 [28800/697932 (4%)]\tLoss: 3.187295\n",
      "Train Epoch: 5 [29440/697932 (4%)]\tLoss: 3.148002\n",
      "Train Epoch: 5 [30080/697932 (4%)]\tLoss: 3.172754\n",
      "Train Epoch: 5 [30720/697932 (4%)]\tLoss: 3.157090\n",
      "Train Epoch: 5 [31360/697932 (4%)]\tLoss: 3.134447\n",
      "Train Epoch: 5 [32000/697932 (5%)]\tLoss: 3.173215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [32640/697932 (5%)]\tLoss: 3.151616\n",
      "Train Epoch: 5 [33280/697932 (5%)]\tLoss: 3.172497\n",
      "Train Epoch: 5 [33920/697932 (5%)]\tLoss: 3.132146\n",
      "Train Epoch: 5 [34560/697932 (5%)]\tLoss: 3.151337\n",
      "Train Epoch: 5 [35200/697932 (5%)]\tLoss: 3.173831\n",
      "Train Epoch: 5 [35840/697932 (5%)]\tLoss: 3.158912\n",
      "Train Epoch: 5 [36480/697932 (5%)]\tLoss: 3.184581\n",
      "Train Epoch: 5 [37120/697932 (5%)]\tLoss: 3.188871\n",
      "Train Epoch: 5 [37760/697932 (5%)]\tLoss: 3.193330\n",
      "Train Epoch: 5 [38400/697932 (6%)]\tLoss: 3.152044\n",
      "Train Epoch: 5 [39040/697932 (6%)]\tLoss: 3.170386\n",
      "Train Epoch: 5 [39680/697932 (6%)]\tLoss: 3.166916\n",
      "Train Epoch: 5 [40320/697932 (6%)]\tLoss: 3.168717\n",
      "Train Epoch: 5 [40960/697932 (6%)]\tLoss: 3.176554\n",
      "Train Epoch: 5 [41600/697932 (6%)]\tLoss: 3.148865\n",
      "Train Epoch: 5 [42240/697932 (6%)]\tLoss: 3.160835\n",
      "Train Epoch: 5 [42880/697932 (6%)]\tLoss: 3.168784\n",
      "Train Epoch: 5 [43520/697932 (6%)]\tLoss: 3.183403\n",
      "Train Epoch: 5 [44160/697932 (6%)]\tLoss: 3.154083\n",
      "Train Epoch: 5 [44800/697932 (6%)]\tLoss: 3.163309\n",
      "Train Epoch: 5 [45440/697932 (7%)]\tLoss: 3.158010\n",
      "Train Epoch: 5 [46080/697932 (7%)]\tLoss: 3.183783\n",
      "Train Epoch: 5 [46720/697932 (7%)]\tLoss: 3.167691\n",
      "Train Epoch: 5 [47360/697932 (7%)]\tLoss: 3.188461\n",
      "Train Epoch: 5 [48000/697932 (7%)]\tLoss: 3.149929\n",
      "Train Epoch: 5 [48640/697932 (7%)]\tLoss: 3.176784\n",
      "Train Epoch: 5 [49280/697932 (7%)]\tLoss: 3.146771\n",
      "Train Epoch: 5 [49920/697932 (7%)]\tLoss: 3.154937\n",
      "Train Epoch: 5 [50560/697932 (7%)]\tLoss: 3.176194\n",
      "Train Epoch: 5 [51200/697932 (7%)]\tLoss: 3.207031\n",
      "Train Epoch: 5 [51840/697932 (7%)]\tLoss: 3.164362\n",
      "Train Epoch: 5 [52480/697932 (8%)]\tLoss: 3.165705\n",
      "Train Epoch: 5 [53120/697932 (8%)]\tLoss: 3.130748\n",
      "Train Epoch: 5 [53760/697932 (8%)]\tLoss: 3.160579\n",
      "Train Epoch: 5 [54400/697932 (8%)]\tLoss: 3.182251\n",
      "Train Epoch: 5 [55040/697932 (8%)]\tLoss: 3.182660\n",
      "Train Epoch: 5 [55680/697932 (8%)]\tLoss: 3.161253\n",
      "Train Epoch: 5 [56320/697932 (8%)]\tLoss: 3.165111\n",
      "Train Epoch: 5 [56960/697932 (8%)]\tLoss: 3.161234\n",
      "Train Epoch: 5 [57600/697932 (8%)]\tLoss: 3.166992\n",
      "Train Epoch: 5 [58240/697932 (8%)]\tLoss: 3.171914\n",
      "Train Epoch: 5 [58880/697932 (8%)]\tLoss: 3.202737\n",
      "Train Epoch: 5 [59520/697932 (9%)]\tLoss: 3.167948\n",
      "Train Epoch: 5 [60160/697932 (9%)]\tLoss: 3.181637\n",
      "Train Epoch: 5 [60800/697932 (9%)]\tLoss: 3.178135\n",
      "Train Epoch: 5 [61440/697932 (9%)]\tLoss: 3.204435\n",
      "Train Epoch: 5 [62080/697932 (9%)]\tLoss: 3.210249\n",
      "Train Epoch: 5 [62720/697932 (9%)]\tLoss: 3.180716\n",
      "Train Epoch: 5 [63360/697932 (9%)]\tLoss: 3.159727\n",
      "Train Epoch: 5 [64000/697932 (9%)]\tLoss: 3.151849\n",
      "Train Epoch: 5 [64640/697932 (9%)]\tLoss: 3.146281\n",
      "Train Epoch: 5 [65280/697932 (9%)]\tLoss: 3.159989\n",
      "Train Epoch: 5 [65920/697932 (9%)]\tLoss: 3.169619\n",
      "Train Epoch: 5 [66560/697932 (10%)]\tLoss: 3.171413\n",
      "Train Epoch: 5 [67200/697932 (10%)]\tLoss: 3.166479\n",
      "Train Epoch: 5 [67840/697932 (10%)]\tLoss: 3.160131\n",
      "Train Epoch: 5 [68480/697932 (10%)]\tLoss: 3.170557\n",
      "Train Epoch: 5 [69120/697932 (10%)]\tLoss: 3.176739\n",
      "Train Epoch: 5 [69760/697932 (10%)]\tLoss: 3.186823\n",
      "Train Epoch: 5 [70400/697932 (10%)]\tLoss: 3.167790\n",
      "Train Epoch: 5 [71040/697932 (10%)]\tLoss: 3.159568\n",
      "Train Epoch: 5 [71680/697932 (10%)]\tLoss: 3.169372\n",
      "Train Epoch: 5 [72320/697932 (10%)]\tLoss: 3.161623\n",
      "Train Epoch: 5 [72960/697932 (10%)]\tLoss: 3.169042\n",
      "Train Epoch: 5 [73600/697932 (11%)]\tLoss: 3.211955\n",
      "Train Epoch: 5 [74240/697932 (11%)]\tLoss: 3.184887\n",
      "Train Epoch: 5 [74880/697932 (11%)]\tLoss: 3.194977\n",
      "Train Epoch: 5 [75520/697932 (11%)]\tLoss: 3.173786\n",
      "Train Epoch: 5 [76160/697932 (11%)]\tLoss: 3.177343\n",
      "Train Epoch: 5 [76800/697932 (11%)]\tLoss: 3.182190\n",
      "Train Epoch: 5 [77440/697932 (11%)]\tLoss: 3.165790\n",
      "Train Epoch: 5 [78080/697932 (11%)]\tLoss: 3.163570\n",
      "Train Epoch: 5 [78720/697932 (11%)]\tLoss: 3.183572\n",
      "Train Epoch: 5 [79360/697932 (11%)]\tLoss: 3.184085\n",
      "Train Epoch: 5 [80000/697932 (11%)]\tLoss: 3.162696\n",
      "Train Epoch: 5 [80640/697932 (12%)]\tLoss: 3.149746\n",
      "Train Epoch: 5 [81280/697932 (12%)]\tLoss: 3.147795\n",
      "Train Epoch: 5 [81920/697932 (12%)]\tLoss: 3.198035\n",
      "Train Epoch: 5 [82560/697932 (12%)]\tLoss: 3.163116\n",
      "Train Epoch: 5 [83200/697932 (12%)]\tLoss: 3.213994\n",
      "Train Epoch: 5 [83840/697932 (12%)]\tLoss: 3.183870\n",
      "Train Epoch: 5 [84480/697932 (12%)]\tLoss: 3.189053\n",
      "Train Epoch: 5 [85120/697932 (12%)]\tLoss: 3.174084\n",
      "Train Epoch: 5 [85760/697932 (12%)]\tLoss: 3.164773\n",
      "Train Epoch: 5 [86400/697932 (12%)]\tLoss: 3.171999\n",
      "Train Epoch: 5 [87040/697932 (12%)]\tLoss: 3.150355\n",
      "Train Epoch: 5 [87680/697932 (13%)]\tLoss: 3.161380\n",
      "Train Epoch: 5 [88320/697932 (13%)]\tLoss: 3.151759\n",
      "Train Epoch: 5 [88960/697932 (13%)]\tLoss: 3.159028\n",
      "Train Epoch: 5 [89600/697932 (13%)]\tLoss: 3.160168\n",
      "Train Epoch: 5 [90240/697932 (13%)]\tLoss: 3.148861\n",
      "Train Epoch: 5 [90880/697932 (13%)]\tLoss: 3.177779\n",
      "Train Epoch: 5 [91520/697932 (13%)]\tLoss: 3.192984\n",
      "Train Epoch: 5 [92160/697932 (13%)]\tLoss: 3.159903\n",
      "Train Epoch: 5 [92800/697932 (13%)]\tLoss: 3.162994\n",
      "Train Epoch: 5 [93440/697932 (13%)]\tLoss: 3.170773\n",
      "Train Epoch: 5 [94080/697932 (13%)]\tLoss: 3.140196\n",
      "Train Epoch: 5 [94720/697932 (14%)]\tLoss: 3.160351\n",
      "Train Epoch: 5 [95360/697932 (14%)]\tLoss: 3.177088\n",
      "Train Epoch: 5 [96000/697932 (14%)]\tLoss: 3.173304\n",
      "Train Epoch: 5 [96640/697932 (14%)]\tLoss: 3.209169\n",
      "Train Epoch: 5 [97280/697932 (14%)]\tLoss: 3.180310\n",
      "Train Epoch: 5 [97920/697932 (14%)]\tLoss: 3.149430\n",
      "Train Epoch: 5 [98560/697932 (14%)]\tLoss: 3.168994\n",
      "Train Epoch: 5 [99200/697932 (14%)]\tLoss: 3.155622\n",
      "Train Epoch: 5 [99840/697932 (14%)]\tLoss: 3.213905\n",
      "Train Epoch: 5 [100480/697932 (14%)]\tLoss: 3.193489\n",
      "Train Epoch: 5 [101120/697932 (14%)]\tLoss: 3.173378\n",
      "Train Epoch: 5 [101760/697932 (15%)]\tLoss: 3.186155\n",
      "Train Epoch: 5 [102400/697932 (15%)]\tLoss: 3.161369\n",
      "Train Epoch: 5 [103040/697932 (15%)]\tLoss: 3.165344\n",
      "Train Epoch: 5 [103680/697932 (15%)]\tLoss: 3.193887\n",
      "Train Epoch: 5 [104320/697932 (15%)]\tLoss: 3.171049\n",
      "Train Epoch: 5 [104960/697932 (15%)]\tLoss: 3.175624\n",
      "Train Epoch: 5 [105600/697932 (15%)]\tLoss: 3.159049\n",
      "Train Epoch: 5 [106240/697932 (15%)]\tLoss: 3.169517\n",
      "Train Epoch: 5 [106880/697932 (15%)]\tLoss: 3.152629\n",
      "Train Epoch: 5 [107520/697932 (15%)]\tLoss: 3.178457\n",
      "Train Epoch: 5 [108160/697932 (15%)]\tLoss: 3.171139\n",
      "Train Epoch: 5 [108800/697932 (16%)]\tLoss: 3.165020\n",
      "Train Epoch: 5 [109440/697932 (16%)]\tLoss: 3.192703\n",
      "Train Epoch: 5 [110080/697932 (16%)]\tLoss: 3.166750\n",
      "Train Epoch: 5 [110720/697932 (16%)]\tLoss: 3.208149\n",
      "Train Epoch: 5 [111360/697932 (16%)]\tLoss: 3.182079\n",
      "Train Epoch: 5 [112000/697932 (16%)]\tLoss: 3.126902\n",
      "Train Epoch: 5 [112640/697932 (16%)]\tLoss: 3.180681\n",
      "Train Epoch: 5 [113280/697932 (16%)]\tLoss: 3.168736\n",
      "Train Epoch: 5 [113920/697932 (16%)]\tLoss: 3.158557\n",
      "Train Epoch: 5 [114560/697932 (16%)]\tLoss: 3.160545\n",
      "Train Epoch: 5 [115200/697932 (17%)]\tLoss: 3.159465\n",
      "Train Epoch: 5 [115840/697932 (17%)]\tLoss: 3.175901\n",
      "Train Epoch: 5 [116480/697932 (17%)]\tLoss: 3.156608\n",
      "Train Epoch: 5 [117120/697932 (17%)]\tLoss: 3.198988\n",
      "Train Epoch: 5 [117760/697932 (17%)]\tLoss: 3.178066\n",
      "Train Epoch: 5 [118400/697932 (17%)]\tLoss: 3.140504\n",
      "Train Epoch: 5 [119040/697932 (17%)]\tLoss: 3.191986\n",
      "Train Epoch: 5 [119680/697932 (17%)]\tLoss: 3.176281\n",
      "Train Epoch: 5 [120320/697932 (17%)]\tLoss: 3.168634\n",
      "Train Epoch: 5 [120960/697932 (17%)]\tLoss: 3.171871\n",
      "Train Epoch: 5 [121600/697932 (17%)]\tLoss: 3.149209\n",
      "Train Epoch: 5 [122240/697932 (18%)]\tLoss: 3.177479\n",
      "Train Epoch: 5 [122880/697932 (18%)]\tLoss: 3.153196\n",
      "Train Epoch: 5 [123520/697932 (18%)]\tLoss: 3.153274\n",
      "Train Epoch: 5 [124160/697932 (18%)]\tLoss: 3.177831\n",
      "Train Epoch: 5 [124800/697932 (18%)]\tLoss: 3.197625\n",
      "Train Epoch: 5 [125440/697932 (18%)]\tLoss: 3.167195\n",
      "Train Epoch: 5 [126080/697932 (18%)]\tLoss: 3.166680\n",
      "Train Epoch: 5 [126720/697932 (18%)]\tLoss: 3.172907\n",
      "Train Epoch: 5 [127360/697932 (18%)]\tLoss: 3.176665\n",
      "Train Epoch: 5 [128000/697932 (18%)]\tLoss: 3.163352\n",
      "Train Epoch: 5 [128640/697932 (18%)]\tLoss: 3.156807\n",
      "Train Epoch: 5 [129280/697932 (19%)]\tLoss: 3.156361\n",
      "Train Epoch: 5 [129920/697932 (19%)]\tLoss: 3.180277\n",
      "Train Epoch: 5 [130560/697932 (19%)]\tLoss: 3.175307\n",
      "Train Epoch: 5 [131200/697932 (19%)]\tLoss: 3.182638\n",
      "Train Epoch: 5 [131840/697932 (19%)]\tLoss: 3.180957\n",
      "Train Epoch: 5 [132480/697932 (19%)]\tLoss: 3.151809\n",
      "Train Epoch: 5 [133120/697932 (19%)]\tLoss: 3.147528\n",
      "Train Epoch: 5 [133760/697932 (19%)]\tLoss: 3.145904\n",
      "Train Epoch: 5 [134400/697932 (19%)]\tLoss: 3.175004\n",
      "Train Epoch: 5 [135040/697932 (19%)]\tLoss: 3.197654\n",
      "Train Epoch: 5 [135680/697932 (19%)]\tLoss: 3.162846\n",
      "Train Epoch: 5 [136320/697932 (20%)]\tLoss: 3.167082\n",
      "Train Epoch: 5 [136960/697932 (20%)]\tLoss: 3.151290\n",
      "Train Epoch: 5 [137600/697932 (20%)]\tLoss: 3.187087\n",
      "Train Epoch: 5 [138240/697932 (20%)]\tLoss: 3.187343\n",
      "Train Epoch: 5 [138880/697932 (20%)]\tLoss: 3.159111\n",
      "Train Epoch: 5 [139520/697932 (20%)]\tLoss: 3.186333\n",
      "Train Epoch: 5 [140160/697932 (20%)]\tLoss: 3.171620\n",
      "Train Epoch: 5 [140800/697932 (20%)]\tLoss: 3.171156\n",
      "Train Epoch: 5 [141440/697932 (20%)]\tLoss: 3.151098\n",
      "Train Epoch: 5 [142080/697932 (20%)]\tLoss: 3.185003\n",
      "Train Epoch: 5 [142720/697932 (20%)]\tLoss: 3.146146\n",
      "Train Epoch: 5 [143360/697932 (21%)]\tLoss: 3.183974\n",
      "Train Epoch: 5 [144000/697932 (21%)]\tLoss: 3.146309\n",
      "Train Epoch: 5 [144640/697932 (21%)]\tLoss: 3.169139\n",
      "Train Epoch: 5 [145280/697932 (21%)]\tLoss: 3.192022\n",
      "Train Epoch: 5 [145920/697932 (21%)]\tLoss: 3.170268\n",
      "Train Epoch: 5 [146560/697932 (21%)]\tLoss: 3.183078\n",
      "Train Epoch: 5 [147200/697932 (21%)]\tLoss: 3.169893\n",
      "Train Epoch: 5 [147840/697932 (21%)]\tLoss: 3.158930\n",
      "Train Epoch: 5 [148480/697932 (21%)]\tLoss: 3.181536\n",
      "Train Epoch: 5 [149120/697932 (21%)]\tLoss: 3.176484\n",
      "Train Epoch: 5 [149760/697932 (21%)]\tLoss: 3.181806\n",
      "Train Epoch: 5 [150400/697932 (22%)]\tLoss: 3.160943\n",
      "Train Epoch: 5 [151040/697932 (22%)]\tLoss: 3.173643\n",
      "Train Epoch: 5 [151680/697932 (22%)]\tLoss: 3.166186\n",
      "Train Epoch: 5 [152320/697932 (22%)]\tLoss: 3.159151\n",
      "Train Epoch: 5 [152960/697932 (22%)]\tLoss: 3.182791\n",
      "Train Epoch: 5 [153600/697932 (22%)]\tLoss: 3.173832\n",
      "Train Epoch: 5 [154240/697932 (22%)]\tLoss: 3.183280\n",
      "Train Epoch: 5 [154880/697932 (22%)]\tLoss: 3.186478\n",
      "Train Epoch: 5 [155520/697932 (22%)]\tLoss: 3.155653\n",
      "Train Epoch: 5 [156160/697932 (22%)]\tLoss: 3.178392\n",
      "Train Epoch: 5 [156800/697932 (22%)]\tLoss: 3.171899\n",
      "Train Epoch: 5 [157440/697932 (23%)]\tLoss: 3.177055\n",
      "Train Epoch: 5 [158080/697932 (23%)]\tLoss: 3.173156\n",
      "Train Epoch: 5 [158720/697932 (23%)]\tLoss: 3.182551\n",
      "Train Epoch: 5 [159360/697932 (23%)]\tLoss: 3.191402\n",
      "Train Epoch: 5 [160000/697932 (23%)]\tLoss: 3.181660\n",
      "Train Epoch: 5 [160640/697932 (23%)]\tLoss: 3.204935\n",
      "Train Epoch: 5 [161280/697932 (23%)]\tLoss: 3.170417\n",
      "Train Epoch: 5 [161920/697932 (23%)]\tLoss: 3.161976\n",
      "Train Epoch: 5 [162560/697932 (23%)]\tLoss: 3.158484\n",
      "Train Epoch: 5 [163200/697932 (23%)]\tLoss: 3.181225\n",
      "Train Epoch: 5 [163840/697932 (23%)]\tLoss: 3.144087\n",
      "Train Epoch: 5 [164480/697932 (24%)]\tLoss: 3.168459\n",
      "Train Epoch: 5 [165120/697932 (24%)]\tLoss: 3.183446\n",
      "Train Epoch: 5 [165760/697932 (24%)]\tLoss: 3.159330\n",
      "Train Epoch: 5 [166400/697932 (24%)]\tLoss: 3.162402\n",
      "Train Epoch: 5 [167040/697932 (24%)]\tLoss: 3.172802\n",
      "Train Epoch: 5 [167680/697932 (24%)]\tLoss: 3.145436\n",
      "Train Epoch: 5 [168320/697932 (24%)]\tLoss: 3.145046\n",
      "Train Epoch: 5 [168960/697932 (24%)]\tLoss: 3.149954\n",
      "Train Epoch: 5 [169600/697932 (24%)]\tLoss: 3.217215\n",
      "Train Epoch: 5 [170240/697932 (24%)]\tLoss: 3.213598\n",
      "Train Epoch: 5 [170880/697932 (24%)]\tLoss: 3.165938\n",
      "Train Epoch: 5 [171520/697932 (25%)]\tLoss: 3.166396\n",
      "Train Epoch: 5 [172160/697932 (25%)]\tLoss: 3.185418\n",
      "Train Epoch: 5 [172800/697932 (25%)]\tLoss: 3.144323\n",
      "Train Epoch: 5 [173440/697932 (25%)]\tLoss: 3.166896\n",
      "Train Epoch: 5 [174080/697932 (25%)]\tLoss: 3.145101\n",
      "Train Epoch: 5 [174720/697932 (25%)]\tLoss: 3.142901\n",
      "Train Epoch: 5 [175360/697932 (25%)]\tLoss: 3.154119\n",
      "Train Epoch: 5 [176000/697932 (25%)]\tLoss: 3.181113\n",
      "Train Epoch: 5 [176640/697932 (25%)]\tLoss: 3.182142\n",
      "Train Epoch: 5 [177280/697932 (25%)]\tLoss: 3.183303\n",
      "Train Epoch: 5 [177920/697932 (25%)]\tLoss: 3.146050\n",
      "Train Epoch: 5 [178560/697932 (26%)]\tLoss: 3.125287\n",
      "Train Epoch: 5 [179200/697932 (26%)]\tLoss: 3.184303\n",
      "Train Epoch: 5 [179840/697932 (26%)]\tLoss: 3.143477\n",
      "Train Epoch: 5 [180480/697932 (26%)]\tLoss: 3.176173\n",
      "Train Epoch: 5 [181120/697932 (26%)]\tLoss: 3.165365\n",
      "Train Epoch: 5 [181760/697932 (26%)]\tLoss: 3.166072\n",
      "Train Epoch: 5 [182400/697932 (26%)]\tLoss: 3.146300\n",
      "Train Epoch: 5 [183040/697932 (26%)]\tLoss: 3.169121\n",
      "Train Epoch: 5 [183680/697932 (26%)]\tLoss: 3.175733\n",
      "Train Epoch: 5 [184320/697932 (26%)]\tLoss: 3.182771\n",
      "Train Epoch: 5 [184960/697932 (26%)]\tLoss: 3.169963\n",
      "Train Epoch: 5 [185600/697932 (27%)]\tLoss: 3.150028\n",
      "Train Epoch: 5 [186240/697932 (27%)]\tLoss: 3.143965\n",
      "Train Epoch: 5 [186880/697932 (27%)]\tLoss: 3.148329\n",
      "Train Epoch: 5 [187520/697932 (27%)]\tLoss: 3.166685\n",
      "Train Epoch: 5 [188160/697932 (27%)]\tLoss: 3.168224\n",
      "Train Epoch: 5 [188800/697932 (27%)]\tLoss: 3.206758\n",
      "Train Epoch: 5 [189440/697932 (27%)]\tLoss: 3.137478\n",
      "Train Epoch: 5 [190080/697932 (27%)]\tLoss: 3.137640\n",
      "Train Epoch: 5 [190720/697932 (27%)]\tLoss: 3.176471\n",
      "Train Epoch: 5 [191360/697932 (27%)]\tLoss: 3.183328\n",
      "Train Epoch: 5 [192000/697932 (28%)]\tLoss: 3.176832\n",
      "Train Epoch: 5 [192640/697932 (28%)]\tLoss: 3.186300\n",
      "Train Epoch: 5 [193280/697932 (28%)]\tLoss: 3.180115\n",
      "Train Epoch: 5 [193920/697932 (28%)]\tLoss: 3.140117\n",
      "Train Epoch: 5 [194560/697932 (28%)]\tLoss: 3.179910\n",
      "Train Epoch: 5 [195200/697932 (28%)]\tLoss: 3.145836\n",
      "Train Epoch: 5 [195840/697932 (28%)]\tLoss: 3.163433\n",
      "Train Epoch: 5 [196480/697932 (28%)]\tLoss: 3.164453\n",
      "Train Epoch: 5 [197120/697932 (28%)]\tLoss: 3.161207\n",
      "Train Epoch: 5 [197760/697932 (28%)]\tLoss: 3.193231\n",
      "Train Epoch: 5 [198400/697932 (28%)]\tLoss: 3.171304\n",
      "Train Epoch: 5 [199040/697932 (29%)]\tLoss: 3.194073\n",
      "Train Epoch: 5 [199680/697932 (29%)]\tLoss: 3.152402\n",
      "Train Epoch: 5 [200320/697932 (29%)]\tLoss: 3.157716\n",
      "Train Epoch: 5 [200960/697932 (29%)]\tLoss: 3.140962\n",
      "Train Epoch: 5 [201600/697932 (29%)]\tLoss: 3.176579\n",
      "Train Epoch: 5 [202240/697932 (29%)]\tLoss: 3.212523\n",
      "Train Epoch: 5 [202880/697932 (29%)]\tLoss: 3.129507\n",
      "Train Epoch: 5 [203520/697932 (29%)]\tLoss: 3.150849\n",
      "Train Epoch: 5 [204160/697932 (29%)]\tLoss: 3.175584\n",
      "Train Epoch: 5 [204800/697932 (29%)]\tLoss: 3.174090\n",
      "Train Epoch: 5 [205440/697932 (29%)]\tLoss: 3.151043\n",
      "Train Epoch: 5 [206080/697932 (30%)]\tLoss: 3.158104\n",
      "Train Epoch: 5 [206720/697932 (30%)]\tLoss: 3.202158\n",
      "Train Epoch: 5 [207360/697932 (30%)]\tLoss: 3.150885\n",
      "Train Epoch: 5 [208000/697932 (30%)]\tLoss: 3.138390\n",
      "Train Epoch: 5 [208640/697932 (30%)]\tLoss: 3.173770\n",
      "Train Epoch: 5 [209280/697932 (30%)]\tLoss: 3.171782\n",
      "Train Epoch: 5 [209920/697932 (30%)]\tLoss: 3.197079\n",
      "Train Epoch: 5 [210560/697932 (30%)]\tLoss: 3.172009\n",
      "Train Epoch: 5 [211200/697932 (30%)]\tLoss: 3.157454\n",
      "Train Epoch: 5 [211840/697932 (30%)]\tLoss: 3.177573\n",
      "Train Epoch: 5 [212480/697932 (30%)]\tLoss: 3.184581\n",
      "Train Epoch: 5 [213120/697932 (31%)]\tLoss: 3.194689\n",
      "Train Epoch: 5 [213760/697932 (31%)]\tLoss: 3.185511\n",
      "Train Epoch: 5 [214400/697932 (31%)]\tLoss: 3.133603\n",
      "Train Epoch: 5 [215040/697932 (31%)]\tLoss: 3.192073\n",
      "Train Epoch: 5 [215680/697932 (31%)]\tLoss: 3.157926\n",
      "Train Epoch: 5 [216320/697932 (31%)]\tLoss: 3.144417\n",
      "Train Epoch: 5 [216960/697932 (31%)]\tLoss: 3.163168\n",
      "Train Epoch: 5 [217600/697932 (31%)]\tLoss: 3.131093\n",
      "Train Epoch: 5 [218240/697932 (31%)]\tLoss: 3.174740\n",
      "Train Epoch: 5 [218880/697932 (31%)]\tLoss: 3.211818\n",
      "Train Epoch: 5 [219520/697932 (31%)]\tLoss: 3.181370\n",
      "Train Epoch: 5 [220160/697932 (32%)]\tLoss: 3.161340\n",
      "Train Epoch: 5 [220800/697932 (32%)]\tLoss: 3.179525\n",
      "Train Epoch: 5 [221440/697932 (32%)]\tLoss: 3.144959\n",
      "Train Epoch: 5 [222080/697932 (32%)]\tLoss: 3.196838\n",
      "Train Epoch: 5 [222720/697932 (32%)]\tLoss: 3.188276\n",
      "Train Epoch: 5 [223360/697932 (32%)]\tLoss: 3.194095\n",
      "Train Epoch: 5 [224000/697932 (32%)]\tLoss: 3.217902\n",
      "Train Epoch: 5 [224640/697932 (32%)]\tLoss: 3.144069\n",
      "Train Epoch: 5 [225280/697932 (32%)]\tLoss: 3.185755\n",
      "Train Epoch: 5 [225920/697932 (32%)]\tLoss: 3.164315\n",
      "Train Epoch: 5 [226560/697932 (32%)]\tLoss: 3.164588\n",
      "Train Epoch: 5 [227200/697932 (33%)]\tLoss: 3.198622\n",
      "Train Epoch: 5 [227840/697932 (33%)]\tLoss: 3.165463\n",
      "Train Epoch: 5 [228480/697932 (33%)]\tLoss: 3.190703\n",
      "Train Epoch: 5 [229120/697932 (33%)]\tLoss: 3.155300\n",
      "Train Epoch: 5 [229760/697932 (33%)]\tLoss: 3.144197\n",
      "Train Epoch: 5 [230400/697932 (33%)]\tLoss: 3.145529\n",
      "Train Epoch: 5 [231040/697932 (33%)]\tLoss: 3.153614\n",
      "Train Epoch: 5 [231680/697932 (33%)]\tLoss: 3.176969\n",
      "Train Epoch: 5 [232320/697932 (33%)]\tLoss: 3.200044\n",
      "Train Epoch: 5 [232960/697932 (33%)]\tLoss: 3.163785\n",
      "Train Epoch: 5 [233600/697932 (33%)]\tLoss: 3.173739\n",
      "Train Epoch: 5 [234240/697932 (34%)]\tLoss: 3.167426\n",
      "Train Epoch: 5 [234880/697932 (34%)]\tLoss: 3.203244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [235520/697932 (34%)]\tLoss: 3.198459\n",
      "Train Epoch: 5 [236160/697932 (34%)]\tLoss: 3.164593\n",
      "Train Epoch: 5 [236800/697932 (34%)]\tLoss: 3.168103\n",
      "Train Epoch: 5 [237440/697932 (34%)]\tLoss: 3.160295\n",
      "Train Epoch: 5 [238080/697932 (34%)]\tLoss: 3.205174\n",
      "Train Epoch: 5 [238720/697932 (34%)]\tLoss: 3.191908\n",
      "Train Epoch: 5 [239360/697932 (34%)]\tLoss: 3.163018\n",
      "Train Epoch: 5 [240000/697932 (34%)]\tLoss: 3.194265\n",
      "Train Epoch: 5 [240640/697932 (34%)]\tLoss: 3.167400\n",
      "Train Epoch: 5 [241280/697932 (35%)]\tLoss: 3.180587\n",
      "Train Epoch: 5 [241920/697932 (35%)]\tLoss: 3.195534\n",
      "Train Epoch: 5 [242560/697932 (35%)]\tLoss: 3.152755\n",
      "Train Epoch: 5 [243200/697932 (35%)]\tLoss: 3.169147\n",
      "Train Epoch: 5 [243840/697932 (35%)]\tLoss: 3.172341\n",
      "Train Epoch: 5 [244480/697932 (35%)]\tLoss: 3.135632\n",
      "Train Epoch: 5 [245120/697932 (35%)]\tLoss: 3.153182\n",
      "Train Epoch: 5 [245760/697932 (35%)]\tLoss: 3.160584\n",
      "Train Epoch: 5 [246400/697932 (35%)]\tLoss: 3.155613\n",
      "Train Epoch: 5 [247040/697932 (35%)]\tLoss: 3.161963\n",
      "Train Epoch: 5 [247680/697932 (35%)]\tLoss: 3.163239\n",
      "Train Epoch: 5 [248320/697932 (36%)]\tLoss: 3.189208\n",
      "Train Epoch: 5 [248960/697932 (36%)]\tLoss: 3.183308\n",
      "Train Epoch: 5 [249600/697932 (36%)]\tLoss: 3.200458\n",
      "Train Epoch: 5 [250240/697932 (36%)]\tLoss: 3.172852\n",
      "Train Epoch: 5 [250880/697932 (36%)]\tLoss: 3.191997\n",
      "Train Epoch: 5 [251520/697932 (36%)]\tLoss: 3.167267\n",
      "Train Epoch: 5 [252160/697932 (36%)]\tLoss: 3.181722\n",
      "Train Epoch: 5 [252800/697932 (36%)]\tLoss: 3.189811\n",
      "Train Epoch: 5 [253440/697932 (36%)]\tLoss: 3.207608\n",
      "Train Epoch: 5 [254080/697932 (36%)]\tLoss: 3.172213\n",
      "Train Epoch: 5 [254720/697932 (36%)]\tLoss: 3.166507\n",
      "Train Epoch: 5 [255360/697932 (37%)]\tLoss: 3.165036\n",
      "Train Epoch: 5 [256000/697932 (37%)]\tLoss: 3.152900\n",
      "Train Epoch: 5 [256640/697932 (37%)]\tLoss: 3.141741\n",
      "Train Epoch: 5 [257280/697932 (37%)]\tLoss: 3.170236\n",
      "Train Epoch: 5 [257920/697932 (37%)]\tLoss: 3.195471\n",
      "Train Epoch: 5 [258560/697932 (37%)]\tLoss: 3.163327\n",
      "Train Epoch: 5 [259200/697932 (37%)]\tLoss: 3.164263\n",
      "Train Epoch: 5 [259840/697932 (37%)]\tLoss: 3.161050\n",
      "Train Epoch: 5 [260480/697932 (37%)]\tLoss: 3.188268\n",
      "Train Epoch: 5 [261120/697932 (37%)]\tLoss: 3.162538\n",
      "Train Epoch: 5 [261760/697932 (38%)]\tLoss: 3.158858\n",
      "Train Epoch: 5 [262400/697932 (38%)]\tLoss: 3.174002\n",
      "Train Epoch: 5 [263040/697932 (38%)]\tLoss: 3.162728\n",
      "Train Epoch: 5 [263680/697932 (38%)]\tLoss: 3.186064\n",
      "Train Epoch: 5 [264320/697932 (38%)]\tLoss: 3.158222\n",
      "Train Epoch: 5 [264960/697932 (38%)]\tLoss: 3.182692\n",
      "Train Epoch: 5 [265600/697932 (38%)]\tLoss: 3.184979\n",
      "Train Epoch: 5 [266240/697932 (38%)]\tLoss: 3.159838\n",
      "Train Epoch: 5 [266880/697932 (38%)]\tLoss: 3.195032\n",
      "Train Epoch: 5 [267520/697932 (38%)]\tLoss: 3.178490\n",
      "Train Epoch: 5 [268160/697932 (38%)]\tLoss: 3.142524\n",
      "Train Epoch: 5 [268800/697932 (39%)]\tLoss: 3.138841\n",
      "Train Epoch: 5 [269440/697932 (39%)]\tLoss: 3.175543\n",
      "Train Epoch: 5 [270080/697932 (39%)]\tLoss: 3.167448\n",
      "Train Epoch: 5 [270720/697932 (39%)]\tLoss: 3.186150\n",
      "Train Epoch: 5 [271360/697932 (39%)]\tLoss: 3.168141\n",
      "Train Epoch: 5 [272000/697932 (39%)]\tLoss: 3.172590\n",
      "Train Epoch: 5 [272640/697932 (39%)]\tLoss: 3.165962\n",
      "Train Epoch: 5 [273280/697932 (39%)]\tLoss: 3.163558\n",
      "Train Epoch: 5 [273920/697932 (39%)]\tLoss: 3.148612\n",
      "Train Epoch: 5 [274560/697932 (39%)]\tLoss: 3.173226\n",
      "Train Epoch: 5 [275200/697932 (39%)]\tLoss: 3.166114\n",
      "Train Epoch: 5 [275840/697932 (40%)]\tLoss: 3.183013\n",
      "Train Epoch: 5 [276480/697932 (40%)]\tLoss: 3.136852\n",
      "Train Epoch: 5 [277120/697932 (40%)]\tLoss: 3.170523\n",
      "Train Epoch: 5 [277760/697932 (40%)]\tLoss: 3.176518\n",
      "Train Epoch: 5 [278400/697932 (40%)]\tLoss: 3.170645\n",
      "Train Epoch: 5 [279040/697932 (40%)]\tLoss: 3.178414\n",
      "Train Epoch: 5 [279680/697932 (40%)]\tLoss: 3.171112\n",
      "Train Epoch: 5 [280320/697932 (40%)]\tLoss: 3.164685\n",
      "Train Epoch: 5 [280960/697932 (40%)]\tLoss: 3.189494\n",
      "Train Epoch: 5 [281600/697932 (40%)]\tLoss: 3.195637\n",
      "Train Epoch: 5 [282240/697932 (40%)]\tLoss: 3.168293\n",
      "Train Epoch: 5 [282880/697932 (41%)]\tLoss: 3.166250\n",
      "Train Epoch: 5 [283520/697932 (41%)]\tLoss: 3.171489\n",
      "Train Epoch: 5 [284160/697932 (41%)]\tLoss: 3.180587\n",
      "Train Epoch: 5 [284800/697932 (41%)]\tLoss: 3.181689\n",
      "Train Epoch: 5 [285440/697932 (41%)]\tLoss: 3.138297\n",
      "Train Epoch: 5 [286080/697932 (41%)]\tLoss: 3.152588\n",
      "Train Epoch: 5 [286720/697932 (41%)]\tLoss: 3.157943\n",
      "Train Epoch: 5 [287360/697932 (41%)]\tLoss: 3.174030\n",
      "Train Epoch: 5 [288000/697932 (41%)]\tLoss: 3.164068\n",
      "Train Epoch: 5 [288640/697932 (41%)]\tLoss: 3.171615\n",
      "Train Epoch: 5 [289280/697932 (41%)]\tLoss: 3.169674\n",
      "Train Epoch: 5 [289920/697932 (42%)]\tLoss: 3.190363\n",
      "Train Epoch: 5 [290560/697932 (42%)]\tLoss: 3.166532\n",
      "Train Epoch: 5 [291200/697932 (42%)]\tLoss: 3.201251\n",
      "Train Epoch: 5 [291840/697932 (42%)]\tLoss: 3.151229\n",
      "Train Epoch: 5 [292480/697932 (42%)]\tLoss: 3.145893\n",
      "Train Epoch: 5 [293120/697932 (42%)]\tLoss: 3.138569\n",
      "Train Epoch: 5 [293760/697932 (42%)]\tLoss: 3.206187\n",
      "Train Epoch: 5 [294400/697932 (42%)]\tLoss: 3.165091\n",
      "Train Epoch: 5 [295040/697932 (42%)]\tLoss: 3.150542\n",
      "Train Epoch: 5 [295680/697932 (42%)]\tLoss: 3.156978\n",
      "Train Epoch: 5 [296320/697932 (42%)]\tLoss: 3.182435\n",
      "Train Epoch: 5 [296960/697932 (43%)]\tLoss: 3.176227\n",
      "Train Epoch: 5 [297600/697932 (43%)]\tLoss: 3.131465\n",
      "Train Epoch: 5 [298240/697932 (43%)]\tLoss: 3.159864\n",
      "Train Epoch: 5 [298880/697932 (43%)]\tLoss: 3.159838\n",
      "Train Epoch: 5 [299520/697932 (43%)]\tLoss: 3.153988\n",
      "Train Epoch: 5 [300160/697932 (43%)]\tLoss: 3.181425\n",
      "Train Epoch: 5 [300800/697932 (43%)]\tLoss: 3.160601\n",
      "Train Epoch: 5 [301440/697932 (43%)]\tLoss: 3.163466\n",
      "Train Epoch: 5 [302080/697932 (43%)]\tLoss: 3.153112\n",
      "Train Epoch: 5 [302720/697932 (43%)]\tLoss: 3.177676\n",
      "Train Epoch: 5 [303360/697932 (43%)]\tLoss: 3.153192\n",
      "Train Epoch: 5 [304000/697932 (44%)]\tLoss: 3.201557\n",
      "Train Epoch: 5 [304640/697932 (44%)]\tLoss: 3.164623\n",
      "Train Epoch: 5 [305280/697932 (44%)]\tLoss: 3.176225\n",
      "Train Epoch: 5 [305920/697932 (44%)]\tLoss: 3.195058\n",
      "Train Epoch: 5 [306560/697932 (44%)]\tLoss: 3.148237\n",
      "Train Epoch: 5 [307200/697932 (44%)]\tLoss: 3.169141\n",
      "Train Epoch: 5 [307840/697932 (44%)]\tLoss: 3.149078\n",
      "Train Epoch: 5 [308480/697932 (44%)]\tLoss: 3.175966\n",
      "Train Epoch: 5 [309120/697932 (44%)]\tLoss: 3.190442\n",
      "Train Epoch: 5 [309760/697932 (44%)]\tLoss: 3.178564\n",
      "Train Epoch: 5 [310400/697932 (44%)]\tLoss: 3.163640\n",
      "Train Epoch: 5 [311040/697932 (45%)]\tLoss: 3.146559\n",
      "Train Epoch: 5 [311680/697932 (45%)]\tLoss: 3.202005\n",
      "Train Epoch: 5 [312320/697932 (45%)]\tLoss: 3.177685\n",
      "Train Epoch: 5 [312960/697932 (45%)]\tLoss: 3.176906\n",
      "Train Epoch: 5 [313600/697932 (45%)]\tLoss: 3.161014\n",
      "Train Epoch: 5 [314240/697932 (45%)]\tLoss: 3.154892\n",
      "Train Epoch: 5 [314880/697932 (45%)]\tLoss: 3.159828\n",
      "Train Epoch: 5 [315520/697932 (45%)]\tLoss: 3.175970\n",
      "Train Epoch: 5 [316160/697932 (45%)]\tLoss: 3.180492\n",
      "Train Epoch: 5 [316800/697932 (45%)]\tLoss: 3.154373\n",
      "Train Epoch: 5 [317440/697932 (45%)]\tLoss: 3.166547\n",
      "Train Epoch: 5 [318080/697932 (46%)]\tLoss: 3.177664\n",
      "Train Epoch: 5 [318720/697932 (46%)]\tLoss: 3.177241\n",
      "Train Epoch: 5 [319360/697932 (46%)]\tLoss: 3.135413\n",
      "Train Epoch: 5 [320000/697932 (46%)]\tLoss: 3.165551\n",
      "Train Epoch: 5 [320640/697932 (46%)]\tLoss: 3.170496\n",
      "Train Epoch: 5 [321280/697932 (46%)]\tLoss: 3.181039\n",
      "Train Epoch: 5 [321920/697932 (46%)]\tLoss: 3.174015\n",
      "Train Epoch: 5 [322560/697932 (46%)]\tLoss: 3.206456\n",
      "Train Epoch: 5 [323200/697932 (46%)]\tLoss: 3.137790\n",
      "Train Epoch: 5 [323840/697932 (46%)]\tLoss: 3.159390\n",
      "Train Epoch: 5 [324480/697932 (46%)]\tLoss: 3.151779\n",
      "Train Epoch: 5 [325120/697932 (47%)]\tLoss: 3.144210\n",
      "Train Epoch: 5 [325760/697932 (47%)]\tLoss: 3.170744\n",
      "Train Epoch: 5 [326400/697932 (47%)]\tLoss: 3.186986\n",
      "Train Epoch: 5 [327040/697932 (47%)]\tLoss: 3.209096\n",
      "Train Epoch: 5 [327680/697932 (47%)]\tLoss: 3.166384\n",
      "Train Epoch: 5 [328320/697932 (47%)]\tLoss: 3.138571\n",
      "Train Epoch: 5 [328960/697932 (47%)]\tLoss: 3.160375\n",
      "Train Epoch: 5 [329600/697932 (47%)]\tLoss: 3.152495\n",
      "Train Epoch: 5 [330240/697932 (47%)]\tLoss: 3.172028\n",
      "Train Epoch: 5 [330880/697932 (47%)]\tLoss: 3.171217\n",
      "Train Epoch: 5 [331520/697932 (47%)]\tLoss: 3.157745\n",
      "Train Epoch: 5 [332160/697932 (48%)]\tLoss: 3.171130\n",
      "Train Epoch: 5 [332800/697932 (48%)]\tLoss: 3.172283\n",
      "Train Epoch: 5 [333440/697932 (48%)]\tLoss: 3.171762\n",
      "Train Epoch: 5 [334080/697932 (48%)]\tLoss: 3.162071\n",
      "Train Epoch: 5 [334720/697932 (48%)]\tLoss: 3.153603\n",
      "Train Epoch: 5 [335360/697932 (48%)]\tLoss: 3.191308\n",
      "Train Epoch: 5 [336000/697932 (48%)]\tLoss: 3.156462\n",
      "Train Epoch: 5 [336640/697932 (48%)]\tLoss: 3.160255\n",
      "Train Epoch: 5 [337280/697932 (48%)]\tLoss: 3.201014\n",
      "Train Epoch: 5 [337920/697932 (48%)]\tLoss: 3.203792\n",
      "Train Epoch: 5 [338560/697932 (49%)]\tLoss: 3.185712\n",
      "Train Epoch: 5 [339200/697932 (49%)]\tLoss: 3.188274\n",
      "Train Epoch: 5 [339840/697932 (49%)]\tLoss: 3.158533\n",
      "Train Epoch: 5 [340480/697932 (49%)]\tLoss: 3.162600\n",
      "Train Epoch: 5 [341120/697932 (49%)]\tLoss: 3.174595\n",
      "Train Epoch: 5 [341760/697932 (49%)]\tLoss: 3.157558\n",
      "Train Epoch: 5 [342400/697932 (49%)]\tLoss: 3.120451\n",
      "Train Epoch: 5 [343040/697932 (49%)]\tLoss: 3.169842\n",
      "Train Epoch: 5 [343680/697932 (49%)]\tLoss: 3.146952\n",
      "Train Epoch: 5 [344320/697932 (49%)]\tLoss: 3.159405\n",
      "Train Epoch: 5 [344960/697932 (49%)]\tLoss: 3.150202\n",
      "Train Epoch: 5 [345600/697932 (50%)]\tLoss: 3.174290\n",
      "Train Epoch: 5 [346240/697932 (50%)]\tLoss: 3.179962\n",
      "Train Epoch: 5 [346880/697932 (50%)]\tLoss: 3.165265\n",
      "Train Epoch: 5 [347520/697932 (50%)]\tLoss: 3.192355\n",
      "Train Epoch: 5 [348160/697932 (50%)]\tLoss: 3.177137\n",
      "Train Epoch: 5 [348800/697932 (50%)]\tLoss: 3.159503\n",
      "Train Epoch: 5 [349440/697932 (50%)]\tLoss: 3.185174\n",
      "Train Epoch: 5 [350080/697932 (50%)]\tLoss: 3.166791\n",
      "Train Epoch: 5 [350720/697932 (50%)]\tLoss: 3.153271\n",
      "Train Epoch: 5 [351360/697932 (50%)]\tLoss: 3.154565\n",
      "Train Epoch: 5 [352000/697932 (50%)]\tLoss: 3.168246\n",
      "Train Epoch: 5 [352640/697932 (51%)]\tLoss: 3.177705\n",
      "Train Epoch: 5 [353280/697932 (51%)]\tLoss: 3.171659\n",
      "Train Epoch: 5 [353920/697932 (51%)]\tLoss: 3.158223\n",
      "Train Epoch: 5 [354560/697932 (51%)]\tLoss: 3.186239\n",
      "Train Epoch: 5 [355200/697932 (51%)]\tLoss: 3.163314\n",
      "Train Epoch: 5 [355840/697932 (51%)]\tLoss: 3.138383\n",
      "Train Epoch: 5 [356480/697932 (51%)]\tLoss: 3.159551\n",
      "Train Epoch: 5 [357120/697932 (51%)]\tLoss: 3.187553\n",
      "Train Epoch: 5 [357760/697932 (51%)]\tLoss: 3.170498\n",
      "Train Epoch: 5 [358400/697932 (51%)]\tLoss: 3.186394\n",
      "Train Epoch: 5 [359040/697932 (51%)]\tLoss: 3.152312\n",
      "Train Epoch: 5 [359680/697932 (52%)]\tLoss: 3.178392\n",
      "Train Epoch: 5 [360320/697932 (52%)]\tLoss: 3.168573\n",
      "Train Epoch: 5 [360960/697932 (52%)]\tLoss: 3.175698\n",
      "Train Epoch: 5 [361600/697932 (52%)]\tLoss: 3.171627\n",
      "Train Epoch: 5 [362240/697932 (52%)]\tLoss: 3.187465\n",
      "Train Epoch: 5 [362880/697932 (52%)]\tLoss: 3.174986\n",
      "Train Epoch: 5 [363520/697932 (52%)]\tLoss: 3.160400\n",
      "Train Epoch: 5 [364160/697932 (52%)]\tLoss: 3.161111\n",
      "Train Epoch: 5 [364800/697932 (52%)]\tLoss: 3.170220\n",
      "Train Epoch: 5 [365440/697932 (52%)]\tLoss: 3.153250\n",
      "Train Epoch: 5 [366080/697932 (52%)]\tLoss: 3.152109\n",
      "Train Epoch: 5 [366720/697932 (53%)]\tLoss: 3.173920\n",
      "Train Epoch: 5 [367360/697932 (53%)]\tLoss: 3.199161\n",
      "Train Epoch: 5 [368000/697932 (53%)]\tLoss: 3.165036\n",
      "Train Epoch: 5 [368640/697932 (53%)]\tLoss: 3.179777\n",
      "Train Epoch: 5 [369280/697932 (53%)]\tLoss: 3.181152\n",
      "Train Epoch: 5 [369920/697932 (53%)]\tLoss: 3.168570\n",
      "Train Epoch: 5 [370560/697932 (53%)]\tLoss: 3.154208\n",
      "Train Epoch: 5 [371200/697932 (53%)]\tLoss: 3.183536\n",
      "Train Epoch: 5 [371840/697932 (53%)]\tLoss: 3.157415\n",
      "Train Epoch: 5 [372480/697932 (53%)]\tLoss: 3.175619\n",
      "Train Epoch: 5 [373120/697932 (53%)]\tLoss: 3.176759\n",
      "Train Epoch: 5 [373760/697932 (54%)]\tLoss: 3.185090\n",
      "Train Epoch: 5 [374400/697932 (54%)]\tLoss: 3.208848\n",
      "Train Epoch: 5 [375040/697932 (54%)]\tLoss: 3.152684\n",
      "Train Epoch: 5 [375680/697932 (54%)]\tLoss: 3.171701\n",
      "Train Epoch: 5 [376320/697932 (54%)]\tLoss: 3.189126\n",
      "Train Epoch: 5 [376960/697932 (54%)]\tLoss: 3.166473\n",
      "Train Epoch: 5 [377600/697932 (54%)]\tLoss: 3.182302\n",
      "Train Epoch: 5 [378240/697932 (54%)]\tLoss: 3.188620\n",
      "Train Epoch: 5 [378880/697932 (54%)]\tLoss: 3.172053\n",
      "Train Epoch: 5 [379520/697932 (54%)]\tLoss: 3.186128\n",
      "Train Epoch: 5 [380160/697932 (54%)]\tLoss: 3.169755\n",
      "Train Epoch: 5 [380800/697932 (55%)]\tLoss: 3.188980\n",
      "Train Epoch: 5 [381440/697932 (55%)]\tLoss: 3.164143\n",
      "Train Epoch: 5 [382080/697932 (55%)]\tLoss: 3.162869\n",
      "Train Epoch: 5 [382720/697932 (55%)]\tLoss: 3.178532\n",
      "Train Epoch: 5 [383360/697932 (55%)]\tLoss: 3.179981\n",
      "Train Epoch: 5 [384000/697932 (55%)]\tLoss: 3.182889\n",
      "Train Epoch: 5 [384640/697932 (55%)]\tLoss: 3.167913\n",
      "Train Epoch: 5 [385280/697932 (55%)]\tLoss: 3.167244\n",
      "Train Epoch: 5 [385920/697932 (55%)]\tLoss: 3.172865\n",
      "Train Epoch: 5 [386560/697932 (55%)]\tLoss: 3.193842\n",
      "Train Epoch: 5 [387200/697932 (55%)]\tLoss: 3.147117\n",
      "Train Epoch: 5 [387840/697932 (56%)]\tLoss: 3.190213\n",
      "Train Epoch: 5 [388480/697932 (56%)]\tLoss: 3.193791\n",
      "Train Epoch: 5 [389120/697932 (56%)]\tLoss: 3.170280\n",
      "Train Epoch: 5 [389760/697932 (56%)]\tLoss: 3.174096\n",
      "Train Epoch: 5 [390400/697932 (56%)]\tLoss: 3.162961\n",
      "Train Epoch: 5 [391040/697932 (56%)]\tLoss: 3.181721\n",
      "Train Epoch: 5 [391680/697932 (56%)]\tLoss: 3.179355\n",
      "Train Epoch: 5 [392320/697932 (56%)]\tLoss: 3.145090\n",
      "Train Epoch: 5 [392960/697932 (56%)]\tLoss: 3.175026\n",
      "Train Epoch: 5 [393600/697932 (56%)]\tLoss: 3.196279\n",
      "Train Epoch: 5 [394240/697932 (56%)]\tLoss: 3.173532\n",
      "Train Epoch: 5 [394880/697932 (57%)]\tLoss: 3.160166\n",
      "Train Epoch: 5 [395520/697932 (57%)]\tLoss: 3.167881\n",
      "Train Epoch: 5 [396160/697932 (57%)]\tLoss: 3.184423\n",
      "Train Epoch: 5 [396800/697932 (57%)]\tLoss: 3.145548\n",
      "Train Epoch: 5 [397440/697932 (57%)]\tLoss: 3.160667\n",
      "Train Epoch: 5 [398080/697932 (57%)]\tLoss: 3.199577\n",
      "Train Epoch: 5 [398720/697932 (57%)]\tLoss: 3.171594\n",
      "Train Epoch: 5 [399360/697932 (57%)]\tLoss: 3.164159\n",
      "Train Epoch: 5 [400000/697932 (57%)]\tLoss: 3.142369\n",
      "Train Epoch: 5 [400640/697932 (57%)]\tLoss: 3.153989\n",
      "Train Epoch: 5 [401280/697932 (57%)]\tLoss: 3.158662\n",
      "Train Epoch: 5 [401920/697932 (58%)]\tLoss: 3.148027\n",
      "Train Epoch: 5 [402560/697932 (58%)]\tLoss: 3.178069\n",
      "Train Epoch: 5 [403200/697932 (58%)]\tLoss: 3.182469\n",
      "Train Epoch: 5 [403840/697932 (58%)]\tLoss: 3.149345\n",
      "Train Epoch: 5 [404480/697932 (58%)]\tLoss: 3.167093\n",
      "Train Epoch: 5 [405120/697932 (58%)]\tLoss: 3.159598\n",
      "Train Epoch: 5 [405760/697932 (58%)]\tLoss: 3.152586\n",
      "Train Epoch: 5 [406400/697932 (58%)]\tLoss: 3.189378\n",
      "Train Epoch: 5 [407040/697932 (58%)]\tLoss: 3.185823\n",
      "Train Epoch: 5 [407680/697932 (58%)]\tLoss: 3.173922\n",
      "Train Epoch: 5 [408320/697932 (58%)]\tLoss: 3.151929\n",
      "Train Epoch: 5 [408960/697932 (59%)]\tLoss: 3.140006\n",
      "Train Epoch: 5 [409600/697932 (59%)]\tLoss: 3.167381\n",
      "Train Epoch: 5 [410240/697932 (59%)]\tLoss: 3.162428\n",
      "Train Epoch: 5 [410880/697932 (59%)]\tLoss: 3.164665\n",
      "Train Epoch: 5 [411520/697932 (59%)]\tLoss: 3.166557\n",
      "Train Epoch: 5 [412160/697932 (59%)]\tLoss: 3.166100\n",
      "Train Epoch: 5 [412800/697932 (59%)]\tLoss: 3.165513\n",
      "Train Epoch: 5 [413440/697932 (59%)]\tLoss: 3.151921\n",
      "Train Epoch: 5 [414080/697932 (59%)]\tLoss: 3.176075\n",
      "Train Epoch: 5 [414720/697932 (59%)]\tLoss: 3.179737\n",
      "Train Epoch: 5 [415360/697932 (60%)]\tLoss: 3.196477\n",
      "Train Epoch: 5 [416000/697932 (60%)]\tLoss: 3.164134\n",
      "Train Epoch: 5 [416640/697932 (60%)]\tLoss: 3.193601\n",
      "Train Epoch: 5 [417280/697932 (60%)]\tLoss: 3.166436\n",
      "Train Epoch: 5 [417920/697932 (60%)]\tLoss: 3.161729\n",
      "Train Epoch: 5 [418560/697932 (60%)]\tLoss: 3.149878\n",
      "Train Epoch: 5 [419200/697932 (60%)]\tLoss: 3.198075\n",
      "Train Epoch: 5 [419840/697932 (60%)]\tLoss: 3.173309\n",
      "Train Epoch: 5 [420480/697932 (60%)]\tLoss: 3.184238\n",
      "Train Epoch: 5 [421120/697932 (60%)]\tLoss: 3.167848\n",
      "Train Epoch: 5 [421760/697932 (60%)]\tLoss: 3.154711\n",
      "Train Epoch: 5 [422400/697932 (61%)]\tLoss: 3.154374\n",
      "Train Epoch: 5 [423040/697932 (61%)]\tLoss: 3.188256\n",
      "Train Epoch: 5 [423680/697932 (61%)]\tLoss: 3.158608\n",
      "Train Epoch: 5 [424320/697932 (61%)]\tLoss: 3.184388\n",
      "Train Epoch: 5 [424960/697932 (61%)]\tLoss: 3.170682\n",
      "Train Epoch: 5 [425600/697932 (61%)]\tLoss: 3.161166\n",
      "Train Epoch: 5 [426240/697932 (61%)]\tLoss: 3.151464\n",
      "Train Epoch: 5 [426880/697932 (61%)]\tLoss: 3.147744\n",
      "Train Epoch: 5 [427520/697932 (61%)]\tLoss: 3.172337\n",
      "Train Epoch: 5 [428160/697932 (61%)]\tLoss: 3.156960\n",
      "Train Epoch: 5 [428800/697932 (61%)]\tLoss: 3.154538\n",
      "Train Epoch: 5 [429440/697932 (62%)]\tLoss: 3.148870\n",
      "Train Epoch: 5 [430080/697932 (62%)]\tLoss: 3.167090\n",
      "Train Epoch: 5 [430720/697932 (62%)]\tLoss: 3.167557\n",
      "Train Epoch: 5 [431360/697932 (62%)]\tLoss: 3.157760\n",
      "Train Epoch: 5 [432000/697932 (62%)]\tLoss: 3.157281\n",
      "Train Epoch: 5 [432640/697932 (62%)]\tLoss: 3.178138\n",
      "Train Epoch: 5 [433280/697932 (62%)]\tLoss: 3.189265\n",
      "Train Epoch: 5 [433920/697932 (62%)]\tLoss: 3.188430\n",
      "Train Epoch: 5 [434560/697932 (62%)]\tLoss: 3.173828\n",
      "Train Epoch: 5 [435200/697932 (62%)]\tLoss: 3.175871\n",
      "Train Epoch: 5 [435840/697932 (62%)]\tLoss: 3.195028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [436480/697932 (63%)]\tLoss: 3.159865\n",
      "Train Epoch: 5 [437120/697932 (63%)]\tLoss: 3.179069\n",
      "Train Epoch: 5 [437760/697932 (63%)]\tLoss: 3.160126\n",
      "Train Epoch: 5 [438400/697932 (63%)]\tLoss: 3.175601\n",
      "Train Epoch: 5 [439040/697932 (63%)]\tLoss: 3.156234\n",
      "Train Epoch: 5 [439680/697932 (63%)]\tLoss: 3.146194\n",
      "Train Epoch: 5 [440320/697932 (63%)]\tLoss: 3.190565\n",
      "Train Epoch: 5 [440960/697932 (63%)]\tLoss: 3.169559\n",
      "Train Epoch: 5 [441600/697932 (63%)]\tLoss: 3.161359\n",
      "Train Epoch: 5 [442240/697932 (63%)]\tLoss: 3.155555\n",
      "Train Epoch: 5 [442880/697932 (63%)]\tLoss: 3.193995\n",
      "Train Epoch: 5 [443520/697932 (64%)]\tLoss: 3.180029\n",
      "Train Epoch: 5 [444160/697932 (64%)]\tLoss: 3.183661\n",
      "Train Epoch: 5 [444800/697932 (64%)]\tLoss: 3.146732\n",
      "Train Epoch: 5 [445440/697932 (64%)]\tLoss: 3.181396\n",
      "Train Epoch: 5 [446080/697932 (64%)]\tLoss: 3.140406\n",
      "Train Epoch: 5 [446720/697932 (64%)]\tLoss: 3.175652\n",
      "Train Epoch: 5 [447360/697932 (64%)]\tLoss: 3.173965\n",
      "Train Epoch: 5 [448000/697932 (64%)]\tLoss: 3.156538\n",
      "Train Epoch: 5 [448640/697932 (64%)]\tLoss: 3.172599\n",
      "Train Epoch: 5 [449280/697932 (64%)]\tLoss: 3.151148\n",
      "Train Epoch: 5 [449920/697932 (64%)]\tLoss: 3.150188\n",
      "Train Epoch: 5 [450560/697932 (65%)]\tLoss: 3.193260\n",
      "Train Epoch: 5 [451200/697932 (65%)]\tLoss: 3.172171\n",
      "Train Epoch: 5 [451840/697932 (65%)]\tLoss: 3.152570\n",
      "Train Epoch: 5 [452480/697932 (65%)]\tLoss: 3.168954\n",
      "Train Epoch: 5 [453120/697932 (65%)]\tLoss: 3.117586\n",
      "Train Epoch: 5 [453760/697932 (65%)]\tLoss: 3.176829\n",
      "Train Epoch: 5 [454400/697932 (65%)]\tLoss: 3.169220\n",
      "Train Epoch: 5 [455040/697932 (65%)]\tLoss: 3.134987\n",
      "Train Epoch: 5 [455680/697932 (65%)]\tLoss: 3.167885\n",
      "Train Epoch: 5 [456320/697932 (65%)]\tLoss: 3.205713\n",
      "Train Epoch: 5 [456960/697932 (65%)]\tLoss: 3.157830\n",
      "Train Epoch: 5 [457600/697932 (66%)]\tLoss: 3.130455\n",
      "Train Epoch: 5 [458240/697932 (66%)]\tLoss: 3.183442\n",
      "Train Epoch: 5 [458880/697932 (66%)]\tLoss: 3.150275\n",
      "Train Epoch: 5 [459520/697932 (66%)]\tLoss: 3.205846\n",
      "Train Epoch: 5 [460160/697932 (66%)]\tLoss: 3.180285\n",
      "Train Epoch: 5 [460800/697932 (66%)]\tLoss: 3.166700\n",
      "Train Epoch: 5 [461440/697932 (66%)]\tLoss: 3.198107\n",
      "Train Epoch: 5 [462080/697932 (66%)]\tLoss: 3.139592\n",
      "Train Epoch: 5 [462720/697932 (66%)]\tLoss: 3.192279\n",
      "Train Epoch: 5 [463360/697932 (66%)]\tLoss: 3.162393\n",
      "Train Epoch: 5 [464000/697932 (66%)]\tLoss: 3.173084\n",
      "Train Epoch: 5 [464640/697932 (67%)]\tLoss: 3.174969\n",
      "Train Epoch: 5 [465280/697932 (67%)]\tLoss: 3.157046\n",
      "Train Epoch: 5 [465920/697932 (67%)]\tLoss: 3.156565\n",
      "Train Epoch: 5 [466560/697932 (67%)]\tLoss: 3.182653\n",
      "Train Epoch: 5 [467200/697932 (67%)]\tLoss: 3.140053\n",
      "Train Epoch: 5 [467840/697932 (67%)]\tLoss: 3.174214\n",
      "Train Epoch: 5 [468480/697932 (67%)]\tLoss: 3.162366\n",
      "Train Epoch: 5 [469120/697932 (67%)]\tLoss: 3.169077\n",
      "Train Epoch: 5 [469760/697932 (67%)]\tLoss: 3.168055\n",
      "Train Epoch: 5 [470400/697932 (67%)]\tLoss: 3.184588\n",
      "Train Epoch: 5 [471040/697932 (67%)]\tLoss: 3.165725\n",
      "Train Epoch: 5 [471680/697932 (68%)]\tLoss: 3.182862\n",
      "Train Epoch: 5 [472320/697932 (68%)]\tLoss: 3.197488\n",
      "Train Epoch: 5 [472960/697932 (68%)]\tLoss: 3.135252\n",
      "Train Epoch: 5 [473600/697932 (68%)]\tLoss: 3.182547\n",
      "Train Epoch: 5 [474240/697932 (68%)]\tLoss: 3.165199\n",
      "Train Epoch: 5 [474880/697932 (68%)]\tLoss: 3.171024\n",
      "Train Epoch: 5 [475520/697932 (68%)]\tLoss: 3.161534\n",
      "Train Epoch: 5 [476160/697932 (68%)]\tLoss: 3.157899\n",
      "Train Epoch: 5 [476800/697932 (68%)]\tLoss: 3.192392\n",
      "Train Epoch: 5 [477440/697932 (68%)]\tLoss: 3.166994\n",
      "Train Epoch: 5 [478080/697932 (68%)]\tLoss: 3.154498\n",
      "Train Epoch: 5 [478720/697932 (69%)]\tLoss: 3.172749\n",
      "Train Epoch: 5 [479360/697932 (69%)]\tLoss: 3.171543\n",
      "Train Epoch: 5 [480000/697932 (69%)]\tLoss: 3.190689\n",
      "Train Epoch: 5 [480640/697932 (69%)]\tLoss: 3.174779\n",
      "Train Epoch: 5 [481280/697932 (69%)]\tLoss: 3.149311\n",
      "Train Epoch: 5 [481920/697932 (69%)]\tLoss: 3.161354\n",
      "Train Epoch: 5 [482560/697932 (69%)]\tLoss: 3.136940\n",
      "Train Epoch: 5 [483200/697932 (69%)]\tLoss: 3.197222\n",
      "Train Epoch: 5 [483840/697932 (69%)]\tLoss: 3.154333\n",
      "Train Epoch: 5 [484480/697932 (69%)]\tLoss: 3.164998\n",
      "Train Epoch: 5 [485120/697932 (70%)]\tLoss: 3.156555\n",
      "Train Epoch: 5 [485760/697932 (70%)]\tLoss: 3.181740\n",
      "Train Epoch: 5 [486400/697932 (70%)]\tLoss: 3.201749\n",
      "Train Epoch: 5 [487040/697932 (70%)]\tLoss: 3.155622\n",
      "Train Epoch: 5 [487680/697932 (70%)]\tLoss: 3.184531\n",
      "Train Epoch: 5 [488320/697932 (70%)]\tLoss: 3.171616\n",
      "Train Epoch: 5 [488960/697932 (70%)]\tLoss: 3.151795\n",
      "Train Epoch: 5 [489600/697932 (70%)]\tLoss: 3.127722\n",
      "Train Epoch: 5 [490240/697932 (70%)]\tLoss: 3.169069\n",
      "Train Epoch: 5 [490880/697932 (70%)]\tLoss: 3.162541\n",
      "Train Epoch: 5 [491520/697932 (70%)]\tLoss: 3.174397\n",
      "Train Epoch: 5 [492160/697932 (71%)]\tLoss: 3.183848\n",
      "Train Epoch: 5 [492800/697932 (71%)]\tLoss: 3.159745\n",
      "Train Epoch: 5 [493440/697932 (71%)]\tLoss: 3.186188\n",
      "Train Epoch: 5 [494080/697932 (71%)]\tLoss: 3.159406\n",
      "Train Epoch: 5 [494720/697932 (71%)]\tLoss: 3.181057\n",
      "Train Epoch: 5 [495360/697932 (71%)]\tLoss: 3.165485\n",
      "Train Epoch: 5 [496000/697932 (71%)]\tLoss: 3.168874\n",
      "Train Epoch: 5 [496640/697932 (71%)]\tLoss: 3.178798\n",
      "Train Epoch: 5 [497280/697932 (71%)]\tLoss: 3.152412\n",
      "Train Epoch: 5 [497920/697932 (71%)]\tLoss: 3.194184\n",
      "Train Epoch: 5 [498560/697932 (71%)]\tLoss: 3.178868\n",
      "Train Epoch: 5 [499200/697932 (72%)]\tLoss: 3.188044\n",
      "Train Epoch: 5 [499840/697932 (72%)]\tLoss: 3.189781\n",
      "Train Epoch: 5 [500480/697932 (72%)]\tLoss: 3.166136\n",
      "Train Epoch: 5 [501120/697932 (72%)]\tLoss: 3.197454\n",
      "Train Epoch: 5 [501760/697932 (72%)]\tLoss: 3.170637\n",
      "Train Epoch: 5 [502400/697932 (72%)]\tLoss: 3.159143\n",
      "Train Epoch: 5 [503040/697932 (72%)]\tLoss: 3.203244\n",
      "Train Epoch: 5 [503680/697932 (72%)]\tLoss: 3.176997\n",
      "Train Epoch: 5 [504320/697932 (72%)]\tLoss: 3.164391\n",
      "Train Epoch: 5 [504960/697932 (72%)]\tLoss: 3.200630\n",
      "Train Epoch: 5 [505600/697932 (72%)]\tLoss: 3.173007\n",
      "Train Epoch: 5 [506240/697932 (73%)]\tLoss: 3.162595\n",
      "Train Epoch: 5 [506880/697932 (73%)]\tLoss: 3.194144\n",
      "Train Epoch: 5 [507520/697932 (73%)]\tLoss: 3.190370\n",
      "Train Epoch: 5 [508160/697932 (73%)]\tLoss: 3.134375\n",
      "Train Epoch: 5 [508800/697932 (73%)]\tLoss: 3.182797\n",
      "Train Epoch: 5 [509440/697932 (73%)]\tLoss: 3.148044\n",
      "Train Epoch: 5 [510080/697932 (73%)]\tLoss: 3.145235\n",
      "Train Epoch: 5 [510720/697932 (73%)]\tLoss: 3.165429\n",
      "Train Epoch: 5 [511360/697932 (73%)]\tLoss: 3.162514\n",
      "Train Epoch: 5 [512000/697932 (73%)]\tLoss: 3.171105\n",
      "Train Epoch: 5 [512640/697932 (73%)]\tLoss: 3.164480\n",
      "Train Epoch: 5 [513280/697932 (74%)]\tLoss: 3.157363\n",
      "Train Epoch: 5 [513920/697932 (74%)]\tLoss: 3.172212\n",
      "Train Epoch: 5 [514560/697932 (74%)]\tLoss: 3.158779\n",
      "Train Epoch: 5 [515200/697932 (74%)]\tLoss: 3.189260\n",
      "Train Epoch: 5 [515840/697932 (74%)]\tLoss: 3.173321\n",
      "Train Epoch: 5 [516480/697932 (74%)]\tLoss: 3.180471\n",
      "Train Epoch: 5 [517120/697932 (74%)]\tLoss: 3.175177\n",
      "Train Epoch: 5 [517760/697932 (74%)]\tLoss: 3.159645\n",
      "Train Epoch: 5 [518400/697932 (74%)]\tLoss: 3.172637\n",
      "Train Epoch: 5 [519040/697932 (74%)]\tLoss: 3.152166\n",
      "Train Epoch: 5 [519680/697932 (74%)]\tLoss: 3.211305\n",
      "Train Epoch: 5 [520320/697932 (75%)]\tLoss: 3.141565\n",
      "Train Epoch: 5 [520960/697932 (75%)]\tLoss: 3.139404\n",
      "Train Epoch: 5 [521600/697932 (75%)]\tLoss: 3.171615\n",
      "Train Epoch: 5 [522240/697932 (75%)]\tLoss: 3.179327\n",
      "Train Epoch: 5 [522880/697932 (75%)]\tLoss: 3.149238\n",
      "Train Epoch: 5 [523520/697932 (75%)]\tLoss: 3.147702\n",
      "Train Epoch: 5 [524160/697932 (75%)]\tLoss: 3.160231\n",
      "Train Epoch: 5 [524800/697932 (75%)]\tLoss: 3.167101\n",
      "Train Epoch: 5 [525440/697932 (75%)]\tLoss: 3.178534\n",
      "Train Epoch: 5 [526080/697932 (75%)]\tLoss: 3.169409\n",
      "Train Epoch: 5 [526720/697932 (75%)]\tLoss: 3.157480\n",
      "Train Epoch: 5 [527360/697932 (76%)]\tLoss: 3.168774\n",
      "Train Epoch: 5 [528000/697932 (76%)]\tLoss: 3.177864\n",
      "Train Epoch: 5 [528640/697932 (76%)]\tLoss: 3.170601\n",
      "Train Epoch: 5 [529280/697932 (76%)]\tLoss: 3.172465\n",
      "Train Epoch: 5 [529920/697932 (76%)]\tLoss: 3.145955\n",
      "Train Epoch: 5 [530560/697932 (76%)]\tLoss: 3.157261\n",
      "Train Epoch: 5 [531200/697932 (76%)]\tLoss: 3.179025\n",
      "Train Epoch: 5 [531840/697932 (76%)]\tLoss: 3.171810\n",
      "Train Epoch: 5 [532480/697932 (76%)]\tLoss: 3.163466\n",
      "Train Epoch: 5 [533120/697932 (76%)]\tLoss: 3.157712\n",
      "Train Epoch: 5 [533760/697932 (76%)]\tLoss: 3.186867\n",
      "Train Epoch: 5 [534400/697932 (77%)]\tLoss: 3.161445\n",
      "Train Epoch: 5 [535040/697932 (77%)]\tLoss: 3.167005\n",
      "Train Epoch: 5 [535680/697932 (77%)]\tLoss: 3.174301\n",
      "Train Epoch: 5 [536320/697932 (77%)]\tLoss: 3.155978\n",
      "Train Epoch: 5 [536960/697932 (77%)]\tLoss: 3.152387\n",
      "Train Epoch: 5 [537600/697932 (77%)]\tLoss: 3.168872\n",
      "Train Epoch: 5 [538240/697932 (77%)]\tLoss: 3.161102\n",
      "Train Epoch: 5 [538880/697932 (77%)]\tLoss: 3.166579\n",
      "Train Epoch: 5 [539520/697932 (77%)]\tLoss: 3.174893\n",
      "Train Epoch: 5 [540160/697932 (77%)]\tLoss: 3.144677\n",
      "Train Epoch: 5 [540800/697932 (77%)]\tLoss: 3.199646\n",
      "Train Epoch: 5 [541440/697932 (78%)]\tLoss: 3.181772\n",
      "Train Epoch: 5 [542080/697932 (78%)]\tLoss: 3.173376\n",
      "Train Epoch: 5 [542720/697932 (78%)]\tLoss: 3.161617\n",
      "Train Epoch: 5 [543360/697932 (78%)]\tLoss: 3.182661\n",
      "Train Epoch: 5 [544000/697932 (78%)]\tLoss: 3.173353\n",
      "Train Epoch: 5 [544640/697932 (78%)]\tLoss: 3.152001\n",
      "Train Epoch: 5 [545280/697932 (78%)]\tLoss: 3.173529\n",
      "Train Epoch: 5 [545920/697932 (78%)]\tLoss: 3.137606\n",
      "Train Epoch: 5 [546560/697932 (78%)]\tLoss: 3.181160\n",
      "Train Epoch: 5 [547200/697932 (78%)]\tLoss: 3.183737\n",
      "Train Epoch: 5 [547840/697932 (78%)]\tLoss: 3.176414\n",
      "Train Epoch: 5 [548480/697932 (79%)]\tLoss: 3.174962\n",
      "Train Epoch: 5 [549120/697932 (79%)]\tLoss: 3.159776\n",
      "Train Epoch: 5 [549760/697932 (79%)]\tLoss: 3.146336\n",
      "Train Epoch: 5 [550400/697932 (79%)]\tLoss: 3.187081\n",
      "Train Epoch: 5 [551040/697932 (79%)]\tLoss: 3.151219\n",
      "Train Epoch: 5 [551680/697932 (79%)]\tLoss: 3.175563\n",
      "Train Epoch: 5 [552320/697932 (79%)]\tLoss: 3.151489\n",
      "Train Epoch: 5 [552960/697932 (79%)]\tLoss: 3.153854\n",
      "Train Epoch: 5 [553600/697932 (79%)]\tLoss: 3.151725\n",
      "Train Epoch: 5 [554240/697932 (79%)]\tLoss: 3.162318\n",
      "Train Epoch: 5 [554880/697932 (79%)]\tLoss: 3.177167\n",
      "Train Epoch: 5 [555520/697932 (80%)]\tLoss: 3.166385\n",
      "Train Epoch: 5 [556160/697932 (80%)]\tLoss: 3.172737\n",
      "Train Epoch: 5 [556800/697932 (80%)]\tLoss: 3.179541\n",
      "Train Epoch: 5 [557440/697932 (80%)]\tLoss: 3.146606\n",
      "Train Epoch: 5 [558080/697932 (80%)]\tLoss: 3.213490\n",
      "Train Epoch: 5 [558720/697932 (80%)]\tLoss: 3.160281\n",
      "Train Epoch: 5 [559360/697932 (80%)]\tLoss: 3.162058\n",
      "Train Epoch: 5 [560000/697932 (80%)]\tLoss: 3.145471\n",
      "Train Epoch: 5 [560640/697932 (80%)]\tLoss: 3.184059\n",
      "Train Epoch: 5 [561280/697932 (80%)]\tLoss: 3.164348\n",
      "Train Epoch: 5 [561920/697932 (81%)]\tLoss: 3.173548\n",
      "Train Epoch: 5 [562560/697932 (81%)]\tLoss: 3.165971\n",
      "Train Epoch: 5 [563200/697932 (81%)]\tLoss: 3.163032\n",
      "Train Epoch: 5 [563840/697932 (81%)]\tLoss: 3.162433\n",
      "Train Epoch: 5 [564480/697932 (81%)]\tLoss: 3.175761\n",
      "Train Epoch: 5 [565120/697932 (81%)]\tLoss: 3.179423\n",
      "Train Epoch: 5 [565760/697932 (81%)]\tLoss: 3.192315\n",
      "Train Epoch: 5 [566400/697932 (81%)]\tLoss: 3.195121\n",
      "Train Epoch: 5 [567040/697932 (81%)]\tLoss: 3.163986\n",
      "Train Epoch: 5 [567680/697932 (81%)]\tLoss: 3.171374\n",
      "Train Epoch: 5 [568320/697932 (81%)]\tLoss: 3.179545\n",
      "Train Epoch: 5 [568960/697932 (82%)]\tLoss: 3.160866\n",
      "Train Epoch: 5 [569600/697932 (82%)]\tLoss: 3.156804\n",
      "Train Epoch: 5 [570240/697932 (82%)]\tLoss: 3.176328\n",
      "Train Epoch: 5 [570880/697932 (82%)]\tLoss: 3.189626\n",
      "Train Epoch: 5 [571520/697932 (82%)]\tLoss: 3.162042\n",
      "Train Epoch: 5 [572160/697932 (82%)]\tLoss: 3.157686\n",
      "Train Epoch: 5 [572800/697932 (82%)]\tLoss: 3.144466\n",
      "Train Epoch: 5 [573440/697932 (82%)]\tLoss: 3.170373\n",
      "Train Epoch: 5 [574080/697932 (82%)]\tLoss: 3.159284\n",
      "Train Epoch: 5 [574720/697932 (82%)]\tLoss: 3.171540\n",
      "Train Epoch: 5 [575360/697932 (82%)]\tLoss: 3.139578\n",
      "Train Epoch: 5 [576000/697932 (83%)]\tLoss: 3.165797\n",
      "Train Epoch: 5 [576640/697932 (83%)]\tLoss: 3.172185\n",
      "Train Epoch: 5 [577280/697932 (83%)]\tLoss: 3.190576\n",
      "Train Epoch: 5 [577920/697932 (83%)]\tLoss: 3.148831\n",
      "Train Epoch: 5 [578560/697932 (83%)]\tLoss: 3.202097\n",
      "Train Epoch: 5 [579200/697932 (83%)]\tLoss: 3.171793\n",
      "Train Epoch: 5 [579840/697932 (83%)]\tLoss: 3.205489\n",
      "Train Epoch: 5 [580480/697932 (83%)]\tLoss: 3.150070\n",
      "Train Epoch: 5 [581120/697932 (83%)]\tLoss: 3.168934\n",
      "Train Epoch: 5 [581760/697932 (83%)]\tLoss: 3.154526\n",
      "Train Epoch: 5 [582400/697932 (83%)]\tLoss: 3.162077\n",
      "Train Epoch: 5 [583040/697932 (84%)]\tLoss: 3.191014\n",
      "Train Epoch: 5 [583680/697932 (84%)]\tLoss: 3.162947\n",
      "Train Epoch: 5 [584320/697932 (84%)]\tLoss: 3.186882\n",
      "Train Epoch: 5 [584960/697932 (84%)]\tLoss: 3.165301\n",
      "Train Epoch: 5 [585600/697932 (84%)]\tLoss: 3.166657\n",
      "Train Epoch: 5 [586240/697932 (84%)]\tLoss: 3.166641\n",
      "Train Epoch: 5 [586880/697932 (84%)]\tLoss: 3.189106\n",
      "Train Epoch: 5 [587520/697932 (84%)]\tLoss: 3.153499\n",
      "Train Epoch: 5 [588160/697932 (84%)]\tLoss: 3.153450\n",
      "Train Epoch: 5 [588800/697932 (84%)]\tLoss: 3.173752\n",
      "Train Epoch: 5 [589440/697932 (84%)]\tLoss: 3.175234\n",
      "Train Epoch: 5 [590080/697932 (85%)]\tLoss: 3.187904\n",
      "Train Epoch: 5 [590720/697932 (85%)]\tLoss: 3.176613\n",
      "Train Epoch: 5 [591360/697932 (85%)]\tLoss: 3.162494\n",
      "Train Epoch: 5 [592000/697932 (85%)]\tLoss: 3.174175\n",
      "Train Epoch: 5 [592640/697932 (85%)]\tLoss: 3.158340\n",
      "Train Epoch: 5 [593280/697932 (85%)]\tLoss: 3.166154\n",
      "Train Epoch: 5 [593920/697932 (85%)]\tLoss: 3.192061\n",
      "Train Epoch: 5 [594560/697932 (85%)]\tLoss: 3.145517\n",
      "Train Epoch: 5 [595200/697932 (85%)]\tLoss: 3.168551\n",
      "Train Epoch: 5 [595840/697932 (85%)]\tLoss: 3.168534\n",
      "Train Epoch: 5 [596480/697932 (85%)]\tLoss: 3.190341\n",
      "Train Epoch: 5 [597120/697932 (86%)]\tLoss: 3.180952\n",
      "Train Epoch: 5 [597760/697932 (86%)]\tLoss: 3.183580\n",
      "Train Epoch: 5 [598400/697932 (86%)]\tLoss: 3.148279\n",
      "Train Epoch: 5 [599040/697932 (86%)]\tLoss: 3.175364\n",
      "Train Epoch: 5 [599680/697932 (86%)]\tLoss: 3.139302\n",
      "Train Epoch: 5 [600320/697932 (86%)]\tLoss: 3.173192\n",
      "Train Epoch: 5 [600960/697932 (86%)]\tLoss: 3.175390\n",
      "Train Epoch: 5 [601600/697932 (86%)]\tLoss: 3.144961\n",
      "Train Epoch: 5 [602240/697932 (86%)]\tLoss: 3.153586\n",
      "Train Epoch: 5 [602880/697932 (86%)]\tLoss: 3.163198\n",
      "Train Epoch: 5 [603520/697932 (86%)]\tLoss: 3.171295\n",
      "Train Epoch: 5 [604160/697932 (87%)]\tLoss: 3.147161\n",
      "Train Epoch: 5 [604800/697932 (87%)]\tLoss: 3.156425\n",
      "Train Epoch: 5 [605440/697932 (87%)]\tLoss: 3.176214\n",
      "Train Epoch: 5 [606080/697932 (87%)]\tLoss: 3.164382\n",
      "Train Epoch: 5 [606720/697932 (87%)]\tLoss: 3.137250\n",
      "Train Epoch: 5 [607360/697932 (87%)]\tLoss: 3.174200\n",
      "Train Epoch: 5 [608000/697932 (87%)]\tLoss: 3.181313\n",
      "Train Epoch: 5 [608640/697932 (87%)]\tLoss: 3.200841\n",
      "Train Epoch: 5 [609280/697932 (87%)]\tLoss: 3.162028\n",
      "Train Epoch: 5 [609920/697932 (87%)]\tLoss: 3.153053\n",
      "Train Epoch: 5 [610560/697932 (87%)]\tLoss: 3.155505\n",
      "Train Epoch: 5 [611200/697932 (88%)]\tLoss: 3.149222\n",
      "Train Epoch: 5 [611840/697932 (88%)]\tLoss: 3.169819\n",
      "Train Epoch: 5 [612480/697932 (88%)]\tLoss: 3.203691\n",
      "Train Epoch: 5 [613120/697932 (88%)]\tLoss: 3.158244\n",
      "Train Epoch: 5 [613760/697932 (88%)]\tLoss: 3.179329\n",
      "Train Epoch: 5 [614400/697932 (88%)]\tLoss: 3.173733\n",
      "Train Epoch: 5 [615040/697932 (88%)]\tLoss: 3.157917\n",
      "Train Epoch: 5 [615680/697932 (88%)]\tLoss: 3.179167\n",
      "Train Epoch: 5 [616320/697932 (88%)]\tLoss: 3.147593\n",
      "Train Epoch: 5 [616960/697932 (88%)]\tLoss: 3.171782\n",
      "Train Epoch: 5 [617600/697932 (88%)]\tLoss: 3.150652\n",
      "Train Epoch: 5 [618240/697932 (89%)]\tLoss: 3.193050\n",
      "Train Epoch: 5 [618880/697932 (89%)]\tLoss: 3.165941\n",
      "Train Epoch: 5 [619520/697932 (89%)]\tLoss: 3.168649\n",
      "Train Epoch: 5 [620160/697932 (89%)]\tLoss: 3.146874\n",
      "Train Epoch: 5 [620800/697932 (89%)]\tLoss: 3.170125\n",
      "Train Epoch: 5 [621440/697932 (89%)]\tLoss: 3.191622\n",
      "Train Epoch: 5 [622080/697932 (89%)]\tLoss: 3.170462\n",
      "Train Epoch: 5 [622720/697932 (89%)]\tLoss: 3.196044\n",
      "Train Epoch: 5 [623360/697932 (89%)]\tLoss: 3.195684\n",
      "Train Epoch: 5 [624000/697932 (89%)]\tLoss: 3.174109\n",
      "Train Epoch: 5 [624640/697932 (89%)]\tLoss: 3.186401\n",
      "Train Epoch: 5 [625280/697932 (90%)]\tLoss: 3.149470\n",
      "Train Epoch: 5 [625920/697932 (90%)]\tLoss: 3.157899\n",
      "Train Epoch: 5 [626560/697932 (90%)]\tLoss: 3.172289\n",
      "Train Epoch: 5 [627200/697932 (90%)]\tLoss: 3.157296\n",
      "Train Epoch: 5 [627840/697932 (90%)]\tLoss: 3.169635\n",
      "Train Epoch: 5 [628480/697932 (90%)]\tLoss: 3.177691\n",
      "Train Epoch: 5 [629120/697932 (90%)]\tLoss: 3.179732\n",
      "Train Epoch: 5 [629760/697932 (90%)]\tLoss: 3.147199\n",
      "Train Epoch: 5 [630400/697932 (90%)]\tLoss: 3.145381\n",
      "Train Epoch: 5 [631040/697932 (90%)]\tLoss: 3.175315\n",
      "Train Epoch: 5 [631680/697932 (91%)]\tLoss: 3.153701\n",
      "Train Epoch: 5 [632320/697932 (91%)]\tLoss: 3.166647\n",
      "Train Epoch: 5 [632960/697932 (91%)]\tLoss: 3.153420\n",
      "Train Epoch: 5 [633600/697932 (91%)]\tLoss: 3.159823\n",
      "Train Epoch: 5 [634240/697932 (91%)]\tLoss: 3.179461\n",
      "Train Epoch: 5 [634880/697932 (91%)]\tLoss: 3.141744\n",
      "Train Epoch: 5 [635520/697932 (91%)]\tLoss: 3.151419\n",
      "Train Epoch: 5 [636160/697932 (91%)]\tLoss: 3.166794\n",
      "Train Epoch: 5 [636800/697932 (91%)]\tLoss: 3.180813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [637440/697932 (91%)]\tLoss: 3.159111\n",
      "Train Epoch: 5 [638080/697932 (91%)]\tLoss: 3.189210\n",
      "Train Epoch: 5 [638720/697932 (92%)]\tLoss: 3.156379\n",
      "Train Epoch: 5 [639360/697932 (92%)]\tLoss: 3.199141\n",
      "Train Epoch: 5 [640000/697932 (92%)]\tLoss: 3.176257\n",
      "Train Epoch: 5 [640640/697932 (92%)]\tLoss: 3.166009\n",
      "Train Epoch: 5 [641280/697932 (92%)]\tLoss: 3.180170\n",
      "Train Epoch: 5 [641920/697932 (92%)]\tLoss: 3.165186\n",
      "Train Epoch: 5 [642560/697932 (92%)]\tLoss: 3.155585\n",
      "Train Epoch: 5 [643200/697932 (92%)]\tLoss: 3.182022\n",
      "Train Epoch: 5 [643840/697932 (92%)]\tLoss: 3.180910\n",
      "Train Epoch: 5 [644480/697932 (92%)]\tLoss: 3.165732\n",
      "Train Epoch: 5 [645120/697932 (92%)]\tLoss: 3.164456\n",
      "Train Epoch: 5 [645760/697932 (93%)]\tLoss: 3.187074\n",
      "Train Epoch: 5 [646400/697932 (93%)]\tLoss: 3.178810\n",
      "Train Epoch: 5 [647040/697932 (93%)]\tLoss: 3.164080\n",
      "Train Epoch: 5 [647680/697932 (93%)]\tLoss: 3.161879\n",
      "Train Epoch: 5 [648320/697932 (93%)]\tLoss: 3.159651\n",
      "Train Epoch: 5 [648960/697932 (93%)]\tLoss: 3.203682\n",
      "Train Epoch: 5 [649600/697932 (93%)]\tLoss: 3.162045\n",
      "Train Epoch: 5 [650240/697932 (93%)]\tLoss: 3.200484\n",
      "Train Epoch: 5 [650880/697932 (93%)]\tLoss: 3.183110\n",
      "Train Epoch: 5 [651520/697932 (93%)]\tLoss: 3.152073\n",
      "Train Epoch: 5 [652160/697932 (93%)]\tLoss: 3.149067\n",
      "Train Epoch: 5 [652800/697932 (94%)]\tLoss: 3.149616\n",
      "Train Epoch: 5 [653440/697932 (94%)]\tLoss: 3.203212\n",
      "Train Epoch: 5 [654080/697932 (94%)]\tLoss: 3.168766\n",
      "Train Epoch: 5 [654720/697932 (94%)]\tLoss: 3.164502\n",
      "Train Epoch: 5 [655360/697932 (94%)]\tLoss: 3.169491\n",
      "Train Epoch: 5 [656000/697932 (94%)]\tLoss: 3.156968\n",
      "Train Epoch: 5 [656640/697932 (94%)]\tLoss: 3.165881\n",
      "Train Epoch: 5 [657280/697932 (94%)]\tLoss: 3.155226\n",
      "Train Epoch: 5 [657920/697932 (94%)]\tLoss: 3.149736\n",
      "Train Epoch: 5 [658560/697932 (94%)]\tLoss: 3.176483\n",
      "Train Epoch: 5 [659200/697932 (94%)]\tLoss: 3.181585\n",
      "Train Epoch: 5 [659840/697932 (95%)]\tLoss: 3.176963\n",
      "Train Epoch: 5 [660480/697932 (95%)]\tLoss: 3.169154\n",
      "Train Epoch: 5 [661120/697932 (95%)]\tLoss: 3.153052\n",
      "Train Epoch: 5 [661760/697932 (95%)]\tLoss: 3.184996\n",
      "Train Epoch: 5 [662400/697932 (95%)]\tLoss: 3.179029\n",
      "Train Epoch: 5 [663040/697932 (95%)]\tLoss: 3.154869\n",
      "Train Epoch: 5 [663680/697932 (95%)]\tLoss: 3.187925\n",
      "Train Epoch: 5 [664320/697932 (95%)]\tLoss: 3.171409\n",
      "Train Epoch: 5 [664960/697932 (95%)]\tLoss: 3.174103\n",
      "Train Epoch: 5 [665600/697932 (95%)]\tLoss: 3.161916\n",
      "Train Epoch: 5 [666240/697932 (95%)]\tLoss: 3.179478\n",
      "Train Epoch: 5 [666880/697932 (96%)]\tLoss: 3.188746\n",
      "Train Epoch: 5 [667520/697932 (96%)]\tLoss: 3.163240\n",
      "Train Epoch: 5 [668160/697932 (96%)]\tLoss: 3.178505\n",
      "Train Epoch: 5 [668800/697932 (96%)]\tLoss: 3.183246\n",
      "Train Epoch: 5 [669440/697932 (96%)]\tLoss: 3.174166\n",
      "Train Epoch: 5 [670080/697932 (96%)]\tLoss: 3.173672\n",
      "Train Epoch: 5 [670720/697932 (96%)]\tLoss: 3.193031\n",
      "Train Epoch: 5 [671360/697932 (96%)]\tLoss: 3.176002\n",
      "Train Epoch: 5 [672000/697932 (96%)]\tLoss: 3.156463\n",
      "Train Epoch: 5 [672640/697932 (96%)]\tLoss: 3.172047\n",
      "Train Epoch: 5 [673280/697932 (96%)]\tLoss: 3.170779\n",
      "Train Epoch: 5 [673920/697932 (97%)]\tLoss: 3.172953\n",
      "Train Epoch: 5 [674560/697932 (97%)]\tLoss: 3.185623\n",
      "Train Epoch: 5 [675200/697932 (97%)]\tLoss: 3.177922\n",
      "Train Epoch: 5 [675840/697932 (97%)]\tLoss: 3.189795\n",
      "Train Epoch: 5 [676480/697932 (97%)]\tLoss: 3.141637\n",
      "Train Epoch: 5 [677120/697932 (97%)]\tLoss: 3.182793\n",
      "Train Epoch: 5 [677760/697932 (97%)]\tLoss: 3.173147\n",
      "Train Epoch: 5 [678400/697932 (97%)]\tLoss: 3.174890\n",
      "Train Epoch: 5 [679040/697932 (97%)]\tLoss: 3.163763\n",
      "Train Epoch: 5 [679680/697932 (97%)]\tLoss: 3.197172\n",
      "Train Epoch: 5 [680320/697932 (97%)]\tLoss: 3.143704\n",
      "Train Epoch: 5 [680960/697932 (98%)]\tLoss: 3.168028\n",
      "Train Epoch: 5 [681600/697932 (98%)]\tLoss: 3.172752\n",
      "Train Epoch: 5 [682240/697932 (98%)]\tLoss: 3.177256\n",
      "Train Epoch: 5 [682880/697932 (98%)]\tLoss: 3.157518\n",
      "Train Epoch: 5 [683520/697932 (98%)]\tLoss: 3.174233\n",
      "Train Epoch: 5 [684160/697932 (98%)]\tLoss: 3.134770\n",
      "Train Epoch: 5 [684800/697932 (98%)]\tLoss: 3.166072\n",
      "Train Epoch: 5 [685440/697932 (98%)]\tLoss: 3.180910\n",
      "Train Epoch: 5 [686080/697932 (98%)]\tLoss: 3.185822\n",
      "Train Epoch: 5 [686720/697932 (98%)]\tLoss: 3.156006\n",
      "Train Epoch: 5 [687360/697932 (98%)]\tLoss: 3.155049\n",
      "Train Epoch: 5 [688000/697932 (99%)]\tLoss: 3.189498\n",
      "Train Epoch: 5 [688640/697932 (99%)]\tLoss: 3.155439\n",
      "Train Epoch: 5 [689280/697932 (99%)]\tLoss: 3.190818\n",
      "Train Epoch: 5 [689920/697932 (99%)]\tLoss: 3.179397\n",
      "Train Epoch: 5 [690560/697932 (99%)]\tLoss: 3.156078\n",
      "Train Epoch: 5 [691200/697932 (99%)]\tLoss: 3.155931\n",
      "Train Epoch: 5 [691840/697932 (99%)]\tLoss: 3.145518\n",
      "Train Epoch: 5 [692480/697932 (99%)]\tLoss: 3.203327\n",
      "Train Epoch: 5 [693120/697932 (99%)]\tLoss: 3.176621\n",
      "Train Epoch: 5 [693760/697932 (99%)]\tLoss: 3.176163\n",
      "Train Epoch: 5 [694400/697932 (99%)]\tLoss: 3.188275\n",
      "Train Epoch: 5 [695040/697932 (100%)]\tLoss: 3.175427\n",
      "Train Epoch: 5 [695680/697932 (100%)]\tLoss: 3.143160\n",
      "Train Epoch: 5 [696320/697932 (100%)]\tLoss: 3.158692\n",
      "Train Epoch: 5 [696960/697932 (100%)]\tLoss: 3.166677\n",
      "Train Epoch: 5 [697600/697932 (100%)]\tLoss: 3.124296\n",
      "\n",
      "Test set: Avg. loss: 0.0043, Accuracy: 38/116323 (0%)\n",
      "\n",
      "Train Epoch: 6 [0/697932 (0%)]\tLoss: 3.161576\n",
      "Train Epoch: 6 [640/697932 (0%)]\tLoss: 3.172592\n",
      "Train Epoch: 6 [1280/697932 (0%)]\tLoss: 3.180506\n",
      "Train Epoch: 6 [1920/697932 (0%)]\tLoss: 3.166607\n",
      "Train Epoch: 6 [2560/697932 (0%)]\tLoss: 3.160281\n",
      "Train Epoch: 6 [3200/697932 (0%)]\tLoss: 3.153622\n",
      "Train Epoch: 6 [3840/697932 (1%)]\tLoss: 3.160135\n",
      "Train Epoch: 6 [4480/697932 (1%)]\tLoss: 3.167377\n",
      "Train Epoch: 6 [5120/697932 (1%)]\tLoss: 3.165285\n",
      "Train Epoch: 6 [5760/697932 (1%)]\tLoss: 3.173132\n",
      "Train Epoch: 6 [6400/697932 (1%)]\tLoss: 3.167407\n",
      "Train Epoch: 6 [7040/697932 (1%)]\tLoss: 3.179427\n",
      "Train Epoch: 6 [7680/697932 (1%)]\tLoss: 3.161424\n",
      "Train Epoch: 6 [8320/697932 (1%)]\tLoss: 3.174480\n",
      "Train Epoch: 6 [8960/697932 (1%)]\tLoss: 3.165474\n",
      "Train Epoch: 6 [9600/697932 (1%)]\tLoss: 3.195297\n",
      "Train Epoch: 6 [10240/697932 (1%)]\tLoss: 3.190291\n",
      "Train Epoch: 6 [10880/697932 (2%)]\tLoss: 3.170444\n",
      "Train Epoch: 6 [11520/697932 (2%)]\tLoss: 3.176279\n",
      "Train Epoch: 6 [12160/697932 (2%)]\tLoss: 3.133967\n",
      "Train Epoch: 6 [12800/697932 (2%)]\tLoss: 3.184781\n",
      "Train Epoch: 6 [13440/697932 (2%)]\tLoss: 3.176155\n",
      "Train Epoch: 6 [14080/697932 (2%)]\tLoss: 3.165182\n",
      "Train Epoch: 6 [14720/697932 (2%)]\tLoss: 3.162901\n",
      "Train Epoch: 6 [15360/697932 (2%)]\tLoss: 3.163321\n",
      "Train Epoch: 6 [16000/697932 (2%)]\tLoss: 3.181364\n",
      "Train Epoch: 6 [16640/697932 (2%)]\tLoss: 3.177741\n",
      "Train Epoch: 6 [17280/697932 (2%)]\tLoss: 3.175661\n",
      "Train Epoch: 6 [17920/697932 (3%)]\tLoss: 3.178908\n",
      "Train Epoch: 6 [18560/697932 (3%)]\tLoss: 3.196177\n",
      "Train Epoch: 6 [19200/697932 (3%)]\tLoss: 3.174219\n",
      "Train Epoch: 6 [19840/697932 (3%)]\tLoss: 3.168254\n",
      "Train Epoch: 6 [20480/697932 (3%)]\tLoss: 3.164437\n",
      "Train Epoch: 6 [21120/697932 (3%)]\tLoss: 3.161542\n",
      "Train Epoch: 6 [21760/697932 (3%)]\tLoss: 3.187667\n",
      "Train Epoch: 6 [22400/697932 (3%)]\tLoss: 3.160141\n",
      "Train Epoch: 6 [23040/697932 (3%)]\tLoss: 3.139139\n",
      "Train Epoch: 6 [23680/697932 (3%)]\tLoss: 3.180903\n",
      "Train Epoch: 6 [24320/697932 (3%)]\tLoss: 3.192624\n",
      "Train Epoch: 6 [24960/697932 (4%)]\tLoss: 3.169729\n",
      "Train Epoch: 6 [25600/697932 (4%)]\tLoss: 3.148956\n",
      "Train Epoch: 6 [26240/697932 (4%)]\tLoss: 3.188160\n",
      "Train Epoch: 6 [26880/697932 (4%)]\tLoss: 3.180530\n",
      "Train Epoch: 6 [27520/697932 (4%)]\tLoss: 3.167007\n",
      "Train Epoch: 6 [28160/697932 (4%)]\tLoss: 3.171633\n",
      "Train Epoch: 6 [28800/697932 (4%)]\tLoss: 3.167769\n",
      "Train Epoch: 6 [29440/697932 (4%)]\tLoss: 3.173217\n",
      "Train Epoch: 6 [30080/697932 (4%)]\tLoss: 3.181207\n",
      "Train Epoch: 6 [30720/697932 (4%)]\tLoss: 3.145751\n",
      "Train Epoch: 6 [31360/697932 (4%)]\tLoss: 3.155034\n",
      "Train Epoch: 6 [32000/697932 (5%)]\tLoss: 3.172554\n",
      "Train Epoch: 6 [32640/697932 (5%)]\tLoss: 3.139663\n",
      "Train Epoch: 6 [33280/697932 (5%)]\tLoss: 3.175732\n",
      "Train Epoch: 6 [33920/697932 (5%)]\tLoss: 3.182418\n",
      "Train Epoch: 6 [34560/697932 (5%)]\tLoss: 3.190535\n",
      "Train Epoch: 6 [35200/697932 (5%)]\tLoss: 3.192333\n",
      "Train Epoch: 6 [35840/697932 (5%)]\tLoss: 3.161232\n",
      "Train Epoch: 6 [36480/697932 (5%)]\tLoss: 3.171323\n",
      "Train Epoch: 6 [37120/697932 (5%)]\tLoss: 3.154262\n",
      "Train Epoch: 6 [37760/697932 (5%)]\tLoss: 3.181126\n",
      "Train Epoch: 6 [38400/697932 (6%)]\tLoss: 3.152938\n",
      "Train Epoch: 6 [39040/697932 (6%)]\tLoss: 3.157365\n",
      "Train Epoch: 6 [39680/697932 (6%)]\tLoss: 3.162835\n",
      "Train Epoch: 6 [40320/697932 (6%)]\tLoss: 3.148449\n",
      "Train Epoch: 6 [40960/697932 (6%)]\tLoss: 3.178465\n",
      "Train Epoch: 6 [41600/697932 (6%)]\tLoss: 3.153566\n",
      "Train Epoch: 6 [42240/697932 (6%)]\tLoss: 3.147608\n",
      "Train Epoch: 6 [42880/697932 (6%)]\tLoss: 3.167428\n",
      "Train Epoch: 6 [43520/697932 (6%)]\tLoss: 3.154131\n",
      "Train Epoch: 6 [44160/697932 (6%)]\tLoss: 3.166242\n",
      "Train Epoch: 6 [44800/697932 (6%)]\tLoss: 3.167232\n",
      "Train Epoch: 6 [45440/697932 (7%)]\tLoss: 3.146235\n",
      "Train Epoch: 6 [46080/697932 (7%)]\tLoss: 3.182634\n",
      "Train Epoch: 6 [46720/697932 (7%)]\tLoss: 3.165039\n",
      "Train Epoch: 6 [47360/697932 (7%)]\tLoss: 3.156777\n",
      "Train Epoch: 6 [48000/697932 (7%)]\tLoss: 3.131979\n",
      "Train Epoch: 6 [48640/697932 (7%)]\tLoss: 3.201873\n",
      "Train Epoch: 6 [49280/697932 (7%)]\tLoss: 3.192095\n",
      "Train Epoch: 6 [49920/697932 (7%)]\tLoss: 3.149778\n",
      "Train Epoch: 6 [50560/697932 (7%)]\tLoss: 3.154576\n",
      "Train Epoch: 6 [51200/697932 (7%)]\tLoss: 3.155730\n",
      "Train Epoch: 6 [51840/697932 (7%)]\tLoss: 3.163922\n",
      "Train Epoch: 6 [52480/697932 (8%)]\tLoss: 3.178228\n",
      "Train Epoch: 6 [53120/697932 (8%)]\tLoss: 3.180421\n",
      "Train Epoch: 6 [53760/697932 (8%)]\tLoss: 3.163983\n",
      "Train Epoch: 6 [54400/697932 (8%)]\tLoss: 3.172315\n",
      "Train Epoch: 6 [55040/697932 (8%)]\tLoss: 3.195340\n",
      "Train Epoch: 6 [55680/697932 (8%)]\tLoss: 3.174997\n",
      "Train Epoch: 6 [56320/697932 (8%)]\tLoss: 3.181765\n",
      "Train Epoch: 6 [56960/697932 (8%)]\tLoss: 3.180815\n",
      "Train Epoch: 6 [57600/697932 (8%)]\tLoss: 3.159263\n",
      "Train Epoch: 6 [58240/697932 (8%)]\tLoss: 3.193548\n",
      "Train Epoch: 6 [58880/697932 (8%)]\tLoss: 3.181231\n",
      "Train Epoch: 6 [59520/697932 (9%)]\tLoss: 3.161893\n",
      "Train Epoch: 6 [60160/697932 (9%)]\tLoss: 3.173580\n",
      "Train Epoch: 6 [60800/697932 (9%)]\tLoss: 3.162443\n",
      "Train Epoch: 6 [61440/697932 (9%)]\tLoss: 3.179668\n",
      "Train Epoch: 6 [62080/697932 (9%)]\tLoss: 3.161036\n",
      "Train Epoch: 6 [62720/697932 (9%)]\tLoss: 3.188698\n",
      "Train Epoch: 6 [63360/697932 (9%)]\tLoss: 3.179118\n",
      "Train Epoch: 6 [64000/697932 (9%)]\tLoss: 3.180798\n",
      "Train Epoch: 6 [64640/697932 (9%)]\tLoss: 3.141608\n",
      "Train Epoch: 6 [65280/697932 (9%)]\tLoss: 3.192701\n",
      "Train Epoch: 6 [65920/697932 (9%)]\tLoss: 3.140840\n",
      "Train Epoch: 6 [66560/697932 (10%)]\tLoss: 3.188321\n",
      "Train Epoch: 6 [67200/697932 (10%)]\tLoss: 3.163477\n",
      "Train Epoch: 6 [67840/697932 (10%)]\tLoss: 3.159570\n",
      "Train Epoch: 6 [68480/697932 (10%)]\tLoss: 3.194735\n",
      "Train Epoch: 6 [69120/697932 (10%)]\tLoss: 3.172793\n",
      "Train Epoch: 6 [69760/697932 (10%)]\tLoss: 3.173572\n",
      "Train Epoch: 6 [70400/697932 (10%)]\tLoss: 3.165378\n",
      "Train Epoch: 6 [71040/697932 (10%)]\tLoss: 3.164637\n",
      "Train Epoch: 6 [71680/697932 (10%)]\tLoss: 3.168287\n",
      "Train Epoch: 6 [72320/697932 (10%)]\tLoss: 3.171059\n",
      "Train Epoch: 6 [72960/697932 (10%)]\tLoss: 3.147623\n",
      "Train Epoch: 6 [73600/697932 (11%)]\tLoss: 3.160962\n",
      "Train Epoch: 6 [74240/697932 (11%)]\tLoss: 3.168616\n",
      "Train Epoch: 6 [74880/697932 (11%)]\tLoss: 3.171397\n",
      "Train Epoch: 6 [75520/697932 (11%)]\tLoss: 3.171560\n",
      "Train Epoch: 6 [76160/697932 (11%)]\tLoss: 3.193259\n",
      "Train Epoch: 6 [76800/697932 (11%)]\tLoss: 3.167597\n",
      "Train Epoch: 6 [77440/697932 (11%)]\tLoss: 3.157568\n",
      "Train Epoch: 6 [78080/697932 (11%)]\tLoss: 3.184098\n",
      "Train Epoch: 6 [78720/697932 (11%)]\tLoss: 3.151831\n",
      "Train Epoch: 6 [79360/697932 (11%)]\tLoss: 3.180959\n",
      "Train Epoch: 6 [80000/697932 (11%)]\tLoss: 3.188534\n",
      "Train Epoch: 6 [80640/697932 (12%)]\tLoss: 3.161613\n",
      "Train Epoch: 6 [81280/697932 (12%)]\tLoss: 3.156935\n",
      "Train Epoch: 6 [81920/697932 (12%)]\tLoss: 3.178856\n",
      "Train Epoch: 6 [82560/697932 (12%)]\tLoss: 3.165222\n",
      "Train Epoch: 6 [83200/697932 (12%)]\tLoss: 3.168506\n",
      "Train Epoch: 6 [83840/697932 (12%)]\tLoss: 3.162763\n",
      "Train Epoch: 6 [84480/697932 (12%)]\tLoss: 3.167842\n",
      "Train Epoch: 6 [85120/697932 (12%)]\tLoss: 3.172654\n",
      "Train Epoch: 6 [85760/697932 (12%)]\tLoss: 3.170137\n",
      "Train Epoch: 6 [86400/697932 (12%)]\tLoss: 3.169348\n",
      "Train Epoch: 6 [87040/697932 (12%)]\tLoss: 3.151900\n",
      "Train Epoch: 6 [87680/697932 (13%)]\tLoss: 3.185772\n",
      "Train Epoch: 6 [88320/697932 (13%)]\tLoss: 3.162043\n",
      "Train Epoch: 6 [88960/697932 (13%)]\tLoss: 3.168591\n",
      "Train Epoch: 6 [89600/697932 (13%)]\tLoss: 3.170616\n",
      "Train Epoch: 6 [90240/697932 (13%)]\tLoss: 3.160818\n",
      "Train Epoch: 6 [90880/697932 (13%)]\tLoss: 3.169546\n",
      "Train Epoch: 6 [91520/697932 (13%)]\tLoss: 3.204359\n",
      "Train Epoch: 6 [92160/697932 (13%)]\tLoss: 3.188958\n",
      "Train Epoch: 6 [92800/697932 (13%)]\tLoss: 3.162171\n",
      "Train Epoch: 6 [93440/697932 (13%)]\tLoss: 3.188055\n",
      "Train Epoch: 6 [94080/697932 (13%)]\tLoss: 3.158540\n",
      "Train Epoch: 6 [94720/697932 (14%)]\tLoss: 3.182044\n",
      "Train Epoch: 6 [95360/697932 (14%)]\tLoss: 3.154691\n",
      "Train Epoch: 6 [96000/697932 (14%)]\tLoss: 3.151390\n",
      "Train Epoch: 6 [96640/697932 (14%)]\tLoss: 3.174471\n",
      "Train Epoch: 6 [97280/697932 (14%)]\tLoss: 3.170508\n",
      "Train Epoch: 6 [97920/697932 (14%)]\tLoss: 3.135739\n",
      "Train Epoch: 6 [98560/697932 (14%)]\tLoss: 3.173229\n",
      "Train Epoch: 6 [99200/697932 (14%)]\tLoss: 3.151435\n",
      "Train Epoch: 6 [99840/697932 (14%)]\tLoss: 3.160612\n",
      "Train Epoch: 6 [100480/697932 (14%)]\tLoss: 3.172913\n",
      "Train Epoch: 6 [101120/697932 (14%)]\tLoss: 3.128172\n",
      "Train Epoch: 6 [101760/697932 (15%)]\tLoss: 3.186016\n",
      "Train Epoch: 6 [102400/697932 (15%)]\tLoss: 3.187742\n",
      "Train Epoch: 6 [103040/697932 (15%)]\tLoss: 3.170084\n",
      "Train Epoch: 6 [103680/697932 (15%)]\tLoss: 3.161304\n",
      "Train Epoch: 6 [104320/697932 (15%)]\tLoss: 3.144723\n",
      "Train Epoch: 6 [104960/697932 (15%)]\tLoss: 3.184966\n",
      "Train Epoch: 6 [105600/697932 (15%)]\tLoss: 3.163959\n",
      "Train Epoch: 6 [106240/697932 (15%)]\tLoss: 3.179163\n",
      "Train Epoch: 6 [106880/697932 (15%)]\tLoss: 3.164444\n",
      "Train Epoch: 6 [107520/697932 (15%)]\tLoss: 3.169565\n",
      "Train Epoch: 6 [108160/697932 (15%)]\tLoss: 3.149468\n",
      "Train Epoch: 6 [108800/697932 (16%)]\tLoss: 3.177778\n",
      "Train Epoch: 6 [109440/697932 (16%)]\tLoss: 3.159869\n",
      "Train Epoch: 6 [110080/697932 (16%)]\tLoss: 3.165763\n",
      "Train Epoch: 6 [110720/697932 (16%)]\tLoss: 3.177893\n",
      "Train Epoch: 6 [111360/697932 (16%)]\tLoss: 3.170120\n",
      "Train Epoch: 6 [112000/697932 (16%)]\tLoss: 3.191193\n",
      "Train Epoch: 6 [112640/697932 (16%)]\tLoss: 3.155670\n",
      "Train Epoch: 6 [113280/697932 (16%)]\tLoss: 3.161972\n",
      "Train Epoch: 6 [113920/697932 (16%)]\tLoss: 3.165750\n",
      "Train Epoch: 6 [114560/697932 (16%)]\tLoss: 3.166584\n",
      "Train Epoch: 6 [115200/697932 (17%)]\tLoss: 3.151406\n",
      "Train Epoch: 6 [115840/697932 (17%)]\tLoss: 3.168561\n",
      "Train Epoch: 6 [116480/697932 (17%)]\tLoss: 3.159501\n",
      "Train Epoch: 6 [117120/697932 (17%)]\tLoss: 3.187720\n",
      "Train Epoch: 6 [117760/697932 (17%)]\tLoss: 3.179438\n",
      "Train Epoch: 6 [118400/697932 (17%)]\tLoss: 3.177373\n",
      "Train Epoch: 6 [119040/697932 (17%)]\tLoss: 3.169214\n",
      "Train Epoch: 6 [119680/697932 (17%)]\tLoss: 3.166382\n",
      "Train Epoch: 6 [120320/697932 (17%)]\tLoss: 3.176433\n",
      "Train Epoch: 6 [120960/697932 (17%)]\tLoss: 3.169080\n",
      "Train Epoch: 6 [121600/697932 (17%)]\tLoss: 3.177404\n",
      "Train Epoch: 6 [122240/697932 (18%)]\tLoss: 3.174513\n",
      "Train Epoch: 6 [122880/697932 (18%)]\tLoss: 3.155601\n",
      "Train Epoch: 6 [123520/697932 (18%)]\tLoss: 3.163489\n",
      "Train Epoch: 6 [124160/697932 (18%)]\tLoss: 3.181354\n",
      "Train Epoch: 6 [124800/697932 (18%)]\tLoss: 3.149392\n",
      "Train Epoch: 6 [125440/697932 (18%)]\tLoss: 3.185743\n",
      "Train Epoch: 6 [126080/697932 (18%)]\tLoss: 3.188554\n",
      "Train Epoch: 6 [126720/697932 (18%)]\tLoss: 3.207979\n",
      "Train Epoch: 6 [127360/697932 (18%)]\tLoss: 3.167252\n",
      "Train Epoch: 6 [128000/697932 (18%)]\tLoss: 3.143149\n",
      "Train Epoch: 6 [128640/697932 (18%)]\tLoss: 3.178334\n",
      "Train Epoch: 6 [129280/697932 (19%)]\tLoss: 3.191856\n",
      "Train Epoch: 6 [129920/697932 (19%)]\tLoss: 3.170523\n",
      "Train Epoch: 6 [130560/697932 (19%)]\tLoss: 3.165324\n",
      "Train Epoch: 6 [131200/697932 (19%)]\tLoss: 3.191532\n",
      "Train Epoch: 6 [131840/697932 (19%)]\tLoss: 3.166283\n",
      "Train Epoch: 6 [132480/697932 (19%)]\tLoss: 3.159980\n",
      "Train Epoch: 6 [133120/697932 (19%)]\tLoss: 3.168892\n",
      "Train Epoch: 6 [133760/697932 (19%)]\tLoss: 3.177551\n",
      "Train Epoch: 6 [134400/697932 (19%)]\tLoss: 3.163531\n",
      "Train Epoch: 6 [135040/697932 (19%)]\tLoss: 3.203199\n",
      "Train Epoch: 6 [135680/697932 (19%)]\tLoss: 3.161674\n",
      "Train Epoch: 6 [136320/697932 (20%)]\tLoss: 3.159189\n",
      "Train Epoch: 6 [136960/697932 (20%)]\tLoss: 3.163116\n",
      "Train Epoch: 6 [137600/697932 (20%)]\tLoss: 3.173098\n",
      "Train Epoch: 6 [138240/697932 (20%)]\tLoss: 3.174896\n",
      "Train Epoch: 6 [138880/697932 (20%)]\tLoss: 3.184968\n",
      "Train Epoch: 6 [139520/697932 (20%)]\tLoss: 3.181015\n",
      "Train Epoch: 6 [140160/697932 (20%)]\tLoss: 3.183219\n",
      "Train Epoch: 6 [140800/697932 (20%)]\tLoss: 3.165581\n",
      "Train Epoch: 6 [141440/697932 (20%)]\tLoss: 3.151600\n",
      "Train Epoch: 6 [142080/697932 (20%)]\tLoss: 3.172000\n",
      "Train Epoch: 6 [142720/697932 (20%)]\tLoss: 3.147088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [143360/697932 (21%)]\tLoss: 3.141268\n",
      "Train Epoch: 6 [144000/697932 (21%)]\tLoss: 3.174965\n",
      "Train Epoch: 6 [144640/697932 (21%)]\tLoss: 3.169376\n",
      "Train Epoch: 6 [145280/697932 (21%)]\tLoss: 3.193427\n",
      "Train Epoch: 6 [145920/697932 (21%)]\tLoss: 3.171893\n",
      "Train Epoch: 6 [146560/697932 (21%)]\tLoss: 3.145022\n",
      "Train Epoch: 6 [147200/697932 (21%)]\tLoss: 3.172341\n",
      "Train Epoch: 6 [147840/697932 (21%)]\tLoss: 3.164587\n",
      "Train Epoch: 6 [148480/697932 (21%)]\tLoss: 3.188916\n",
      "Train Epoch: 6 [149120/697932 (21%)]\tLoss: 3.165345\n",
      "Train Epoch: 6 [149760/697932 (21%)]\tLoss: 3.164299\n",
      "Train Epoch: 6 [150400/697932 (22%)]\tLoss: 3.178779\n",
      "Train Epoch: 6 [151040/697932 (22%)]\tLoss: 3.149874\n",
      "Train Epoch: 6 [151680/697932 (22%)]\tLoss: 3.172269\n",
      "Train Epoch: 6 [152320/697932 (22%)]\tLoss: 3.176740\n",
      "Train Epoch: 6 [152960/697932 (22%)]\tLoss: 3.199972\n",
      "Train Epoch: 6 [153600/697932 (22%)]\tLoss: 3.163527\n",
      "Train Epoch: 6 [154240/697932 (22%)]\tLoss: 3.165664\n",
      "Train Epoch: 6 [154880/697932 (22%)]\tLoss: 3.147896\n",
      "Train Epoch: 6 [155520/697932 (22%)]\tLoss: 3.160768\n",
      "Train Epoch: 6 [156160/697932 (22%)]\tLoss: 3.176833\n",
      "Train Epoch: 6 [156800/697932 (22%)]\tLoss: 3.163855\n",
      "Train Epoch: 6 [157440/697932 (23%)]\tLoss: 3.170360\n",
      "Train Epoch: 6 [158080/697932 (23%)]\tLoss: 3.137955\n",
      "Train Epoch: 6 [158720/697932 (23%)]\tLoss: 3.153019\n",
      "Train Epoch: 6 [159360/697932 (23%)]\tLoss: 3.141168\n",
      "Train Epoch: 6 [160000/697932 (23%)]\tLoss: 3.174962\n",
      "Train Epoch: 6 [160640/697932 (23%)]\tLoss: 3.163424\n",
      "Train Epoch: 6 [161280/697932 (23%)]\tLoss: 3.146967\n",
      "Train Epoch: 6 [161920/697932 (23%)]\tLoss: 3.157552\n",
      "Train Epoch: 6 [162560/697932 (23%)]\tLoss: 3.189241\n",
      "Train Epoch: 6 [163200/697932 (23%)]\tLoss: 3.138609\n",
      "Train Epoch: 6 [163840/697932 (23%)]\tLoss: 3.159366\n",
      "Train Epoch: 6 [164480/697932 (24%)]\tLoss: 3.178278\n",
      "Train Epoch: 6 [165120/697932 (24%)]\tLoss: 3.163477\n",
      "Train Epoch: 6 [165760/697932 (24%)]\tLoss: 3.170324\n",
      "Train Epoch: 6 [166400/697932 (24%)]\tLoss: 3.167451\n",
      "Train Epoch: 6 [167040/697932 (24%)]\tLoss: 3.191500\n",
      "Train Epoch: 6 [167680/697932 (24%)]\tLoss: 3.180477\n",
      "Train Epoch: 6 [168320/697932 (24%)]\tLoss: 3.180386\n",
      "Train Epoch: 6 [168960/697932 (24%)]\tLoss: 3.202442\n",
      "Train Epoch: 6 [169600/697932 (24%)]\tLoss: 3.190371\n",
      "Train Epoch: 6 [170240/697932 (24%)]\tLoss: 3.118138\n",
      "Train Epoch: 6 [170880/697932 (24%)]\tLoss: 3.158911\n",
      "Train Epoch: 6 [171520/697932 (25%)]\tLoss: 3.173001\n",
      "Train Epoch: 6 [172160/697932 (25%)]\tLoss: 3.175416\n",
      "Train Epoch: 6 [172800/697932 (25%)]\tLoss: 3.155001\n",
      "Train Epoch: 6 [173440/697932 (25%)]\tLoss: 3.190634\n",
      "Train Epoch: 6 [174080/697932 (25%)]\tLoss: 3.169788\n",
      "Train Epoch: 6 [174720/697932 (25%)]\tLoss: 3.165549\n",
      "Train Epoch: 6 [175360/697932 (25%)]\tLoss: 3.170341\n",
      "Train Epoch: 6 [176000/697932 (25%)]\tLoss: 3.161238\n",
      "Train Epoch: 6 [176640/697932 (25%)]\tLoss: 3.163081\n",
      "Train Epoch: 6 [177280/697932 (25%)]\tLoss: 3.172885\n",
      "Train Epoch: 6 [177920/697932 (25%)]\tLoss: 3.154837\n",
      "Train Epoch: 6 [178560/697932 (26%)]\tLoss: 3.167385\n",
      "Train Epoch: 6 [179200/697932 (26%)]\tLoss: 3.199005\n",
      "Train Epoch: 6 [179840/697932 (26%)]\tLoss: 3.197162\n",
      "Train Epoch: 6 [180480/697932 (26%)]\tLoss: 3.152434\n",
      "Train Epoch: 6 [181120/697932 (26%)]\tLoss: 3.163523\n",
      "Train Epoch: 6 [181760/697932 (26%)]\tLoss: 3.155487\n",
      "Train Epoch: 6 [182400/697932 (26%)]\tLoss: 3.130837\n",
      "Train Epoch: 6 [183040/697932 (26%)]\tLoss: 3.163910\n",
      "Train Epoch: 6 [183680/697932 (26%)]\tLoss: 3.190388\n",
      "Train Epoch: 6 [184320/697932 (26%)]\tLoss: 3.155344\n",
      "Train Epoch: 6 [184960/697932 (26%)]\tLoss: 3.180282\n",
      "Train Epoch: 6 [185600/697932 (27%)]\tLoss: 3.166458\n",
      "Train Epoch: 6 [186240/697932 (27%)]\tLoss: 3.181807\n",
      "Train Epoch: 6 [186880/697932 (27%)]\tLoss: 3.162661\n",
      "Train Epoch: 6 [187520/697932 (27%)]\tLoss: 3.123127\n",
      "Train Epoch: 6 [188160/697932 (27%)]\tLoss: 3.168238\n",
      "Train Epoch: 6 [188800/697932 (27%)]\tLoss: 3.158037\n",
      "Train Epoch: 6 [189440/697932 (27%)]\tLoss: 3.170775\n",
      "Train Epoch: 6 [190080/697932 (27%)]\tLoss: 3.167918\n",
      "Train Epoch: 6 [190720/697932 (27%)]\tLoss: 3.202764\n",
      "Train Epoch: 6 [191360/697932 (27%)]\tLoss: 3.181259\n",
      "Train Epoch: 6 [192000/697932 (28%)]\tLoss: 3.200845\n",
      "Train Epoch: 6 [192640/697932 (28%)]\tLoss: 3.143720\n",
      "Train Epoch: 6 [193280/697932 (28%)]\tLoss: 3.194210\n",
      "Train Epoch: 6 [193920/697932 (28%)]\tLoss: 3.179409\n",
      "Train Epoch: 6 [194560/697932 (28%)]\tLoss: 3.160234\n",
      "Train Epoch: 6 [195200/697932 (28%)]\tLoss: 3.153454\n",
      "Train Epoch: 6 [195840/697932 (28%)]\tLoss: 3.211830\n",
      "Train Epoch: 6 [196480/697932 (28%)]\tLoss: 3.165366\n",
      "Train Epoch: 6 [197120/697932 (28%)]\tLoss: 3.146744\n",
      "Train Epoch: 6 [197760/697932 (28%)]\tLoss: 3.158589\n",
      "Train Epoch: 6 [198400/697932 (28%)]\tLoss: 3.187684\n",
      "Train Epoch: 6 [199040/697932 (29%)]\tLoss: 3.169106\n",
      "Train Epoch: 6 [199680/697932 (29%)]\tLoss: 3.191519\n",
      "Train Epoch: 6 [200320/697932 (29%)]\tLoss: 3.147550\n",
      "Train Epoch: 6 [200960/697932 (29%)]\tLoss: 3.156911\n",
      "Train Epoch: 6 [201600/697932 (29%)]\tLoss: 3.173891\n",
      "Train Epoch: 6 [202240/697932 (29%)]\tLoss: 3.142935\n",
      "Train Epoch: 6 [202880/697932 (29%)]\tLoss: 3.172429\n",
      "Train Epoch: 6 [203520/697932 (29%)]\tLoss: 3.152229\n",
      "Train Epoch: 6 [204160/697932 (29%)]\tLoss: 3.157183\n",
      "Train Epoch: 6 [204800/697932 (29%)]\tLoss: 3.145104\n",
      "Train Epoch: 6 [205440/697932 (29%)]\tLoss: 3.202569\n",
      "Train Epoch: 6 [206080/697932 (30%)]\tLoss: 3.199133\n",
      "Train Epoch: 6 [206720/697932 (30%)]\tLoss: 3.184600\n",
      "Train Epoch: 6 [207360/697932 (30%)]\tLoss: 3.158432\n",
      "Train Epoch: 6 [208000/697932 (30%)]\tLoss: 3.140891\n",
      "Train Epoch: 6 [208640/697932 (30%)]\tLoss: 3.194452\n",
      "Train Epoch: 6 [209280/697932 (30%)]\tLoss: 3.202885\n",
      "Train Epoch: 6 [209920/697932 (30%)]\tLoss: 3.174397\n",
      "Train Epoch: 6 [210560/697932 (30%)]\tLoss: 3.160432\n",
      "Train Epoch: 6 [211200/697932 (30%)]\tLoss: 3.163337\n",
      "Train Epoch: 6 [211840/697932 (30%)]\tLoss: 3.163274\n",
      "Train Epoch: 6 [212480/697932 (30%)]\tLoss: 3.162498\n",
      "Train Epoch: 6 [213120/697932 (31%)]\tLoss: 3.182958\n",
      "Train Epoch: 6 [213760/697932 (31%)]\tLoss: 3.172847\n",
      "Train Epoch: 6 [214400/697932 (31%)]\tLoss: 3.156479\n",
      "Train Epoch: 6 [215040/697932 (31%)]\tLoss: 3.173507\n",
      "Train Epoch: 6 [215680/697932 (31%)]\tLoss: 3.206115\n",
      "Train Epoch: 6 [216320/697932 (31%)]\tLoss: 3.192994\n",
      "Train Epoch: 6 [216960/697932 (31%)]\tLoss: 3.197469\n",
      "Train Epoch: 6 [217600/697932 (31%)]\tLoss: 3.171958\n",
      "Train Epoch: 6 [218240/697932 (31%)]\tLoss: 3.188596\n",
      "Train Epoch: 6 [218880/697932 (31%)]\tLoss: 3.161089\n",
      "Train Epoch: 6 [219520/697932 (31%)]\tLoss: 3.156942\n",
      "Train Epoch: 6 [220160/697932 (32%)]\tLoss: 3.177364\n",
      "Train Epoch: 6 [220800/697932 (32%)]\tLoss: 3.163418\n",
      "Train Epoch: 6 [221440/697932 (32%)]\tLoss: 3.161350\n",
      "Train Epoch: 6 [222080/697932 (32%)]\tLoss: 3.163141\n",
      "Train Epoch: 6 [222720/697932 (32%)]\tLoss: 3.174764\n",
      "Train Epoch: 6 [223360/697932 (32%)]\tLoss: 3.167886\n",
      "Train Epoch: 6 [224000/697932 (32%)]\tLoss: 3.162087\n",
      "Train Epoch: 6 [224640/697932 (32%)]\tLoss: 3.156606\n",
      "Train Epoch: 6 [225280/697932 (32%)]\tLoss: 3.186234\n",
      "Train Epoch: 6 [225920/697932 (32%)]\tLoss: 3.167214\n",
      "Train Epoch: 6 [226560/697932 (32%)]\tLoss: 3.188066\n",
      "Train Epoch: 6 [227200/697932 (33%)]\tLoss: 3.168920\n",
      "Train Epoch: 6 [227840/697932 (33%)]\tLoss: 3.180838\n",
      "Train Epoch: 6 [228480/697932 (33%)]\tLoss: 3.148361\n",
      "Train Epoch: 6 [229120/697932 (33%)]\tLoss: 3.179231\n",
      "Train Epoch: 6 [229760/697932 (33%)]\tLoss: 3.159118\n",
      "Train Epoch: 6 [230400/697932 (33%)]\tLoss: 3.166889\n",
      "Train Epoch: 6 [231040/697932 (33%)]\tLoss: 3.178292\n",
      "Train Epoch: 6 [231680/697932 (33%)]\tLoss: 3.178473\n",
      "Train Epoch: 6 [232320/697932 (33%)]\tLoss: 3.154584\n",
      "Train Epoch: 6 [232960/697932 (33%)]\tLoss: 3.180724\n",
      "Train Epoch: 6 [233600/697932 (33%)]\tLoss: 3.166073\n",
      "Train Epoch: 6 [234240/697932 (34%)]\tLoss: 3.173423\n",
      "Train Epoch: 6 [234880/697932 (34%)]\tLoss: 3.141735\n",
      "Train Epoch: 6 [235520/697932 (34%)]\tLoss: 3.151763\n",
      "Train Epoch: 6 [236160/697932 (34%)]\tLoss: 3.177552\n",
      "Train Epoch: 6 [236800/697932 (34%)]\tLoss: 3.149960\n",
      "Train Epoch: 6 [237440/697932 (34%)]\tLoss: 3.157940\n",
      "Train Epoch: 6 [238080/697932 (34%)]\tLoss: 3.180423\n",
      "Train Epoch: 6 [238720/697932 (34%)]\tLoss: 3.167798\n",
      "Train Epoch: 6 [239360/697932 (34%)]\tLoss: 3.171669\n",
      "Train Epoch: 6 [240000/697932 (34%)]\tLoss: 3.140850\n",
      "Train Epoch: 6 [240640/697932 (34%)]\tLoss: 3.188468\n",
      "Train Epoch: 6 [241280/697932 (35%)]\tLoss: 3.191389\n",
      "Train Epoch: 6 [241920/697932 (35%)]\tLoss: 3.181618\n",
      "Train Epoch: 6 [242560/697932 (35%)]\tLoss: 3.170696\n",
      "Train Epoch: 6 [243200/697932 (35%)]\tLoss: 3.157580\n",
      "Train Epoch: 6 [243840/697932 (35%)]\tLoss: 3.170371\n",
      "Train Epoch: 6 [244480/697932 (35%)]\tLoss: 3.191936\n",
      "Train Epoch: 6 [245120/697932 (35%)]\tLoss: 3.141583\n",
      "Train Epoch: 6 [245760/697932 (35%)]\tLoss: 3.175736\n",
      "Train Epoch: 6 [246400/697932 (35%)]\tLoss: 3.168197\n",
      "Train Epoch: 6 [247040/697932 (35%)]\tLoss: 3.162686\n",
      "Train Epoch: 6 [247680/697932 (35%)]\tLoss: 3.166962\n",
      "Train Epoch: 6 [248320/697932 (36%)]\tLoss: 3.174376\n",
      "Train Epoch: 6 [248960/697932 (36%)]\tLoss: 3.165351\n",
      "Train Epoch: 6 [249600/697932 (36%)]\tLoss: 3.169445\n",
      "Train Epoch: 6 [250240/697932 (36%)]\tLoss: 3.160265\n",
      "Train Epoch: 6 [250880/697932 (36%)]\tLoss: 3.136426\n",
      "Train Epoch: 6 [251520/697932 (36%)]\tLoss: 3.163682\n",
      "Train Epoch: 6 [252160/697932 (36%)]\tLoss: 3.168538\n",
      "Train Epoch: 6 [252800/697932 (36%)]\tLoss: 3.158833\n",
      "Train Epoch: 6 [253440/697932 (36%)]\tLoss: 3.160519\n",
      "Train Epoch: 6 [254080/697932 (36%)]\tLoss: 3.199789\n",
      "Train Epoch: 6 [254720/697932 (36%)]\tLoss: 3.159460\n",
      "Train Epoch: 6 [255360/697932 (37%)]\tLoss: 3.173698\n",
      "Train Epoch: 6 [256000/697932 (37%)]\tLoss: 3.132296\n",
      "Train Epoch: 6 [256640/697932 (37%)]\tLoss: 3.162765\n",
      "Train Epoch: 6 [257280/697932 (37%)]\tLoss: 3.150986\n",
      "Train Epoch: 6 [257920/697932 (37%)]\tLoss: 3.161449\n",
      "Train Epoch: 6 [258560/697932 (37%)]\tLoss: 3.163600\n",
      "Train Epoch: 6 [259200/697932 (37%)]\tLoss: 3.151389\n",
      "Train Epoch: 6 [259840/697932 (37%)]\tLoss: 3.174562\n",
      "Train Epoch: 6 [260480/697932 (37%)]\tLoss: 3.171117\n",
      "Train Epoch: 6 [261120/697932 (37%)]\tLoss: 3.181979\n",
      "Train Epoch: 6 [261760/697932 (38%)]\tLoss: 3.180269\n",
      "Train Epoch: 6 [262400/697932 (38%)]\tLoss: 3.163919\n",
      "Train Epoch: 6 [263040/697932 (38%)]\tLoss: 3.183907\n",
      "Train Epoch: 6 [263680/697932 (38%)]\tLoss: 3.180549\n",
      "Train Epoch: 6 [264320/697932 (38%)]\tLoss: 3.165023\n",
      "Train Epoch: 6 [264960/697932 (38%)]\tLoss: 3.153705\n",
      "Train Epoch: 6 [265600/697932 (38%)]\tLoss: 3.151089\n",
      "Train Epoch: 6 [266240/697932 (38%)]\tLoss: 3.206912\n",
      "Train Epoch: 6 [266880/697932 (38%)]\tLoss: 3.196275\n",
      "Train Epoch: 6 [267520/697932 (38%)]\tLoss: 3.137920\n",
      "Train Epoch: 6 [268160/697932 (38%)]\tLoss: 3.159920\n",
      "Train Epoch: 6 [268800/697932 (39%)]\tLoss: 3.190023\n",
      "Train Epoch: 6 [269440/697932 (39%)]\tLoss: 3.180459\n",
      "Train Epoch: 6 [270080/697932 (39%)]\tLoss: 3.169565\n",
      "Train Epoch: 6 [270720/697932 (39%)]\tLoss: 3.150253\n",
      "Train Epoch: 6 [271360/697932 (39%)]\tLoss: 3.140136\n",
      "Train Epoch: 6 [272000/697932 (39%)]\tLoss: 3.188934\n",
      "Train Epoch: 6 [272640/697932 (39%)]\tLoss: 3.157604\n",
      "Train Epoch: 6 [273280/697932 (39%)]\tLoss: 3.161993\n",
      "Train Epoch: 6 [273920/697932 (39%)]\tLoss: 3.189275\n",
      "Train Epoch: 6 [274560/697932 (39%)]\tLoss: 3.149327\n",
      "Train Epoch: 6 [275200/697932 (39%)]\tLoss: 3.158791\n",
      "Train Epoch: 6 [275840/697932 (40%)]\tLoss: 3.173432\n",
      "Train Epoch: 6 [276480/697932 (40%)]\tLoss: 3.198157\n",
      "Train Epoch: 6 [277120/697932 (40%)]\tLoss: 3.174711\n",
      "Train Epoch: 6 [277760/697932 (40%)]\tLoss: 3.177901\n",
      "Train Epoch: 6 [278400/697932 (40%)]\tLoss: 3.183605\n",
      "Train Epoch: 6 [279040/697932 (40%)]\tLoss: 3.180526\n",
      "Train Epoch: 6 [279680/697932 (40%)]\tLoss: 3.161137\n",
      "Train Epoch: 6 [280320/697932 (40%)]\tLoss: 3.198846\n",
      "Train Epoch: 6 [280960/697932 (40%)]\tLoss: 3.182923\n",
      "Train Epoch: 6 [281600/697932 (40%)]\tLoss: 3.164019\n",
      "Train Epoch: 6 [282240/697932 (40%)]\tLoss: 3.167819\n",
      "Train Epoch: 6 [282880/697932 (41%)]\tLoss: 3.157837\n",
      "Train Epoch: 6 [283520/697932 (41%)]\tLoss: 3.169241\n",
      "Train Epoch: 6 [284160/697932 (41%)]\tLoss: 3.139104\n",
      "Train Epoch: 6 [284800/697932 (41%)]\tLoss: 3.150975\n",
      "Train Epoch: 6 [285440/697932 (41%)]\tLoss: 3.167768\n",
      "Train Epoch: 6 [286080/697932 (41%)]\tLoss: 3.191832\n",
      "Train Epoch: 6 [286720/697932 (41%)]\tLoss: 3.166626\n",
      "Train Epoch: 6 [287360/697932 (41%)]\tLoss: 3.156378\n",
      "Train Epoch: 6 [288000/697932 (41%)]\tLoss: 3.157573\n",
      "Train Epoch: 6 [288640/697932 (41%)]\tLoss: 3.140290\n",
      "Train Epoch: 6 [289280/697932 (41%)]\tLoss: 3.162067\n",
      "Train Epoch: 6 [289920/697932 (42%)]\tLoss: 3.199068\n",
      "Train Epoch: 6 [290560/697932 (42%)]\tLoss: 3.165655\n",
      "Train Epoch: 6 [291200/697932 (42%)]\tLoss: 3.174592\n",
      "Train Epoch: 6 [291840/697932 (42%)]\tLoss: 3.171636\n",
      "Train Epoch: 6 [292480/697932 (42%)]\tLoss: 3.169893\n",
      "Train Epoch: 6 [293120/697932 (42%)]\tLoss: 3.175709\n",
      "Train Epoch: 6 [293760/697932 (42%)]\tLoss: 3.167451\n",
      "Train Epoch: 6 [294400/697932 (42%)]\tLoss: 3.165384\n",
      "Train Epoch: 6 [295040/697932 (42%)]\tLoss: 3.174011\n",
      "Train Epoch: 6 [295680/697932 (42%)]\tLoss: 3.151457\n",
      "Train Epoch: 6 [296320/697932 (42%)]\tLoss: 3.184682\n",
      "Train Epoch: 6 [296960/697932 (43%)]\tLoss: 3.173288\n",
      "Train Epoch: 6 [297600/697932 (43%)]\tLoss: 3.174294\n",
      "Train Epoch: 6 [298240/697932 (43%)]\tLoss: 3.175752\n",
      "Train Epoch: 6 [298880/697932 (43%)]\tLoss: 3.165832\n",
      "Train Epoch: 6 [299520/697932 (43%)]\tLoss: 3.175829\n",
      "Train Epoch: 6 [300160/697932 (43%)]\tLoss: 3.157534\n",
      "Train Epoch: 6 [300800/697932 (43%)]\tLoss: 3.159998\n",
      "Train Epoch: 6 [301440/697932 (43%)]\tLoss: 3.176557\n",
      "Train Epoch: 6 [302080/697932 (43%)]\tLoss: 3.162811\n",
      "Train Epoch: 6 [302720/697932 (43%)]\tLoss: 3.158856\n",
      "Train Epoch: 6 [303360/697932 (43%)]\tLoss: 3.151394\n",
      "Train Epoch: 6 [304000/697932 (44%)]\tLoss: 3.185726\n",
      "Train Epoch: 6 [304640/697932 (44%)]\tLoss: 3.163320\n",
      "Train Epoch: 6 [305280/697932 (44%)]\tLoss: 3.142002\n",
      "Train Epoch: 6 [305920/697932 (44%)]\tLoss: 3.166935\n",
      "Train Epoch: 6 [306560/697932 (44%)]\tLoss: 3.170822\n",
      "Train Epoch: 6 [307200/697932 (44%)]\tLoss: 3.172193\n",
      "Train Epoch: 6 [307840/697932 (44%)]\tLoss: 3.193383\n",
      "Train Epoch: 6 [308480/697932 (44%)]\tLoss: 3.162320\n",
      "Train Epoch: 6 [309120/697932 (44%)]\tLoss: 3.163312\n",
      "Train Epoch: 6 [309760/697932 (44%)]\tLoss: 3.164722\n",
      "Train Epoch: 6 [310400/697932 (44%)]\tLoss: 3.154456\n",
      "Train Epoch: 6 [311040/697932 (45%)]\tLoss: 3.173388\n",
      "Train Epoch: 6 [311680/697932 (45%)]\tLoss: 3.175835\n",
      "Train Epoch: 6 [312320/697932 (45%)]\tLoss: 3.168373\n",
      "Train Epoch: 6 [312960/697932 (45%)]\tLoss: 3.156662\n",
      "Train Epoch: 6 [313600/697932 (45%)]\tLoss: 3.189479\n",
      "Train Epoch: 6 [314240/697932 (45%)]\tLoss: 3.141769\n",
      "Train Epoch: 6 [314880/697932 (45%)]\tLoss: 3.200951\n",
      "Train Epoch: 6 [315520/697932 (45%)]\tLoss: 3.159076\n",
      "Train Epoch: 6 [316160/697932 (45%)]\tLoss: 3.154177\n",
      "Train Epoch: 6 [316800/697932 (45%)]\tLoss: 3.181266\n",
      "Train Epoch: 6 [317440/697932 (45%)]\tLoss: 3.149244\n",
      "Train Epoch: 6 [318080/697932 (46%)]\tLoss: 3.194982\n",
      "Train Epoch: 6 [318720/697932 (46%)]\tLoss: 3.150687\n",
      "Train Epoch: 6 [319360/697932 (46%)]\tLoss: 3.161415\n",
      "Train Epoch: 6 [320000/697932 (46%)]\tLoss: 3.151100\n",
      "Train Epoch: 6 [320640/697932 (46%)]\tLoss: 3.163779\n",
      "Train Epoch: 6 [321280/697932 (46%)]\tLoss: 3.144176\n",
      "Train Epoch: 6 [321920/697932 (46%)]\tLoss: 3.158552\n",
      "Train Epoch: 6 [322560/697932 (46%)]\tLoss: 3.160000\n",
      "Train Epoch: 6 [323200/697932 (46%)]\tLoss: 3.178122\n",
      "Train Epoch: 6 [323840/697932 (46%)]\tLoss: 3.183575\n",
      "Train Epoch: 6 [324480/697932 (46%)]\tLoss: 3.163505\n",
      "Train Epoch: 6 [325120/697932 (47%)]\tLoss: 3.151755\n",
      "Train Epoch: 6 [325760/697932 (47%)]\tLoss: 3.163917\n",
      "Train Epoch: 6 [326400/697932 (47%)]\tLoss: 3.155135\n",
      "Train Epoch: 6 [327040/697932 (47%)]\tLoss: 3.179033\n",
      "Train Epoch: 6 [327680/697932 (47%)]\tLoss: 3.138967\n",
      "Train Epoch: 6 [328320/697932 (47%)]\tLoss: 3.176565\n",
      "Train Epoch: 6 [328960/697932 (47%)]\tLoss: 3.198909\n",
      "Train Epoch: 6 [329600/697932 (47%)]\tLoss: 3.195031\n",
      "Train Epoch: 6 [330240/697932 (47%)]\tLoss: 3.198465\n",
      "Train Epoch: 6 [330880/697932 (47%)]\tLoss: 3.184204\n",
      "Train Epoch: 6 [331520/697932 (47%)]\tLoss: 3.139597\n",
      "Train Epoch: 6 [332160/697932 (48%)]\tLoss: 3.175371\n",
      "Train Epoch: 6 [332800/697932 (48%)]\tLoss: 3.161884\n",
      "Train Epoch: 6 [333440/697932 (48%)]\tLoss: 3.185113\n",
      "Train Epoch: 6 [334080/697932 (48%)]\tLoss: 3.158924\n",
      "Train Epoch: 6 [334720/697932 (48%)]\tLoss: 3.193982\n",
      "Train Epoch: 6 [335360/697932 (48%)]\tLoss: 3.167436\n",
      "Train Epoch: 6 [336000/697932 (48%)]\tLoss: 3.153810\n",
      "Train Epoch: 6 [336640/697932 (48%)]\tLoss: 3.187091\n",
      "Train Epoch: 6 [337280/697932 (48%)]\tLoss: 3.164923\n",
      "Train Epoch: 6 [337920/697932 (48%)]\tLoss: 3.164694\n",
      "Train Epoch: 6 [338560/697932 (49%)]\tLoss: 3.163005\n",
      "Train Epoch: 6 [339200/697932 (49%)]\tLoss: 3.172942\n",
      "Train Epoch: 6 [339840/697932 (49%)]\tLoss: 3.164581\n",
      "Train Epoch: 6 [340480/697932 (49%)]\tLoss: 3.162630\n",
      "Train Epoch: 6 [341120/697932 (49%)]\tLoss: 3.159241\n",
      "Train Epoch: 6 [341760/697932 (49%)]\tLoss: 3.139935\n",
      "Train Epoch: 6 [342400/697932 (49%)]\tLoss: 3.134641\n",
      "Train Epoch: 6 [343040/697932 (49%)]\tLoss: 3.183300\n",
      "Train Epoch: 6 [343680/697932 (49%)]\tLoss: 3.146618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [344320/697932 (49%)]\tLoss: 3.176427\n",
      "Train Epoch: 6 [344960/697932 (49%)]\tLoss: 3.187715\n",
      "Train Epoch: 6 [345600/697932 (50%)]\tLoss: 3.197525\n",
      "Train Epoch: 6 [346240/697932 (50%)]\tLoss: 3.165967\n",
      "Train Epoch: 6 [346880/697932 (50%)]\tLoss: 3.166527\n",
      "Train Epoch: 6 [347520/697932 (50%)]\tLoss: 3.146666\n",
      "Train Epoch: 6 [348160/697932 (50%)]\tLoss: 3.152901\n",
      "Train Epoch: 6 [348800/697932 (50%)]\tLoss: 3.175231\n",
      "Train Epoch: 6 [349440/697932 (50%)]\tLoss: 3.182865\n",
      "Train Epoch: 6 [350080/697932 (50%)]\tLoss: 3.179209\n",
      "Train Epoch: 6 [350720/697932 (50%)]\tLoss: 3.181781\n",
      "Train Epoch: 6 [351360/697932 (50%)]\tLoss: 3.149342\n",
      "Train Epoch: 6 [352000/697932 (50%)]\tLoss: 3.147755\n",
      "Train Epoch: 6 [352640/697932 (51%)]\tLoss: 3.151188\n",
      "Train Epoch: 6 [353280/697932 (51%)]\tLoss: 3.168703\n",
      "Train Epoch: 6 [353920/697932 (51%)]\tLoss: 3.158497\n",
      "Train Epoch: 6 [354560/697932 (51%)]\tLoss: 3.174501\n",
      "Train Epoch: 6 [355200/697932 (51%)]\tLoss: 3.165158\n",
      "Train Epoch: 6 [355840/697932 (51%)]\tLoss: 3.187042\n",
      "Train Epoch: 6 [356480/697932 (51%)]\tLoss: 3.162421\n",
      "Train Epoch: 6 [357120/697932 (51%)]\tLoss: 3.153265\n",
      "Train Epoch: 6 [357760/697932 (51%)]\tLoss: 3.144807\n",
      "Train Epoch: 6 [358400/697932 (51%)]\tLoss: 3.178300\n",
      "Train Epoch: 6 [359040/697932 (51%)]\tLoss: 3.164429\n",
      "Train Epoch: 6 [359680/697932 (52%)]\tLoss: 3.174509\n",
      "Train Epoch: 6 [360320/697932 (52%)]\tLoss: 3.172396\n",
      "Train Epoch: 6 [360960/697932 (52%)]\tLoss: 3.174962\n",
      "Train Epoch: 6 [361600/697932 (52%)]\tLoss: 3.156076\n",
      "Train Epoch: 6 [362240/697932 (52%)]\tLoss: 3.147673\n",
      "Train Epoch: 6 [362880/697932 (52%)]\tLoss: 3.197202\n",
      "Train Epoch: 6 [363520/697932 (52%)]\tLoss: 3.160845\n",
      "Train Epoch: 6 [364160/697932 (52%)]\tLoss: 3.160950\n",
      "Train Epoch: 6 [364800/697932 (52%)]\tLoss: 3.168277\n",
      "Train Epoch: 6 [365440/697932 (52%)]\tLoss: 3.172127\n",
      "Train Epoch: 6 [366080/697932 (52%)]\tLoss: 3.141285\n",
      "Train Epoch: 6 [366720/697932 (53%)]\tLoss: 3.168211\n",
      "Train Epoch: 6 [367360/697932 (53%)]\tLoss: 3.157174\n",
      "Train Epoch: 6 [368000/697932 (53%)]\tLoss: 3.182328\n",
      "Train Epoch: 6 [368640/697932 (53%)]\tLoss: 3.152531\n",
      "Train Epoch: 6 [369280/697932 (53%)]\tLoss: 3.187778\n",
      "Train Epoch: 6 [369920/697932 (53%)]\tLoss: 3.170581\n",
      "Train Epoch: 6 [370560/697932 (53%)]\tLoss: 3.154938\n",
      "Train Epoch: 6 [371200/697932 (53%)]\tLoss: 3.173276\n",
      "Train Epoch: 6 [371840/697932 (53%)]\tLoss: 3.147528\n",
      "Train Epoch: 6 [372480/697932 (53%)]\tLoss: 3.183888\n",
      "Train Epoch: 6 [373120/697932 (53%)]\tLoss: 3.190737\n",
      "Train Epoch: 6 [373760/697932 (54%)]\tLoss: 3.148608\n",
      "Train Epoch: 6 [374400/697932 (54%)]\tLoss: 3.144918\n",
      "Train Epoch: 6 [375040/697932 (54%)]\tLoss: 3.150646\n",
      "Train Epoch: 6 [375680/697932 (54%)]\tLoss: 3.170702\n",
      "Train Epoch: 6 [376320/697932 (54%)]\tLoss: 3.186251\n",
      "Train Epoch: 6 [376960/697932 (54%)]\tLoss: 3.163373\n",
      "Train Epoch: 6 [377600/697932 (54%)]\tLoss: 3.161724\n",
      "Train Epoch: 6 [378240/697932 (54%)]\tLoss: 3.169012\n",
      "Train Epoch: 6 [378880/697932 (54%)]\tLoss: 3.140661\n",
      "Train Epoch: 6 [379520/697932 (54%)]\tLoss: 3.182022\n",
      "Train Epoch: 6 [380160/697932 (54%)]\tLoss: 3.148783\n",
      "Train Epoch: 6 [380800/697932 (55%)]\tLoss: 3.195204\n",
      "Train Epoch: 6 [381440/697932 (55%)]\tLoss: 3.151036\n",
      "Train Epoch: 6 [382080/697932 (55%)]\tLoss: 3.184112\n",
      "Train Epoch: 6 [382720/697932 (55%)]\tLoss: 3.143139\n",
      "Train Epoch: 6 [383360/697932 (55%)]\tLoss: 3.171427\n",
      "Train Epoch: 6 [384000/697932 (55%)]\tLoss: 3.168226\n",
      "Train Epoch: 6 [384640/697932 (55%)]\tLoss: 3.175132\n",
      "Train Epoch: 6 [385280/697932 (55%)]\tLoss: 3.167364\n",
      "Train Epoch: 6 [385920/697932 (55%)]\tLoss: 3.159714\n",
      "Train Epoch: 6 [386560/697932 (55%)]\tLoss: 3.169706\n",
      "Train Epoch: 6 [387200/697932 (55%)]\tLoss: 3.145046\n",
      "Train Epoch: 6 [387840/697932 (56%)]\tLoss: 3.170022\n",
      "Train Epoch: 6 [388480/697932 (56%)]\tLoss: 3.168526\n",
      "Train Epoch: 6 [389120/697932 (56%)]\tLoss: 3.194350\n",
      "Train Epoch: 6 [389760/697932 (56%)]\tLoss: 3.166032\n",
      "Train Epoch: 6 [390400/697932 (56%)]\tLoss: 3.152814\n",
      "Train Epoch: 6 [391040/697932 (56%)]\tLoss: 3.176385\n",
      "Train Epoch: 6 [391680/697932 (56%)]\tLoss: 3.149051\n",
      "Train Epoch: 6 [392320/697932 (56%)]\tLoss: 3.141770\n",
      "Train Epoch: 6 [392960/697932 (56%)]\tLoss: 3.195815\n",
      "Train Epoch: 6 [393600/697932 (56%)]\tLoss: 3.166928\n",
      "Train Epoch: 6 [394240/697932 (56%)]\tLoss: 3.174103\n",
      "Train Epoch: 6 [394880/697932 (57%)]\tLoss: 3.164201\n",
      "Train Epoch: 6 [395520/697932 (57%)]\tLoss: 3.159328\n",
      "Train Epoch: 6 [396160/697932 (57%)]\tLoss: 3.197687\n",
      "Train Epoch: 6 [396800/697932 (57%)]\tLoss: 3.185421\n",
      "Train Epoch: 6 [397440/697932 (57%)]\tLoss: 3.178793\n",
      "Train Epoch: 6 [398080/697932 (57%)]\tLoss: 3.172439\n",
      "Train Epoch: 6 [398720/697932 (57%)]\tLoss: 3.152335\n",
      "Train Epoch: 6 [399360/697932 (57%)]\tLoss: 3.175627\n",
      "Train Epoch: 6 [400000/697932 (57%)]\tLoss: 3.161140\n",
      "Train Epoch: 6 [400640/697932 (57%)]\tLoss: 3.185384\n",
      "Train Epoch: 6 [401280/697932 (57%)]\tLoss: 3.189861\n",
      "Train Epoch: 6 [401920/697932 (58%)]\tLoss: 3.159275\n",
      "Train Epoch: 6 [402560/697932 (58%)]\tLoss: 3.188756\n",
      "Train Epoch: 6 [403200/697932 (58%)]\tLoss: 3.188738\n",
      "Train Epoch: 6 [403840/697932 (58%)]\tLoss: 3.197805\n",
      "Train Epoch: 6 [404480/697932 (58%)]\tLoss: 3.172422\n",
      "Train Epoch: 6 [405120/697932 (58%)]\tLoss: 3.152310\n",
      "Train Epoch: 6 [405760/697932 (58%)]\tLoss: 3.175033\n",
      "Train Epoch: 6 [406400/697932 (58%)]\tLoss: 3.169987\n",
      "Train Epoch: 6 [407040/697932 (58%)]\tLoss: 3.145490\n",
      "Train Epoch: 6 [407680/697932 (58%)]\tLoss: 3.145095\n",
      "Train Epoch: 6 [408320/697932 (58%)]\tLoss: 3.170102\n",
      "Train Epoch: 6 [408960/697932 (59%)]\tLoss: 3.163366\n",
      "Train Epoch: 6 [409600/697932 (59%)]\tLoss: 3.134030\n",
      "Train Epoch: 6 [410240/697932 (59%)]\tLoss: 3.145668\n",
      "Train Epoch: 6 [410880/697932 (59%)]\tLoss: 3.177926\n",
      "Train Epoch: 6 [411520/697932 (59%)]\tLoss: 3.171488\n",
      "Train Epoch: 6 [412160/697932 (59%)]\tLoss: 3.166762\n",
      "Train Epoch: 6 [412800/697932 (59%)]\tLoss: 3.197870\n",
      "Train Epoch: 6 [413440/697932 (59%)]\tLoss: 3.171509\n",
      "Train Epoch: 6 [414080/697932 (59%)]\tLoss: 3.178964\n",
      "Train Epoch: 6 [414720/697932 (59%)]\tLoss: 3.174420\n",
      "Train Epoch: 6 [415360/697932 (60%)]\tLoss: 3.170436\n",
      "Train Epoch: 6 [416000/697932 (60%)]\tLoss: 3.158758\n",
      "Train Epoch: 6 [416640/697932 (60%)]\tLoss: 3.165172\n",
      "Train Epoch: 6 [417280/697932 (60%)]\tLoss: 3.167072\n",
      "Train Epoch: 6 [417920/697932 (60%)]\tLoss: 3.185251\n",
      "Train Epoch: 6 [418560/697932 (60%)]\tLoss: 3.183123\n",
      "Train Epoch: 6 [419200/697932 (60%)]\tLoss: 3.135146\n",
      "Train Epoch: 6 [419840/697932 (60%)]\tLoss: 3.173311\n",
      "Train Epoch: 6 [420480/697932 (60%)]\tLoss: 3.177112\n",
      "Train Epoch: 6 [421120/697932 (60%)]\tLoss: 3.162525\n",
      "Train Epoch: 6 [421760/697932 (60%)]\tLoss: 3.192830\n",
      "Train Epoch: 6 [422400/697932 (61%)]\tLoss: 3.174404\n",
      "Train Epoch: 6 [423040/697932 (61%)]\tLoss: 3.172037\n",
      "Train Epoch: 6 [423680/697932 (61%)]\tLoss: 3.180480\n",
      "Train Epoch: 6 [424320/697932 (61%)]\tLoss: 3.149824\n",
      "Train Epoch: 6 [424960/697932 (61%)]\tLoss: 3.143951\n",
      "Train Epoch: 6 [425600/697932 (61%)]\tLoss: 3.151387\n",
      "Train Epoch: 6 [426240/697932 (61%)]\tLoss: 3.175889\n",
      "Train Epoch: 6 [426880/697932 (61%)]\tLoss: 3.157171\n",
      "Train Epoch: 6 [427520/697932 (61%)]\tLoss: 3.175134\n",
      "Train Epoch: 6 [428160/697932 (61%)]\tLoss: 3.164328\n",
      "Train Epoch: 6 [428800/697932 (61%)]\tLoss: 3.159732\n",
      "Train Epoch: 6 [429440/697932 (62%)]\tLoss: 3.174028\n",
      "Train Epoch: 6 [430080/697932 (62%)]\tLoss: 3.188247\n",
      "Train Epoch: 6 [430720/697932 (62%)]\tLoss: 3.164701\n",
      "Train Epoch: 6 [431360/697932 (62%)]\tLoss: 3.171524\n",
      "Train Epoch: 6 [432000/697932 (62%)]\tLoss: 3.187328\n",
      "Train Epoch: 6 [432640/697932 (62%)]\tLoss: 3.178307\n",
      "Train Epoch: 6 [433280/697932 (62%)]\tLoss: 3.172693\n",
      "Train Epoch: 6 [433920/697932 (62%)]\tLoss: 3.180926\n",
      "Train Epoch: 6 [434560/697932 (62%)]\tLoss: 3.170898\n",
      "Train Epoch: 6 [435200/697932 (62%)]\tLoss: 3.181246\n",
      "Train Epoch: 6 [435840/697932 (62%)]\tLoss: 3.181939\n",
      "Train Epoch: 6 [436480/697932 (63%)]\tLoss: 3.170909\n",
      "Train Epoch: 6 [437120/697932 (63%)]\tLoss: 3.163276\n",
      "Train Epoch: 6 [437760/697932 (63%)]\tLoss: 3.163936\n",
      "Train Epoch: 6 [438400/697932 (63%)]\tLoss: 3.167998\n",
      "Train Epoch: 6 [439040/697932 (63%)]\tLoss: 3.145657\n",
      "Train Epoch: 6 [439680/697932 (63%)]\tLoss: 3.162280\n",
      "Train Epoch: 6 [440320/697932 (63%)]\tLoss: 3.182092\n",
      "Train Epoch: 6 [440960/697932 (63%)]\tLoss: 3.174922\n",
      "Train Epoch: 6 [441600/697932 (63%)]\tLoss: 3.177081\n",
      "Train Epoch: 6 [442240/697932 (63%)]\tLoss: 3.153516\n",
      "Train Epoch: 6 [442880/697932 (63%)]\tLoss: 3.189859\n",
      "Train Epoch: 6 [443520/697932 (64%)]\tLoss: 3.195924\n",
      "Train Epoch: 6 [444160/697932 (64%)]\tLoss: 3.152948\n",
      "Train Epoch: 6 [444800/697932 (64%)]\tLoss: 3.164611\n",
      "Train Epoch: 6 [445440/697932 (64%)]\tLoss: 3.167659\n",
      "Train Epoch: 6 [446080/697932 (64%)]\tLoss: 3.189685\n",
      "Train Epoch: 6 [446720/697932 (64%)]\tLoss: 3.158407\n",
      "Train Epoch: 6 [447360/697932 (64%)]\tLoss: 3.173464\n",
      "Train Epoch: 6 [448000/697932 (64%)]\tLoss: 3.159952\n",
      "Train Epoch: 6 [448640/697932 (64%)]\tLoss: 3.157746\n",
      "Train Epoch: 6 [449280/697932 (64%)]\tLoss: 3.161524\n",
      "Train Epoch: 6 [449920/697932 (64%)]\tLoss: 3.181163\n",
      "Train Epoch: 6 [450560/697932 (65%)]\tLoss: 3.150352\n",
      "Train Epoch: 6 [451200/697932 (65%)]\tLoss: 3.164740\n",
      "Train Epoch: 6 [451840/697932 (65%)]\tLoss: 3.161071\n",
      "Train Epoch: 6 [452480/697932 (65%)]\tLoss: 3.169647\n",
      "Train Epoch: 6 [453120/697932 (65%)]\tLoss: 3.179964\n",
      "Train Epoch: 6 [453760/697932 (65%)]\tLoss: 3.164857\n",
      "Train Epoch: 6 [454400/697932 (65%)]\tLoss: 3.189631\n",
      "Train Epoch: 6 [455040/697932 (65%)]\tLoss: 3.167678\n",
      "Train Epoch: 6 [455680/697932 (65%)]\tLoss: 3.211376\n",
      "Train Epoch: 6 [456320/697932 (65%)]\tLoss: 3.167411\n",
      "Train Epoch: 6 [456960/697932 (65%)]\tLoss: 3.171330\n",
      "Train Epoch: 6 [457600/697932 (66%)]\tLoss: 3.152032\n",
      "Train Epoch: 6 [458240/697932 (66%)]\tLoss: 3.160701\n",
      "Train Epoch: 6 [458880/697932 (66%)]\tLoss: 3.159919\n",
      "Train Epoch: 6 [459520/697932 (66%)]\tLoss: 3.163234\n",
      "Train Epoch: 6 [460160/697932 (66%)]\tLoss: 3.171051\n",
      "Train Epoch: 6 [460800/697932 (66%)]\tLoss: 3.168148\n",
      "Train Epoch: 6 [461440/697932 (66%)]\tLoss: 3.178524\n",
      "Train Epoch: 6 [462080/697932 (66%)]\tLoss: 3.171869\n",
      "Train Epoch: 6 [462720/697932 (66%)]\tLoss: 3.162183\n",
      "Train Epoch: 6 [463360/697932 (66%)]\tLoss: 3.175707\n",
      "Train Epoch: 6 [464000/697932 (66%)]\tLoss: 3.154158\n",
      "Train Epoch: 6 [464640/697932 (67%)]\tLoss: 3.173451\n",
      "Train Epoch: 6 [465280/697932 (67%)]\tLoss: 3.185259\n",
      "Train Epoch: 6 [465920/697932 (67%)]\tLoss: 3.176539\n",
      "Train Epoch: 6 [466560/697932 (67%)]\tLoss: 3.166573\n",
      "Train Epoch: 6 [467200/697932 (67%)]\tLoss: 3.180147\n",
      "Train Epoch: 6 [467840/697932 (67%)]\tLoss: 3.157456\n",
      "Train Epoch: 6 [468480/697932 (67%)]\tLoss: 3.182824\n",
      "Train Epoch: 6 [469120/697932 (67%)]\tLoss: 3.127082\n",
      "Train Epoch: 6 [469760/697932 (67%)]\tLoss: 3.155235\n",
      "Train Epoch: 6 [470400/697932 (67%)]\tLoss: 3.167187\n",
      "Train Epoch: 6 [471040/697932 (67%)]\tLoss: 3.177369\n",
      "Train Epoch: 6 [471680/697932 (68%)]\tLoss: 3.180492\n",
      "Train Epoch: 6 [472320/697932 (68%)]\tLoss: 3.179065\n",
      "Train Epoch: 6 [472960/697932 (68%)]\tLoss: 3.171375\n",
      "Train Epoch: 6 [473600/697932 (68%)]\tLoss: 3.156701\n",
      "Train Epoch: 6 [474240/697932 (68%)]\tLoss: 3.181030\n",
      "Train Epoch: 6 [474880/697932 (68%)]\tLoss: 3.155993\n",
      "Train Epoch: 6 [475520/697932 (68%)]\tLoss: 3.176258\n",
      "Train Epoch: 6 [476160/697932 (68%)]\tLoss: 3.145647\n",
      "Train Epoch: 6 [476800/697932 (68%)]\tLoss: 3.187431\n",
      "Train Epoch: 6 [477440/697932 (68%)]\tLoss: 3.169087\n",
      "Train Epoch: 6 [478080/697932 (68%)]\tLoss: 3.163126\n",
      "Train Epoch: 6 [478720/697932 (69%)]\tLoss: 3.154833\n",
      "Train Epoch: 6 [479360/697932 (69%)]\tLoss: 3.135005\n",
      "Train Epoch: 6 [480000/697932 (69%)]\tLoss: 3.171540\n",
      "Train Epoch: 6 [480640/697932 (69%)]\tLoss: 3.175296\n",
      "Train Epoch: 6 [481280/697932 (69%)]\tLoss: 3.160937\n",
      "Train Epoch: 6 [481920/697932 (69%)]\tLoss: 3.191313\n",
      "Train Epoch: 6 [482560/697932 (69%)]\tLoss: 3.180668\n",
      "Train Epoch: 6 [483200/697932 (69%)]\tLoss: 3.168969\n",
      "Train Epoch: 6 [483840/697932 (69%)]\tLoss: 3.165947\n",
      "Train Epoch: 6 [484480/697932 (69%)]\tLoss: 3.181142\n",
      "Train Epoch: 6 [485120/697932 (70%)]\tLoss: 3.146307\n",
      "Train Epoch: 6 [485760/697932 (70%)]\tLoss: 3.205147\n",
      "Train Epoch: 6 [486400/697932 (70%)]\tLoss: 3.153929\n",
      "Train Epoch: 6 [487040/697932 (70%)]\tLoss: 3.158787\n",
      "Train Epoch: 6 [487680/697932 (70%)]\tLoss: 3.172118\n",
      "Train Epoch: 6 [488320/697932 (70%)]\tLoss: 3.166482\n",
      "Train Epoch: 6 [488960/697932 (70%)]\tLoss: 3.163579\n",
      "Train Epoch: 6 [489600/697932 (70%)]\tLoss: 3.118273\n",
      "Train Epoch: 6 [490240/697932 (70%)]\tLoss: 3.178380\n",
      "Train Epoch: 6 [490880/697932 (70%)]\tLoss: 3.181439\n",
      "Train Epoch: 6 [491520/697932 (70%)]\tLoss: 3.170874\n",
      "Train Epoch: 6 [492160/697932 (71%)]\tLoss: 3.146281\n",
      "Train Epoch: 6 [492800/697932 (71%)]\tLoss: 3.195288\n",
      "Train Epoch: 6 [493440/697932 (71%)]\tLoss: 3.192835\n",
      "Train Epoch: 6 [494080/697932 (71%)]\tLoss: 3.189686\n",
      "Train Epoch: 6 [494720/697932 (71%)]\tLoss: 3.173846\n",
      "Train Epoch: 6 [495360/697932 (71%)]\tLoss: 3.153154\n",
      "Train Epoch: 6 [496000/697932 (71%)]\tLoss: 3.182374\n",
      "Train Epoch: 6 [496640/697932 (71%)]\tLoss: 3.183527\n",
      "Train Epoch: 6 [497280/697932 (71%)]\tLoss: 3.182278\n",
      "Train Epoch: 6 [497920/697932 (71%)]\tLoss: 3.163706\n",
      "Train Epoch: 6 [498560/697932 (71%)]\tLoss: 3.167942\n",
      "Train Epoch: 6 [499200/697932 (72%)]\tLoss: 3.150287\n",
      "Train Epoch: 6 [499840/697932 (72%)]\tLoss: 3.162971\n",
      "Train Epoch: 6 [500480/697932 (72%)]\tLoss: 3.158336\n",
      "Train Epoch: 6 [501120/697932 (72%)]\tLoss: 3.187558\n",
      "Train Epoch: 6 [501760/697932 (72%)]\tLoss: 3.175228\n",
      "Train Epoch: 6 [502400/697932 (72%)]\tLoss: 3.191346\n",
      "Train Epoch: 6 [503040/697932 (72%)]\tLoss: 3.140817\n",
      "Train Epoch: 6 [503680/697932 (72%)]\tLoss: 3.183800\n",
      "Train Epoch: 6 [504320/697932 (72%)]\tLoss: 3.173972\n",
      "Train Epoch: 6 [504960/697932 (72%)]\tLoss: 3.154377\n",
      "Train Epoch: 6 [505600/697932 (72%)]\tLoss: 3.162731\n",
      "Train Epoch: 6 [506240/697932 (73%)]\tLoss: 3.188426\n",
      "Train Epoch: 6 [506880/697932 (73%)]\tLoss: 3.153848\n",
      "Train Epoch: 6 [507520/697932 (73%)]\tLoss: 3.198004\n",
      "Train Epoch: 6 [508160/697932 (73%)]\tLoss: 3.169761\n",
      "Train Epoch: 6 [508800/697932 (73%)]\tLoss: 3.174495\n",
      "Train Epoch: 6 [509440/697932 (73%)]\tLoss: 3.185728\n",
      "Train Epoch: 6 [510080/697932 (73%)]\tLoss: 3.162355\n",
      "Train Epoch: 6 [510720/697932 (73%)]\tLoss: 3.140446\n",
      "Train Epoch: 6 [511360/697932 (73%)]\tLoss: 3.167147\n",
      "Train Epoch: 6 [512000/697932 (73%)]\tLoss: 3.162894\n",
      "Train Epoch: 6 [512640/697932 (73%)]\tLoss: 3.164200\n",
      "Train Epoch: 6 [513280/697932 (74%)]\tLoss: 3.157335\n",
      "Train Epoch: 6 [513920/697932 (74%)]\tLoss: 3.136110\n",
      "Train Epoch: 6 [514560/697932 (74%)]\tLoss: 3.161724\n",
      "Train Epoch: 6 [515200/697932 (74%)]\tLoss: 3.171689\n",
      "Train Epoch: 6 [515840/697932 (74%)]\tLoss: 3.172783\n",
      "Train Epoch: 6 [516480/697932 (74%)]\tLoss: 3.173160\n",
      "Train Epoch: 6 [517120/697932 (74%)]\tLoss: 3.180638\n",
      "Train Epoch: 6 [517760/697932 (74%)]\tLoss: 3.170285\n",
      "Train Epoch: 6 [518400/697932 (74%)]\tLoss: 3.180907\n",
      "Train Epoch: 6 [519040/697932 (74%)]\tLoss: 3.145305\n",
      "Train Epoch: 6 [519680/697932 (74%)]\tLoss: 3.138466\n",
      "Train Epoch: 6 [520320/697932 (75%)]\tLoss: 3.165423\n",
      "Train Epoch: 6 [520960/697932 (75%)]\tLoss: 3.205067\n",
      "Train Epoch: 6 [521600/697932 (75%)]\tLoss: 3.152661\n",
      "Train Epoch: 6 [522240/697932 (75%)]\tLoss: 3.147803\n",
      "Train Epoch: 6 [522880/697932 (75%)]\tLoss: 3.173017\n",
      "Train Epoch: 6 [523520/697932 (75%)]\tLoss: 3.132308\n",
      "Train Epoch: 6 [524160/697932 (75%)]\tLoss: 3.179228\n",
      "Train Epoch: 6 [524800/697932 (75%)]\tLoss: 3.170095\n",
      "Train Epoch: 6 [525440/697932 (75%)]\tLoss: 3.160524\n",
      "Train Epoch: 6 [526080/697932 (75%)]\tLoss: 3.165952\n",
      "Train Epoch: 6 [526720/697932 (75%)]\tLoss: 3.163403\n",
      "Train Epoch: 6 [527360/697932 (76%)]\tLoss: 3.174967\n",
      "Train Epoch: 6 [528000/697932 (76%)]\tLoss: 3.162886\n",
      "Train Epoch: 6 [528640/697932 (76%)]\tLoss: 3.166263\n",
      "Train Epoch: 6 [529280/697932 (76%)]\tLoss: 3.167734\n",
      "Train Epoch: 6 [529920/697932 (76%)]\tLoss: 3.145005\n",
      "Train Epoch: 6 [530560/697932 (76%)]\tLoss: 3.132490\n",
      "Train Epoch: 6 [531200/697932 (76%)]\tLoss: 3.181155\n",
      "Train Epoch: 6 [531840/697932 (76%)]\tLoss: 3.161422\n",
      "Train Epoch: 6 [532480/697932 (76%)]\tLoss: 3.179656\n",
      "Train Epoch: 6 [533120/697932 (76%)]\tLoss: 3.173005\n",
      "Train Epoch: 6 [533760/697932 (76%)]\tLoss: 3.185361\n",
      "Train Epoch: 6 [534400/697932 (77%)]\tLoss: 3.177936\n",
      "Train Epoch: 6 [535040/697932 (77%)]\tLoss: 3.186599\n",
      "Train Epoch: 6 [535680/697932 (77%)]\tLoss: 3.155545\n",
      "Train Epoch: 6 [536320/697932 (77%)]\tLoss: 3.167382\n",
      "Train Epoch: 6 [536960/697932 (77%)]\tLoss: 3.158241\n",
      "Train Epoch: 6 [537600/697932 (77%)]\tLoss: 3.160762\n",
      "Train Epoch: 6 [538240/697932 (77%)]\tLoss: 3.141294\n",
      "Train Epoch: 6 [538880/697932 (77%)]\tLoss: 3.158070\n",
      "Train Epoch: 6 [539520/697932 (77%)]\tLoss: 3.173191\n",
      "Train Epoch: 6 [540160/697932 (77%)]\tLoss: 3.142470\n",
      "Train Epoch: 6 [540800/697932 (77%)]\tLoss: 3.158606\n",
      "Train Epoch: 6 [541440/697932 (78%)]\tLoss: 3.187714\n",
      "Train Epoch: 6 [542080/697932 (78%)]\tLoss: 3.159175\n",
      "Train Epoch: 6 [542720/697932 (78%)]\tLoss: 3.190331\n",
      "Train Epoch: 6 [543360/697932 (78%)]\tLoss: 3.150622\n",
      "Train Epoch: 6 [544000/697932 (78%)]\tLoss: 3.182667\n",
      "Train Epoch: 6 [544640/697932 (78%)]\tLoss: 3.144735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [545280/697932 (78%)]\tLoss: 3.177703\n",
      "Train Epoch: 6 [545920/697932 (78%)]\tLoss: 3.158001\n",
      "Train Epoch: 6 [546560/697932 (78%)]\tLoss: 3.183204\n",
      "Train Epoch: 6 [547200/697932 (78%)]\tLoss: 3.158878\n",
      "Train Epoch: 6 [547840/697932 (78%)]\tLoss: 3.172714\n",
      "Train Epoch: 6 [548480/697932 (79%)]\tLoss: 3.168329\n",
      "Train Epoch: 6 [549120/697932 (79%)]\tLoss: 3.159527\n",
      "Train Epoch: 6 [549760/697932 (79%)]\tLoss: 3.206165\n",
      "Train Epoch: 6 [550400/697932 (79%)]\tLoss: 3.176368\n",
      "Train Epoch: 6 [551040/697932 (79%)]\tLoss: 3.150269\n",
      "Train Epoch: 6 [551680/697932 (79%)]\tLoss: 3.149692\n",
      "Train Epoch: 6 [552320/697932 (79%)]\tLoss: 3.154393\n",
      "Train Epoch: 6 [552960/697932 (79%)]\tLoss: 3.174884\n",
      "Train Epoch: 6 [553600/697932 (79%)]\tLoss: 3.168019\n",
      "Train Epoch: 6 [554240/697932 (79%)]\tLoss: 3.159673\n",
      "Train Epoch: 6 [554880/697932 (79%)]\tLoss: 3.182984\n",
      "Train Epoch: 6 [555520/697932 (80%)]\tLoss: 3.159012\n",
      "Train Epoch: 6 [556160/697932 (80%)]\tLoss: 3.151965\n",
      "Train Epoch: 6 [556800/697932 (80%)]\tLoss: 3.126425\n",
      "Train Epoch: 6 [557440/697932 (80%)]\tLoss: 3.185903\n",
      "Train Epoch: 6 [558080/697932 (80%)]\tLoss: 3.180100\n",
      "Train Epoch: 6 [558720/697932 (80%)]\tLoss: 3.153634\n",
      "Train Epoch: 6 [559360/697932 (80%)]\tLoss: 3.178838\n",
      "Train Epoch: 6 [560000/697932 (80%)]\tLoss: 3.168052\n",
      "Train Epoch: 6 [560640/697932 (80%)]\tLoss: 3.169313\n",
      "Train Epoch: 6 [561280/697932 (80%)]\tLoss: 3.162662\n",
      "Train Epoch: 6 [561920/697932 (81%)]\tLoss: 3.176133\n",
      "Train Epoch: 6 [562560/697932 (81%)]\tLoss: 3.163498\n",
      "Train Epoch: 6 [563200/697932 (81%)]\tLoss: 3.184631\n",
      "Train Epoch: 6 [563840/697932 (81%)]\tLoss: 3.183911\n",
      "Train Epoch: 6 [564480/697932 (81%)]\tLoss: 3.192831\n",
      "Train Epoch: 6 [565120/697932 (81%)]\tLoss: 3.166352\n",
      "Train Epoch: 6 [565760/697932 (81%)]\tLoss: 3.167868\n",
      "Train Epoch: 6 [566400/697932 (81%)]\tLoss: 3.193894\n",
      "Train Epoch: 6 [567040/697932 (81%)]\tLoss: 3.157110\n",
      "Train Epoch: 6 [567680/697932 (81%)]\tLoss: 3.156091\n",
      "Train Epoch: 6 [568320/697932 (81%)]\tLoss: 3.181555\n",
      "Train Epoch: 6 [568960/697932 (82%)]\tLoss: 3.167949\n",
      "Train Epoch: 6 [569600/697932 (82%)]\tLoss: 3.163743\n",
      "Train Epoch: 6 [570240/697932 (82%)]\tLoss: 3.147137\n",
      "Train Epoch: 6 [570880/697932 (82%)]\tLoss: 3.175316\n",
      "Train Epoch: 6 [571520/697932 (82%)]\tLoss: 3.147960\n",
      "Train Epoch: 6 [572160/697932 (82%)]\tLoss: 3.165289\n",
      "Train Epoch: 6 [572800/697932 (82%)]\tLoss: 3.157022\n",
      "Train Epoch: 6 [573440/697932 (82%)]\tLoss: 3.176617\n",
      "Train Epoch: 6 [574080/697932 (82%)]\tLoss: 3.137348\n",
      "Train Epoch: 6 [574720/697932 (82%)]\tLoss: 3.164598\n",
      "Train Epoch: 6 [575360/697932 (82%)]\tLoss: 3.167303\n",
      "Train Epoch: 6 [576000/697932 (83%)]\tLoss: 3.161382\n",
      "Train Epoch: 6 [576640/697932 (83%)]\tLoss: 3.160119\n",
      "Train Epoch: 6 [577280/697932 (83%)]\tLoss: 3.141108\n",
      "Train Epoch: 6 [577920/697932 (83%)]\tLoss: 3.172284\n",
      "Train Epoch: 6 [578560/697932 (83%)]\tLoss: 3.169309\n",
      "Train Epoch: 6 [579200/697932 (83%)]\tLoss: 3.130488\n",
      "Train Epoch: 6 [579840/697932 (83%)]\tLoss: 3.176443\n",
      "Train Epoch: 6 [580480/697932 (83%)]\tLoss: 3.189274\n",
      "Train Epoch: 6 [581120/697932 (83%)]\tLoss: 3.150809\n",
      "Train Epoch: 6 [581760/697932 (83%)]\tLoss: 3.172650\n",
      "Train Epoch: 6 [582400/697932 (83%)]\tLoss: 3.187025\n",
      "Train Epoch: 6 [583040/697932 (84%)]\tLoss: 3.187271\n",
      "Train Epoch: 6 [583680/697932 (84%)]\tLoss: 3.168160\n",
      "Train Epoch: 6 [584320/697932 (84%)]\tLoss: 3.172902\n",
      "Train Epoch: 6 [584960/697932 (84%)]\tLoss: 3.169106\n",
      "Train Epoch: 6 [585600/697932 (84%)]\tLoss: 3.178717\n",
      "Train Epoch: 6 [586240/697932 (84%)]\tLoss: 3.160727\n",
      "Train Epoch: 6 [586880/697932 (84%)]\tLoss: 3.157101\n",
      "Train Epoch: 6 [587520/697932 (84%)]\tLoss: 3.172504\n",
      "Train Epoch: 6 [588160/697932 (84%)]\tLoss: 3.149951\n",
      "Train Epoch: 6 [588800/697932 (84%)]\tLoss: 3.171912\n",
      "Train Epoch: 6 [589440/697932 (84%)]\tLoss: 3.152442\n",
      "Train Epoch: 6 [590080/697932 (85%)]\tLoss: 3.181973\n",
      "Train Epoch: 6 [590720/697932 (85%)]\tLoss: 3.159029\n",
      "Train Epoch: 6 [591360/697932 (85%)]\tLoss: 3.151585\n",
      "Train Epoch: 6 [592000/697932 (85%)]\tLoss: 3.153755\n",
      "Train Epoch: 6 [592640/697932 (85%)]\tLoss: 3.150168\n",
      "Train Epoch: 6 [593280/697932 (85%)]\tLoss: 3.191764\n",
      "Train Epoch: 6 [593920/697932 (85%)]\tLoss: 3.173641\n",
      "Train Epoch: 6 [594560/697932 (85%)]\tLoss: 3.140041\n",
      "Train Epoch: 6 [595200/697932 (85%)]\tLoss: 3.163762\n",
      "Train Epoch: 6 [595840/697932 (85%)]\tLoss: 3.160459\n",
      "Train Epoch: 6 [596480/697932 (85%)]\tLoss: 3.146320\n",
      "Train Epoch: 6 [597120/697932 (86%)]\tLoss: 3.188332\n",
      "Train Epoch: 6 [597760/697932 (86%)]\tLoss: 3.149535\n",
      "Train Epoch: 6 [598400/697932 (86%)]\tLoss: 3.159889\n",
      "Train Epoch: 6 [599040/697932 (86%)]\tLoss: 3.166898\n",
      "Train Epoch: 6 [599680/697932 (86%)]\tLoss: 3.180844\n",
      "Train Epoch: 6 [600320/697932 (86%)]\tLoss: 3.170114\n",
      "Train Epoch: 6 [600960/697932 (86%)]\tLoss: 3.164023\n",
      "Train Epoch: 6 [601600/697932 (86%)]\tLoss: 3.150005\n",
      "Train Epoch: 6 [602240/697932 (86%)]\tLoss: 3.198319\n",
      "Train Epoch: 6 [602880/697932 (86%)]\tLoss: 3.159010\n",
      "Train Epoch: 6 [603520/697932 (86%)]\tLoss: 3.156443\n",
      "Train Epoch: 6 [604160/697932 (87%)]\tLoss: 3.158022\n",
      "Train Epoch: 6 [604800/697932 (87%)]\tLoss: 3.164646\n",
      "Train Epoch: 6 [605440/697932 (87%)]\tLoss: 3.175527\n",
      "Train Epoch: 6 [606080/697932 (87%)]\tLoss: 3.174082\n",
      "Train Epoch: 6 [606720/697932 (87%)]\tLoss: 3.168858\n",
      "Train Epoch: 6 [607360/697932 (87%)]\tLoss: 3.166070\n",
      "Train Epoch: 6 [608000/697932 (87%)]\tLoss: 3.209853\n",
      "Train Epoch: 6 [608640/697932 (87%)]\tLoss: 3.165505\n",
      "Train Epoch: 6 [609280/697932 (87%)]\tLoss: 3.168791\n",
      "Train Epoch: 6 [609920/697932 (87%)]\tLoss: 3.168407\n",
      "Train Epoch: 6 [610560/697932 (87%)]\tLoss: 3.179965\n",
      "Train Epoch: 6 [611200/697932 (88%)]\tLoss: 3.181424\n",
      "Train Epoch: 6 [611840/697932 (88%)]\tLoss: 3.136895\n",
      "Train Epoch: 6 [612480/697932 (88%)]\tLoss: 3.196118\n",
      "Train Epoch: 6 [613120/697932 (88%)]\tLoss: 3.144148\n",
      "Train Epoch: 6 [613760/697932 (88%)]\tLoss: 3.149169\n",
      "Train Epoch: 6 [614400/697932 (88%)]\tLoss: 3.157876\n",
      "Train Epoch: 6 [615040/697932 (88%)]\tLoss: 3.173787\n",
      "Train Epoch: 6 [615680/697932 (88%)]\tLoss: 3.162342\n",
      "Train Epoch: 6 [616320/697932 (88%)]\tLoss: 3.162649\n",
      "Train Epoch: 6 [616960/697932 (88%)]\tLoss: 3.188252\n",
      "Train Epoch: 6 [617600/697932 (88%)]\tLoss: 3.198969\n",
      "Train Epoch: 6 [618240/697932 (89%)]\tLoss: 3.161172\n",
      "Train Epoch: 6 [618880/697932 (89%)]\tLoss: 3.189393\n",
      "Train Epoch: 6 [619520/697932 (89%)]\tLoss: 3.156566\n",
      "Train Epoch: 6 [620160/697932 (89%)]\tLoss: 3.172972\n",
      "Train Epoch: 6 [620800/697932 (89%)]\tLoss: 3.184027\n",
      "Train Epoch: 6 [621440/697932 (89%)]\tLoss: 3.176690\n",
      "Train Epoch: 6 [622080/697932 (89%)]\tLoss: 3.176708\n",
      "Train Epoch: 6 [622720/697932 (89%)]\tLoss: 3.207608\n",
      "Train Epoch: 6 [623360/697932 (89%)]\tLoss: 3.187552\n",
      "Train Epoch: 6 [624000/697932 (89%)]\tLoss: 3.162030\n",
      "Train Epoch: 6 [624640/697932 (89%)]\tLoss: 3.160064\n",
      "Train Epoch: 6 [625280/697932 (90%)]\tLoss: 3.163203\n",
      "Train Epoch: 6 [625920/697932 (90%)]\tLoss: 3.195974\n",
      "Train Epoch: 6 [626560/697932 (90%)]\tLoss: 3.176435\n",
      "Train Epoch: 6 [627200/697932 (90%)]\tLoss: 3.165863\n",
      "Train Epoch: 6 [627840/697932 (90%)]\tLoss: 3.187665\n",
      "Train Epoch: 6 [628480/697932 (90%)]\tLoss: 3.194423\n",
      "Train Epoch: 6 [629120/697932 (90%)]\tLoss: 3.163283\n",
      "Train Epoch: 6 [629760/697932 (90%)]\tLoss: 3.157767\n",
      "Train Epoch: 6 [630400/697932 (90%)]\tLoss: 3.173875\n",
      "Train Epoch: 6 [631040/697932 (90%)]\tLoss: 3.153338\n",
      "Train Epoch: 6 [631680/697932 (91%)]\tLoss: 3.169923\n",
      "Train Epoch: 6 [632320/697932 (91%)]\tLoss: 3.172633\n",
      "Train Epoch: 6 [632960/697932 (91%)]\tLoss: 3.183128\n",
      "Train Epoch: 6 [633600/697932 (91%)]\tLoss: 3.202103\n",
      "Train Epoch: 6 [634240/697932 (91%)]\tLoss: 3.182464\n",
      "Train Epoch: 6 [634880/697932 (91%)]\tLoss: 3.153804\n",
      "Train Epoch: 6 [635520/697932 (91%)]\tLoss: 3.171460\n",
      "Train Epoch: 6 [636160/697932 (91%)]\tLoss: 3.163190\n",
      "Train Epoch: 6 [636800/697932 (91%)]\tLoss: 3.171989\n",
      "Train Epoch: 6 [637440/697932 (91%)]\tLoss: 3.155584\n",
      "Train Epoch: 6 [638080/697932 (91%)]\tLoss: 3.170385\n",
      "Train Epoch: 6 [638720/697932 (92%)]\tLoss: 3.148117\n",
      "Train Epoch: 6 [639360/697932 (92%)]\tLoss: 3.148571\n",
      "Train Epoch: 6 [640000/697932 (92%)]\tLoss: 3.170091\n",
      "Train Epoch: 6 [640640/697932 (92%)]\tLoss: 3.165601\n",
      "Train Epoch: 6 [641280/697932 (92%)]\tLoss: 3.167010\n",
      "Train Epoch: 6 [641920/697932 (92%)]\tLoss: 3.156817\n",
      "Train Epoch: 6 [642560/697932 (92%)]\tLoss: 3.179325\n",
      "Train Epoch: 6 [643200/697932 (92%)]\tLoss: 3.173246\n",
      "Train Epoch: 6 [643840/697932 (92%)]\tLoss: 3.157493\n",
      "Train Epoch: 6 [644480/697932 (92%)]\tLoss: 3.163131\n",
      "Train Epoch: 6 [645120/697932 (92%)]\tLoss: 3.174374\n",
      "Train Epoch: 6 [645760/697932 (93%)]\tLoss: 3.182754\n",
      "Train Epoch: 6 [646400/697932 (93%)]\tLoss: 3.145844\n",
      "Train Epoch: 6 [647040/697932 (93%)]\tLoss: 3.159074\n",
      "Train Epoch: 6 [647680/697932 (93%)]\tLoss: 3.174416\n",
      "Train Epoch: 6 [648320/697932 (93%)]\tLoss: 3.152770\n",
      "Train Epoch: 6 [648960/697932 (93%)]\tLoss: 3.163308\n",
      "Train Epoch: 6 [649600/697932 (93%)]\tLoss: 3.161549\n",
      "Train Epoch: 6 [650240/697932 (93%)]\tLoss: 3.171859\n",
      "Train Epoch: 6 [650880/697932 (93%)]\tLoss: 3.182430\n",
      "Train Epoch: 6 [651520/697932 (93%)]\tLoss: 3.181130\n",
      "Train Epoch: 6 [652160/697932 (93%)]\tLoss: 3.138074\n",
      "Train Epoch: 6 [652800/697932 (94%)]\tLoss: 3.144571\n",
      "Train Epoch: 6 [653440/697932 (94%)]\tLoss: 3.186207\n",
      "Train Epoch: 6 [654080/697932 (94%)]\tLoss: 3.166521\n",
      "Train Epoch: 6 [654720/697932 (94%)]\tLoss: 3.178212\n",
      "Train Epoch: 6 [655360/697932 (94%)]\tLoss: 3.152380\n",
      "Train Epoch: 6 [656000/697932 (94%)]\tLoss: 3.171801\n",
      "Train Epoch: 6 [656640/697932 (94%)]\tLoss: 3.149072\n",
      "Train Epoch: 6 [657280/697932 (94%)]\tLoss: 3.169038\n",
      "Train Epoch: 6 [657920/697932 (94%)]\tLoss: 3.155115\n",
      "Train Epoch: 6 [658560/697932 (94%)]\tLoss: 3.169435\n",
      "Train Epoch: 6 [659200/697932 (94%)]\tLoss: 3.182773\n",
      "Train Epoch: 6 [659840/697932 (95%)]\tLoss: 3.178219\n",
      "Train Epoch: 6 [660480/697932 (95%)]\tLoss: 3.180010\n",
      "Train Epoch: 6 [661120/697932 (95%)]\tLoss: 3.188464\n",
      "Train Epoch: 6 [661760/697932 (95%)]\tLoss: 3.152850\n",
      "Train Epoch: 6 [662400/697932 (95%)]\tLoss: 3.169226\n",
      "Train Epoch: 6 [663040/697932 (95%)]\tLoss: 3.177592\n",
      "Train Epoch: 6 [663680/697932 (95%)]\tLoss: 3.166298\n",
      "Train Epoch: 6 [664320/697932 (95%)]\tLoss: 3.170459\n",
      "Train Epoch: 6 [664960/697932 (95%)]\tLoss: 3.164385\n",
      "Train Epoch: 6 [665600/697932 (95%)]\tLoss: 3.110923\n",
      "Train Epoch: 6 [666240/697932 (95%)]\tLoss: 3.142352\n",
      "Train Epoch: 6 [666880/697932 (96%)]\tLoss: 3.160164\n",
      "Train Epoch: 6 [667520/697932 (96%)]\tLoss: 3.175264\n",
      "Train Epoch: 6 [668160/697932 (96%)]\tLoss: 3.178702\n",
      "Train Epoch: 6 [668800/697932 (96%)]\tLoss: 3.152148\n",
      "Train Epoch: 6 [669440/697932 (96%)]\tLoss: 3.160988\n",
      "Train Epoch: 6 [670080/697932 (96%)]\tLoss: 3.146887\n",
      "Train Epoch: 6 [670720/697932 (96%)]\tLoss: 3.175178\n",
      "Train Epoch: 6 [671360/697932 (96%)]\tLoss: 3.163669\n",
      "Train Epoch: 6 [672000/697932 (96%)]\tLoss: 3.186632\n",
      "Train Epoch: 6 [672640/697932 (96%)]\tLoss: 3.141235\n",
      "Train Epoch: 6 [673280/697932 (96%)]\tLoss: 3.164544\n",
      "Train Epoch: 6 [673920/697932 (97%)]\tLoss: 3.200844\n",
      "Train Epoch: 6 [674560/697932 (97%)]\tLoss: 3.206282\n",
      "Train Epoch: 6 [675200/697932 (97%)]\tLoss: 3.174525\n",
      "Train Epoch: 6 [675840/697932 (97%)]\tLoss: 3.153507\n",
      "Train Epoch: 6 [676480/697932 (97%)]\tLoss: 3.162398\n",
      "Train Epoch: 6 [677120/697932 (97%)]\tLoss: 3.148448\n",
      "Train Epoch: 6 [677760/697932 (97%)]\tLoss: 3.166759\n",
      "Train Epoch: 6 [678400/697932 (97%)]\tLoss: 3.156722\n",
      "Train Epoch: 6 [679040/697932 (97%)]\tLoss: 3.185043\n",
      "Train Epoch: 6 [679680/697932 (97%)]\tLoss: 3.185675\n",
      "Train Epoch: 6 [680320/697932 (97%)]\tLoss: 3.172288\n",
      "Train Epoch: 6 [680960/697932 (98%)]\tLoss: 3.169552\n",
      "Train Epoch: 6 [681600/697932 (98%)]\tLoss: 3.167300\n",
      "Train Epoch: 6 [682240/697932 (98%)]\tLoss: 3.190213\n",
      "Train Epoch: 6 [682880/697932 (98%)]\tLoss: 3.170303\n",
      "Train Epoch: 6 [683520/697932 (98%)]\tLoss: 3.200865\n",
      "Train Epoch: 6 [684160/697932 (98%)]\tLoss: 3.168586\n",
      "Train Epoch: 6 [684800/697932 (98%)]\tLoss: 3.154338\n",
      "Train Epoch: 6 [685440/697932 (98%)]\tLoss: 3.165598\n",
      "Train Epoch: 6 [686080/697932 (98%)]\tLoss: 3.173859\n",
      "Train Epoch: 6 [686720/697932 (98%)]\tLoss: 3.165640\n",
      "Train Epoch: 6 [687360/697932 (98%)]\tLoss: 3.168399\n",
      "Train Epoch: 6 [688000/697932 (99%)]\tLoss: 3.182466\n",
      "Train Epoch: 6 [688640/697932 (99%)]\tLoss: 3.149843\n",
      "Train Epoch: 6 [689280/697932 (99%)]\tLoss: 3.177536\n",
      "Train Epoch: 6 [689920/697932 (99%)]\tLoss: 3.163670\n",
      "Train Epoch: 6 [690560/697932 (99%)]\tLoss: 3.200876\n",
      "Train Epoch: 6 [691200/697932 (99%)]\tLoss: 3.164849\n",
      "Train Epoch: 6 [691840/697932 (99%)]\tLoss: 3.158074\n",
      "Train Epoch: 6 [692480/697932 (99%)]\tLoss: 3.151871\n",
      "Train Epoch: 6 [693120/697932 (99%)]\tLoss: 3.154457\n",
      "Train Epoch: 6 [693760/697932 (99%)]\tLoss: 3.181732\n",
      "Train Epoch: 6 [694400/697932 (99%)]\tLoss: 3.149805\n",
      "Train Epoch: 6 [695040/697932 (100%)]\tLoss: 3.175213\n",
      "Train Epoch: 6 [695680/697932 (100%)]\tLoss: 3.158879\n",
      "Train Epoch: 6 [696320/697932 (100%)]\tLoss: 3.190876\n",
      "Train Epoch: 6 [696960/697932 (100%)]\tLoss: 3.151255\n",
      "Train Epoch: 6 [697600/697932 (100%)]\tLoss: 3.163646\n",
      "\n",
      "Test set: Avg. loss: 0.0045, Accuracy: 38/116323 (0%)\n",
      "\n",
      "Train Epoch: 7 [0/697932 (0%)]\tLoss: 3.188717\n",
      "Train Epoch: 7 [640/697932 (0%)]\tLoss: 3.166734\n",
      "Train Epoch: 7 [1280/697932 (0%)]\tLoss: 3.206273\n",
      "Train Epoch: 7 [1920/697932 (0%)]\tLoss: 3.163032\n",
      "Train Epoch: 7 [2560/697932 (0%)]\tLoss: 3.173611\n",
      "Train Epoch: 7 [3200/697932 (0%)]\tLoss: 3.157633\n",
      "Train Epoch: 7 [3840/697932 (1%)]\tLoss: 3.145289\n",
      "Train Epoch: 7 [4480/697932 (1%)]\tLoss: 3.182176\n",
      "Train Epoch: 7 [5120/697932 (1%)]\tLoss: 3.145191\n",
      "Train Epoch: 7 [5760/697932 (1%)]\tLoss: 3.137631\n",
      "Train Epoch: 7 [6400/697932 (1%)]\tLoss: 3.144439\n",
      "Train Epoch: 7 [7040/697932 (1%)]\tLoss: 3.180740\n",
      "Train Epoch: 7 [7680/697932 (1%)]\tLoss: 3.167565\n",
      "Train Epoch: 7 [8320/697932 (1%)]\tLoss: 3.163862\n",
      "Train Epoch: 7 [8960/697932 (1%)]\tLoss: 3.171875\n",
      "Train Epoch: 7 [9600/697932 (1%)]\tLoss: 3.168700\n",
      "Train Epoch: 7 [10240/697932 (1%)]\tLoss: 3.156525\n",
      "Train Epoch: 7 [10880/697932 (2%)]\tLoss: 3.145012\n",
      "Train Epoch: 7 [11520/697932 (2%)]\tLoss: 3.199500\n",
      "Train Epoch: 7 [12160/697932 (2%)]\tLoss: 3.174748\n",
      "Train Epoch: 7 [12800/697932 (2%)]\tLoss: 3.179463\n",
      "Train Epoch: 7 [13440/697932 (2%)]\tLoss: 3.164041\n",
      "Train Epoch: 7 [14080/697932 (2%)]\tLoss: 3.151295\n",
      "Train Epoch: 7 [14720/697932 (2%)]\tLoss: 3.153612\n",
      "Train Epoch: 7 [15360/697932 (2%)]\tLoss: 3.183038\n",
      "Train Epoch: 7 [16000/697932 (2%)]\tLoss: 3.179954\n",
      "Train Epoch: 7 [16640/697932 (2%)]\tLoss: 3.195150\n",
      "Train Epoch: 7 [17280/697932 (2%)]\tLoss: 3.177843\n",
      "Train Epoch: 7 [17920/697932 (3%)]\tLoss: 3.185397\n",
      "Train Epoch: 7 [18560/697932 (3%)]\tLoss: 3.159948\n",
      "Train Epoch: 7 [19200/697932 (3%)]\tLoss: 3.184728\n",
      "Train Epoch: 7 [19840/697932 (3%)]\tLoss: 3.191655\n",
      "Train Epoch: 7 [20480/697932 (3%)]\tLoss: 3.133767\n",
      "Train Epoch: 7 [21120/697932 (3%)]\tLoss: 3.158777\n",
      "Train Epoch: 7 [21760/697932 (3%)]\tLoss: 3.160085\n",
      "Train Epoch: 7 [22400/697932 (3%)]\tLoss: 3.172842\n",
      "Train Epoch: 7 [23040/697932 (3%)]\tLoss: 3.177087\n",
      "Train Epoch: 7 [23680/697932 (3%)]\tLoss: 3.158756\n",
      "Train Epoch: 7 [24320/697932 (3%)]\tLoss: 3.158249\n",
      "Train Epoch: 7 [24960/697932 (4%)]\tLoss: 3.159179\n",
      "Train Epoch: 7 [25600/697932 (4%)]\tLoss: 3.191245\n",
      "Train Epoch: 7 [26240/697932 (4%)]\tLoss: 3.152179\n",
      "Train Epoch: 7 [26880/697932 (4%)]\tLoss: 3.154901\n",
      "Train Epoch: 7 [27520/697932 (4%)]\tLoss: 3.145368\n",
      "Train Epoch: 7 [28160/697932 (4%)]\tLoss: 3.151725\n",
      "Train Epoch: 7 [28800/697932 (4%)]\tLoss: 3.171619\n",
      "Train Epoch: 7 [29440/697932 (4%)]\tLoss: 3.153060\n",
      "Train Epoch: 7 [30080/697932 (4%)]\tLoss: 3.166986\n",
      "Train Epoch: 7 [30720/697932 (4%)]\tLoss: 3.180001\n",
      "Train Epoch: 7 [31360/697932 (4%)]\tLoss: 3.138077\n",
      "Train Epoch: 7 [32000/697932 (5%)]\tLoss: 3.186940\n",
      "Train Epoch: 7 [32640/697932 (5%)]\tLoss: 3.183804\n",
      "Train Epoch: 7 [33280/697932 (5%)]\tLoss: 3.183522\n",
      "Train Epoch: 7 [33920/697932 (5%)]\tLoss: 3.153797\n",
      "Train Epoch: 7 [34560/697932 (5%)]\tLoss: 3.148433\n",
      "Train Epoch: 7 [35200/697932 (5%)]\tLoss: 3.187763\n",
      "Train Epoch: 7 [35840/697932 (5%)]\tLoss: 3.187366\n",
      "Train Epoch: 7 [36480/697932 (5%)]\tLoss: 3.170107\n",
      "Train Epoch: 7 [37120/697932 (5%)]\tLoss: 3.136733\n",
      "Train Epoch: 7 [37760/697932 (5%)]\tLoss: 3.164263\n",
      "Train Epoch: 7 [38400/697932 (6%)]\tLoss: 3.154929\n",
      "Train Epoch: 7 [39040/697932 (6%)]\tLoss: 3.134913\n",
      "Train Epoch: 7 [39680/697932 (6%)]\tLoss: 3.187895\n",
      "Train Epoch: 7 [40320/697932 (6%)]\tLoss: 3.149122\n",
      "Train Epoch: 7 [40960/697932 (6%)]\tLoss: 3.185508\n",
      "Train Epoch: 7 [41600/697932 (6%)]\tLoss: 3.146944\n",
      "Train Epoch: 7 [42240/697932 (6%)]\tLoss: 3.186200\n",
      "Train Epoch: 7 [42880/697932 (6%)]\tLoss: 3.203477\n",
      "Train Epoch: 7 [43520/697932 (6%)]\tLoss: 3.159582\n",
      "Train Epoch: 7 [44160/697932 (6%)]\tLoss: 3.158730\n",
      "Train Epoch: 7 [44800/697932 (6%)]\tLoss: 3.171678\n",
      "Train Epoch: 7 [45440/697932 (7%)]\tLoss: 3.161433\n",
      "Train Epoch: 7 [46080/697932 (7%)]\tLoss: 3.175214\n",
      "Train Epoch: 7 [46720/697932 (7%)]\tLoss: 3.155276\n",
      "Train Epoch: 7 [47360/697932 (7%)]\tLoss: 3.167760\n",
      "Train Epoch: 7 [48000/697932 (7%)]\tLoss: 3.173761\n",
      "Train Epoch: 7 [48640/697932 (7%)]\tLoss: 3.177808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [49280/697932 (7%)]\tLoss: 3.159916\n",
      "Train Epoch: 7 [49920/697932 (7%)]\tLoss: 3.151820\n",
      "Train Epoch: 7 [50560/697932 (7%)]\tLoss: 3.168130\n",
      "Train Epoch: 7 [51200/697932 (7%)]\tLoss: 3.159175\n",
      "Train Epoch: 7 [51840/697932 (7%)]\tLoss: 3.166905\n",
      "Train Epoch: 7 [52480/697932 (8%)]\tLoss: 3.181556\n",
      "Train Epoch: 7 [53120/697932 (8%)]\tLoss: 3.168844\n",
      "Train Epoch: 7 [53760/697932 (8%)]\tLoss: 3.165419\n",
      "Train Epoch: 7 [54400/697932 (8%)]\tLoss: 3.171701\n",
      "Train Epoch: 7 [55040/697932 (8%)]\tLoss: 3.135735\n",
      "Train Epoch: 7 [55680/697932 (8%)]\tLoss: 3.163558\n",
      "Train Epoch: 7 [56320/697932 (8%)]\tLoss: 3.159317\n",
      "Train Epoch: 7 [56960/697932 (8%)]\tLoss: 3.163466\n",
      "Train Epoch: 7 [57600/697932 (8%)]\tLoss: 3.163382\n",
      "Train Epoch: 7 [58240/697932 (8%)]\tLoss: 3.183859\n",
      "Train Epoch: 7 [58880/697932 (8%)]\tLoss: 3.165461\n",
      "Train Epoch: 7 [59520/697932 (9%)]\tLoss: 3.151791\n",
      "Train Epoch: 7 [60160/697932 (9%)]\tLoss: 3.188061\n",
      "Train Epoch: 7 [60800/697932 (9%)]\tLoss: 3.171029\n",
      "Train Epoch: 7 [61440/697932 (9%)]\tLoss: 3.166589\n",
      "Train Epoch: 7 [62080/697932 (9%)]\tLoss: 3.175565\n",
      "Train Epoch: 7 [62720/697932 (9%)]\tLoss: 3.151414\n",
      "Train Epoch: 7 [63360/697932 (9%)]\tLoss: 3.161848\n",
      "Train Epoch: 7 [64000/697932 (9%)]\tLoss: 3.159721\n",
      "Train Epoch: 7 [64640/697932 (9%)]\tLoss: 3.157326\n",
      "Train Epoch: 7 [65280/697932 (9%)]\tLoss: 3.151532\n",
      "Train Epoch: 7 [65920/697932 (9%)]\tLoss: 3.161070\n",
      "Train Epoch: 7 [66560/697932 (10%)]\tLoss: 3.155555\n",
      "Train Epoch: 7 [67200/697932 (10%)]\tLoss: 3.172099\n",
      "Train Epoch: 7 [67840/697932 (10%)]\tLoss: 3.193080\n",
      "Train Epoch: 7 [68480/697932 (10%)]\tLoss: 3.177119\n",
      "Train Epoch: 7 [69120/697932 (10%)]\tLoss: 3.147485\n",
      "Train Epoch: 7 [69760/697932 (10%)]\tLoss: 3.175028\n",
      "Train Epoch: 7 [70400/697932 (10%)]\tLoss: 3.204232\n",
      "Train Epoch: 7 [71040/697932 (10%)]\tLoss: 3.188545\n",
      "Train Epoch: 7 [71680/697932 (10%)]\tLoss: 3.201636\n",
      "Train Epoch: 7 [72320/697932 (10%)]\tLoss: 3.182528\n",
      "Train Epoch: 7 [72960/697932 (10%)]\tLoss: 3.170731\n",
      "Train Epoch: 7 [73600/697932 (11%)]\tLoss: 3.174102\n",
      "Train Epoch: 7 [74240/697932 (11%)]\tLoss: 3.192616\n",
      "Train Epoch: 7 [74880/697932 (11%)]\tLoss: 3.195422\n",
      "Train Epoch: 7 [75520/697932 (11%)]\tLoss: 3.183761\n",
      "Train Epoch: 7 [76160/697932 (11%)]\tLoss: 3.146331\n",
      "Train Epoch: 7 [76800/697932 (11%)]\tLoss: 3.162473\n",
      "Train Epoch: 7 [77440/697932 (11%)]\tLoss: 3.161980\n",
      "Train Epoch: 7 [78080/697932 (11%)]\tLoss: 3.139275\n",
      "Train Epoch: 7 [78720/697932 (11%)]\tLoss: 3.201049\n",
      "Train Epoch: 7 [79360/697932 (11%)]\tLoss: 3.179091\n",
      "Train Epoch: 7 [80000/697932 (11%)]\tLoss: 3.161837\n",
      "Train Epoch: 7 [80640/697932 (12%)]\tLoss: 3.156933\n",
      "Train Epoch: 7 [81280/697932 (12%)]\tLoss: 3.199667\n",
      "Train Epoch: 7 [81920/697932 (12%)]\tLoss: 3.130291\n",
      "Train Epoch: 7 [82560/697932 (12%)]\tLoss: 3.148874\n",
      "Train Epoch: 7 [83200/697932 (12%)]\tLoss: 3.175990\n",
      "Train Epoch: 7 [83840/697932 (12%)]\tLoss: 3.192174\n",
      "Train Epoch: 7 [84480/697932 (12%)]\tLoss: 3.160589\n",
      "Train Epoch: 7 [85120/697932 (12%)]\tLoss: 3.201620\n",
      "Train Epoch: 7 [85760/697932 (12%)]\tLoss: 3.153537\n",
      "Train Epoch: 7 [86400/697932 (12%)]\tLoss: 3.172300\n",
      "Train Epoch: 7 [87040/697932 (12%)]\tLoss: 3.154031\n",
      "Train Epoch: 7 [87680/697932 (13%)]\tLoss: 3.166566\n",
      "Train Epoch: 7 [88320/697932 (13%)]\tLoss: 3.172698\n",
      "Train Epoch: 7 [88960/697932 (13%)]\tLoss: 3.152284\n",
      "Train Epoch: 7 [89600/697932 (13%)]\tLoss: 3.193081\n",
      "Train Epoch: 7 [90240/697932 (13%)]\tLoss: 3.162141\n",
      "Train Epoch: 7 [90880/697932 (13%)]\tLoss: 3.162078\n",
      "Train Epoch: 7 [91520/697932 (13%)]\tLoss: 3.149833\n",
      "Train Epoch: 7 [92160/697932 (13%)]\tLoss: 3.157140\n",
      "Train Epoch: 7 [92800/697932 (13%)]\tLoss: 3.173996\n",
      "Train Epoch: 7 [93440/697932 (13%)]\tLoss: 3.197500\n",
      "Train Epoch: 7 [94080/697932 (13%)]\tLoss: 3.146192\n",
      "Train Epoch: 7 [94720/697932 (14%)]\tLoss: 3.175860\n",
      "Train Epoch: 7 [95360/697932 (14%)]\tLoss: 3.195816\n",
      "Train Epoch: 7 [96000/697932 (14%)]\tLoss: 3.154957\n",
      "Train Epoch: 7 [96640/697932 (14%)]\tLoss: 3.203903\n",
      "Train Epoch: 7 [97280/697932 (14%)]\tLoss: 3.187593\n",
      "Train Epoch: 7 [97920/697932 (14%)]\tLoss: 3.183284\n",
      "Train Epoch: 7 [98560/697932 (14%)]\tLoss: 3.161458\n",
      "Train Epoch: 7 [99200/697932 (14%)]\tLoss: 3.156617\n",
      "Train Epoch: 7 [99840/697932 (14%)]\tLoss: 3.164474\n",
      "Train Epoch: 7 [100480/697932 (14%)]\tLoss: 3.168267\n",
      "Train Epoch: 7 [101120/697932 (14%)]\tLoss: 3.149129\n",
      "Train Epoch: 7 [101760/697932 (15%)]\tLoss: 3.180778\n",
      "Train Epoch: 7 [102400/697932 (15%)]\tLoss: 3.174172\n",
      "Train Epoch: 7 [103040/697932 (15%)]\tLoss: 3.172387\n",
      "Train Epoch: 7 [103680/697932 (15%)]\tLoss: 3.151427\n",
      "Train Epoch: 7 [104320/697932 (15%)]\tLoss: 3.165828\n",
      "Train Epoch: 7 [104960/697932 (15%)]\tLoss: 3.158339\n",
      "Train Epoch: 7 [105600/697932 (15%)]\tLoss: 3.174999\n",
      "Train Epoch: 7 [106240/697932 (15%)]\tLoss: 3.175938\n",
      "Train Epoch: 7 [106880/697932 (15%)]\tLoss: 3.182219\n",
      "Train Epoch: 7 [107520/697932 (15%)]\tLoss: 3.165838\n",
      "Train Epoch: 7 [108160/697932 (15%)]\tLoss: 3.172866\n",
      "Train Epoch: 7 [108800/697932 (16%)]\tLoss: 3.179624\n",
      "Train Epoch: 7 [109440/697932 (16%)]\tLoss: 3.173135\n",
      "Train Epoch: 7 [110080/697932 (16%)]\tLoss: 3.170514\n",
      "Train Epoch: 7 [110720/697932 (16%)]\tLoss: 3.165708\n",
      "Train Epoch: 7 [111360/697932 (16%)]\tLoss: 3.177460\n",
      "Train Epoch: 7 [112000/697932 (16%)]\tLoss: 3.167414\n",
      "Train Epoch: 7 [112640/697932 (16%)]\tLoss: 3.174129\n",
      "Train Epoch: 7 [113280/697932 (16%)]\tLoss: 3.170346\n",
      "Train Epoch: 7 [113920/697932 (16%)]\tLoss: 3.190111\n",
      "Train Epoch: 7 [114560/697932 (16%)]\tLoss: 3.158997\n",
      "Train Epoch: 7 [115200/697932 (17%)]\tLoss: 3.159059\n",
      "Train Epoch: 7 [115840/697932 (17%)]\tLoss: 3.161124\n",
      "Train Epoch: 7 [116480/697932 (17%)]\tLoss: 3.164018\n",
      "Train Epoch: 7 [117120/697932 (17%)]\tLoss: 3.205535\n",
      "Train Epoch: 7 [117760/697932 (17%)]\tLoss: 3.186723\n",
      "Train Epoch: 7 [118400/697932 (17%)]\tLoss: 3.150785\n",
      "Train Epoch: 7 [119040/697932 (17%)]\tLoss: 3.179815\n",
      "Train Epoch: 7 [119680/697932 (17%)]\tLoss: 3.164626\n",
      "Train Epoch: 7 [120320/697932 (17%)]\tLoss: 3.164435\n",
      "Train Epoch: 7 [120960/697932 (17%)]\tLoss: 3.204200\n",
      "Train Epoch: 7 [121600/697932 (17%)]\tLoss: 3.142417\n",
      "Train Epoch: 7 [122240/697932 (18%)]\tLoss: 3.162450\n",
      "Train Epoch: 7 [122880/697932 (18%)]\tLoss: 3.188426\n",
      "Train Epoch: 7 [123520/697932 (18%)]\tLoss: 3.177000\n",
      "Train Epoch: 7 [124160/697932 (18%)]\tLoss: 3.160723\n",
      "Train Epoch: 7 [124800/697932 (18%)]\tLoss: 3.176739\n",
      "Train Epoch: 7 [125440/697932 (18%)]\tLoss: 3.157799\n",
      "Train Epoch: 7 [126080/697932 (18%)]\tLoss: 3.160625\n",
      "Train Epoch: 7 [126720/697932 (18%)]\tLoss: 3.174682\n",
      "Train Epoch: 7 [127360/697932 (18%)]\tLoss: 3.209024\n",
      "Train Epoch: 7 [128000/697932 (18%)]\tLoss: 3.156322\n",
      "Train Epoch: 7 [128640/697932 (18%)]\tLoss: 3.152026\n",
      "Train Epoch: 7 [129280/697932 (19%)]\tLoss: 3.153907\n",
      "Train Epoch: 7 [129920/697932 (19%)]\tLoss: 3.174590\n",
      "Train Epoch: 7 [130560/697932 (19%)]\tLoss: 3.162100\n",
      "Train Epoch: 7 [131200/697932 (19%)]\tLoss: 3.156195\n",
      "Train Epoch: 7 [131840/697932 (19%)]\tLoss: 3.162125\n",
      "Train Epoch: 7 [132480/697932 (19%)]\tLoss: 3.188801\n",
      "Train Epoch: 7 [133120/697932 (19%)]\tLoss: 3.157416\n",
      "Train Epoch: 7 [133760/697932 (19%)]\tLoss: 3.165565\n",
      "Train Epoch: 7 [134400/697932 (19%)]\tLoss: 3.159976\n",
      "Train Epoch: 7 [135040/697932 (19%)]\tLoss: 3.175312\n",
      "Train Epoch: 7 [135680/697932 (19%)]\tLoss: 3.186741\n",
      "Train Epoch: 7 [136320/697932 (20%)]\tLoss: 3.161937\n",
      "Train Epoch: 7 [136960/697932 (20%)]\tLoss: 3.168607\n",
      "Train Epoch: 7 [137600/697932 (20%)]\tLoss: 3.197036\n",
      "Train Epoch: 7 [138240/697932 (20%)]\tLoss: 3.152886\n",
      "Train Epoch: 7 [138880/697932 (20%)]\tLoss: 3.138969\n",
      "Train Epoch: 7 [139520/697932 (20%)]\tLoss: 3.166499\n",
      "Train Epoch: 7 [140160/697932 (20%)]\tLoss: 3.181537\n",
      "Train Epoch: 7 [140800/697932 (20%)]\tLoss: 3.171535\n",
      "Train Epoch: 7 [141440/697932 (20%)]\tLoss: 3.170762\n",
      "Train Epoch: 7 [142080/697932 (20%)]\tLoss: 3.172662\n",
      "Train Epoch: 7 [142720/697932 (20%)]\tLoss: 3.168463\n",
      "Train Epoch: 7 [143360/697932 (21%)]\tLoss: 3.174715\n",
      "Train Epoch: 7 [144000/697932 (21%)]\tLoss: 3.148479\n",
      "Train Epoch: 7 [144640/697932 (21%)]\tLoss: 3.137918\n",
      "Train Epoch: 7 [145280/697932 (21%)]\tLoss: 3.194131\n",
      "Train Epoch: 7 [145920/697932 (21%)]\tLoss: 3.163031\n",
      "Train Epoch: 7 [146560/697932 (21%)]\tLoss: 3.177813\n",
      "Train Epoch: 7 [147200/697932 (21%)]\tLoss: 3.149233\n",
      "Train Epoch: 7 [147840/697932 (21%)]\tLoss: 3.165300\n",
      "Train Epoch: 7 [148480/697932 (21%)]\tLoss: 3.174469\n",
      "Train Epoch: 7 [149120/697932 (21%)]\tLoss: 3.160868\n",
      "Train Epoch: 7 [149760/697932 (21%)]\tLoss: 3.168674\n",
      "Train Epoch: 7 [150400/697932 (22%)]\tLoss: 3.152440\n",
      "Train Epoch: 7 [151040/697932 (22%)]\tLoss: 3.206744\n",
      "Train Epoch: 7 [151680/697932 (22%)]\tLoss: 3.168036\n",
      "Train Epoch: 7 [152320/697932 (22%)]\tLoss: 3.181952\n",
      "Train Epoch: 7 [152960/697932 (22%)]\tLoss: 3.169505\n",
      "Train Epoch: 7 [153600/697932 (22%)]\tLoss: 3.161862\n",
      "Train Epoch: 7 [154240/697932 (22%)]\tLoss: 3.185184\n",
      "Train Epoch: 7 [154880/697932 (22%)]\tLoss: 3.178224\n",
      "Train Epoch: 7 [155520/697932 (22%)]\tLoss: 3.182039\n",
      "Train Epoch: 7 [156160/697932 (22%)]\tLoss: 3.175487\n",
      "Train Epoch: 7 [156800/697932 (22%)]\tLoss: 3.181490\n",
      "Train Epoch: 7 [157440/697932 (23%)]\tLoss: 3.171488\n",
      "Train Epoch: 7 [158080/697932 (23%)]\tLoss: 3.172375\n",
      "Train Epoch: 7 [158720/697932 (23%)]\tLoss: 3.171876\n",
      "Train Epoch: 7 [159360/697932 (23%)]\tLoss: 3.169396\n",
      "Train Epoch: 7 [160000/697932 (23%)]\tLoss: 3.169606\n",
      "Train Epoch: 7 [160640/697932 (23%)]\tLoss: 3.156708\n",
      "Train Epoch: 7 [161280/697932 (23%)]\tLoss: 3.171810\n",
      "Train Epoch: 7 [161920/697932 (23%)]\tLoss: 3.167997\n",
      "Train Epoch: 7 [162560/697932 (23%)]\tLoss: 3.159290\n",
      "Train Epoch: 7 [163200/697932 (23%)]\tLoss: 3.184959\n",
      "Train Epoch: 7 [163840/697932 (23%)]\tLoss: 3.183907\n",
      "Train Epoch: 7 [164480/697932 (24%)]\tLoss: 3.178678\n",
      "Train Epoch: 7 [165120/697932 (24%)]\tLoss: 3.152323\n",
      "Train Epoch: 7 [165760/697932 (24%)]\tLoss: 3.175063\n",
      "Train Epoch: 7 [166400/697932 (24%)]\tLoss: 3.152211\n",
      "Train Epoch: 7 [167040/697932 (24%)]\tLoss: 3.143314\n",
      "Train Epoch: 7 [167680/697932 (24%)]\tLoss: 3.189813\n",
      "Train Epoch: 7 [168320/697932 (24%)]\tLoss: 3.163403\n",
      "Train Epoch: 7 [168960/697932 (24%)]\tLoss: 3.189511\n",
      "Train Epoch: 7 [169600/697932 (24%)]\tLoss: 3.178365\n",
      "Train Epoch: 7 [170240/697932 (24%)]\tLoss: 3.144017\n",
      "Train Epoch: 7 [170880/697932 (24%)]\tLoss: 3.186195\n",
      "Train Epoch: 7 [171520/697932 (25%)]\tLoss: 3.177741\n",
      "Train Epoch: 7 [172160/697932 (25%)]\tLoss: 3.186863\n",
      "Train Epoch: 7 [172800/697932 (25%)]\tLoss: 3.177586\n",
      "Train Epoch: 7 [173440/697932 (25%)]\tLoss: 3.195400\n",
      "Train Epoch: 7 [174080/697932 (25%)]\tLoss: 3.183315\n",
      "Train Epoch: 7 [174720/697932 (25%)]\tLoss: 3.180470\n",
      "Train Epoch: 7 [175360/697932 (25%)]\tLoss: 3.184376\n",
      "Train Epoch: 7 [176000/697932 (25%)]\tLoss: 3.169456\n",
      "Train Epoch: 7 [176640/697932 (25%)]\tLoss: 3.143770\n",
      "Train Epoch: 7 [177280/697932 (25%)]\tLoss: 3.161106\n",
      "Train Epoch: 7 [177920/697932 (25%)]\tLoss: 3.169481\n",
      "Train Epoch: 7 [178560/697932 (26%)]\tLoss: 3.144321\n",
      "Train Epoch: 7 [179200/697932 (26%)]\tLoss: 3.158393\n",
      "Train Epoch: 7 [179840/697932 (26%)]\tLoss: 3.184198\n",
      "Train Epoch: 7 [180480/697932 (26%)]\tLoss: 3.162734\n",
      "Train Epoch: 7 [181120/697932 (26%)]\tLoss: 3.180523\n",
      "Train Epoch: 7 [181760/697932 (26%)]\tLoss: 3.179735\n",
      "Train Epoch: 7 [182400/697932 (26%)]\tLoss: 3.148670\n",
      "Train Epoch: 7 [183040/697932 (26%)]\tLoss: 3.184157\n",
      "Train Epoch: 7 [183680/697932 (26%)]\tLoss: 3.169973\n",
      "Train Epoch: 7 [184320/697932 (26%)]\tLoss: 3.175035\n",
      "Train Epoch: 7 [184960/697932 (26%)]\tLoss: 3.168411\n",
      "Train Epoch: 7 [185600/697932 (27%)]\tLoss: 3.190927\n",
      "Train Epoch: 7 [186240/697932 (27%)]\tLoss: 3.185536\n",
      "Train Epoch: 7 [186880/697932 (27%)]\tLoss: 3.176476\n",
      "Train Epoch: 7 [187520/697932 (27%)]\tLoss: 3.184304\n",
      "Train Epoch: 7 [188160/697932 (27%)]\tLoss: 3.154361\n",
      "Train Epoch: 7 [188800/697932 (27%)]\tLoss: 3.190738\n",
      "Train Epoch: 7 [189440/697932 (27%)]\tLoss: 3.176148\n",
      "Train Epoch: 7 [190080/697932 (27%)]\tLoss: 3.205605\n",
      "Train Epoch: 7 [190720/697932 (27%)]\tLoss: 3.148231\n",
      "Train Epoch: 7 [191360/697932 (27%)]\tLoss: 3.174834\n",
      "Train Epoch: 7 [192000/697932 (28%)]\tLoss: 3.179045\n",
      "Train Epoch: 7 [192640/697932 (28%)]\tLoss: 3.171773\n",
      "Train Epoch: 7 [193280/697932 (28%)]\tLoss: 3.154648\n",
      "Train Epoch: 7 [193920/697932 (28%)]\tLoss: 3.184607\n",
      "Train Epoch: 7 [194560/697932 (28%)]\tLoss: 3.167181\n",
      "Train Epoch: 7 [195200/697932 (28%)]\tLoss: 3.155596\n",
      "Train Epoch: 7 [195840/697932 (28%)]\tLoss: 3.176106\n",
      "Train Epoch: 7 [196480/697932 (28%)]\tLoss: 3.173542\n",
      "Train Epoch: 7 [197120/697932 (28%)]\tLoss: 3.150791\n",
      "Train Epoch: 7 [197760/697932 (28%)]\tLoss: 3.175817\n",
      "Train Epoch: 7 [198400/697932 (28%)]\tLoss: 3.176408\n",
      "Train Epoch: 7 [199040/697932 (29%)]\tLoss: 3.181931\n",
      "Train Epoch: 7 [199680/697932 (29%)]\tLoss: 3.176842\n",
      "Train Epoch: 7 [200320/697932 (29%)]\tLoss: 3.176304\n",
      "Train Epoch: 7 [200960/697932 (29%)]\tLoss: 3.168488\n",
      "Train Epoch: 7 [201600/697932 (29%)]\tLoss: 3.179520\n",
      "Train Epoch: 7 [202240/697932 (29%)]\tLoss: 3.159441\n",
      "Train Epoch: 7 [202880/697932 (29%)]\tLoss: 3.168523\n",
      "Train Epoch: 7 [203520/697932 (29%)]\tLoss: 3.193829\n",
      "Train Epoch: 7 [204160/697932 (29%)]\tLoss: 3.180955\n",
      "Train Epoch: 7 [204800/697932 (29%)]\tLoss: 3.167584\n",
      "Train Epoch: 7 [205440/697932 (29%)]\tLoss: 3.163817\n",
      "Train Epoch: 7 [206080/697932 (30%)]\tLoss: 3.167436\n",
      "Train Epoch: 7 [206720/697932 (30%)]\tLoss: 3.175551\n",
      "Train Epoch: 7 [207360/697932 (30%)]\tLoss: 3.141289\n",
      "Train Epoch: 7 [208000/697932 (30%)]\tLoss: 3.178057\n",
      "Train Epoch: 7 [208640/697932 (30%)]\tLoss: 3.190031\n",
      "Train Epoch: 7 [209280/697932 (30%)]\tLoss: 3.164748\n",
      "Train Epoch: 7 [209920/697932 (30%)]\tLoss: 3.152799\n",
      "Train Epoch: 7 [210560/697932 (30%)]\tLoss: 3.171751\n",
      "Train Epoch: 7 [211200/697932 (30%)]\tLoss: 3.167179\n",
      "Train Epoch: 7 [211840/697932 (30%)]\tLoss: 3.149727\n",
      "Train Epoch: 7 [212480/697932 (30%)]\tLoss: 3.165067\n",
      "Train Epoch: 7 [213120/697932 (31%)]\tLoss: 3.159580\n",
      "Train Epoch: 7 [213760/697932 (31%)]\tLoss: 3.156373\n",
      "Train Epoch: 7 [214400/697932 (31%)]\tLoss: 3.180582\n",
      "Train Epoch: 7 [215040/697932 (31%)]\tLoss: 3.169182\n",
      "Train Epoch: 7 [215680/697932 (31%)]\tLoss: 3.151513\n",
      "Train Epoch: 7 [216320/697932 (31%)]\tLoss: 3.180292\n",
      "Train Epoch: 7 [216960/697932 (31%)]\tLoss: 3.164310\n",
      "Train Epoch: 7 [217600/697932 (31%)]\tLoss: 3.184512\n",
      "Train Epoch: 7 [218240/697932 (31%)]\tLoss: 3.174665\n",
      "Train Epoch: 7 [218880/697932 (31%)]\tLoss: 3.172907\n",
      "Train Epoch: 7 [219520/697932 (31%)]\tLoss: 3.164771\n",
      "Train Epoch: 7 [220160/697932 (32%)]\tLoss: 3.206634\n",
      "Train Epoch: 7 [220800/697932 (32%)]\tLoss: 3.158991\n",
      "Train Epoch: 7 [221440/697932 (32%)]\tLoss: 3.158289\n",
      "Train Epoch: 7 [222080/697932 (32%)]\tLoss: 3.188401\n",
      "Train Epoch: 7 [222720/697932 (32%)]\tLoss: 3.174703\n",
      "Train Epoch: 7 [223360/697932 (32%)]\tLoss: 3.150965\n",
      "Train Epoch: 7 [224000/697932 (32%)]\tLoss: 3.162590\n",
      "Train Epoch: 7 [224640/697932 (32%)]\tLoss: 3.189358\n",
      "Train Epoch: 7 [225280/697932 (32%)]\tLoss: 3.165393\n",
      "Train Epoch: 7 [225920/697932 (32%)]\tLoss: 3.166268\n",
      "Train Epoch: 7 [226560/697932 (32%)]\tLoss: 3.161443\n",
      "Train Epoch: 7 [227200/697932 (33%)]\tLoss: 3.178369\n",
      "Train Epoch: 7 [227840/697932 (33%)]\tLoss: 3.161172\n",
      "Train Epoch: 7 [228480/697932 (33%)]\tLoss: 3.180208\n",
      "Train Epoch: 7 [229120/697932 (33%)]\tLoss: 3.147832\n",
      "Train Epoch: 7 [229760/697932 (33%)]\tLoss: 3.170093\n",
      "Train Epoch: 7 [230400/697932 (33%)]\tLoss: 3.172675\n",
      "Train Epoch: 7 [231040/697932 (33%)]\tLoss: 3.150404\n",
      "Train Epoch: 7 [231680/697932 (33%)]\tLoss: 3.169670\n",
      "Train Epoch: 7 [232320/697932 (33%)]\tLoss: 3.143679\n",
      "Train Epoch: 7 [232960/697932 (33%)]\tLoss: 3.179394\n",
      "Train Epoch: 7 [233600/697932 (33%)]\tLoss: 3.154228\n",
      "Train Epoch: 7 [234240/697932 (34%)]\tLoss: 3.162055\n",
      "Train Epoch: 7 [234880/697932 (34%)]\tLoss: 3.174446\n",
      "Train Epoch: 7 [235520/697932 (34%)]\tLoss: 3.162567\n",
      "Train Epoch: 7 [236160/697932 (34%)]\tLoss: 3.190142\n",
      "Train Epoch: 7 [236800/697932 (34%)]\tLoss: 3.148442\n",
      "Train Epoch: 7 [237440/697932 (34%)]\tLoss: 3.163849\n",
      "Train Epoch: 7 [238080/697932 (34%)]\tLoss: 3.177686\n",
      "Train Epoch: 7 [238720/697932 (34%)]\tLoss: 3.164584\n",
      "Train Epoch: 7 [239360/697932 (34%)]\tLoss: 3.188615\n",
      "Train Epoch: 7 [240000/697932 (34%)]\tLoss: 3.145586\n",
      "Train Epoch: 7 [240640/697932 (34%)]\tLoss: 3.182834\n",
      "Train Epoch: 7 [241280/697932 (35%)]\tLoss: 3.145055\n",
      "Train Epoch: 7 [241920/697932 (35%)]\tLoss: 3.148667\n",
      "Train Epoch: 7 [242560/697932 (35%)]\tLoss: 3.174176\n",
      "Train Epoch: 7 [243200/697932 (35%)]\tLoss: 3.139516\n",
      "Train Epoch: 7 [243840/697932 (35%)]\tLoss: 3.160800\n",
      "Train Epoch: 7 [244480/697932 (35%)]\tLoss: 3.172962\n",
      "Train Epoch: 7 [245120/697932 (35%)]\tLoss: 3.168731\n",
      "Train Epoch: 7 [245760/697932 (35%)]\tLoss: 3.173204\n",
      "Train Epoch: 7 [246400/697932 (35%)]\tLoss: 3.155346\n",
      "Train Epoch: 7 [247040/697932 (35%)]\tLoss: 3.179140\n",
      "Train Epoch: 7 [247680/697932 (35%)]\tLoss: 3.153325\n",
      "Train Epoch: 7 [248320/697932 (36%)]\tLoss: 3.172621\n",
      "Train Epoch: 7 [248960/697932 (36%)]\tLoss: 3.185301\n",
      "Train Epoch: 7 [249600/697932 (36%)]\tLoss: 3.173593\n",
      "Train Epoch: 7 [250240/697932 (36%)]\tLoss: 3.180594\n",
      "Train Epoch: 7 [250880/697932 (36%)]\tLoss: 3.167657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [251520/697932 (36%)]\tLoss: 3.162620\n",
      "Train Epoch: 7 [252160/697932 (36%)]\tLoss: 3.181675\n",
      "Train Epoch: 7 [252800/697932 (36%)]\tLoss: 3.135291\n",
      "Train Epoch: 7 [253440/697932 (36%)]\tLoss: 3.152874\n",
      "Train Epoch: 7 [254080/697932 (36%)]\tLoss: 3.176054\n",
      "Train Epoch: 7 [254720/697932 (36%)]\tLoss: 3.133242\n",
      "Train Epoch: 7 [255360/697932 (37%)]\tLoss: 3.161963\n",
      "Train Epoch: 7 [256000/697932 (37%)]\tLoss: 3.142713\n",
      "Train Epoch: 7 [256640/697932 (37%)]\tLoss: 3.153813\n",
      "Train Epoch: 7 [257280/697932 (37%)]\tLoss: 3.136864\n",
      "Train Epoch: 7 [257920/697932 (37%)]\tLoss: 3.170960\n",
      "Train Epoch: 7 [258560/697932 (37%)]\tLoss: 3.148501\n",
      "Train Epoch: 7 [259200/697932 (37%)]\tLoss: 3.173924\n",
      "Train Epoch: 7 [259840/697932 (37%)]\tLoss: 3.155731\n",
      "Train Epoch: 7 [260480/697932 (37%)]\tLoss: 3.182516\n",
      "Train Epoch: 7 [261120/697932 (37%)]\tLoss: 3.169440\n",
      "Train Epoch: 7 [261760/697932 (38%)]\tLoss: 3.168545\n",
      "Train Epoch: 7 [262400/697932 (38%)]\tLoss: 3.177363\n",
      "Train Epoch: 7 [263040/697932 (38%)]\tLoss: 3.151068\n",
      "Train Epoch: 7 [263680/697932 (38%)]\tLoss: 3.167194\n",
      "Train Epoch: 7 [264320/697932 (38%)]\tLoss: 3.156418\n",
      "Train Epoch: 7 [264960/697932 (38%)]\tLoss: 3.158742\n",
      "Train Epoch: 7 [265600/697932 (38%)]\tLoss: 3.145981\n",
      "Train Epoch: 7 [266240/697932 (38%)]\tLoss: 3.142626\n",
      "Train Epoch: 7 [266880/697932 (38%)]\tLoss: 3.166017\n",
      "Train Epoch: 7 [267520/697932 (38%)]\tLoss: 3.150856\n",
      "Train Epoch: 7 [268160/697932 (38%)]\tLoss: 3.182009\n",
      "Train Epoch: 7 [268800/697932 (39%)]\tLoss: 3.205096\n",
      "Train Epoch: 7 [269440/697932 (39%)]\tLoss: 3.170057\n",
      "Train Epoch: 7 [270080/697932 (39%)]\tLoss: 3.187853\n",
      "Train Epoch: 7 [270720/697932 (39%)]\tLoss: 3.168147\n",
      "Train Epoch: 7 [271360/697932 (39%)]\tLoss: 3.151471\n",
      "Train Epoch: 7 [272000/697932 (39%)]\tLoss: 3.150486\n",
      "Train Epoch: 7 [272640/697932 (39%)]\tLoss: 3.183308\n",
      "Train Epoch: 7 [273280/697932 (39%)]\tLoss: 3.155140\n",
      "Train Epoch: 7 [273920/697932 (39%)]\tLoss: 3.148539\n",
      "Train Epoch: 7 [274560/697932 (39%)]\tLoss: 3.188329\n",
      "Train Epoch: 7 [275200/697932 (39%)]\tLoss: 3.150174\n",
      "Train Epoch: 7 [275840/697932 (40%)]\tLoss: 3.170474\n",
      "Train Epoch: 7 [276480/697932 (40%)]\tLoss: 3.189746\n",
      "Train Epoch: 7 [277120/697932 (40%)]\tLoss: 3.150435\n",
      "Train Epoch: 7 [277760/697932 (40%)]\tLoss: 3.171218\n",
      "Train Epoch: 7 [278400/697932 (40%)]\tLoss: 3.147753\n",
      "Train Epoch: 7 [279040/697932 (40%)]\tLoss: 3.182693\n",
      "Train Epoch: 7 [279680/697932 (40%)]\tLoss: 3.161328\n",
      "Train Epoch: 7 [280320/697932 (40%)]\tLoss: 3.193142\n",
      "Train Epoch: 7 [280960/697932 (40%)]\tLoss: 3.170466\n",
      "Train Epoch: 7 [281600/697932 (40%)]\tLoss: 3.179673\n",
      "Train Epoch: 7 [282240/697932 (40%)]\tLoss: 3.195547\n",
      "Train Epoch: 7 [282880/697932 (41%)]\tLoss: 3.146216\n",
      "Train Epoch: 7 [283520/697932 (41%)]\tLoss: 3.177257\n",
      "Train Epoch: 7 [284160/697932 (41%)]\tLoss: 3.165766\n",
      "Train Epoch: 7 [284800/697932 (41%)]\tLoss: 3.177952\n",
      "Train Epoch: 7 [285440/697932 (41%)]\tLoss: 3.174700\n",
      "Train Epoch: 7 [286080/697932 (41%)]\tLoss: 3.176923\n",
      "Train Epoch: 7 [286720/697932 (41%)]\tLoss: 3.149038\n",
      "Train Epoch: 7 [287360/697932 (41%)]\tLoss: 3.166483\n",
      "Train Epoch: 7 [288000/697932 (41%)]\tLoss: 3.167067\n",
      "Train Epoch: 7 [288640/697932 (41%)]\tLoss: 3.162408\n",
      "Train Epoch: 7 [289280/697932 (41%)]\tLoss: 3.142448\n",
      "Train Epoch: 7 [289920/697932 (42%)]\tLoss: 3.158467\n",
      "Train Epoch: 7 [290560/697932 (42%)]\tLoss: 3.174102\n",
      "Train Epoch: 7 [291200/697932 (42%)]\tLoss: 3.173476\n",
      "Train Epoch: 7 [291840/697932 (42%)]\tLoss: 3.167538\n",
      "Train Epoch: 7 [292480/697932 (42%)]\tLoss: 3.128677\n",
      "Train Epoch: 7 [293120/697932 (42%)]\tLoss: 3.168050\n",
      "Train Epoch: 7 [293760/697932 (42%)]\tLoss: 3.157572\n",
      "Train Epoch: 7 [294400/697932 (42%)]\tLoss: 3.168822\n",
      "Train Epoch: 7 [295040/697932 (42%)]\tLoss: 3.171748\n",
      "Train Epoch: 7 [295680/697932 (42%)]\tLoss: 3.153609\n",
      "Train Epoch: 7 [296320/697932 (42%)]\tLoss: 3.143971\n",
      "Train Epoch: 7 [296960/697932 (43%)]\tLoss: 3.172216\n",
      "Train Epoch: 7 [297600/697932 (43%)]\tLoss: 3.136167\n",
      "Train Epoch: 7 [298240/697932 (43%)]\tLoss: 3.186109\n",
      "Train Epoch: 7 [298880/697932 (43%)]\tLoss: 3.154184\n",
      "Train Epoch: 7 [299520/697932 (43%)]\tLoss: 3.174650\n",
      "Train Epoch: 7 [300160/697932 (43%)]\tLoss: 3.184385\n",
      "Train Epoch: 7 [300800/697932 (43%)]\tLoss: 3.196840\n",
      "Train Epoch: 7 [301440/697932 (43%)]\tLoss: 3.164923\n",
      "Train Epoch: 7 [302080/697932 (43%)]\tLoss: 3.183150\n",
      "Train Epoch: 7 [302720/697932 (43%)]\tLoss: 3.191687\n",
      "Train Epoch: 7 [303360/697932 (43%)]\tLoss: 3.179873\n",
      "Train Epoch: 7 [304000/697932 (44%)]\tLoss: 3.161576\n",
      "Train Epoch: 7 [304640/697932 (44%)]\tLoss: 3.171407\n",
      "Train Epoch: 7 [305280/697932 (44%)]\tLoss: 3.184895\n",
      "Train Epoch: 7 [305920/697932 (44%)]\tLoss: 3.173979\n",
      "Train Epoch: 7 [306560/697932 (44%)]\tLoss: 3.160862\n",
      "Train Epoch: 7 [307200/697932 (44%)]\tLoss: 3.176897\n",
      "Train Epoch: 7 [307840/697932 (44%)]\tLoss: 3.175043\n",
      "Train Epoch: 7 [308480/697932 (44%)]\tLoss: 3.173217\n",
      "Train Epoch: 7 [309120/697932 (44%)]\tLoss: 3.159698\n",
      "Train Epoch: 7 [309760/697932 (44%)]\tLoss: 3.183674\n",
      "Train Epoch: 7 [310400/697932 (44%)]\tLoss: 3.159137\n",
      "Train Epoch: 7 [311040/697932 (45%)]\tLoss: 3.180349\n",
      "Train Epoch: 7 [311680/697932 (45%)]\tLoss: 3.138899\n",
      "Train Epoch: 7 [312320/697932 (45%)]\tLoss: 3.148503\n",
      "Train Epoch: 7 [312960/697932 (45%)]\tLoss: 3.149729\n",
      "Train Epoch: 7 [313600/697932 (45%)]\tLoss: 3.178326\n",
      "Train Epoch: 7 [314240/697932 (45%)]\tLoss: 3.167806\n",
      "Train Epoch: 7 [314880/697932 (45%)]\tLoss: 3.163195\n",
      "Train Epoch: 7 [315520/697932 (45%)]\tLoss: 3.172978\n",
      "Train Epoch: 7 [316160/697932 (45%)]\tLoss: 3.165275\n",
      "Train Epoch: 7 [316800/697932 (45%)]\tLoss: 3.185225\n",
      "Train Epoch: 7 [317440/697932 (45%)]\tLoss: 3.158803\n",
      "Train Epoch: 7 [318080/697932 (46%)]\tLoss: 3.178850\n",
      "Train Epoch: 7 [318720/697932 (46%)]\tLoss: 3.177489\n",
      "Train Epoch: 7 [319360/697932 (46%)]\tLoss: 3.167961\n",
      "Train Epoch: 7 [320000/697932 (46%)]\tLoss: 3.139789\n",
      "Train Epoch: 7 [320640/697932 (46%)]\tLoss: 3.154079\n",
      "Train Epoch: 7 [321280/697932 (46%)]\tLoss: 3.172460\n",
      "Train Epoch: 7 [321920/697932 (46%)]\tLoss: 3.159064\n",
      "Train Epoch: 7 [322560/697932 (46%)]\tLoss: 3.164315\n",
      "Train Epoch: 7 [323200/697932 (46%)]\tLoss: 3.165507\n",
      "Train Epoch: 7 [323840/697932 (46%)]\tLoss: 3.168574\n",
      "Train Epoch: 7 [324480/697932 (46%)]\tLoss: 3.182875\n",
      "Train Epoch: 7 [325120/697932 (47%)]\tLoss: 3.142147\n",
      "Train Epoch: 7 [325760/697932 (47%)]\tLoss: 3.146518\n",
      "Train Epoch: 7 [326400/697932 (47%)]\tLoss: 3.191498\n",
      "Train Epoch: 7 [327040/697932 (47%)]\tLoss: 3.160104\n",
      "Train Epoch: 7 [327680/697932 (47%)]\tLoss: 3.174008\n",
      "Train Epoch: 7 [328320/697932 (47%)]\tLoss: 3.172853\n",
      "Train Epoch: 7 [328960/697932 (47%)]\tLoss: 3.161541\n",
      "Train Epoch: 7 [329600/697932 (47%)]\tLoss: 3.193941\n",
      "Train Epoch: 7 [330240/697932 (47%)]\tLoss: 3.164553\n",
      "Train Epoch: 7 [330880/697932 (47%)]\tLoss: 3.163384\n",
      "Train Epoch: 7 [331520/697932 (47%)]\tLoss: 3.163215\n",
      "Train Epoch: 7 [332160/697932 (48%)]\tLoss: 3.205233\n",
      "Train Epoch: 7 [332800/697932 (48%)]\tLoss: 3.156099\n",
      "Train Epoch: 7 [333440/697932 (48%)]\tLoss: 3.162603\n",
      "Train Epoch: 7 [334080/697932 (48%)]\tLoss: 3.164421\n",
      "Train Epoch: 7 [334720/697932 (48%)]\tLoss: 3.158158\n",
      "Train Epoch: 7 [335360/697932 (48%)]\tLoss: 3.152105\n",
      "Train Epoch: 7 [336000/697932 (48%)]\tLoss: 3.199729\n",
      "Train Epoch: 7 [336640/697932 (48%)]\tLoss: 3.157181\n",
      "Train Epoch: 7 [337280/697932 (48%)]\tLoss: 3.148990\n",
      "Train Epoch: 7 [337920/697932 (48%)]\tLoss: 3.154523\n",
      "Train Epoch: 7 [338560/697932 (49%)]\tLoss: 3.177533\n",
      "Train Epoch: 7 [339200/697932 (49%)]\tLoss: 3.142988\n",
      "Train Epoch: 7 [339840/697932 (49%)]\tLoss: 3.146949\n",
      "Train Epoch: 7 [340480/697932 (49%)]\tLoss: 3.179987\n",
      "Train Epoch: 7 [341120/697932 (49%)]\tLoss: 3.150162\n",
      "Train Epoch: 7 [341760/697932 (49%)]\tLoss: 3.171727\n",
      "Train Epoch: 7 [342400/697932 (49%)]\tLoss: 3.142229\n",
      "Train Epoch: 7 [343040/697932 (49%)]\tLoss: 3.130675\n",
      "Train Epoch: 7 [343680/697932 (49%)]\tLoss: 3.163223\n",
      "Train Epoch: 7 [344320/697932 (49%)]\tLoss: 3.173740\n",
      "Train Epoch: 7 [344960/697932 (49%)]\tLoss: 3.183986\n",
      "Train Epoch: 7 [345600/697932 (50%)]\tLoss: 3.172642\n",
      "Train Epoch: 7 [346240/697932 (50%)]\tLoss: 3.175483\n",
      "Train Epoch: 7 [346880/697932 (50%)]\tLoss: 3.165831\n",
      "Train Epoch: 7 [347520/697932 (50%)]\tLoss: 3.156305\n",
      "Train Epoch: 7 [348160/697932 (50%)]\tLoss: 3.164649\n",
      "Train Epoch: 7 [348800/697932 (50%)]\tLoss: 3.196124\n",
      "Train Epoch: 7 [349440/697932 (50%)]\tLoss: 3.138257\n",
      "Train Epoch: 7 [350080/697932 (50%)]\tLoss: 3.143934\n",
      "Train Epoch: 7 [350720/697932 (50%)]\tLoss: 3.158515\n",
      "Train Epoch: 7 [351360/697932 (50%)]\tLoss: 3.143662\n",
      "Train Epoch: 7 [352000/697932 (50%)]\tLoss: 3.167338\n",
      "Train Epoch: 7 [352640/697932 (51%)]\tLoss: 3.165462\n",
      "Train Epoch: 7 [353280/697932 (51%)]\tLoss: 3.176806\n",
      "Train Epoch: 7 [353920/697932 (51%)]\tLoss: 3.144023\n",
      "Train Epoch: 7 [354560/697932 (51%)]\tLoss: 3.171859\n",
      "Train Epoch: 7 [355200/697932 (51%)]\tLoss: 3.171268\n",
      "Train Epoch: 7 [355840/697932 (51%)]\tLoss: 3.176668\n",
      "Train Epoch: 7 [356480/697932 (51%)]\tLoss: 3.144098\n",
      "Train Epoch: 7 [357120/697932 (51%)]\tLoss: 3.160894\n",
      "Train Epoch: 7 [357760/697932 (51%)]\tLoss: 3.153767\n",
      "Train Epoch: 7 [358400/697932 (51%)]\tLoss: 3.154351\n",
      "Train Epoch: 7 [359040/697932 (51%)]\tLoss: 3.163377\n",
      "Train Epoch: 7 [359680/697932 (52%)]\tLoss: 3.185905\n",
      "Train Epoch: 7 [360320/697932 (52%)]\tLoss: 3.151126\n",
      "Train Epoch: 7 [360960/697932 (52%)]\tLoss: 3.206572\n",
      "Train Epoch: 7 [361600/697932 (52%)]\tLoss: 3.155031\n",
      "Train Epoch: 7 [362240/697932 (52%)]\tLoss: 3.189001\n",
      "Train Epoch: 7 [362880/697932 (52%)]\tLoss: 3.162226\n",
      "Train Epoch: 7 [363520/697932 (52%)]\tLoss: 3.170224\n",
      "Train Epoch: 7 [364160/697932 (52%)]\tLoss: 3.137519\n",
      "Train Epoch: 7 [364800/697932 (52%)]\tLoss: 3.192545\n",
      "Train Epoch: 7 [365440/697932 (52%)]\tLoss: 3.172148\n",
      "Train Epoch: 7 [366080/697932 (52%)]\tLoss: 3.172150\n",
      "Train Epoch: 7 [366720/697932 (53%)]\tLoss: 3.148721\n",
      "Train Epoch: 7 [367360/697932 (53%)]\tLoss: 3.165375\n",
      "Train Epoch: 7 [368000/697932 (53%)]\tLoss: 3.186273\n",
      "Train Epoch: 7 [368640/697932 (53%)]\tLoss: 3.174118\n",
      "Train Epoch: 7 [369280/697932 (53%)]\tLoss: 3.203342\n",
      "Train Epoch: 7 [369920/697932 (53%)]\tLoss: 3.171568\n",
      "Train Epoch: 7 [370560/697932 (53%)]\tLoss: 3.176130\n",
      "Train Epoch: 7 [371200/697932 (53%)]\tLoss: 3.147024\n",
      "Train Epoch: 7 [371840/697932 (53%)]\tLoss: 3.175582\n",
      "Train Epoch: 7 [372480/697932 (53%)]\tLoss: 3.161479\n",
      "Train Epoch: 7 [373120/697932 (53%)]\tLoss: 3.177583\n",
      "Train Epoch: 7 [373760/697932 (54%)]\tLoss: 3.139126\n",
      "Train Epoch: 7 [374400/697932 (54%)]\tLoss: 3.142812\n",
      "Train Epoch: 7 [375040/697932 (54%)]\tLoss: 3.182466\n",
      "Train Epoch: 7 [375680/697932 (54%)]\tLoss: 3.167118\n",
      "Train Epoch: 7 [376320/697932 (54%)]\tLoss: 3.205213\n",
      "Train Epoch: 7 [376960/697932 (54%)]\tLoss: 3.166274\n",
      "Train Epoch: 7 [377600/697932 (54%)]\tLoss: 3.162628\n",
      "Train Epoch: 7 [378240/697932 (54%)]\tLoss: 3.142018\n",
      "Train Epoch: 7 [378880/697932 (54%)]\tLoss: 3.153971\n",
      "Train Epoch: 7 [379520/697932 (54%)]\tLoss: 3.164707\n",
      "Train Epoch: 7 [380160/697932 (54%)]\tLoss: 3.180075\n",
      "Train Epoch: 7 [380800/697932 (55%)]\tLoss: 3.181772\n",
      "Train Epoch: 7 [381440/697932 (55%)]\tLoss: 3.155364\n",
      "Train Epoch: 7 [382080/697932 (55%)]\tLoss: 3.172031\n",
      "Train Epoch: 7 [382720/697932 (55%)]\tLoss: 3.159719\n",
      "Train Epoch: 7 [383360/697932 (55%)]\tLoss: 3.171674\n",
      "Train Epoch: 7 [384000/697932 (55%)]\tLoss: 3.192885\n",
      "Train Epoch: 7 [384640/697932 (55%)]\tLoss: 3.169947\n",
      "Train Epoch: 7 [385280/697932 (55%)]\tLoss: 3.150936\n",
      "Train Epoch: 7 [385920/697932 (55%)]\tLoss: 3.163351\n",
      "Train Epoch: 7 [386560/697932 (55%)]\tLoss: 3.178697\n",
      "Train Epoch: 7 [387200/697932 (55%)]\tLoss: 3.178322\n",
      "Train Epoch: 7 [387840/697932 (56%)]\tLoss: 3.168112\n",
      "Train Epoch: 7 [388480/697932 (56%)]\tLoss: 3.176830\n",
      "Train Epoch: 7 [389120/697932 (56%)]\tLoss: 3.193953\n",
      "Train Epoch: 7 [389760/697932 (56%)]\tLoss: 3.161794\n",
      "Train Epoch: 7 [390400/697932 (56%)]\tLoss: 3.144930\n",
      "Train Epoch: 7 [391040/697932 (56%)]\tLoss: 3.141609\n",
      "Train Epoch: 7 [391680/697932 (56%)]\tLoss: 3.188714\n",
      "Train Epoch: 7 [392320/697932 (56%)]\tLoss: 3.167266\n",
      "Train Epoch: 7 [392960/697932 (56%)]\tLoss: 3.173619\n",
      "Train Epoch: 7 [393600/697932 (56%)]\tLoss: 3.186049\n",
      "Train Epoch: 7 [394240/697932 (56%)]\tLoss: 3.176867\n",
      "Train Epoch: 7 [394880/697932 (57%)]\tLoss: 3.165295\n",
      "Train Epoch: 7 [395520/697932 (57%)]\tLoss: 3.153589\n",
      "Train Epoch: 7 [396160/697932 (57%)]\tLoss: 3.169514\n",
      "Train Epoch: 7 [396800/697932 (57%)]\tLoss: 3.155552\n",
      "Train Epoch: 7 [397440/697932 (57%)]\tLoss: 3.158012\n",
      "Train Epoch: 7 [398080/697932 (57%)]\tLoss: 3.186437\n",
      "Train Epoch: 7 [398720/697932 (57%)]\tLoss: 3.152493\n",
      "Train Epoch: 7 [399360/697932 (57%)]\tLoss: 3.176627\n",
      "Train Epoch: 7 [400000/697932 (57%)]\tLoss: 3.164450\n",
      "Train Epoch: 7 [400640/697932 (57%)]\tLoss: 3.189024\n",
      "Train Epoch: 7 [401280/697932 (57%)]\tLoss: 3.159737\n",
      "Train Epoch: 7 [401920/697932 (58%)]\tLoss: 3.162876\n",
      "Train Epoch: 7 [402560/697932 (58%)]\tLoss: 3.161766\n",
      "Train Epoch: 7 [403200/697932 (58%)]\tLoss: 3.164206\n",
      "Train Epoch: 7 [403840/697932 (58%)]\tLoss: 3.179217\n",
      "Train Epoch: 7 [404480/697932 (58%)]\tLoss: 3.159537\n",
      "Train Epoch: 7 [405120/697932 (58%)]\tLoss: 3.178867\n",
      "Train Epoch: 7 [405760/697932 (58%)]\tLoss: 3.175069\n",
      "Train Epoch: 7 [406400/697932 (58%)]\tLoss: 3.195596\n",
      "Train Epoch: 7 [407040/697932 (58%)]\tLoss: 3.161823\n",
      "Train Epoch: 7 [407680/697932 (58%)]\tLoss: 3.168455\n",
      "Train Epoch: 7 [408320/697932 (58%)]\tLoss: 3.164366\n",
      "Train Epoch: 7 [408960/697932 (59%)]\tLoss: 3.172447\n",
      "Train Epoch: 7 [409600/697932 (59%)]\tLoss: 3.179177\n",
      "Train Epoch: 7 [410240/697932 (59%)]\tLoss: 3.175350\n",
      "Train Epoch: 7 [410880/697932 (59%)]\tLoss: 3.178163\n",
      "Train Epoch: 7 [411520/697932 (59%)]\tLoss: 3.167964\n",
      "Train Epoch: 7 [412160/697932 (59%)]\tLoss: 3.154291\n",
      "Train Epoch: 7 [412800/697932 (59%)]\tLoss: 3.171888\n",
      "Train Epoch: 7 [413440/697932 (59%)]\tLoss: 3.173073\n",
      "Train Epoch: 7 [414080/697932 (59%)]\tLoss: 3.186948\n",
      "Train Epoch: 7 [414720/697932 (59%)]\tLoss: 3.160311\n",
      "Train Epoch: 7 [415360/697932 (60%)]\tLoss: 3.157460\n",
      "Train Epoch: 7 [416000/697932 (60%)]\tLoss: 3.134785\n",
      "Train Epoch: 7 [416640/697932 (60%)]\tLoss: 3.157258\n",
      "Train Epoch: 7 [417280/697932 (60%)]\tLoss: 3.179832\n",
      "Train Epoch: 7 [417920/697932 (60%)]\tLoss: 3.153851\n",
      "Train Epoch: 7 [418560/697932 (60%)]\tLoss: 3.176716\n",
      "Train Epoch: 7 [419200/697932 (60%)]\tLoss: 3.174873\n",
      "Train Epoch: 7 [419840/697932 (60%)]\tLoss: 3.148285\n",
      "Train Epoch: 7 [420480/697932 (60%)]\tLoss: 3.198101\n",
      "Train Epoch: 7 [421120/697932 (60%)]\tLoss: 3.164677\n",
      "Train Epoch: 7 [421760/697932 (60%)]\tLoss: 3.179626\n",
      "Train Epoch: 7 [422400/697932 (61%)]\tLoss: 3.158835\n",
      "Train Epoch: 7 [423040/697932 (61%)]\tLoss: 3.187429\n",
      "Train Epoch: 7 [423680/697932 (61%)]\tLoss: 3.137522\n",
      "Train Epoch: 7 [424320/697932 (61%)]\tLoss: 3.172631\n",
      "Train Epoch: 7 [424960/697932 (61%)]\tLoss: 3.167868\n",
      "Train Epoch: 7 [425600/697932 (61%)]\tLoss: 3.167400\n",
      "Train Epoch: 7 [426240/697932 (61%)]\tLoss: 3.159689\n",
      "Train Epoch: 7 [426880/697932 (61%)]\tLoss: 3.144754\n",
      "Train Epoch: 7 [427520/697932 (61%)]\tLoss: 3.171564\n",
      "Train Epoch: 7 [428160/697932 (61%)]\tLoss: 3.148020\n",
      "Train Epoch: 7 [428800/697932 (61%)]\tLoss: 3.155887\n",
      "Train Epoch: 7 [429440/697932 (62%)]\tLoss: 3.166018\n",
      "Train Epoch: 7 [430080/697932 (62%)]\tLoss: 3.170255\n",
      "Train Epoch: 7 [430720/697932 (62%)]\tLoss: 3.159215\n",
      "Train Epoch: 7 [431360/697932 (62%)]\tLoss: 3.160493\n",
      "Train Epoch: 7 [432000/697932 (62%)]\tLoss: 3.166423\n",
      "Train Epoch: 7 [432640/697932 (62%)]\tLoss: 3.141716\n",
      "Train Epoch: 7 [433280/697932 (62%)]\tLoss: 3.163172\n",
      "Train Epoch: 7 [433920/697932 (62%)]\tLoss: 3.151445\n",
      "Train Epoch: 7 [434560/697932 (62%)]\tLoss: 3.150577\n",
      "Train Epoch: 7 [435200/697932 (62%)]\tLoss: 3.149973\n",
      "Train Epoch: 7 [435840/697932 (62%)]\tLoss: 3.162641\n",
      "Train Epoch: 7 [436480/697932 (63%)]\tLoss: 3.138138\n",
      "Train Epoch: 7 [437120/697932 (63%)]\tLoss: 3.178719\n",
      "Train Epoch: 7 [437760/697932 (63%)]\tLoss: 3.181065\n",
      "Train Epoch: 7 [438400/697932 (63%)]\tLoss: 3.170818\n",
      "Train Epoch: 7 [439040/697932 (63%)]\tLoss: 3.151366\n",
      "Train Epoch: 7 [439680/697932 (63%)]\tLoss: 3.183799\n",
      "Train Epoch: 7 [440320/697932 (63%)]\tLoss: 3.189862\n",
      "Train Epoch: 7 [440960/697932 (63%)]\tLoss: 3.182673\n",
      "Train Epoch: 7 [441600/697932 (63%)]\tLoss: 3.167707\n",
      "Train Epoch: 7 [442240/697932 (63%)]\tLoss: 3.161554\n",
      "Train Epoch: 7 [442880/697932 (63%)]\tLoss: 3.186024\n",
      "Train Epoch: 7 [443520/697932 (64%)]\tLoss: 3.187636\n",
      "Train Epoch: 7 [444160/697932 (64%)]\tLoss: 3.153673\n",
      "Train Epoch: 7 [444800/697932 (64%)]\tLoss: 3.190542\n",
      "Train Epoch: 7 [445440/697932 (64%)]\tLoss: 3.186157\n",
      "Train Epoch: 7 [446080/697932 (64%)]\tLoss: 3.178045\n",
      "Train Epoch: 7 [446720/697932 (64%)]\tLoss: 3.178840\n",
      "Train Epoch: 7 [447360/697932 (64%)]\tLoss: 3.182895\n",
      "Train Epoch: 7 [448000/697932 (64%)]\tLoss: 3.184456\n",
      "Train Epoch: 7 [448640/697932 (64%)]\tLoss: 3.153280\n",
      "Train Epoch: 7 [449280/697932 (64%)]\tLoss: 3.129692\n",
      "Train Epoch: 7 [449920/697932 (64%)]\tLoss: 3.183191\n",
      "Train Epoch: 7 [450560/697932 (65%)]\tLoss: 3.158196\n",
      "Train Epoch: 7 [451200/697932 (65%)]\tLoss: 3.170632\n",
      "Train Epoch: 7 [451840/697932 (65%)]\tLoss: 3.183388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [452480/697932 (65%)]\tLoss: 3.195583\n",
      "Train Epoch: 7 [453120/697932 (65%)]\tLoss: 3.181825\n",
      "Train Epoch: 7 [453760/697932 (65%)]\tLoss: 3.139652\n",
      "Train Epoch: 7 [454400/697932 (65%)]\tLoss: 3.159777\n",
      "Train Epoch: 7 [455040/697932 (65%)]\tLoss: 3.161728\n",
      "Train Epoch: 7 [455680/697932 (65%)]\tLoss: 3.198882\n",
      "Train Epoch: 7 [456320/697932 (65%)]\tLoss: 3.162450\n",
      "Train Epoch: 7 [456960/697932 (65%)]\tLoss: 3.189126\n",
      "Train Epoch: 7 [457600/697932 (66%)]\tLoss: 3.145439\n",
      "Train Epoch: 7 [458240/697932 (66%)]\tLoss: 3.174820\n",
      "Train Epoch: 7 [458880/697932 (66%)]\tLoss: 3.186143\n",
      "Train Epoch: 7 [459520/697932 (66%)]\tLoss: 3.154026\n",
      "Train Epoch: 7 [460160/697932 (66%)]\tLoss: 3.159834\n",
      "Train Epoch: 7 [460800/697932 (66%)]\tLoss: 3.158658\n",
      "Train Epoch: 7 [461440/697932 (66%)]\tLoss: 3.183854\n",
      "Train Epoch: 7 [462080/697932 (66%)]\tLoss: 3.163373\n",
      "Train Epoch: 7 [462720/697932 (66%)]\tLoss: 3.199085\n",
      "Train Epoch: 7 [463360/697932 (66%)]\tLoss: 3.172015\n",
      "Train Epoch: 7 [464000/697932 (66%)]\tLoss: 3.166852\n",
      "Train Epoch: 7 [464640/697932 (67%)]\tLoss: 3.185006\n",
      "Train Epoch: 7 [465280/697932 (67%)]\tLoss: 3.155125\n",
      "Train Epoch: 7 [465920/697932 (67%)]\tLoss: 3.134939\n",
      "Train Epoch: 7 [466560/697932 (67%)]\tLoss: 3.200809\n",
      "Train Epoch: 7 [467200/697932 (67%)]\tLoss: 3.181096\n",
      "Train Epoch: 7 [467840/697932 (67%)]\tLoss: 3.178591\n",
      "Train Epoch: 7 [468480/697932 (67%)]\tLoss: 3.188338\n",
      "Train Epoch: 7 [469120/697932 (67%)]\tLoss: 3.160703\n",
      "Train Epoch: 7 [469760/697932 (67%)]\tLoss: 3.135590\n",
      "Train Epoch: 7 [470400/697932 (67%)]\tLoss: 3.150013\n",
      "Train Epoch: 7 [471040/697932 (67%)]\tLoss: 3.188108\n",
      "Train Epoch: 7 [471680/697932 (68%)]\tLoss: 3.178650\n",
      "Train Epoch: 7 [472320/697932 (68%)]\tLoss: 3.197613\n",
      "Train Epoch: 7 [472960/697932 (68%)]\tLoss: 3.163038\n",
      "Train Epoch: 7 [473600/697932 (68%)]\tLoss: 3.159154\n",
      "Train Epoch: 7 [474240/697932 (68%)]\tLoss: 3.132755\n",
      "Train Epoch: 7 [474880/697932 (68%)]\tLoss: 3.202692\n",
      "Train Epoch: 7 [475520/697932 (68%)]\tLoss: 3.178727\n",
      "Train Epoch: 7 [476160/697932 (68%)]\tLoss: 3.169393\n",
      "Train Epoch: 7 [476800/697932 (68%)]\tLoss: 3.168078\n",
      "Train Epoch: 7 [477440/697932 (68%)]\tLoss: 3.194857\n",
      "Train Epoch: 7 [478080/697932 (68%)]\tLoss: 3.156010\n",
      "Train Epoch: 7 [478720/697932 (69%)]\tLoss: 3.166320\n",
      "Train Epoch: 7 [479360/697932 (69%)]\tLoss: 3.174745\n",
      "Train Epoch: 7 [480000/697932 (69%)]\tLoss: 3.164437\n",
      "Train Epoch: 7 [480640/697932 (69%)]\tLoss: 3.197695\n",
      "Train Epoch: 7 [481280/697932 (69%)]\tLoss: 3.184041\n",
      "Train Epoch: 7 [481920/697932 (69%)]\tLoss: 3.177145\n",
      "Train Epoch: 7 [482560/697932 (69%)]\tLoss: 3.144381\n",
      "Train Epoch: 7 [483200/697932 (69%)]\tLoss: 3.186641\n",
      "Train Epoch: 7 [483840/697932 (69%)]\tLoss: 3.152546\n",
      "Train Epoch: 7 [484480/697932 (69%)]\tLoss: 3.191885\n",
      "Train Epoch: 7 [485120/697932 (70%)]\tLoss: 3.169768\n",
      "Train Epoch: 7 [485760/697932 (70%)]\tLoss: 3.187517\n",
      "Train Epoch: 7 [486400/697932 (70%)]\tLoss: 3.199280\n",
      "Train Epoch: 7 [487040/697932 (70%)]\tLoss: 3.170946\n",
      "Train Epoch: 7 [487680/697932 (70%)]\tLoss: 3.195315\n",
      "Train Epoch: 7 [488320/697932 (70%)]\tLoss: 3.179274\n",
      "Train Epoch: 7 [488960/697932 (70%)]\tLoss: 3.190865\n",
      "Train Epoch: 7 [489600/697932 (70%)]\tLoss: 3.161675\n",
      "Train Epoch: 7 [490240/697932 (70%)]\tLoss: 3.160681\n",
      "Train Epoch: 7 [490880/697932 (70%)]\tLoss: 3.173306\n",
      "Train Epoch: 7 [491520/697932 (70%)]\tLoss: 3.165696\n",
      "Train Epoch: 7 [492160/697932 (71%)]\tLoss: 3.169747\n",
      "Train Epoch: 7 [492800/697932 (71%)]\tLoss: 3.162393\n",
      "Train Epoch: 7 [493440/697932 (71%)]\tLoss: 3.183597\n",
      "Train Epoch: 7 [494080/697932 (71%)]\tLoss: 3.157653\n",
      "Train Epoch: 7 [494720/697932 (71%)]\tLoss: 3.154799\n",
      "Train Epoch: 7 [495360/697932 (71%)]\tLoss: 3.160601\n",
      "Train Epoch: 7 [496000/697932 (71%)]\tLoss: 3.161142\n",
      "Train Epoch: 7 [496640/697932 (71%)]\tLoss: 3.150536\n",
      "Train Epoch: 7 [497280/697932 (71%)]\tLoss: 3.154652\n",
      "Train Epoch: 7 [497920/697932 (71%)]\tLoss: 3.168648\n",
      "Train Epoch: 7 [498560/697932 (71%)]\tLoss: 3.173138\n",
      "Train Epoch: 7 [499200/697932 (72%)]\tLoss: 3.179948\n",
      "Train Epoch: 7 [499840/697932 (72%)]\tLoss: 3.171426\n",
      "Train Epoch: 7 [500480/697932 (72%)]\tLoss: 3.158669\n",
      "Train Epoch: 7 [501120/697932 (72%)]\tLoss: 3.162514\n",
      "Train Epoch: 7 [501760/697932 (72%)]\tLoss: 3.170052\n",
      "Train Epoch: 7 [502400/697932 (72%)]\tLoss: 3.170384\n",
      "Train Epoch: 7 [503040/697932 (72%)]\tLoss: 3.148264\n",
      "Train Epoch: 7 [503680/697932 (72%)]\tLoss: 3.164792\n",
      "Train Epoch: 7 [504320/697932 (72%)]\tLoss: 3.144059\n",
      "Train Epoch: 7 [504960/697932 (72%)]\tLoss: 3.182463\n",
      "Train Epoch: 7 [505600/697932 (72%)]\tLoss: 3.147143\n",
      "Train Epoch: 7 [506240/697932 (73%)]\tLoss: 3.159453\n",
      "Train Epoch: 7 [506880/697932 (73%)]\tLoss: 3.155391\n",
      "Train Epoch: 7 [507520/697932 (73%)]\tLoss: 3.175644\n",
      "Train Epoch: 7 [508160/697932 (73%)]\tLoss: 3.170212\n",
      "Train Epoch: 7 [508800/697932 (73%)]\tLoss: 3.170089\n",
      "Train Epoch: 7 [509440/697932 (73%)]\tLoss: 3.152052\n",
      "Train Epoch: 7 [510080/697932 (73%)]\tLoss: 3.176472\n",
      "Train Epoch: 7 [510720/697932 (73%)]\tLoss: 3.163567\n",
      "Train Epoch: 7 [511360/697932 (73%)]\tLoss: 3.145748\n",
      "Train Epoch: 7 [512000/697932 (73%)]\tLoss: 3.172696\n",
      "Train Epoch: 7 [512640/697932 (73%)]\tLoss: 3.219204\n",
      "Train Epoch: 7 [513280/697932 (74%)]\tLoss: 3.154251\n",
      "Train Epoch: 7 [513920/697932 (74%)]\tLoss: 3.146024\n",
      "Train Epoch: 7 [514560/697932 (74%)]\tLoss: 3.157758\n",
      "Train Epoch: 7 [515200/697932 (74%)]\tLoss: 3.156838\n",
      "Train Epoch: 7 [515840/697932 (74%)]\tLoss: 3.155091\n",
      "Train Epoch: 7 [516480/697932 (74%)]\tLoss: 3.185572\n",
      "Train Epoch: 7 [517120/697932 (74%)]\tLoss: 3.147121\n",
      "Train Epoch: 7 [517760/697932 (74%)]\tLoss: 3.147115\n",
      "Train Epoch: 7 [518400/697932 (74%)]\tLoss: 3.176666\n",
      "Train Epoch: 7 [519040/697932 (74%)]\tLoss: 3.157328\n",
      "Train Epoch: 7 [519680/697932 (74%)]\tLoss: 3.174356\n",
      "Train Epoch: 7 [520320/697932 (75%)]\tLoss: 3.145039\n",
      "Train Epoch: 7 [520960/697932 (75%)]\tLoss: 3.182669\n",
      "Train Epoch: 7 [521600/697932 (75%)]\tLoss: 3.139622\n",
      "Train Epoch: 7 [522240/697932 (75%)]\tLoss: 3.165845\n",
      "Train Epoch: 7 [522880/697932 (75%)]\tLoss: 3.158238\n",
      "Train Epoch: 7 [523520/697932 (75%)]\tLoss: 3.157914\n",
      "Train Epoch: 7 [524160/697932 (75%)]\tLoss: 3.172024\n",
      "Train Epoch: 7 [524800/697932 (75%)]\tLoss: 3.163042\n",
      "Train Epoch: 7 [525440/697932 (75%)]\tLoss: 3.164258\n",
      "Train Epoch: 7 [526080/697932 (75%)]\tLoss: 3.174063\n",
      "Train Epoch: 7 [526720/697932 (75%)]\tLoss: 3.166635\n",
      "Train Epoch: 7 [527360/697932 (76%)]\tLoss: 3.180604\n",
      "Train Epoch: 7 [528000/697932 (76%)]\tLoss: 3.212601\n",
      "Train Epoch: 7 [528640/697932 (76%)]\tLoss: 3.146653\n",
      "Train Epoch: 7 [529280/697932 (76%)]\tLoss: 3.184409\n",
      "Train Epoch: 7 [529920/697932 (76%)]\tLoss: 3.148417\n",
      "Train Epoch: 7 [530560/697932 (76%)]\tLoss: 3.181027\n",
      "Train Epoch: 7 [531200/697932 (76%)]\tLoss: 3.169354\n",
      "Train Epoch: 7 [531840/697932 (76%)]\tLoss: 3.160288\n",
      "Train Epoch: 7 [532480/697932 (76%)]\tLoss: 3.155754\n",
      "Train Epoch: 7 [533120/697932 (76%)]\tLoss: 3.157662\n",
      "Train Epoch: 7 [533760/697932 (76%)]\tLoss: 3.140989\n",
      "Train Epoch: 7 [534400/697932 (77%)]\tLoss: 3.149697\n",
      "Train Epoch: 7 [535040/697932 (77%)]\tLoss: 3.154539\n",
      "Train Epoch: 7 [535680/697932 (77%)]\tLoss: 3.186218\n",
      "Train Epoch: 7 [536320/697932 (77%)]\tLoss: 3.177999\n",
      "Train Epoch: 7 [536960/697932 (77%)]\tLoss: 3.162947\n",
      "Train Epoch: 7 [537600/697932 (77%)]\tLoss: 3.173667\n",
      "Train Epoch: 7 [538240/697932 (77%)]\tLoss: 3.179079\n",
      "Train Epoch: 7 [538880/697932 (77%)]\tLoss: 3.197172\n",
      "Train Epoch: 7 [539520/697932 (77%)]\tLoss: 3.152642\n",
      "Train Epoch: 7 [540160/697932 (77%)]\tLoss: 3.159441\n",
      "Train Epoch: 7 [540800/697932 (77%)]\tLoss: 3.155950\n",
      "Train Epoch: 7 [541440/697932 (78%)]\tLoss: 3.178727\n",
      "Train Epoch: 7 [542080/697932 (78%)]\tLoss: 3.163942\n",
      "Train Epoch: 7 [542720/697932 (78%)]\tLoss: 3.204649\n",
      "Train Epoch: 7 [543360/697932 (78%)]\tLoss: 3.155967\n",
      "Train Epoch: 7 [544000/697932 (78%)]\tLoss: 3.173875\n",
      "Train Epoch: 7 [544640/697932 (78%)]\tLoss: 3.170039\n",
      "Train Epoch: 7 [545280/697932 (78%)]\tLoss: 3.137792\n",
      "Train Epoch: 7 [545920/697932 (78%)]\tLoss: 3.172110\n",
      "Train Epoch: 7 [546560/697932 (78%)]\tLoss: 3.154016\n",
      "Train Epoch: 7 [547200/697932 (78%)]\tLoss: 3.180273\n",
      "Train Epoch: 7 [547840/697932 (78%)]\tLoss: 3.156115\n",
      "Train Epoch: 7 [548480/697932 (79%)]\tLoss: 3.181489\n",
      "Train Epoch: 7 [549120/697932 (79%)]\tLoss: 3.149504\n",
      "Train Epoch: 7 [549760/697932 (79%)]\tLoss: 3.153793\n",
      "Train Epoch: 7 [550400/697932 (79%)]\tLoss: 3.161871\n",
      "Train Epoch: 7 [551040/697932 (79%)]\tLoss: 3.192918\n",
      "Train Epoch: 7 [551680/697932 (79%)]\tLoss: 3.174485\n",
      "Train Epoch: 7 [552320/697932 (79%)]\tLoss: 3.143783\n",
      "Train Epoch: 7 [552960/697932 (79%)]\tLoss: 3.140606\n",
      "Train Epoch: 7 [553600/697932 (79%)]\tLoss: 3.177170\n",
      "Train Epoch: 7 [554240/697932 (79%)]\tLoss: 3.158751\n",
      "Train Epoch: 7 [554880/697932 (79%)]\tLoss: 3.146053\n",
      "Train Epoch: 7 [555520/697932 (80%)]\tLoss: 3.175711\n",
      "Train Epoch: 7 [556160/697932 (80%)]\tLoss: 3.169795\n",
      "Train Epoch: 7 [556800/697932 (80%)]\tLoss: 3.176067\n",
      "Train Epoch: 7 [557440/697932 (80%)]\tLoss: 3.180235\n",
      "Train Epoch: 7 [558080/697932 (80%)]\tLoss: 3.171842\n",
      "Train Epoch: 7 [558720/697932 (80%)]\tLoss: 3.151605\n",
      "Train Epoch: 7 [559360/697932 (80%)]\tLoss: 3.156794\n",
      "Train Epoch: 7 [560000/697932 (80%)]\tLoss: 3.168780\n",
      "Train Epoch: 7 [560640/697932 (80%)]\tLoss: 3.160247\n",
      "Train Epoch: 7 [561280/697932 (80%)]\tLoss: 3.185581\n",
      "Train Epoch: 7 [561920/697932 (81%)]\tLoss: 3.156407\n",
      "Train Epoch: 7 [562560/697932 (81%)]\tLoss: 3.174301\n",
      "Train Epoch: 7 [563200/697932 (81%)]\tLoss: 3.171716\n",
      "Train Epoch: 7 [563840/697932 (81%)]\tLoss: 3.165284\n",
      "Train Epoch: 7 [564480/697932 (81%)]\tLoss: 3.179291\n",
      "Train Epoch: 7 [565120/697932 (81%)]\tLoss: 3.171560\n",
      "Train Epoch: 7 [565760/697932 (81%)]\tLoss: 3.172203\n",
      "Train Epoch: 7 [566400/697932 (81%)]\tLoss: 3.203740\n",
      "Train Epoch: 7 [567040/697932 (81%)]\tLoss: 3.167962\n",
      "Train Epoch: 7 [567680/697932 (81%)]\tLoss: 3.117446\n",
      "Train Epoch: 7 [568320/697932 (81%)]\tLoss: 3.187000\n",
      "Train Epoch: 7 [568960/697932 (82%)]\tLoss: 3.142855\n",
      "Train Epoch: 7 [569600/697932 (82%)]\tLoss: 3.166984\n",
      "Train Epoch: 7 [570240/697932 (82%)]\tLoss: 3.152760\n",
      "Train Epoch: 7 [570880/697932 (82%)]\tLoss: 3.167064\n",
      "Train Epoch: 7 [571520/697932 (82%)]\tLoss: 3.173433\n",
      "Train Epoch: 7 [572160/697932 (82%)]\tLoss: 3.203755\n",
      "Train Epoch: 7 [572800/697932 (82%)]\tLoss: 3.144613\n",
      "Train Epoch: 7 [573440/697932 (82%)]\tLoss: 3.166448\n",
      "Train Epoch: 7 [574080/697932 (82%)]\tLoss: 3.146971\n",
      "Train Epoch: 7 [574720/697932 (82%)]\tLoss: 3.170152\n",
      "Train Epoch: 7 [575360/697932 (82%)]\tLoss: 3.177373\n",
      "Train Epoch: 7 [576000/697932 (83%)]\tLoss: 3.174050\n",
      "Train Epoch: 7 [576640/697932 (83%)]\tLoss: 3.172345\n",
      "Train Epoch: 7 [577280/697932 (83%)]\tLoss: 3.176056\n",
      "Train Epoch: 7 [577920/697932 (83%)]\tLoss: 3.153917\n",
      "Train Epoch: 7 [578560/697932 (83%)]\tLoss: 3.153145\n",
      "Train Epoch: 7 [579200/697932 (83%)]\tLoss: 3.191633\n",
      "Train Epoch: 7 [579840/697932 (83%)]\tLoss: 3.187909\n",
      "Train Epoch: 7 [580480/697932 (83%)]\tLoss: 3.162502\n",
      "Train Epoch: 7 [581120/697932 (83%)]\tLoss: 3.192014\n",
      "Train Epoch: 7 [581760/697932 (83%)]\tLoss: 3.161442\n",
      "Train Epoch: 7 [582400/697932 (83%)]\tLoss: 3.172214\n",
      "Train Epoch: 7 [583040/697932 (84%)]\tLoss: 3.169974\n",
      "Train Epoch: 7 [583680/697932 (84%)]\tLoss: 3.159744\n",
      "Train Epoch: 7 [584320/697932 (84%)]\tLoss: 3.154257\n",
      "Train Epoch: 7 [584960/697932 (84%)]\tLoss: 3.167190\n",
      "Train Epoch: 7 [585600/697932 (84%)]\tLoss: 3.158398\n",
      "Train Epoch: 7 [586240/697932 (84%)]\tLoss: 3.168706\n",
      "Train Epoch: 7 [586880/697932 (84%)]\tLoss: 3.204870\n",
      "Train Epoch: 7 [587520/697932 (84%)]\tLoss: 3.149914\n",
      "Train Epoch: 7 [588160/697932 (84%)]\tLoss: 3.194879\n",
      "Train Epoch: 7 [588800/697932 (84%)]\tLoss: 3.183121\n",
      "Train Epoch: 7 [589440/697932 (84%)]\tLoss: 3.148552\n",
      "Train Epoch: 7 [590080/697932 (85%)]\tLoss: 3.167507\n",
      "Train Epoch: 7 [590720/697932 (85%)]\tLoss: 3.167887\n",
      "Train Epoch: 7 [591360/697932 (85%)]\tLoss: 3.166070\n",
      "Train Epoch: 7 [592000/697932 (85%)]\tLoss: 3.186456\n",
      "Train Epoch: 7 [592640/697932 (85%)]\tLoss: 3.178358\n",
      "Train Epoch: 7 [593280/697932 (85%)]\tLoss: 3.161676\n",
      "Train Epoch: 7 [593920/697932 (85%)]\tLoss: 3.184921\n",
      "Train Epoch: 7 [594560/697932 (85%)]\tLoss: 3.166439\n",
      "Train Epoch: 7 [595200/697932 (85%)]\tLoss: 3.138508\n",
      "Train Epoch: 7 [595840/697932 (85%)]\tLoss: 3.183262\n",
      "Train Epoch: 7 [596480/697932 (85%)]\tLoss: 3.191545\n",
      "Train Epoch: 7 [597120/697932 (86%)]\tLoss: 3.200064\n",
      "Train Epoch: 7 [597760/697932 (86%)]\tLoss: 3.153084\n",
      "Train Epoch: 7 [598400/697932 (86%)]\tLoss: 3.162291\n",
      "Train Epoch: 7 [599040/697932 (86%)]\tLoss: 3.188475\n",
      "Train Epoch: 7 [599680/697932 (86%)]\tLoss: 3.166693\n",
      "Train Epoch: 7 [600320/697932 (86%)]\tLoss: 3.164589\n",
      "Train Epoch: 7 [600960/697932 (86%)]\tLoss: 3.170550\n",
      "Train Epoch: 7 [601600/697932 (86%)]\tLoss: 3.160417\n",
      "Train Epoch: 7 [602240/697932 (86%)]\tLoss: 3.153746\n",
      "Train Epoch: 7 [602880/697932 (86%)]\tLoss: 3.199148\n",
      "Train Epoch: 7 [603520/697932 (86%)]\tLoss: 3.129644\n",
      "Train Epoch: 7 [604160/697932 (87%)]\tLoss: 3.147163\n",
      "Train Epoch: 7 [604800/697932 (87%)]\tLoss: 3.155960\n",
      "Train Epoch: 7 [605440/697932 (87%)]\tLoss: 3.184713\n",
      "Train Epoch: 7 [606080/697932 (87%)]\tLoss: 3.184758\n",
      "Train Epoch: 7 [606720/697932 (87%)]\tLoss: 3.186884\n",
      "Train Epoch: 7 [607360/697932 (87%)]\tLoss: 3.182878\n",
      "Train Epoch: 7 [608000/697932 (87%)]\tLoss: 3.164103\n",
      "Train Epoch: 7 [608640/697932 (87%)]\tLoss: 3.167347\n",
      "Train Epoch: 7 [609280/697932 (87%)]\tLoss: 3.155172\n",
      "Train Epoch: 7 [609920/697932 (87%)]\tLoss: 3.144646\n",
      "Train Epoch: 7 [610560/697932 (87%)]\tLoss: 3.183228\n",
      "Train Epoch: 7 [611200/697932 (88%)]\tLoss: 3.185294\n",
      "Train Epoch: 7 [611840/697932 (88%)]\tLoss: 3.180202\n",
      "Train Epoch: 7 [612480/697932 (88%)]\tLoss: 3.166003\n",
      "Train Epoch: 7 [613120/697932 (88%)]\tLoss: 3.167542\n",
      "Train Epoch: 7 [613760/697932 (88%)]\tLoss: 3.170131\n",
      "Train Epoch: 7 [614400/697932 (88%)]\tLoss: 3.177767\n",
      "Train Epoch: 7 [615040/697932 (88%)]\tLoss: 3.175591\n",
      "Train Epoch: 7 [615680/697932 (88%)]\tLoss: 3.135617\n",
      "Train Epoch: 7 [616320/697932 (88%)]\tLoss: 3.205087\n",
      "Train Epoch: 7 [616960/697932 (88%)]\tLoss: 3.166167\n",
      "Train Epoch: 7 [617600/697932 (88%)]\tLoss: 3.179784\n",
      "Train Epoch: 7 [618240/697932 (89%)]\tLoss: 3.190464\n",
      "Train Epoch: 7 [618880/697932 (89%)]\tLoss: 3.149095\n",
      "Train Epoch: 7 [619520/697932 (89%)]\tLoss: 3.166107\n",
      "Train Epoch: 7 [620160/697932 (89%)]\tLoss: 3.170356\n",
      "Train Epoch: 7 [620800/697932 (89%)]\tLoss: 3.173883\n",
      "Train Epoch: 7 [621440/697932 (89%)]\tLoss: 3.169569\n",
      "Train Epoch: 7 [622080/697932 (89%)]\tLoss: 3.167135\n",
      "Train Epoch: 7 [622720/697932 (89%)]\tLoss: 3.181851\n",
      "Train Epoch: 7 [623360/697932 (89%)]\tLoss: 3.178741\n",
      "Train Epoch: 7 [624000/697932 (89%)]\tLoss: 3.164936\n",
      "Train Epoch: 7 [624640/697932 (89%)]\tLoss: 3.169788\n",
      "Train Epoch: 7 [625280/697932 (90%)]\tLoss: 3.196507\n",
      "Train Epoch: 7 [625920/697932 (90%)]\tLoss: 3.148490\n",
      "Train Epoch: 7 [626560/697932 (90%)]\tLoss: 3.163406\n",
      "Train Epoch: 7 [627200/697932 (90%)]\tLoss: 3.184883\n",
      "Train Epoch: 7 [627840/697932 (90%)]\tLoss: 3.174124\n",
      "Train Epoch: 7 [628480/697932 (90%)]\tLoss: 3.161242\n",
      "Train Epoch: 7 [629120/697932 (90%)]\tLoss: 3.165582\n",
      "Train Epoch: 7 [629760/697932 (90%)]\tLoss: 3.177285\n",
      "Train Epoch: 7 [630400/697932 (90%)]\tLoss: 3.177523\n",
      "Train Epoch: 7 [631040/697932 (90%)]\tLoss: 3.177200\n",
      "Train Epoch: 7 [631680/697932 (91%)]\tLoss: 3.204106\n",
      "Train Epoch: 7 [632320/697932 (91%)]\tLoss: 3.156887\n",
      "Train Epoch: 7 [632960/697932 (91%)]\tLoss: 3.161938\n",
      "Train Epoch: 7 [633600/697932 (91%)]\tLoss: 3.174151\n",
      "Train Epoch: 7 [634240/697932 (91%)]\tLoss: 3.163466\n",
      "Train Epoch: 7 [634880/697932 (91%)]\tLoss: 3.175874\n",
      "Train Epoch: 7 [635520/697932 (91%)]\tLoss: 3.167548\n",
      "Train Epoch: 7 [636160/697932 (91%)]\tLoss: 3.189854\n",
      "Train Epoch: 7 [636800/697932 (91%)]\tLoss: 3.139998\n",
      "Train Epoch: 7 [637440/697932 (91%)]\tLoss: 3.169540\n",
      "Train Epoch: 7 [638080/697932 (91%)]\tLoss: 3.152204\n",
      "Train Epoch: 7 [638720/697932 (92%)]\tLoss: 3.168176\n",
      "Train Epoch: 7 [639360/697932 (92%)]\tLoss: 3.162243\n",
      "Train Epoch: 7 [640000/697932 (92%)]\tLoss: 3.143981\n",
      "Train Epoch: 7 [640640/697932 (92%)]\tLoss: 3.173649\n",
      "Train Epoch: 7 [641280/697932 (92%)]\tLoss: 3.169558\n",
      "Train Epoch: 7 [641920/697932 (92%)]\tLoss: 3.153608\n",
      "Train Epoch: 7 [642560/697932 (92%)]\tLoss: 3.146704\n",
      "Train Epoch: 7 [643200/697932 (92%)]\tLoss: 3.158806\n",
      "Train Epoch: 7 [643840/697932 (92%)]\tLoss: 3.167461\n",
      "Train Epoch: 7 [644480/697932 (92%)]\tLoss: 3.151662\n",
      "Train Epoch: 7 [645120/697932 (92%)]\tLoss: 3.155219\n",
      "Train Epoch: 7 [645760/697932 (93%)]\tLoss: 3.170158\n",
      "Train Epoch: 7 [646400/697932 (93%)]\tLoss: 3.144013\n",
      "Train Epoch: 7 [647040/697932 (93%)]\tLoss: 3.142845\n",
      "Train Epoch: 7 [647680/697932 (93%)]\tLoss: 3.192744\n",
      "Train Epoch: 7 [648320/697932 (93%)]\tLoss: 3.157677\n",
      "Train Epoch: 7 [648960/697932 (93%)]\tLoss: 3.143567\n",
      "Train Epoch: 7 [649600/697932 (93%)]\tLoss: 3.186977\n",
      "Train Epoch: 7 [650240/697932 (93%)]\tLoss: 3.170293\n",
      "Train Epoch: 7 [650880/697932 (93%)]\tLoss: 3.185498\n",
      "Train Epoch: 7 [651520/697932 (93%)]\tLoss: 3.152240\n",
      "Train Epoch: 7 [652160/697932 (93%)]\tLoss: 3.175566\n",
      "Train Epoch: 7 [652800/697932 (94%)]\tLoss: 3.173592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 [653440/697932 (94%)]\tLoss: 3.153466\n",
      "Train Epoch: 7 [654080/697932 (94%)]\tLoss: 3.170508\n",
      "Train Epoch: 7 [654720/697932 (94%)]\tLoss: 3.183086\n",
      "Train Epoch: 7 [655360/697932 (94%)]\tLoss: 3.134138\n",
      "Train Epoch: 7 [656000/697932 (94%)]\tLoss: 3.150609\n",
      "Train Epoch: 7 [656640/697932 (94%)]\tLoss: 3.173745\n",
      "Train Epoch: 7 [657280/697932 (94%)]\tLoss: 3.158494\n",
      "Train Epoch: 7 [657920/697932 (94%)]\tLoss: 3.175252\n",
      "Train Epoch: 7 [658560/697932 (94%)]\tLoss: 3.177700\n",
      "Train Epoch: 7 [659200/697932 (94%)]\tLoss: 3.151475\n",
      "Train Epoch: 7 [659840/697932 (95%)]\tLoss: 3.162272\n",
      "Train Epoch: 7 [660480/697932 (95%)]\tLoss: 3.174596\n",
      "Train Epoch: 7 [661120/697932 (95%)]\tLoss: 3.178581\n",
      "Train Epoch: 7 [661760/697932 (95%)]\tLoss: 3.134029\n",
      "Train Epoch: 7 [662400/697932 (95%)]\tLoss: 3.167377\n",
      "Train Epoch: 7 [663040/697932 (95%)]\tLoss: 3.165393\n",
      "Train Epoch: 7 [663680/697932 (95%)]\tLoss: 3.200532\n",
      "Train Epoch: 7 [664320/697932 (95%)]\tLoss: 3.156602\n",
      "Train Epoch: 7 [664960/697932 (95%)]\tLoss: 3.178651\n",
      "Train Epoch: 7 [665600/697932 (95%)]\tLoss: 3.189191\n",
      "Train Epoch: 7 [666240/697932 (95%)]\tLoss: 3.159963\n",
      "Train Epoch: 7 [666880/697932 (96%)]\tLoss: 3.175325\n",
      "Train Epoch: 7 [667520/697932 (96%)]\tLoss: 3.152159\n",
      "Train Epoch: 7 [668160/697932 (96%)]\tLoss: 3.161902\n",
      "Train Epoch: 7 [668800/697932 (96%)]\tLoss: 3.151711\n",
      "Train Epoch: 7 [669440/697932 (96%)]\tLoss: 3.179069\n",
      "Train Epoch: 7 [670080/697932 (96%)]\tLoss: 3.185228\n",
      "Train Epoch: 7 [670720/697932 (96%)]\tLoss: 3.149998\n",
      "Train Epoch: 7 [671360/697932 (96%)]\tLoss: 3.160805\n",
      "Train Epoch: 7 [672000/697932 (96%)]\tLoss: 3.176643\n",
      "Train Epoch: 7 [672640/697932 (96%)]\tLoss: 3.175643\n",
      "Train Epoch: 7 [673280/697932 (96%)]\tLoss: 3.174098\n",
      "Train Epoch: 7 [673920/697932 (97%)]\tLoss: 3.168070\n",
      "Train Epoch: 7 [674560/697932 (97%)]\tLoss: 3.148275\n",
      "Train Epoch: 7 [675200/697932 (97%)]\tLoss: 3.156841\n",
      "Train Epoch: 7 [675840/697932 (97%)]\tLoss: 3.174021\n",
      "Train Epoch: 7 [676480/697932 (97%)]\tLoss: 3.149389\n",
      "Train Epoch: 7 [677120/697932 (97%)]\tLoss: 3.161644\n",
      "Train Epoch: 7 [677760/697932 (97%)]\tLoss: 3.161400\n",
      "Train Epoch: 7 [678400/697932 (97%)]\tLoss: 3.168922\n",
      "Train Epoch: 7 [679040/697932 (97%)]\tLoss: 3.176989\n",
      "Train Epoch: 7 [679680/697932 (97%)]\tLoss: 3.156738\n",
      "Train Epoch: 7 [680320/697932 (97%)]\tLoss: 3.230016\n",
      "Train Epoch: 7 [680960/697932 (98%)]\tLoss: 3.178066\n",
      "Train Epoch: 7 [681600/697932 (98%)]\tLoss: 3.139930\n",
      "Train Epoch: 7 [682240/697932 (98%)]\tLoss: 3.174985\n",
      "Train Epoch: 7 [682880/697932 (98%)]\tLoss: 3.176537\n",
      "Train Epoch: 7 [683520/697932 (98%)]\tLoss: 3.159676\n",
      "Train Epoch: 7 [684160/697932 (98%)]\tLoss: 3.172574\n",
      "Train Epoch: 7 [684800/697932 (98%)]\tLoss: 3.150663\n",
      "Train Epoch: 7 [685440/697932 (98%)]\tLoss: 3.166554\n",
      "Train Epoch: 7 [686080/697932 (98%)]\tLoss: 3.151837\n",
      "Train Epoch: 7 [686720/697932 (98%)]\tLoss: 3.157448\n",
      "Train Epoch: 7 [687360/697932 (98%)]\tLoss: 3.164044\n",
      "Train Epoch: 7 [688000/697932 (99%)]\tLoss: 3.190310\n",
      "Train Epoch: 7 [688640/697932 (99%)]\tLoss: 3.171428\n",
      "Train Epoch: 7 [689280/697932 (99%)]\tLoss: 3.188285\n",
      "Train Epoch: 7 [689920/697932 (99%)]\tLoss: 3.166474\n",
      "Train Epoch: 7 [690560/697932 (99%)]\tLoss: 3.165670\n",
      "Train Epoch: 7 [691200/697932 (99%)]\tLoss: 3.163865\n",
      "Train Epoch: 7 [691840/697932 (99%)]\tLoss: 3.185391\n",
      "Train Epoch: 7 [692480/697932 (99%)]\tLoss: 3.173918\n",
      "Train Epoch: 7 [693120/697932 (99%)]\tLoss: 3.173715\n",
      "Train Epoch: 7 [693760/697932 (99%)]\tLoss: 3.201123\n",
      "Train Epoch: 7 [694400/697932 (99%)]\tLoss: 3.155770\n",
      "Train Epoch: 7 [695040/697932 (100%)]\tLoss: 3.194623\n",
      "Train Epoch: 7 [695680/697932 (100%)]\tLoss: 3.131156\n",
      "Train Epoch: 7 [696320/697932 (100%)]\tLoss: 3.180563\n",
      "Train Epoch: 7 [696960/697932 (100%)]\tLoss: 3.153283\n",
      "Train Epoch: 7 [697600/697932 (100%)]\tLoss: 3.187154\n",
      "\n",
      "Test set: Avg. loss: 0.0050, Accuracy: 38/116323 (0%)\n",
      "\n",
      "Train Epoch: 8 [0/697932 (0%)]\tLoss: 3.188348\n",
      "Train Epoch: 8 [640/697932 (0%)]\tLoss: 3.177043\n",
      "Train Epoch: 8 [1280/697932 (0%)]\tLoss: 3.171769\n",
      "Train Epoch: 8 [1920/697932 (0%)]\tLoss: 3.175250\n",
      "Train Epoch: 8 [2560/697932 (0%)]\tLoss: 3.170281\n",
      "Train Epoch: 8 [3200/697932 (0%)]\tLoss: 3.187958\n",
      "Train Epoch: 8 [3840/697932 (1%)]\tLoss: 3.172307\n",
      "Train Epoch: 8 [4480/697932 (1%)]\tLoss: 3.188602\n",
      "Train Epoch: 8 [5120/697932 (1%)]\tLoss: 3.170974\n",
      "Train Epoch: 8 [5760/697932 (1%)]\tLoss: 3.158528\n",
      "Train Epoch: 8 [6400/697932 (1%)]\tLoss: 3.168739\n",
      "Train Epoch: 8 [7040/697932 (1%)]\tLoss: 3.190421\n",
      "Train Epoch: 8 [7680/697932 (1%)]\tLoss: 3.182488\n",
      "Train Epoch: 8 [8320/697932 (1%)]\tLoss: 3.145997\n",
      "Train Epoch: 8 [8960/697932 (1%)]\tLoss: 3.146827\n",
      "Train Epoch: 8 [9600/697932 (1%)]\tLoss: 3.159662\n",
      "Train Epoch: 8 [10240/697932 (1%)]\tLoss: 3.153423\n",
      "Train Epoch: 8 [10880/697932 (2%)]\tLoss: 3.175380\n",
      "Train Epoch: 8 [11520/697932 (2%)]\tLoss: 3.172153\n",
      "Train Epoch: 8 [12160/697932 (2%)]\tLoss: 3.167263\n",
      "Train Epoch: 8 [12800/697932 (2%)]\tLoss: 3.176875\n",
      "Train Epoch: 8 [13440/697932 (2%)]\tLoss: 3.178051\n",
      "Train Epoch: 8 [14080/697932 (2%)]\tLoss: 3.141663\n",
      "Train Epoch: 8 [14720/697932 (2%)]\tLoss: 3.169270\n",
      "Train Epoch: 8 [15360/697932 (2%)]\tLoss: 3.165833\n",
      "Train Epoch: 8 [16000/697932 (2%)]\tLoss: 3.180992\n",
      "Train Epoch: 8 [16640/697932 (2%)]\tLoss: 3.163563\n",
      "Train Epoch: 8 [17280/697932 (2%)]\tLoss: 3.202702\n",
      "Train Epoch: 8 [17920/697932 (3%)]\tLoss: 3.134755\n",
      "Train Epoch: 8 [18560/697932 (3%)]\tLoss: 3.174412\n",
      "Train Epoch: 8 [19200/697932 (3%)]\tLoss: 3.167600\n",
      "Train Epoch: 8 [19840/697932 (3%)]\tLoss: 3.197361\n",
      "Train Epoch: 8 [20480/697932 (3%)]\tLoss: 3.173461\n",
      "Train Epoch: 8 [21120/697932 (3%)]\tLoss: 3.130673\n",
      "Train Epoch: 8 [21760/697932 (3%)]\tLoss: 3.186780\n",
      "Train Epoch: 8 [22400/697932 (3%)]\tLoss: 3.152369\n",
      "Train Epoch: 8 [23040/697932 (3%)]\tLoss: 3.162163\n",
      "Train Epoch: 8 [23680/697932 (3%)]\tLoss: 3.154631\n",
      "Train Epoch: 8 [24320/697932 (3%)]\tLoss: 3.155162\n",
      "Train Epoch: 8 [24960/697932 (4%)]\tLoss: 3.149093\n",
      "Train Epoch: 8 [25600/697932 (4%)]\tLoss: 3.147009\n",
      "Train Epoch: 8 [26240/697932 (4%)]\tLoss: 3.173187\n",
      "Train Epoch: 8 [26880/697932 (4%)]\tLoss: 3.160311\n",
      "Train Epoch: 8 [27520/697932 (4%)]\tLoss: 3.162424\n",
      "Train Epoch: 8 [28160/697932 (4%)]\tLoss: 3.152583\n",
      "Train Epoch: 8 [28800/697932 (4%)]\tLoss: 3.179372\n",
      "Train Epoch: 8 [29440/697932 (4%)]\tLoss: 3.149785\n",
      "Train Epoch: 8 [30080/697932 (4%)]\tLoss: 3.149443\n",
      "Train Epoch: 8 [30720/697932 (4%)]\tLoss: 3.172250\n",
      "Train Epoch: 8 [31360/697932 (4%)]\tLoss: 3.170407\n",
      "Train Epoch: 8 [32000/697932 (5%)]\tLoss: 3.164713\n",
      "Train Epoch: 8 [32640/697932 (5%)]\tLoss: 3.158616\n",
      "Train Epoch: 8 [33280/697932 (5%)]\tLoss: 3.177951\n",
      "Train Epoch: 8 [33920/697932 (5%)]\tLoss: 3.161875\n",
      "Train Epoch: 8 [34560/697932 (5%)]\tLoss: 3.224127\n",
      "Train Epoch: 8 [35200/697932 (5%)]\tLoss: 3.173105\n",
      "Train Epoch: 8 [35840/697932 (5%)]\tLoss: 3.171203\n",
      "Train Epoch: 8 [36480/697932 (5%)]\tLoss: 3.162475\n",
      "Train Epoch: 8 [37120/697932 (5%)]\tLoss: 3.155734\n",
      "Train Epoch: 8 [37760/697932 (5%)]\tLoss: 3.166147\n",
      "Train Epoch: 8 [38400/697932 (6%)]\tLoss: 3.126442\n",
      "Train Epoch: 8 [39040/697932 (6%)]\tLoss: 3.154270\n",
      "Train Epoch: 8 [39680/697932 (6%)]\tLoss: 3.152019\n",
      "Train Epoch: 8 [40320/697932 (6%)]\tLoss: 3.169522\n",
      "Train Epoch: 8 [40960/697932 (6%)]\tLoss: 3.162993\n",
      "Train Epoch: 8 [41600/697932 (6%)]\tLoss: 3.166335\n",
      "Train Epoch: 8 [42240/697932 (6%)]\tLoss: 3.163775\n",
      "Train Epoch: 8 [42880/697932 (6%)]\tLoss: 3.169663\n",
      "Train Epoch: 8 [43520/697932 (6%)]\tLoss: 3.177689\n",
      "Train Epoch: 8 [44160/697932 (6%)]\tLoss: 3.198066\n",
      "Train Epoch: 8 [44800/697932 (6%)]\tLoss: 3.156261\n",
      "Train Epoch: 8 [45440/697932 (7%)]\tLoss: 3.185638\n",
      "Train Epoch: 8 [46080/697932 (7%)]\tLoss: 3.160046\n",
      "Train Epoch: 8 [46720/697932 (7%)]\tLoss: 3.169359\n",
      "Train Epoch: 8 [47360/697932 (7%)]\tLoss: 3.166906\n",
      "Train Epoch: 8 [48000/697932 (7%)]\tLoss: 3.164822\n",
      "Train Epoch: 8 [48640/697932 (7%)]\tLoss: 3.167887\n",
      "Train Epoch: 8 [49280/697932 (7%)]\tLoss: 3.159313\n",
      "Train Epoch: 8 [49920/697932 (7%)]\tLoss: 3.170777\n",
      "Train Epoch: 8 [50560/697932 (7%)]\tLoss: 3.161151\n",
      "Train Epoch: 8 [51200/697932 (7%)]\tLoss: 3.173746\n",
      "Train Epoch: 8 [51840/697932 (7%)]\tLoss: 3.169032\n",
      "Train Epoch: 8 [52480/697932 (8%)]\tLoss: 3.167737\n",
      "Train Epoch: 8 [53120/697932 (8%)]\tLoss: 3.176976\n",
      "Train Epoch: 8 [53760/697932 (8%)]\tLoss: 3.172269\n",
      "Train Epoch: 8 [54400/697932 (8%)]\tLoss: 3.141171\n",
      "Train Epoch: 8 [55040/697932 (8%)]\tLoss: 3.171114\n",
      "Train Epoch: 8 [55680/697932 (8%)]\tLoss: 3.163550\n",
      "Train Epoch: 8 [56320/697932 (8%)]\tLoss: 3.155313\n",
      "Train Epoch: 8 [56960/697932 (8%)]\tLoss: 3.190153\n",
      "Train Epoch: 8 [57600/697932 (8%)]\tLoss: 3.178675\n",
      "Train Epoch: 8 [58240/697932 (8%)]\tLoss: 3.189725\n",
      "Train Epoch: 8 [58880/697932 (8%)]\tLoss: 3.143932\n",
      "Train Epoch: 8 [59520/697932 (9%)]\tLoss: 3.162472\n",
      "Train Epoch: 8 [60160/697932 (9%)]\tLoss: 3.163337\n",
      "Train Epoch: 8 [60800/697932 (9%)]\tLoss: 3.161932\n",
      "Train Epoch: 8 [61440/697932 (9%)]\tLoss: 3.149661\n",
      "Train Epoch: 8 [62080/697932 (9%)]\tLoss: 3.173926\n",
      "Train Epoch: 8 [62720/697932 (9%)]\tLoss: 3.192557\n",
      "Train Epoch: 8 [63360/697932 (9%)]\tLoss: 3.172353\n",
      "Train Epoch: 8 [64000/697932 (9%)]\tLoss: 3.170798\n",
      "Train Epoch: 8 [64640/697932 (9%)]\tLoss: 3.171293\n",
      "Train Epoch: 8 [65280/697932 (9%)]\tLoss: 3.176989\n",
      "Train Epoch: 8 [65920/697932 (9%)]\tLoss: 3.188574\n",
      "Train Epoch: 8 [66560/697932 (10%)]\tLoss: 3.192668\n",
      "Train Epoch: 8 [67200/697932 (10%)]\tLoss: 3.158343\n",
      "Train Epoch: 8 [67840/697932 (10%)]\tLoss: 3.140858\n",
      "Train Epoch: 8 [68480/697932 (10%)]\tLoss: 3.173463\n",
      "Train Epoch: 8 [69120/697932 (10%)]\tLoss: 3.181686\n",
      "Train Epoch: 8 [69760/697932 (10%)]\tLoss: 3.181052\n",
      "Train Epoch: 8 [70400/697932 (10%)]\tLoss: 3.147806\n",
      "Train Epoch: 8 [71040/697932 (10%)]\tLoss: 3.186555\n",
      "Train Epoch: 8 [71680/697932 (10%)]\tLoss: 3.160774\n",
      "Train Epoch: 8 [72320/697932 (10%)]\tLoss: 3.167467\n",
      "Train Epoch: 8 [72960/697932 (10%)]\tLoss: 3.170082\n",
      "Train Epoch: 8 [73600/697932 (11%)]\tLoss: 3.165979\n",
      "Train Epoch: 8 [74240/697932 (11%)]\tLoss: 3.151611\n",
      "Train Epoch: 8 [74880/697932 (11%)]\tLoss: 3.187542\n",
      "Train Epoch: 8 [75520/697932 (11%)]\tLoss: 3.131360\n",
      "Train Epoch: 8 [76160/697932 (11%)]\tLoss: 3.161618\n",
      "Train Epoch: 8 [76800/697932 (11%)]\tLoss: 3.151431\n",
      "Train Epoch: 8 [77440/697932 (11%)]\tLoss: 3.163512\n",
      "Train Epoch: 8 [78080/697932 (11%)]\tLoss: 3.169703\n",
      "Train Epoch: 8 [78720/697932 (11%)]\tLoss: 3.160775\n",
      "Train Epoch: 8 [79360/697932 (11%)]\tLoss: 3.176700\n",
      "Train Epoch: 8 [80000/697932 (11%)]\tLoss: 3.151376\n",
      "Train Epoch: 8 [80640/697932 (12%)]\tLoss: 3.160911\n",
      "Train Epoch: 8 [81280/697932 (12%)]\tLoss: 3.187850\n",
      "Train Epoch: 8 [81920/697932 (12%)]\tLoss: 3.193000\n",
      "Train Epoch: 8 [82560/697932 (12%)]\tLoss: 3.157706\n",
      "Train Epoch: 8 [83200/697932 (12%)]\tLoss: 3.128891\n",
      "Train Epoch: 8 [83840/697932 (12%)]\tLoss: 3.186055\n",
      "Train Epoch: 8 [84480/697932 (12%)]\tLoss: 3.172461\n",
      "Train Epoch: 8 [85120/697932 (12%)]\tLoss: 3.209552\n",
      "Train Epoch: 8 [85760/697932 (12%)]\tLoss: 3.165297\n",
      "Train Epoch: 8 [86400/697932 (12%)]\tLoss: 3.159415\n",
      "Train Epoch: 8 [87040/697932 (12%)]\tLoss: 3.181095\n",
      "Train Epoch: 8 [87680/697932 (13%)]\tLoss: 3.153256\n",
      "Train Epoch: 8 [88320/697932 (13%)]\tLoss: 3.180495\n",
      "Train Epoch: 8 [88960/697932 (13%)]\tLoss: 3.153608\n",
      "Train Epoch: 8 [89600/697932 (13%)]\tLoss: 3.164922\n",
      "Train Epoch: 8 [90240/697932 (13%)]\tLoss: 3.159464\n",
      "Train Epoch: 8 [90880/697932 (13%)]\tLoss: 3.177777\n",
      "Train Epoch: 8 [91520/697932 (13%)]\tLoss: 3.151848\n",
      "Train Epoch: 8 [92160/697932 (13%)]\tLoss: 3.176479\n",
      "Train Epoch: 8 [92800/697932 (13%)]\tLoss: 3.172617\n",
      "Train Epoch: 8 [93440/697932 (13%)]\tLoss: 3.185034\n",
      "Train Epoch: 8 [94080/697932 (13%)]\tLoss: 3.170194\n",
      "Train Epoch: 8 [94720/697932 (14%)]\tLoss: 3.158966\n",
      "Train Epoch: 8 [95360/697932 (14%)]\tLoss: 3.164405\n",
      "Train Epoch: 8 [96000/697932 (14%)]\tLoss: 3.156658\n",
      "Train Epoch: 8 [96640/697932 (14%)]\tLoss: 3.201604\n",
      "Train Epoch: 8 [97280/697932 (14%)]\tLoss: 3.150135\n",
      "Train Epoch: 8 [97920/697932 (14%)]\tLoss: 3.168793\n",
      "Train Epoch: 8 [98560/697932 (14%)]\tLoss: 3.148931\n",
      "Train Epoch: 8 [99200/697932 (14%)]\tLoss: 3.172339\n",
      "Train Epoch: 8 [99840/697932 (14%)]\tLoss: 3.153382\n",
      "Train Epoch: 8 [100480/697932 (14%)]\tLoss: 3.159204\n",
      "Train Epoch: 8 [101120/697932 (14%)]\tLoss: 3.158189\n",
      "Train Epoch: 8 [101760/697932 (15%)]\tLoss: 3.165215\n",
      "Train Epoch: 8 [102400/697932 (15%)]\tLoss: 3.156788\n",
      "Train Epoch: 8 [103040/697932 (15%)]\tLoss: 3.155449\n",
      "Train Epoch: 8 [103680/697932 (15%)]\tLoss: 3.144979\n",
      "Train Epoch: 8 [104320/697932 (15%)]\tLoss: 3.173751\n",
      "Train Epoch: 8 [104960/697932 (15%)]\tLoss: 3.195578\n",
      "Train Epoch: 8 [105600/697932 (15%)]\tLoss: 3.168045\n",
      "Train Epoch: 8 [106240/697932 (15%)]\tLoss: 3.151339\n",
      "Train Epoch: 8 [106880/697932 (15%)]\tLoss: 3.197908\n",
      "Train Epoch: 8 [107520/697932 (15%)]\tLoss: 3.152902\n",
      "Train Epoch: 8 [108160/697932 (15%)]\tLoss: 3.164567\n",
      "Train Epoch: 8 [108800/697932 (16%)]\tLoss: 3.171886\n",
      "Train Epoch: 8 [109440/697932 (16%)]\tLoss: 3.156750\n",
      "Train Epoch: 8 [110080/697932 (16%)]\tLoss: 3.165466\n",
      "Train Epoch: 8 [110720/697932 (16%)]\tLoss: 3.178922\n",
      "Train Epoch: 8 [111360/697932 (16%)]\tLoss: 3.148889\n",
      "Train Epoch: 8 [112000/697932 (16%)]\tLoss: 3.171704\n",
      "Train Epoch: 8 [112640/697932 (16%)]\tLoss: 3.173072\n",
      "Train Epoch: 8 [113280/697932 (16%)]\tLoss: 3.180653\n",
      "Train Epoch: 8 [113920/697932 (16%)]\tLoss: 3.171469\n",
      "Train Epoch: 8 [114560/697932 (16%)]\tLoss: 3.196824\n",
      "Train Epoch: 8 [115200/697932 (17%)]\tLoss: 3.185118\n",
      "Train Epoch: 8 [115840/697932 (17%)]\tLoss: 3.149237\n",
      "Train Epoch: 8 [116480/697932 (17%)]\tLoss: 3.143380\n",
      "Train Epoch: 8 [117120/697932 (17%)]\tLoss: 3.158391\n",
      "Train Epoch: 8 [117760/697932 (17%)]\tLoss: 3.185066\n",
      "Train Epoch: 8 [118400/697932 (17%)]\tLoss: 3.181884\n",
      "Train Epoch: 8 [119040/697932 (17%)]\tLoss: 3.163221\n",
      "Train Epoch: 8 [119680/697932 (17%)]\tLoss: 3.180382\n",
      "Train Epoch: 8 [120320/697932 (17%)]\tLoss: 3.169188\n",
      "Train Epoch: 8 [120960/697932 (17%)]\tLoss: 3.209604\n",
      "Train Epoch: 8 [121600/697932 (17%)]\tLoss: 3.160582\n",
      "Train Epoch: 8 [122240/697932 (18%)]\tLoss: 3.138121\n",
      "Train Epoch: 8 [122880/697932 (18%)]\tLoss: 3.149477\n",
      "Train Epoch: 8 [123520/697932 (18%)]\tLoss: 3.167095\n",
      "Train Epoch: 8 [124160/697932 (18%)]\tLoss: 3.175967\n",
      "Train Epoch: 8 [124800/697932 (18%)]\tLoss: 3.180386\n",
      "Train Epoch: 8 [125440/697932 (18%)]\tLoss: 3.174535\n",
      "Train Epoch: 8 [126080/697932 (18%)]\tLoss: 3.154803\n",
      "Train Epoch: 8 [126720/697932 (18%)]\tLoss: 3.158014\n",
      "Train Epoch: 8 [127360/697932 (18%)]\tLoss: 3.158597\n",
      "Train Epoch: 8 [128000/697932 (18%)]\tLoss: 3.166417\n",
      "Train Epoch: 8 [128640/697932 (18%)]\tLoss: 3.168287\n",
      "Train Epoch: 8 [129280/697932 (19%)]\tLoss: 3.158982\n",
      "Train Epoch: 8 [129920/697932 (19%)]\tLoss: 3.176504\n",
      "Train Epoch: 8 [130560/697932 (19%)]\tLoss: 3.146312\n",
      "Train Epoch: 8 [131200/697932 (19%)]\tLoss: 3.173093\n",
      "Train Epoch: 8 [131840/697932 (19%)]\tLoss: 3.163636\n",
      "Train Epoch: 8 [132480/697932 (19%)]\tLoss: 3.187766\n",
      "Train Epoch: 8 [133120/697932 (19%)]\tLoss: 3.153142\n",
      "Train Epoch: 8 [133760/697932 (19%)]\tLoss: 3.161446\n",
      "Train Epoch: 8 [134400/697932 (19%)]\tLoss: 3.184162\n",
      "Train Epoch: 8 [135040/697932 (19%)]\tLoss: 3.182360\n",
      "Train Epoch: 8 [135680/697932 (19%)]\tLoss: 3.185151\n",
      "Train Epoch: 8 [136320/697932 (20%)]\tLoss: 3.161738\n",
      "Train Epoch: 8 [136960/697932 (20%)]\tLoss: 3.142577\n",
      "Train Epoch: 8 [137600/697932 (20%)]\tLoss: 3.158381\n",
      "Train Epoch: 8 [138240/697932 (20%)]\tLoss: 3.149347\n",
      "Train Epoch: 8 [138880/697932 (20%)]\tLoss: 3.143435\n",
      "Train Epoch: 8 [139520/697932 (20%)]\tLoss: 3.169188\n",
      "Train Epoch: 8 [140160/697932 (20%)]\tLoss: 3.164856\n",
      "Train Epoch: 8 [140800/697932 (20%)]\tLoss: 3.161673\n",
      "Train Epoch: 8 [141440/697932 (20%)]\tLoss: 3.162761\n",
      "Train Epoch: 8 [142080/697932 (20%)]\tLoss: 3.157477\n",
      "Train Epoch: 8 [142720/697932 (20%)]\tLoss: 3.163318\n",
      "Train Epoch: 8 [143360/697932 (21%)]\tLoss: 3.164263\n",
      "Train Epoch: 8 [144000/697932 (21%)]\tLoss: 3.170919\n",
      "Train Epoch: 8 [144640/697932 (21%)]\tLoss: 3.180242\n",
      "Train Epoch: 8 [145280/697932 (21%)]\tLoss: 3.177864\n",
      "Train Epoch: 8 [145920/697932 (21%)]\tLoss: 3.150259\n",
      "Train Epoch: 8 [146560/697932 (21%)]\tLoss: 3.162326\n",
      "Train Epoch: 8 [147200/697932 (21%)]\tLoss: 3.166799\n",
      "Train Epoch: 8 [147840/697932 (21%)]\tLoss: 3.151954\n",
      "Train Epoch: 8 [148480/697932 (21%)]\tLoss: 3.138866\n",
      "Train Epoch: 8 [149120/697932 (21%)]\tLoss: 3.157891\n",
      "Train Epoch: 8 [149760/697932 (21%)]\tLoss: 3.154548\n",
      "Train Epoch: 8 [150400/697932 (22%)]\tLoss: 3.168455\n",
      "Train Epoch: 8 [151040/697932 (22%)]\tLoss: 3.170540\n",
      "Train Epoch: 8 [151680/697932 (22%)]\tLoss: 3.156265\n",
      "Train Epoch: 8 [152320/697932 (22%)]\tLoss: 3.168429\n",
      "Train Epoch: 8 [152960/697932 (22%)]\tLoss: 3.155270\n",
      "Train Epoch: 8 [153600/697932 (22%)]\tLoss: 3.159604\n",
      "Train Epoch: 8 [154240/697932 (22%)]\tLoss: 3.162497\n",
      "Train Epoch: 8 [154880/697932 (22%)]\tLoss: 3.166851\n",
      "Train Epoch: 8 [155520/697932 (22%)]\tLoss: 3.154990\n",
      "Train Epoch: 8 [156160/697932 (22%)]\tLoss: 3.161193\n",
      "Train Epoch: 8 [156800/697932 (22%)]\tLoss: 3.183057\n",
      "Train Epoch: 8 [157440/697932 (23%)]\tLoss: 3.196895\n",
      "Train Epoch: 8 [158080/697932 (23%)]\tLoss: 3.146571\n",
      "Train Epoch: 8 [158720/697932 (23%)]\tLoss: 3.175195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [159360/697932 (23%)]\tLoss: 3.177613\n",
      "Train Epoch: 8 [160000/697932 (23%)]\tLoss: 3.170019\n",
      "Train Epoch: 8 [160640/697932 (23%)]\tLoss: 3.193684\n",
      "Train Epoch: 8 [161280/697932 (23%)]\tLoss: 3.176343\n",
      "Train Epoch: 8 [161920/697932 (23%)]\tLoss: 3.150668\n",
      "Train Epoch: 8 [162560/697932 (23%)]\tLoss: 3.174155\n",
      "Train Epoch: 8 [163200/697932 (23%)]\tLoss: 3.153389\n",
      "Train Epoch: 8 [163840/697932 (23%)]\tLoss: 3.165936\n",
      "Train Epoch: 8 [164480/697932 (24%)]\tLoss: 3.166667\n",
      "Train Epoch: 8 [165120/697932 (24%)]\tLoss: 3.154486\n",
      "Train Epoch: 8 [165760/697932 (24%)]\tLoss: 3.156860\n",
      "Train Epoch: 8 [166400/697932 (24%)]\tLoss: 3.166124\n",
      "Train Epoch: 8 [167040/697932 (24%)]\tLoss: 3.149364\n",
      "Train Epoch: 8 [167680/697932 (24%)]\tLoss: 3.170346\n",
      "Train Epoch: 8 [168320/697932 (24%)]\tLoss: 3.164380\n",
      "Train Epoch: 8 [168960/697932 (24%)]\tLoss: 3.155565\n",
      "Train Epoch: 8 [169600/697932 (24%)]\tLoss: 3.163112\n",
      "Train Epoch: 8 [170240/697932 (24%)]\tLoss: 3.178100\n",
      "Train Epoch: 8 [170880/697932 (24%)]\tLoss: 3.146450\n",
      "Train Epoch: 8 [171520/697932 (25%)]\tLoss: 3.182404\n",
      "Train Epoch: 8 [172160/697932 (25%)]\tLoss: 3.176270\n",
      "Train Epoch: 8 [172800/697932 (25%)]\tLoss: 3.156405\n",
      "Train Epoch: 8 [173440/697932 (25%)]\tLoss: 3.175961\n",
      "Train Epoch: 8 [174080/697932 (25%)]\tLoss: 3.194665\n",
      "Train Epoch: 8 [174720/697932 (25%)]\tLoss: 3.166780\n",
      "Train Epoch: 8 [175360/697932 (25%)]\tLoss: 3.145726\n",
      "Train Epoch: 8 [176000/697932 (25%)]\tLoss: 3.154871\n",
      "Train Epoch: 8 [176640/697932 (25%)]\tLoss: 3.160363\n",
      "Train Epoch: 8 [177280/697932 (25%)]\tLoss: 3.173676\n",
      "Train Epoch: 8 [177920/697932 (25%)]\tLoss: 3.144316\n",
      "Train Epoch: 8 [178560/697932 (26%)]\tLoss: 3.189686\n",
      "Train Epoch: 8 [179200/697932 (26%)]\tLoss: 3.146455\n",
      "Train Epoch: 8 [179840/697932 (26%)]\tLoss: 3.140594\n",
      "Train Epoch: 8 [180480/697932 (26%)]\tLoss: 3.178287\n",
      "Train Epoch: 8 [181120/697932 (26%)]\tLoss: 3.159924\n",
      "Train Epoch: 8 [181760/697932 (26%)]\tLoss: 3.160327\n",
      "Train Epoch: 8 [182400/697932 (26%)]\tLoss: 3.169873\n",
      "Train Epoch: 8 [183040/697932 (26%)]\tLoss: 3.163268\n",
      "Train Epoch: 8 [183680/697932 (26%)]\tLoss: 3.167053\n",
      "Train Epoch: 8 [184320/697932 (26%)]\tLoss: 3.167784\n",
      "Train Epoch: 8 [184960/697932 (26%)]\tLoss: 3.169705\n",
      "Train Epoch: 8 [185600/697932 (27%)]\tLoss: 3.125889\n",
      "Train Epoch: 8 [186240/697932 (27%)]\tLoss: 3.184193\n",
      "Train Epoch: 8 [186880/697932 (27%)]\tLoss: 3.159909\n",
      "Train Epoch: 8 [187520/697932 (27%)]\tLoss: 3.158383\n",
      "Train Epoch: 8 [188160/697932 (27%)]\tLoss: 3.134307\n",
      "Train Epoch: 8 [188800/697932 (27%)]\tLoss: 3.160035\n",
      "Train Epoch: 8 [189440/697932 (27%)]\tLoss: 3.153239\n",
      "Train Epoch: 8 [190080/697932 (27%)]\tLoss: 3.140411\n",
      "Train Epoch: 8 [190720/697932 (27%)]\tLoss: 3.177832\n",
      "Train Epoch: 8 [191360/697932 (27%)]\tLoss: 3.157520\n",
      "Train Epoch: 8 [192000/697932 (28%)]\tLoss: 3.176938\n",
      "Train Epoch: 8 [192640/697932 (28%)]\tLoss: 3.145834\n",
      "Train Epoch: 8 [193280/697932 (28%)]\tLoss: 3.171436\n",
      "Train Epoch: 8 [193920/697932 (28%)]\tLoss: 3.155283\n",
      "Train Epoch: 8 [194560/697932 (28%)]\tLoss: 3.158649\n",
      "Train Epoch: 8 [195200/697932 (28%)]\tLoss: 3.170139\n",
      "Train Epoch: 8 [195840/697932 (28%)]\tLoss: 3.178183\n",
      "Train Epoch: 8 [196480/697932 (28%)]\tLoss: 3.189996\n",
      "Train Epoch: 8 [197120/697932 (28%)]\tLoss: 3.153045\n",
      "Train Epoch: 8 [197760/697932 (28%)]\tLoss: 3.170046\n",
      "Train Epoch: 8 [198400/697932 (28%)]\tLoss: 3.166789\n",
      "Train Epoch: 8 [199040/697932 (29%)]\tLoss: 3.166705\n",
      "Train Epoch: 8 [199680/697932 (29%)]\tLoss: 3.187664\n",
      "Train Epoch: 8 [200320/697932 (29%)]\tLoss: 3.173087\n",
      "Train Epoch: 8 [200960/697932 (29%)]\tLoss: 3.139702\n",
      "Train Epoch: 8 [201600/697932 (29%)]\tLoss: 3.166331\n",
      "Train Epoch: 8 [202240/697932 (29%)]\tLoss: 3.151749\n",
      "Train Epoch: 8 [202880/697932 (29%)]\tLoss: 3.184600\n",
      "Train Epoch: 8 [203520/697932 (29%)]\tLoss: 3.166640\n",
      "Train Epoch: 8 [204160/697932 (29%)]\tLoss: 3.211223\n",
      "Train Epoch: 8 [204800/697932 (29%)]\tLoss: 3.174392\n",
      "Train Epoch: 8 [205440/697932 (29%)]\tLoss: 3.184905\n",
      "Train Epoch: 8 [206080/697932 (30%)]\tLoss: 3.177379\n",
      "Train Epoch: 8 [206720/697932 (30%)]\tLoss: 3.190307\n",
      "Train Epoch: 8 [207360/697932 (30%)]\tLoss: 3.155760\n",
      "Train Epoch: 8 [208000/697932 (30%)]\tLoss: 3.153897\n",
      "Train Epoch: 8 [208640/697932 (30%)]\tLoss: 3.193648\n",
      "Train Epoch: 8 [209280/697932 (30%)]\tLoss: 3.187932\n",
      "Train Epoch: 8 [209920/697932 (30%)]\tLoss: 3.164220\n",
      "Train Epoch: 8 [210560/697932 (30%)]\tLoss: 3.169571\n",
      "Train Epoch: 8 [211200/697932 (30%)]\tLoss: 3.183318\n",
      "Train Epoch: 8 [211840/697932 (30%)]\tLoss: 3.174359\n",
      "Train Epoch: 8 [212480/697932 (30%)]\tLoss: 3.143102\n",
      "Train Epoch: 8 [213120/697932 (31%)]\tLoss: 3.173728\n",
      "Train Epoch: 8 [213760/697932 (31%)]\tLoss: 3.176924\n",
      "Train Epoch: 8 [214400/697932 (31%)]\tLoss: 3.182768\n",
      "Train Epoch: 8 [215040/697932 (31%)]\tLoss: 3.181851\n",
      "Train Epoch: 8 [215680/697932 (31%)]\tLoss: 3.177119\n",
      "Train Epoch: 8 [216320/697932 (31%)]\tLoss: 3.155975\n",
      "Train Epoch: 8 [216960/697932 (31%)]\tLoss: 3.162547\n",
      "Train Epoch: 8 [217600/697932 (31%)]\tLoss: 3.178267\n",
      "Train Epoch: 8 [218240/697932 (31%)]\tLoss: 3.186362\n",
      "Train Epoch: 8 [218880/697932 (31%)]\tLoss: 3.174345\n",
      "Train Epoch: 8 [219520/697932 (31%)]\tLoss: 3.198852\n",
      "Train Epoch: 8 [220160/697932 (32%)]\tLoss: 3.151037\n",
      "Train Epoch: 8 [220800/697932 (32%)]\tLoss: 3.168010\n",
      "Train Epoch: 8 [221440/697932 (32%)]\tLoss: 3.184370\n",
      "Train Epoch: 8 [222080/697932 (32%)]\tLoss: 3.167654\n",
      "Train Epoch: 8 [222720/697932 (32%)]\tLoss: 3.168250\n",
      "Train Epoch: 8 [223360/697932 (32%)]\tLoss: 3.156093\n",
      "Train Epoch: 8 [224000/697932 (32%)]\tLoss: 3.166306\n",
      "Train Epoch: 8 [224640/697932 (32%)]\tLoss: 3.173755\n",
      "Train Epoch: 8 [225280/697932 (32%)]\tLoss: 3.188632\n",
      "Train Epoch: 8 [225920/697932 (32%)]\tLoss: 3.170884\n",
      "Train Epoch: 8 [226560/697932 (32%)]\tLoss: 3.152339\n",
      "Train Epoch: 8 [227200/697932 (33%)]\tLoss: 3.148383\n",
      "Train Epoch: 8 [227840/697932 (33%)]\tLoss: 3.168497\n",
      "Train Epoch: 8 [228480/697932 (33%)]\tLoss: 3.167830\n",
      "Train Epoch: 8 [229120/697932 (33%)]\tLoss: 3.171042\n",
      "Train Epoch: 8 [229760/697932 (33%)]\tLoss: 3.166365\n",
      "Train Epoch: 8 [230400/697932 (33%)]\tLoss: 3.156307\n",
      "Train Epoch: 8 [231040/697932 (33%)]\tLoss: 3.191843\n",
      "Train Epoch: 8 [231680/697932 (33%)]\tLoss: 3.193032\n",
      "Train Epoch: 8 [232320/697932 (33%)]\tLoss: 3.172998\n",
      "Train Epoch: 8 [232960/697932 (33%)]\tLoss: 3.154669\n",
      "Train Epoch: 8 [233600/697932 (33%)]\tLoss: 3.146179\n",
      "Train Epoch: 8 [234240/697932 (34%)]\tLoss: 3.170823\n",
      "Train Epoch: 8 [234880/697932 (34%)]\tLoss: 3.186108\n",
      "Train Epoch: 8 [235520/697932 (34%)]\tLoss: 3.159806\n",
      "Train Epoch: 8 [236160/697932 (34%)]\tLoss: 3.172497\n",
      "Train Epoch: 8 [236800/697932 (34%)]\tLoss: 3.152012\n",
      "Train Epoch: 8 [237440/697932 (34%)]\tLoss: 3.152821\n",
      "Train Epoch: 8 [238080/697932 (34%)]\tLoss: 3.156264\n",
      "Train Epoch: 8 [238720/697932 (34%)]\tLoss: 3.158208\n",
      "Train Epoch: 8 [239360/697932 (34%)]\tLoss: 3.162195\n",
      "Train Epoch: 8 [240000/697932 (34%)]\tLoss: 3.148917\n",
      "Train Epoch: 8 [240640/697932 (34%)]\tLoss: 3.194683\n",
      "Train Epoch: 8 [241280/697932 (35%)]\tLoss: 3.158892\n",
      "Train Epoch: 8 [241920/697932 (35%)]\tLoss: 3.157205\n",
      "Train Epoch: 8 [242560/697932 (35%)]\tLoss: 3.149519\n",
      "Train Epoch: 8 [243200/697932 (35%)]\tLoss: 3.159347\n",
      "Train Epoch: 8 [243840/697932 (35%)]\tLoss: 3.149507\n",
      "Train Epoch: 8 [244480/697932 (35%)]\tLoss: 3.155823\n",
      "Train Epoch: 8 [245120/697932 (35%)]\tLoss: 3.153255\n",
      "Train Epoch: 8 [245760/697932 (35%)]\tLoss: 3.193825\n",
      "Train Epoch: 8 [246400/697932 (35%)]\tLoss: 3.196787\n",
      "Train Epoch: 8 [247040/697932 (35%)]\tLoss: 3.166219\n",
      "Train Epoch: 8 [247680/697932 (35%)]\tLoss: 3.181261\n",
      "Train Epoch: 8 [248320/697932 (36%)]\tLoss: 3.166519\n",
      "Train Epoch: 8 [248960/697932 (36%)]\tLoss: 3.181922\n",
      "Train Epoch: 8 [249600/697932 (36%)]\tLoss: 3.148527\n",
      "Train Epoch: 8 [250240/697932 (36%)]\tLoss: 3.163820\n",
      "Train Epoch: 8 [250880/697932 (36%)]\tLoss: 3.148067\n",
      "Train Epoch: 8 [251520/697932 (36%)]\tLoss: 3.176357\n",
      "Train Epoch: 8 [252160/697932 (36%)]\tLoss: 3.185792\n",
      "Train Epoch: 8 [252800/697932 (36%)]\tLoss: 3.168755\n",
      "Train Epoch: 8 [253440/697932 (36%)]\tLoss: 3.169352\n",
      "Train Epoch: 8 [254080/697932 (36%)]\tLoss: 3.162308\n",
      "Train Epoch: 8 [254720/697932 (36%)]\tLoss: 3.198572\n",
      "Train Epoch: 8 [255360/697932 (37%)]\tLoss: 3.178611\n",
      "Train Epoch: 8 [256000/697932 (37%)]\tLoss: 3.168009\n",
      "Train Epoch: 8 [256640/697932 (37%)]\tLoss: 3.186486\n",
      "Train Epoch: 8 [257280/697932 (37%)]\tLoss: 3.166270\n",
      "Train Epoch: 8 [257920/697932 (37%)]\tLoss: 3.172012\n",
      "Train Epoch: 8 [258560/697932 (37%)]\tLoss: 3.186254\n",
      "Train Epoch: 8 [259200/697932 (37%)]\tLoss: 3.147079\n",
      "Train Epoch: 8 [259840/697932 (37%)]\tLoss: 3.177848\n",
      "Train Epoch: 8 [260480/697932 (37%)]\tLoss: 3.191976\n",
      "Train Epoch: 8 [261120/697932 (37%)]\tLoss: 3.179446\n",
      "Train Epoch: 8 [261760/697932 (38%)]\tLoss: 3.165107\n",
      "Train Epoch: 8 [262400/697932 (38%)]\tLoss: 3.155349\n",
      "Train Epoch: 8 [263040/697932 (38%)]\tLoss: 3.151785\n",
      "Train Epoch: 8 [263680/697932 (38%)]\tLoss: 3.135094\n",
      "Train Epoch: 8 [264320/697932 (38%)]\tLoss: 3.161453\n",
      "Train Epoch: 8 [264960/697932 (38%)]\tLoss: 3.190470\n",
      "Train Epoch: 8 [265600/697932 (38%)]\tLoss: 3.161953\n",
      "Train Epoch: 8 [266240/697932 (38%)]\tLoss: 3.174445\n",
      "Train Epoch: 8 [266880/697932 (38%)]\tLoss: 3.145802\n",
      "Train Epoch: 8 [267520/697932 (38%)]\tLoss: 3.190411\n",
      "Train Epoch: 8 [268160/697932 (38%)]\tLoss: 3.151537\n",
      "Train Epoch: 8 [268800/697932 (39%)]\tLoss: 3.184817\n",
      "Train Epoch: 8 [269440/697932 (39%)]\tLoss: 3.159639\n",
      "Train Epoch: 8 [270080/697932 (39%)]\tLoss: 3.171177\n",
      "Train Epoch: 8 [270720/697932 (39%)]\tLoss: 3.170814\n",
      "Train Epoch: 8 [271360/697932 (39%)]\tLoss: 3.172201\n",
      "Train Epoch: 8 [272000/697932 (39%)]\tLoss: 3.177455\n",
      "Train Epoch: 8 [272640/697932 (39%)]\tLoss: 3.157740\n",
      "Train Epoch: 8 [273280/697932 (39%)]\tLoss: 3.169247\n",
      "Train Epoch: 8 [273920/697932 (39%)]\tLoss: 3.189634\n",
      "Train Epoch: 8 [274560/697932 (39%)]\tLoss: 3.187685\n",
      "Train Epoch: 8 [275200/697932 (39%)]\tLoss: 3.159628\n",
      "Train Epoch: 8 [275840/697932 (40%)]\tLoss: 3.158215\n",
      "Train Epoch: 8 [276480/697932 (40%)]\tLoss: 3.170916\n",
      "Train Epoch: 8 [277120/697932 (40%)]\tLoss: 3.187714\n",
      "Train Epoch: 8 [277760/697932 (40%)]\tLoss: 3.157048\n",
      "Train Epoch: 8 [278400/697932 (40%)]\tLoss: 3.186938\n",
      "Train Epoch: 8 [279040/697932 (40%)]\tLoss: 3.188500\n",
      "Train Epoch: 8 [279680/697932 (40%)]\tLoss: 3.177412\n",
      "Train Epoch: 8 [280320/697932 (40%)]\tLoss: 3.164223\n",
      "Train Epoch: 8 [280960/697932 (40%)]\tLoss: 3.172945\n",
      "Train Epoch: 8 [281600/697932 (40%)]\tLoss: 3.162196\n",
      "Train Epoch: 8 [282240/697932 (40%)]\tLoss: 3.165044\n",
      "Train Epoch: 8 [282880/697932 (41%)]\tLoss: 3.162427\n",
      "Train Epoch: 8 [283520/697932 (41%)]\tLoss: 3.165386\n",
      "Train Epoch: 8 [284160/697932 (41%)]\tLoss: 3.152316\n",
      "Train Epoch: 8 [284800/697932 (41%)]\tLoss: 3.130194\n",
      "Train Epoch: 8 [285440/697932 (41%)]\tLoss: 3.159178\n",
      "Train Epoch: 8 [286080/697932 (41%)]\tLoss: 3.177325\n",
      "Train Epoch: 8 [286720/697932 (41%)]\tLoss: 3.165278\n",
      "Train Epoch: 8 [287360/697932 (41%)]\tLoss: 3.177888\n",
      "Train Epoch: 8 [288000/697932 (41%)]\tLoss: 3.185729\n",
      "Train Epoch: 8 [288640/697932 (41%)]\tLoss: 3.161551\n",
      "Train Epoch: 8 [289280/697932 (41%)]\tLoss: 3.182910\n",
      "Train Epoch: 8 [289920/697932 (42%)]\tLoss: 3.159326\n",
      "Train Epoch: 8 [290560/697932 (42%)]\tLoss: 3.177057\n",
      "Train Epoch: 8 [291200/697932 (42%)]\tLoss: 3.155324\n",
      "Train Epoch: 8 [291840/697932 (42%)]\tLoss: 3.174590\n",
      "Train Epoch: 8 [292480/697932 (42%)]\tLoss: 3.169253\n",
      "Train Epoch: 8 [293120/697932 (42%)]\tLoss: 3.185144\n",
      "Train Epoch: 8 [293760/697932 (42%)]\tLoss: 3.162014\n",
      "Train Epoch: 8 [294400/697932 (42%)]\tLoss: 3.168055\n",
      "Train Epoch: 8 [295040/697932 (42%)]\tLoss: 3.158984\n",
      "Train Epoch: 8 [295680/697932 (42%)]\tLoss: 3.162402\n",
      "Train Epoch: 8 [296320/697932 (42%)]\tLoss: 3.160023\n",
      "Train Epoch: 8 [296960/697932 (43%)]\tLoss: 3.173879\n",
      "Train Epoch: 8 [297600/697932 (43%)]\tLoss: 3.164124\n",
      "Train Epoch: 8 [298240/697932 (43%)]\tLoss: 3.143280\n",
      "Train Epoch: 8 [298880/697932 (43%)]\tLoss: 3.173919\n",
      "Train Epoch: 8 [299520/697932 (43%)]\tLoss: 3.189365\n",
      "Train Epoch: 8 [300160/697932 (43%)]\tLoss: 3.196770\n",
      "Train Epoch: 8 [300800/697932 (43%)]\tLoss: 3.154858\n",
      "Train Epoch: 8 [301440/697932 (43%)]\tLoss: 3.175734\n",
      "Train Epoch: 8 [302080/697932 (43%)]\tLoss: 3.159110\n",
      "Train Epoch: 8 [302720/697932 (43%)]\tLoss: 3.160553\n",
      "Train Epoch: 8 [303360/697932 (43%)]\tLoss: 3.160583\n",
      "Train Epoch: 8 [304000/697932 (44%)]\tLoss: 3.153994\n",
      "Train Epoch: 8 [304640/697932 (44%)]\tLoss: 3.139178\n",
      "Train Epoch: 8 [305280/697932 (44%)]\tLoss: 3.162822\n",
      "Train Epoch: 8 [305920/697932 (44%)]\tLoss: 3.183532\n",
      "Train Epoch: 8 [306560/697932 (44%)]\tLoss: 3.162166\n",
      "Train Epoch: 8 [307200/697932 (44%)]\tLoss: 3.170006\n",
      "Train Epoch: 8 [307840/697932 (44%)]\tLoss: 3.171834\n",
      "Train Epoch: 8 [308480/697932 (44%)]\tLoss: 3.155435\n",
      "Train Epoch: 8 [309120/697932 (44%)]\tLoss: 3.165218\n",
      "Train Epoch: 8 [309760/697932 (44%)]\tLoss: 3.145034\n",
      "Train Epoch: 8 [310400/697932 (44%)]\tLoss: 3.175983\n",
      "Train Epoch: 8 [311040/697932 (45%)]\tLoss: 3.167246\n",
      "Train Epoch: 8 [311680/697932 (45%)]\tLoss: 3.159702\n",
      "Train Epoch: 8 [312320/697932 (45%)]\tLoss: 3.182792\n",
      "Train Epoch: 8 [312960/697932 (45%)]\tLoss: 3.170473\n",
      "Train Epoch: 8 [313600/697932 (45%)]\tLoss: 3.171123\n",
      "Train Epoch: 8 [314240/697932 (45%)]\tLoss: 3.150340\n",
      "Train Epoch: 8 [314880/697932 (45%)]\tLoss: 3.171320\n",
      "Train Epoch: 8 [315520/697932 (45%)]\tLoss: 3.156089\n",
      "Train Epoch: 8 [316160/697932 (45%)]\tLoss: 3.165439\n",
      "Train Epoch: 8 [316800/697932 (45%)]\tLoss: 3.144593\n",
      "Train Epoch: 8 [317440/697932 (45%)]\tLoss: 3.152917\n",
      "Train Epoch: 8 [318080/697932 (46%)]\tLoss: 3.164090\n",
      "Train Epoch: 8 [318720/697932 (46%)]\tLoss: 3.158013\n",
      "Train Epoch: 8 [319360/697932 (46%)]\tLoss: 3.163664\n",
      "Train Epoch: 8 [320000/697932 (46%)]\tLoss: 3.166461\n",
      "Train Epoch: 8 [320640/697932 (46%)]\tLoss: 3.152576\n",
      "Train Epoch: 8 [321280/697932 (46%)]\tLoss: 3.184068\n",
      "Train Epoch: 8 [321920/697932 (46%)]\tLoss: 3.169444\n",
      "Train Epoch: 8 [322560/697932 (46%)]\tLoss: 3.155339\n",
      "Train Epoch: 8 [323200/697932 (46%)]\tLoss: 3.156847\n",
      "Train Epoch: 8 [323840/697932 (46%)]\tLoss: 3.167428\n",
      "Train Epoch: 8 [324480/697932 (46%)]\tLoss: 3.172876\n",
      "Train Epoch: 8 [325120/697932 (47%)]\tLoss: 3.167105\n",
      "Train Epoch: 8 [325760/697932 (47%)]\tLoss: 3.156463\n",
      "Train Epoch: 8 [326400/697932 (47%)]\tLoss: 3.168250\n",
      "Train Epoch: 8 [327040/697932 (47%)]\tLoss: 3.196859\n",
      "Train Epoch: 8 [327680/697932 (47%)]\tLoss: 3.161319\n",
      "Train Epoch: 8 [328320/697932 (47%)]\tLoss: 3.174587\n",
      "Train Epoch: 8 [328960/697932 (47%)]\tLoss: 3.158151\n",
      "Train Epoch: 8 [329600/697932 (47%)]\tLoss: 3.168496\n",
      "Train Epoch: 8 [330240/697932 (47%)]\tLoss: 3.173842\n",
      "Train Epoch: 8 [330880/697932 (47%)]\tLoss: 3.165630\n",
      "Train Epoch: 8 [331520/697932 (47%)]\tLoss: 3.157743\n",
      "Train Epoch: 8 [332160/697932 (48%)]\tLoss: 3.173075\n",
      "Train Epoch: 8 [332800/697932 (48%)]\tLoss: 3.160781\n",
      "Train Epoch: 8 [333440/697932 (48%)]\tLoss: 3.184968\n",
      "Train Epoch: 8 [334080/697932 (48%)]\tLoss: 3.172456\n",
      "Train Epoch: 8 [334720/697932 (48%)]\tLoss: 3.183773\n",
      "Train Epoch: 8 [335360/697932 (48%)]\tLoss: 3.164855\n",
      "Train Epoch: 8 [336000/697932 (48%)]\tLoss: 3.188271\n",
      "Train Epoch: 8 [336640/697932 (48%)]\tLoss: 3.188444\n",
      "Train Epoch: 8 [337280/697932 (48%)]\tLoss: 3.166888\n",
      "Train Epoch: 8 [337920/697932 (48%)]\tLoss: 3.149775\n",
      "Train Epoch: 8 [338560/697932 (49%)]\tLoss: 3.167358\n",
      "Train Epoch: 8 [339200/697932 (49%)]\tLoss: 3.165548\n",
      "Train Epoch: 8 [339840/697932 (49%)]\tLoss: 3.195145\n",
      "Train Epoch: 8 [340480/697932 (49%)]\tLoss: 3.195528\n",
      "Train Epoch: 8 [341120/697932 (49%)]\tLoss: 3.160933\n",
      "Train Epoch: 8 [341760/697932 (49%)]\tLoss: 3.171758\n",
      "Train Epoch: 8 [342400/697932 (49%)]\tLoss: 3.187497\n",
      "Train Epoch: 8 [343040/697932 (49%)]\tLoss: 3.165255\n",
      "Train Epoch: 8 [343680/697932 (49%)]\tLoss: 3.163145\n",
      "Train Epoch: 8 [344320/697932 (49%)]\tLoss: 3.145351\n",
      "Train Epoch: 8 [344960/697932 (49%)]\tLoss: 3.160420\n",
      "Train Epoch: 8 [345600/697932 (50%)]\tLoss: 3.161336\n",
      "Train Epoch: 8 [346240/697932 (50%)]\tLoss: 3.169879\n",
      "Train Epoch: 8 [346880/697932 (50%)]\tLoss: 3.179844\n",
      "Train Epoch: 8 [347520/697932 (50%)]\tLoss: 3.169330\n",
      "Train Epoch: 8 [348160/697932 (50%)]\tLoss: 3.161964\n",
      "Train Epoch: 8 [348800/697932 (50%)]\tLoss: 3.165302\n",
      "Train Epoch: 8 [349440/697932 (50%)]\tLoss: 3.161052\n",
      "Train Epoch: 8 [350080/697932 (50%)]\tLoss: 3.171374\n",
      "Train Epoch: 8 [350720/697932 (50%)]\tLoss: 3.168439\n",
      "Train Epoch: 8 [351360/697932 (50%)]\tLoss: 3.179778\n",
      "Train Epoch: 8 [352000/697932 (50%)]\tLoss: 3.202018\n",
      "Train Epoch: 8 [352640/697932 (51%)]\tLoss: 3.186086\n",
      "Train Epoch: 8 [353280/697932 (51%)]\tLoss: 3.197980\n",
      "Train Epoch: 8 [353920/697932 (51%)]\tLoss: 3.153574\n",
      "Train Epoch: 8 [354560/697932 (51%)]\tLoss: 3.182518\n",
      "Train Epoch: 8 [355200/697932 (51%)]\tLoss: 3.172961\n",
      "Train Epoch: 8 [355840/697932 (51%)]\tLoss: 3.188753\n",
      "Train Epoch: 8 [356480/697932 (51%)]\tLoss: 3.160486\n",
      "Train Epoch: 8 [357120/697932 (51%)]\tLoss: 3.152674\n",
      "Train Epoch: 8 [357760/697932 (51%)]\tLoss: 3.158603\n",
      "Train Epoch: 8 [358400/697932 (51%)]\tLoss: 3.168099\n",
      "Train Epoch: 8 [359040/697932 (51%)]\tLoss: 3.166729\n",
      "Train Epoch: 8 [359680/697932 (52%)]\tLoss: 3.185968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [360320/697932 (52%)]\tLoss: 3.169628\n",
      "Train Epoch: 8 [360960/697932 (52%)]\tLoss: 3.165770\n",
      "Train Epoch: 8 [361600/697932 (52%)]\tLoss: 3.176857\n",
      "Train Epoch: 8 [362240/697932 (52%)]\tLoss: 3.152170\n",
      "Train Epoch: 8 [362880/697932 (52%)]\tLoss: 3.157272\n",
      "Train Epoch: 8 [363520/697932 (52%)]\tLoss: 3.172216\n",
      "Train Epoch: 8 [364160/697932 (52%)]\tLoss: 3.157055\n",
      "Train Epoch: 8 [364800/697932 (52%)]\tLoss: 3.148889\n",
      "Train Epoch: 8 [365440/697932 (52%)]\tLoss: 3.136922\n",
      "Train Epoch: 8 [366080/697932 (52%)]\tLoss: 3.149729\n",
      "Train Epoch: 8 [366720/697932 (53%)]\tLoss: 3.174474\n",
      "Train Epoch: 8 [367360/697932 (53%)]\tLoss: 3.199199\n",
      "Train Epoch: 8 [368000/697932 (53%)]\tLoss: 3.136625\n",
      "Train Epoch: 8 [368640/697932 (53%)]\tLoss: 3.158021\n",
      "Train Epoch: 8 [369280/697932 (53%)]\tLoss: 3.157581\n",
      "Train Epoch: 8 [369920/697932 (53%)]\tLoss: 3.176847\n",
      "Train Epoch: 8 [370560/697932 (53%)]\tLoss: 3.173892\n",
      "Train Epoch: 8 [371200/697932 (53%)]\tLoss: 3.158543\n",
      "Train Epoch: 8 [371840/697932 (53%)]\tLoss: 3.165160\n",
      "Train Epoch: 8 [372480/697932 (53%)]\tLoss: 3.160625\n",
      "Train Epoch: 8 [373120/697932 (53%)]\tLoss: 3.167557\n",
      "Train Epoch: 8 [373760/697932 (54%)]\tLoss: 3.163712\n",
      "Train Epoch: 8 [374400/697932 (54%)]\tLoss: 3.195168\n",
      "Train Epoch: 8 [375040/697932 (54%)]\tLoss: 3.157187\n",
      "Train Epoch: 8 [375680/697932 (54%)]\tLoss: 3.181116\n",
      "Train Epoch: 8 [376320/697932 (54%)]\tLoss: 3.175459\n",
      "Train Epoch: 8 [376960/697932 (54%)]\tLoss: 3.170003\n",
      "Train Epoch: 8 [377600/697932 (54%)]\tLoss: 3.176800\n",
      "Train Epoch: 8 [378240/697932 (54%)]\tLoss: 3.181030\n",
      "Train Epoch: 8 [378880/697932 (54%)]\tLoss: 3.174326\n",
      "Train Epoch: 8 [379520/697932 (54%)]\tLoss: 3.123366\n",
      "Train Epoch: 8 [380160/697932 (54%)]\tLoss: 3.149602\n",
      "Train Epoch: 8 [380800/697932 (55%)]\tLoss: 3.182319\n",
      "Train Epoch: 8 [381440/697932 (55%)]\tLoss: 3.183084\n",
      "Train Epoch: 8 [382080/697932 (55%)]\tLoss: 3.187428\n",
      "Train Epoch: 8 [382720/697932 (55%)]\tLoss: 3.175382\n",
      "Train Epoch: 8 [383360/697932 (55%)]\tLoss: 3.200291\n",
      "Train Epoch: 8 [384000/697932 (55%)]\tLoss: 3.153491\n",
      "Train Epoch: 8 [384640/697932 (55%)]\tLoss: 3.167650\n",
      "Train Epoch: 8 [385280/697932 (55%)]\tLoss: 3.184017\n",
      "Train Epoch: 8 [385920/697932 (55%)]\tLoss: 3.160151\n",
      "Train Epoch: 8 [386560/697932 (55%)]\tLoss: 3.147851\n",
      "Train Epoch: 8 [387200/697932 (55%)]\tLoss: 3.156142\n",
      "Train Epoch: 8 [387840/697932 (56%)]\tLoss: 3.195211\n",
      "Train Epoch: 8 [388480/697932 (56%)]\tLoss: 3.142572\n",
      "Train Epoch: 8 [389120/697932 (56%)]\tLoss: 3.155311\n",
      "Train Epoch: 8 [389760/697932 (56%)]\tLoss: 3.197518\n",
      "Train Epoch: 8 [390400/697932 (56%)]\tLoss: 3.152121\n",
      "Train Epoch: 8 [391040/697932 (56%)]\tLoss: 3.166179\n",
      "Train Epoch: 8 [391680/697932 (56%)]\tLoss: 3.157830\n",
      "Train Epoch: 8 [392320/697932 (56%)]\tLoss: 3.163067\n",
      "Train Epoch: 8 [392960/697932 (56%)]\tLoss: 3.160012\n",
      "Train Epoch: 8 [393600/697932 (56%)]\tLoss: 3.172240\n",
      "Train Epoch: 8 [394240/697932 (56%)]\tLoss: 3.151891\n",
      "Train Epoch: 8 [394880/697932 (57%)]\tLoss: 3.188374\n",
      "Train Epoch: 8 [395520/697932 (57%)]\tLoss: 3.188835\n",
      "Train Epoch: 8 [396160/697932 (57%)]\tLoss: 3.172335\n",
      "Train Epoch: 8 [396800/697932 (57%)]\tLoss: 3.155969\n",
      "Train Epoch: 8 [397440/697932 (57%)]\tLoss: 3.187989\n",
      "Train Epoch: 8 [398080/697932 (57%)]\tLoss: 3.193387\n",
      "Train Epoch: 8 [398720/697932 (57%)]\tLoss: 3.187950\n",
      "Train Epoch: 8 [399360/697932 (57%)]\tLoss: 3.180446\n",
      "Train Epoch: 8 [400000/697932 (57%)]\tLoss: 3.147295\n",
      "Train Epoch: 8 [400640/697932 (57%)]\tLoss: 3.176027\n",
      "Train Epoch: 8 [401280/697932 (57%)]\tLoss: 3.154994\n",
      "Train Epoch: 8 [401920/697932 (58%)]\tLoss: 3.172795\n",
      "Train Epoch: 8 [402560/697932 (58%)]\tLoss: 3.173886\n",
      "Train Epoch: 8 [403200/697932 (58%)]\tLoss: 3.175793\n",
      "Train Epoch: 8 [403840/697932 (58%)]\tLoss: 3.145422\n",
      "Train Epoch: 8 [404480/697932 (58%)]\tLoss: 3.168075\n",
      "Train Epoch: 8 [405120/697932 (58%)]\tLoss: 3.166994\n",
      "Train Epoch: 8 [405760/697932 (58%)]\tLoss: 3.145844\n",
      "Train Epoch: 8 [406400/697932 (58%)]\tLoss: 3.170513\n",
      "Train Epoch: 8 [407040/697932 (58%)]\tLoss: 3.153197\n",
      "Train Epoch: 8 [407680/697932 (58%)]\tLoss: 3.191897\n",
      "Train Epoch: 8 [408320/697932 (58%)]\tLoss: 3.159649\n",
      "Train Epoch: 8 [408960/697932 (59%)]\tLoss: 3.174313\n",
      "Train Epoch: 8 [409600/697932 (59%)]\tLoss: 3.178122\n",
      "Train Epoch: 8 [410240/697932 (59%)]\tLoss: 3.162192\n",
      "Train Epoch: 8 [410880/697932 (59%)]\tLoss: 3.154165\n",
      "Train Epoch: 8 [411520/697932 (59%)]\tLoss: 3.163216\n",
      "Train Epoch: 8 [412160/697932 (59%)]\tLoss: 3.147005\n",
      "Train Epoch: 8 [412800/697932 (59%)]\tLoss: 3.182091\n",
      "Train Epoch: 8 [413440/697932 (59%)]\tLoss: 3.167756\n",
      "Train Epoch: 8 [414080/697932 (59%)]\tLoss: 3.155628\n",
      "Train Epoch: 8 [414720/697932 (59%)]\tLoss: 3.167433\n",
      "Train Epoch: 8 [415360/697932 (60%)]\tLoss: 3.156072\n",
      "Train Epoch: 8 [416000/697932 (60%)]\tLoss: 3.189793\n",
      "Train Epoch: 8 [416640/697932 (60%)]\tLoss: 3.166743\n",
      "Train Epoch: 8 [417280/697932 (60%)]\tLoss: 3.162866\n",
      "Train Epoch: 8 [417920/697932 (60%)]\tLoss: 3.162366\n",
      "Train Epoch: 8 [418560/697932 (60%)]\tLoss: 3.161233\n",
      "Train Epoch: 8 [419200/697932 (60%)]\tLoss: 3.196610\n",
      "Train Epoch: 8 [419840/697932 (60%)]\tLoss: 3.180896\n",
      "Train Epoch: 8 [420480/697932 (60%)]\tLoss: 3.186714\n",
      "Train Epoch: 8 [421120/697932 (60%)]\tLoss: 3.145023\n",
      "Train Epoch: 8 [421760/697932 (60%)]\tLoss: 3.167828\n",
      "Train Epoch: 8 [422400/697932 (61%)]\tLoss: 3.167300\n",
      "Train Epoch: 8 [423040/697932 (61%)]\tLoss: 3.163125\n",
      "Train Epoch: 8 [423680/697932 (61%)]\tLoss: 3.139338\n",
      "Train Epoch: 8 [424320/697932 (61%)]\tLoss: 3.128772\n",
      "Train Epoch: 8 [424960/697932 (61%)]\tLoss: 3.175842\n",
      "Train Epoch: 8 [425600/697932 (61%)]\tLoss: 3.167976\n",
      "Train Epoch: 8 [426240/697932 (61%)]\tLoss: 3.152408\n",
      "Train Epoch: 8 [426880/697932 (61%)]\tLoss: 3.164660\n",
      "Train Epoch: 8 [427520/697932 (61%)]\tLoss: 3.144991\n",
      "Train Epoch: 8 [428160/697932 (61%)]\tLoss: 3.191508\n",
      "Train Epoch: 8 [428800/697932 (61%)]\tLoss: 3.174045\n",
      "Train Epoch: 8 [429440/697932 (62%)]\tLoss: 3.182553\n",
      "Train Epoch: 8 [430080/697932 (62%)]\tLoss: 3.139788\n",
      "Train Epoch: 8 [430720/697932 (62%)]\tLoss: 3.176932\n",
      "Train Epoch: 8 [431360/697932 (62%)]\tLoss: 3.167272\n",
      "Train Epoch: 8 [432000/697932 (62%)]\tLoss: 3.171956\n",
      "Train Epoch: 8 [432640/697932 (62%)]\tLoss: 3.172970\n",
      "Train Epoch: 8 [433280/697932 (62%)]\tLoss: 3.162944\n",
      "Train Epoch: 8 [433920/697932 (62%)]\tLoss: 3.161052\n",
      "Train Epoch: 8 [434560/697932 (62%)]\tLoss: 3.166504\n",
      "Train Epoch: 8 [435200/697932 (62%)]\tLoss: 3.168640\n",
      "Train Epoch: 8 [435840/697932 (62%)]\tLoss: 3.188400\n",
      "Train Epoch: 8 [436480/697932 (63%)]\tLoss: 3.161458\n",
      "Train Epoch: 8 [437120/697932 (63%)]\tLoss: 3.187133\n",
      "Train Epoch: 8 [437760/697932 (63%)]\tLoss: 3.155441\n",
      "Train Epoch: 8 [438400/697932 (63%)]\tLoss: 3.183840\n",
      "Train Epoch: 8 [439040/697932 (63%)]\tLoss: 3.156292\n",
      "Train Epoch: 8 [439680/697932 (63%)]\tLoss: 3.159896\n",
      "Train Epoch: 8 [440320/697932 (63%)]\tLoss: 3.172240\n",
      "Train Epoch: 8 [440960/697932 (63%)]\tLoss: 3.189185\n",
      "Train Epoch: 8 [441600/697932 (63%)]\tLoss: 3.180448\n",
      "Train Epoch: 8 [442240/697932 (63%)]\tLoss: 3.156678\n",
      "Train Epoch: 8 [442880/697932 (63%)]\tLoss: 3.164243\n",
      "Train Epoch: 8 [443520/697932 (64%)]\tLoss: 3.174254\n",
      "Train Epoch: 8 [444160/697932 (64%)]\tLoss: 3.147396\n",
      "Train Epoch: 8 [444800/697932 (64%)]\tLoss: 3.155014\n",
      "Train Epoch: 8 [445440/697932 (64%)]\tLoss: 3.156859\n",
      "Train Epoch: 8 [446080/697932 (64%)]\tLoss: 3.135972\n",
      "Train Epoch: 8 [446720/697932 (64%)]\tLoss: 3.183255\n",
      "Train Epoch: 8 [447360/697932 (64%)]\tLoss: 3.175312\n",
      "Train Epoch: 8 [448000/697932 (64%)]\tLoss: 3.138647\n",
      "Train Epoch: 8 [448640/697932 (64%)]\tLoss: 3.180302\n",
      "Train Epoch: 8 [449280/697932 (64%)]\tLoss: 3.185402\n",
      "Train Epoch: 8 [449920/697932 (64%)]\tLoss: 3.155643\n",
      "Train Epoch: 8 [450560/697932 (65%)]\tLoss: 3.171600\n",
      "Train Epoch: 8 [451200/697932 (65%)]\tLoss: 3.160137\n",
      "Train Epoch: 8 [451840/697932 (65%)]\tLoss: 3.190492\n",
      "Train Epoch: 8 [452480/697932 (65%)]\tLoss: 3.175357\n",
      "Train Epoch: 8 [453120/697932 (65%)]\tLoss: 3.151506\n",
      "Train Epoch: 8 [453760/697932 (65%)]\tLoss: 3.169819\n",
      "Train Epoch: 8 [454400/697932 (65%)]\tLoss: 3.164862\n",
      "Train Epoch: 8 [455040/697932 (65%)]\tLoss: 3.175857\n",
      "Train Epoch: 8 [455680/697932 (65%)]\tLoss: 3.183342\n",
      "Train Epoch: 8 [456320/697932 (65%)]\tLoss: 3.190160\n",
      "Train Epoch: 8 [456960/697932 (65%)]\tLoss: 3.176826\n",
      "Train Epoch: 8 [457600/697932 (66%)]\tLoss: 3.157038\n",
      "Train Epoch: 8 [458240/697932 (66%)]\tLoss: 3.150747\n",
      "Train Epoch: 8 [458880/697932 (66%)]\tLoss: 3.169286\n",
      "Train Epoch: 8 [459520/697932 (66%)]\tLoss: 3.163952\n",
      "Train Epoch: 8 [460160/697932 (66%)]\tLoss: 3.171118\n",
      "Train Epoch: 8 [460800/697932 (66%)]\tLoss: 3.162280\n",
      "Train Epoch: 8 [461440/697932 (66%)]\tLoss: 3.159427\n",
      "Train Epoch: 8 [462080/697932 (66%)]\tLoss: 3.159371\n",
      "Train Epoch: 8 [462720/697932 (66%)]\tLoss: 3.167854\n",
      "Train Epoch: 8 [463360/697932 (66%)]\tLoss: 3.188971\n",
      "Train Epoch: 8 [464000/697932 (66%)]\tLoss: 3.181307\n",
      "Train Epoch: 8 [464640/697932 (67%)]\tLoss: 3.159858\n",
      "Train Epoch: 8 [465280/697932 (67%)]\tLoss: 3.167054\n",
      "Train Epoch: 8 [465920/697932 (67%)]\tLoss: 3.169156\n",
      "Train Epoch: 8 [466560/697932 (67%)]\tLoss: 3.199079\n",
      "Train Epoch: 8 [467200/697932 (67%)]\tLoss: 3.165640\n",
      "Train Epoch: 8 [467840/697932 (67%)]\tLoss: 3.158060\n",
      "Train Epoch: 8 [468480/697932 (67%)]\tLoss: 3.168865\n",
      "Train Epoch: 8 [469120/697932 (67%)]\tLoss: 3.171814\n",
      "Train Epoch: 8 [469760/697932 (67%)]\tLoss: 3.181272\n",
      "Train Epoch: 8 [470400/697932 (67%)]\tLoss: 3.168349\n",
      "Train Epoch: 8 [471040/697932 (67%)]\tLoss: 3.157005\n",
      "Train Epoch: 8 [471680/697932 (68%)]\tLoss: 3.172724\n",
      "Train Epoch: 8 [472320/697932 (68%)]\tLoss: 3.178365\n",
      "Train Epoch: 8 [472960/697932 (68%)]\tLoss: 3.164100\n",
      "Train Epoch: 8 [473600/697932 (68%)]\tLoss: 3.183811\n",
      "Train Epoch: 8 [474240/697932 (68%)]\tLoss: 3.156150\n",
      "Train Epoch: 8 [474880/697932 (68%)]\tLoss: 3.153297\n",
      "Train Epoch: 8 [475520/697932 (68%)]\tLoss: 3.159060\n",
      "Train Epoch: 8 [476160/697932 (68%)]\tLoss: 3.197005\n",
      "Train Epoch: 8 [476800/697932 (68%)]\tLoss: 3.165541\n",
      "Train Epoch: 8 [477440/697932 (68%)]\tLoss: 3.178405\n",
      "Train Epoch: 8 [478080/697932 (68%)]\tLoss: 3.188684\n",
      "Train Epoch: 8 [478720/697932 (69%)]\tLoss: 3.146119\n",
      "Train Epoch: 8 [479360/697932 (69%)]\tLoss: 3.129413\n",
      "Train Epoch: 8 [480000/697932 (69%)]\tLoss: 3.165716\n",
      "Train Epoch: 8 [480640/697932 (69%)]\tLoss: 3.168472\n",
      "Train Epoch: 8 [481280/697932 (69%)]\tLoss: 3.177791\n",
      "Train Epoch: 8 [481920/697932 (69%)]\tLoss: 3.137180\n",
      "Train Epoch: 8 [482560/697932 (69%)]\tLoss: 3.177578\n",
      "Train Epoch: 8 [483200/697932 (69%)]\tLoss: 3.158919\n",
      "Train Epoch: 8 [483840/697932 (69%)]\tLoss: 3.181673\n",
      "Train Epoch: 8 [484480/697932 (69%)]\tLoss: 3.155482\n",
      "Train Epoch: 8 [485120/697932 (70%)]\tLoss: 3.155717\n",
      "Train Epoch: 8 [485760/697932 (70%)]\tLoss: 3.162087\n",
      "Train Epoch: 8 [486400/697932 (70%)]\tLoss: 3.162682\n",
      "Train Epoch: 8 [487040/697932 (70%)]\tLoss: 3.158389\n",
      "Train Epoch: 8 [487680/697932 (70%)]\tLoss: 3.160331\n",
      "Train Epoch: 8 [488320/697932 (70%)]\tLoss: 3.155259\n",
      "Train Epoch: 8 [488960/697932 (70%)]\tLoss: 3.153668\n",
      "Train Epoch: 8 [489600/697932 (70%)]\tLoss: 3.168948\n",
      "Train Epoch: 8 [490240/697932 (70%)]\tLoss: 3.172659\n",
      "Train Epoch: 8 [490880/697932 (70%)]\tLoss: 3.166111\n",
      "Train Epoch: 8 [491520/697932 (70%)]\tLoss: 3.158906\n",
      "Train Epoch: 8 [492160/697932 (71%)]\tLoss: 3.165362\n",
      "Train Epoch: 8 [492800/697932 (71%)]\tLoss: 3.165743\n",
      "Train Epoch: 8 [493440/697932 (71%)]\tLoss: 3.158076\n",
      "Train Epoch: 8 [494080/697932 (71%)]\tLoss: 3.174051\n",
      "Train Epoch: 8 [494720/697932 (71%)]\tLoss: 3.177378\n",
      "Train Epoch: 8 [495360/697932 (71%)]\tLoss: 3.154124\n",
      "Train Epoch: 8 [496000/697932 (71%)]\tLoss: 3.188644\n",
      "Train Epoch: 8 [496640/697932 (71%)]\tLoss: 3.167327\n",
      "Train Epoch: 8 [497280/697932 (71%)]\tLoss: 3.187333\n",
      "Train Epoch: 8 [497920/697932 (71%)]\tLoss: 3.162246\n",
      "Train Epoch: 8 [498560/697932 (71%)]\tLoss: 3.158140\n",
      "Train Epoch: 8 [499200/697932 (72%)]\tLoss: 3.196322\n",
      "Train Epoch: 8 [499840/697932 (72%)]\tLoss: 3.173430\n",
      "Train Epoch: 8 [500480/697932 (72%)]\tLoss: 3.205915\n",
      "Train Epoch: 8 [501120/697932 (72%)]\tLoss: 3.171215\n",
      "Train Epoch: 8 [501760/697932 (72%)]\tLoss: 3.156842\n",
      "Train Epoch: 8 [502400/697932 (72%)]\tLoss: 3.176766\n",
      "Train Epoch: 8 [503040/697932 (72%)]\tLoss: 3.167112\n",
      "Train Epoch: 8 [503680/697932 (72%)]\tLoss: 3.163883\n",
      "Train Epoch: 8 [504320/697932 (72%)]\tLoss: 3.160803\n",
      "Train Epoch: 8 [504960/697932 (72%)]\tLoss: 3.179232\n",
      "Train Epoch: 8 [505600/697932 (72%)]\tLoss: 3.154781\n",
      "Train Epoch: 8 [506240/697932 (73%)]\tLoss: 3.155907\n",
      "Train Epoch: 8 [506880/697932 (73%)]\tLoss: 3.143391\n",
      "Train Epoch: 8 [507520/697932 (73%)]\tLoss: 3.145387\n",
      "Train Epoch: 8 [508160/697932 (73%)]\tLoss: 3.172093\n",
      "Train Epoch: 8 [508800/697932 (73%)]\tLoss: 3.170601\n",
      "Train Epoch: 8 [509440/697932 (73%)]\tLoss: 3.179092\n",
      "Train Epoch: 8 [510080/697932 (73%)]\tLoss: 3.146132\n",
      "Train Epoch: 8 [510720/697932 (73%)]\tLoss: 3.176805\n",
      "Train Epoch: 8 [511360/697932 (73%)]\tLoss: 3.165009\n",
      "Train Epoch: 8 [512000/697932 (73%)]\tLoss: 3.168080\n",
      "Train Epoch: 8 [512640/697932 (73%)]\tLoss: 3.147449\n",
      "Train Epoch: 8 [513280/697932 (74%)]\tLoss: 3.159428\n",
      "Train Epoch: 8 [513920/697932 (74%)]\tLoss: 3.150983\n",
      "Train Epoch: 8 [514560/697932 (74%)]\tLoss: 3.165917\n",
      "Train Epoch: 8 [515200/697932 (74%)]\tLoss: 3.179105\n",
      "Train Epoch: 8 [515840/697932 (74%)]\tLoss: 3.127396\n",
      "Train Epoch: 8 [516480/697932 (74%)]\tLoss: 3.167585\n",
      "Train Epoch: 8 [517120/697932 (74%)]\tLoss: 3.153155\n",
      "Train Epoch: 8 [517760/697932 (74%)]\tLoss: 3.157721\n",
      "Train Epoch: 8 [518400/697932 (74%)]\tLoss: 3.179282\n",
      "Train Epoch: 8 [519040/697932 (74%)]\tLoss: 3.164436\n",
      "Train Epoch: 8 [519680/697932 (74%)]\tLoss: 3.160001\n",
      "Train Epoch: 8 [520320/697932 (75%)]\tLoss: 3.170145\n",
      "Train Epoch: 8 [520960/697932 (75%)]\tLoss: 3.160044\n",
      "Train Epoch: 8 [521600/697932 (75%)]\tLoss: 3.166188\n",
      "Train Epoch: 8 [522240/697932 (75%)]\tLoss: 3.157925\n",
      "Train Epoch: 8 [522880/697932 (75%)]\tLoss: 3.185009\n",
      "Train Epoch: 8 [523520/697932 (75%)]\tLoss: 3.141575\n",
      "Train Epoch: 8 [524160/697932 (75%)]\tLoss: 3.176848\n",
      "Train Epoch: 8 [524800/697932 (75%)]\tLoss: 3.172666\n",
      "Train Epoch: 8 [525440/697932 (75%)]\tLoss: 3.154168\n",
      "Train Epoch: 8 [526080/697932 (75%)]\tLoss: 3.182208\n",
      "Train Epoch: 8 [526720/697932 (75%)]\tLoss: 3.178336\n",
      "Train Epoch: 8 [527360/697932 (76%)]\tLoss: 3.154963\n",
      "Train Epoch: 8 [528000/697932 (76%)]\tLoss: 3.181516\n",
      "Train Epoch: 8 [528640/697932 (76%)]\tLoss: 3.189511\n",
      "Train Epoch: 8 [529280/697932 (76%)]\tLoss: 3.175889\n",
      "Train Epoch: 8 [529920/697932 (76%)]\tLoss: 3.163846\n",
      "Train Epoch: 8 [530560/697932 (76%)]\tLoss: 3.161173\n",
      "Train Epoch: 8 [531200/697932 (76%)]\tLoss: 3.148813\n",
      "Train Epoch: 8 [531840/697932 (76%)]\tLoss: 3.195813\n",
      "Train Epoch: 8 [532480/697932 (76%)]\tLoss: 3.169901\n",
      "Train Epoch: 8 [533120/697932 (76%)]\tLoss: 3.160695\n",
      "Train Epoch: 8 [533760/697932 (76%)]\tLoss: 3.162827\n",
      "Train Epoch: 8 [534400/697932 (77%)]\tLoss: 3.148020\n",
      "Train Epoch: 8 [535040/697932 (77%)]\tLoss: 3.173354\n",
      "Train Epoch: 8 [535680/697932 (77%)]\tLoss: 3.148957\n",
      "Train Epoch: 8 [536320/697932 (77%)]\tLoss: 3.196097\n",
      "Train Epoch: 8 [536960/697932 (77%)]\tLoss: 3.177964\n",
      "Train Epoch: 8 [537600/697932 (77%)]\tLoss: 3.155007\n",
      "Train Epoch: 8 [538240/697932 (77%)]\tLoss: 3.167408\n",
      "Train Epoch: 8 [538880/697932 (77%)]\tLoss: 3.175547\n",
      "Train Epoch: 8 [539520/697932 (77%)]\tLoss: 3.166077\n",
      "Train Epoch: 8 [540160/697932 (77%)]\tLoss: 3.167019\n",
      "Train Epoch: 8 [540800/697932 (77%)]\tLoss: 3.149416\n",
      "Train Epoch: 8 [541440/697932 (78%)]\tLoss: 3.172338\n",
      "Train Epoch: 8 [542080/697932 (78%)]\tLoss: 3.176584\n",
      "Train Epoch: 8 [542720/697932 (78%)]\tLoss: 3.173668\n",
      "Train Epoch: 8 [543360/697932 (78%)]\tLoss: 3.179262\n",
      "Train Epoch: 8 [544000/697932 (78%)]\tLoss: 3.189746\n",
      "Train Epoch: 8 [544640/697932 (78%)]\tLoss: 3.167751\n",
      "Train Epoch: 8 [545280/697932 (78%)]\tLoss: 3.137146\n",
      "Train Epoch: 8 [545920/697932 (78%)]\tLoss: 3.157896\n",
      "Train Epoch: 8 [546560/697932 (78%)]\tLoss: 3.203220\n",
      "Train Epoch: 8 [547200/697932 (78%)]\tLoss: 3.171558\n",
      "Train Epoch: 8 [547840/697932 (78%)]\tLoss: 3.162348\n",
      "Train Epoch: 8 [548480/697932 (79%)]\tLoss: 3.188637\n",
      "Train Epoch: 8 [549120/697932 (79%)]\tLoss: 3.154740\n",
      "Train Epoch: 8 [549760/697932 (79%)]\tLoss: 3.173225\n",
      "Train Epoch: 8 [550400/697932 (79%)]\tLoss: 3.162080\n",
      "Train Epoch: 8 [551040/697932 (79%)]\tLoss: 3.166069\n",
      "Train Epoch: 8 [551680/697932 (79%)]\tLoss: 3.156657\n",
      "Train Epoch: 8 [552320/697932 (79%)]\tLoss: 3.179085\n",
      "Train Epoch: 8 [552960/697932 (79%)]\tLoss: 3.157830\n",
      "Train Epoch: 8 [553600/697932 (79%)]\tLoss: 3.185483\n",
      "Train Epoch: 8 [554240/697932 (79%)]\tLoss: 3.166300\n",
      "Train Epoch: 8 [554880/697932 (79%)]\tLoss: 3.163636\n",
      "Train Epoch: 8 [555520/697932 (80%)]\tLoss: 3.178887\n",
      "Train Epoch: 8 [556160/697932 (80%)]\tLoss: 3.150577\n",
      "Train Epoch: 8 [556800/697932 (80%)]\tLoss: 3.184026\n",
      "Train Epoch: 8 [557440/697932 (80%)]\tLoss: 3.173371\n",
      "Train Epoch: 8 [558080/697932 (80%)]\tLoss: 3.151541\n",
      "Train Epoch: 8 [558720/697932 (80%)]\tLoss: 3.167782\n",
      "Train Epoch: 8 [559360/697932 (80%)]\tLoss: 3.175370\n",
      "Train Epoch: 8 [560000/697932 (80%)]\tLoss: 3.176079\n",
      "Train Epoch: 8 [560640/697932 (80%)]\tLoss: 3.155354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 8 [561280/697932 (80%)]\tLoss: 3.182030\n",
      "Train Epoch: 8 [561920/697932 (81%)]\tLoss: 3.165339\n",
      "Train Epoch: 8 [562560/697932 (81%)]\tLoss: 3.175807\n",
      "Train Epoch: 8 [563200/697932 (81%)]\tLoss: 3.166845\n",
      "Train Epoch: 8 [563840/697932 (81%)]\tLoss: 3.136470\n",
      "Train Epoch: 8 [564480/697932 (81%)]\tLoss: 3.187202\n",
      "Train Epoch: 8 [565120/697932 (81%)]\tLoss: 3.168156\n",
      "Train Epoch: 8 [565760/697932 (81%)]\tLoss: 3.173380\n",
      "Train Epoch: 8 [566400/697932 (81%)]\tLoss: 3.165608\n",
      "Train Epoch: 8 [567040/697932 (81%)]\tLoss: 3.186456\n",
      "Train Epoch: 8 [567680/697932 (81%)]\tLoss: 3.163154\n",
      "Train Epoch: 8 [568320/697932 (81%)]\tLoss: 3.182529\n",
      "Train Epoch: 8 [568960/697932 (82%)]\tLoss: 3.180107\n",
      "Train Epoch: 8 [569600/697932 (82%)]\tLoss: 3.174675\n",
      "Train Epoch: 8 [570240/697932 (82%)]\tLoss: 3.142848\n",
      "Train Epoch: 8 [570880/697932 (82%)]\tLoss: 3.158295\n",
      "Train Epoch: 8 [571520/697932 (82%)]\tLoss: 3.175982\n",
      "Train Epoch: 8 [572160/697932 (82%)]\tLoss: 3.158834\n",
      "Train Epoch: 8 [572800/697932 (82%)]\tLoss: 3.173996\n",
      "Train Epoch: 8 [573440/697932 (82%)]\tLoss: 3.151117\n",
      "Train Epoch: 8 [574080/697932 (82%)]\tLoss: 3.138085\n",
      "Train Epoch: 8 [574720/697932 (82%)]\tLoss: 3.183435\n",
      "Train Epoch: 8 [575360/697932 (82%)]\tLoss: 3.162658\n",
      "Train Epoch: 8 [576000/697932 (83%)]\tLoss: 3.183944\n",
      "Train Epoch: 8 [576640/697932 (83%)]\tLoss: 3.162279\n",
      "Train Epoch: 8 [577280/697932 (83%)]\tLoss: 3.187582\n",
      "Train Epoch: 8 [577920/697932 (83%)]\tLoss: 3.168679\n",
      "Train Epoch: 8 [578560/697932 (83%)]\tLoss: 3.173747\n",
      "Train Epoch: 8 [579200/697932 (83%)]\tLoss: 3.158193\n",
      "Train Epoch: 8 [579840/697932 (83%)]\tLoss: 3.191353\n",
      "Train Epoch: 8 [580480/697932 (83%)]\tLoss: 3.153260\n",
      "Train Epoch: 8 [581120/697932 (83%)]\tLoss: 3.152855\n",
      "Train Epoch: 8 [581760/697932 (83%)]\tLoss: 3.176846\n",
      "Train Epoch: 8 [582400/697932 (83%)]\tLoss: 3.179181\n",
      "Train Epoch: 8 [583040/697932 (84%)]\tLoss: 3.138644\n",
      "Train Epoch: 8 [583680/697932 (84%)]\tLoss: 3.185701\n",
      "Train Epoch: 8 [584320/697932 (84%)]\tLoss: 3.183621\n",
      "Train Epoch: 8 [584960/697932 (84%)]\tLoss: 3.158352\n",
      "Train Epoch: 8 [585600/697932 (84%)]\tLoss: 3.140444\n",
      "Train Epoch: 8 [586240/697932 (84%)]\tLoss: 3.167796\n",
      "Train Epoch: 8 [586880/697932 (84%)]\tLoss: 3.188580\n",
      "Train Epoch: 8 [587520/697932 (84%)]\tLoss: 3.168806\n",
      "Train Epoch: 8 [588160/697932 (84%)]\tLoss: 3.177327\n",
      "Train Epoch: 8 [588800/697932 (84%)]\tLoss: 3.191053\n",
      "Train Epoch: 8 [589440/697932 (84%)]\tLoss: 3.180538\n",
      "Train Epoch: 8 [590080/697932 (85%)]\tLoss: 3.187339\n",
      "Train Epoch: 8 [590720/697932 (85%)]\tLoss: 3.173194\n",
      "Train Epoch: 8 [591360/697932 (85%)]\tLoss: 3.138862\n",
      "Train Epoch: 8 [592000/697932 (85%)]\tLoss: 3.165669\n",
      "Train Epoch: 8 [592640/697932 (85%)]\tLoss: 3.158399\n",
      "Train Epoch: 8 [593280/697932 (85%)]\tLoss: 3.167191\n",
      "Train Epoch: 8 [593920/697932 (85%)]\tLoss: 3.179258\n",
      "Train Epoch: 8 [594560/697932 (85%)]\tLoss: 3.191322\n",
      "Train Epoch: 8 [595200/697932 (85%)]\tLoss: 3.176913\n",
      "Train Epoch: 8 [595840/697932 (85%)]\tLoss: 3.145512\n",
      "Train Epoch: 8 [596480/697932 (85%)]\tLoss: 3.186777\n",
      "Train Epoch: 8 [597120/697932 (86%)]\tLoss: 3.167895\n",
      "Train Epoch: 8 [597760/697932 (86%)]\tLoss: 3.160479\n",
      "Train Epoch: 8 [598400/697932 (86%)]\tLoss: 3.176759\n",
      "Train Epoch: 8 [599040/697932 (86%)]\tLoss: 3.174859\n",
      "Train Epoch: 8 [599680/697932 (86%)]\tLoss: 3.176530\n",
      "Train Epoch: 8 [600320/697932 (86%)]\tLoss: 3.163874\n",
      "Train Epoch: 8 [600960/697932 (86%)]\tLoss: 3.162808\n",
      "Train Epoch: 8 [601600/697932 (86%)]\tLoss: 3.203995\n",
      "Train Epoch: 8 [602240/697932 (86%)]\tLoss: 3.149789\n",
      "Train Epoch: 8 [602880/697932 (86%)]\tLoss: 3.137991\n",
      "Train Epoch: 8 [603520/697932 (86%)]\tLoss: 3.153138\n",
      "Train Epoch: 8 [604160/697932 (87%)]\tLoss: 3.196656\n",
      "Train Epoch: 8 [604800/697932 (87%)]\tLoss: 3.144982\n",
      "Train Epoch: 8 [605440/697932 (87%)]\tLoss: 3.182737\n",
      "Train Epoch: 8 [606080/697932 (87%)]\tLoss: 3.139264\n",
      "Train Epoch: 8 [606720/697932 (87%)]\tLoss: 3.150995\n",
      "Train Epoch: 8 [607360/697932 (87%)]\tLoss: 3.172036\n",
      "Train Epoch: 8 [608000/697932 (87%)]\tLoss: 3.163724\n",
      "Train Epoch: 8 [608640/697932 (87%)]\tLoss: 3.160753\n",
      "Train Epoch: 8 [609280/697932 (87%)]\tLoss: 3.170844\n",
      "Train Epoch: 8 [609920/697932 (87%)]\tLoss: 3.175056\n",
      "Train Epoch: 8 [610560/697932 (87%)]\tLoss: 3.165165\n",
      "Train Epoch: 8 [611200/697932 (88%)]\tLoss: 3.182200\n",
      "Train Epoch: 8 [611840/697932 (88%)]\tLoss: 3.187718\n",
      "Train Epoch: 8 [612480/697932 (88%)]\tLoss: 3.163049\n",
      "Train Epoch: 8 [613120/697932 (88%)]\tLoss: 3.174375\n",
      "Train Epoch: 8 [613760/697932 (88%)]\tLoss: 3.174805\n",
      "Train Epoch: 8 [614400/697932 (88%)]\tLoss: 3.167983\n",
      "Train Epoch: 8 [615040/697932 (88%)]\tLoss: 3.158560\n",
      "Train Epoch: 8 [615680/697932 (88%)]\tLoss: 3.146389\n",
      "Train Epoch: 8 [616320/697932 (88%)]\tLoss: 3.152728\n",
      "Train Epoch: 8 [616960/697932 (88%)]\tLoss: 3.203002\n",
      "Train Epoch: 8 [617600/697932 (88%)]\tLoss: 3.171125\n",
      "Train Epoch: 8 [618240/697932 (89%)]\tLoss: 3.154473\n",
      "Train Epoch: 8 [618880/697932 (89%)]\tLoss: 3.155120\n",
      "Train Epoch: 8 [619520/697932 (89%)]\tLoss: 3.174570\n",
      "Train Epoch: 8 [620160/697932 (89%)]\tLoss: 3.164773\n",
      "Train Epoch: 8 [620800/697932 (89%)]\tLoss: 3.165470\n",
      "Train Epoch: 8 [621440/697932 (89%)]\tLoss: 3.159136\n",
      "Train Epoch: 8 [622080/697932 (89%)]\tLoss: 3.165037\n",
      "Train Epoch: 8 [622720/697932 (89%)]\tLoss: 3.154658\n",
      "Train Epoch: 8 [623360/697932 (89%)]\tLoss: 3.160573\n",
      "Train Epoch: 8 [624000/697932 (89%)]\tLoss: 3.150898\n",
      "Train Epoch: 8 [624640/697932 (89%)]\tLoss: 3.143461\n",
      "Train Epoch: 8 [625280/697932 (90%)]\tLoss: 3.159674\n",
      "Train Epoch: 8 [625920/697932 (90%)]\tLoss: 3.172189\n",
      "Train Epoch: 8 [626560/697932 (90%)]\tLoss: 3.156887\n",
      "Train Epoch: 8 [627200/697932 (90%)]\tLoss: 3.158278\n",
      "Train Epoch: 8 [627840/697932 (90%)]\tLoss: 3.141024\n",
      "Train Epoch: 8 [628480/697932 (90%)]\tLoss: 3.190332\n",
      "Train Epoch: 8 [629120/697932 (90%)]\tLoss: 3.180066\n",
      "Train Epoch: 8 [629760/697932 (90%)]\tLoss: 3.170051\n",
      "Train Epoch: 8 [630400/697932 (90%)]\tLoss: 3.188360\n",
      "Train Epoch: 8 [631040/697932 (90%)]\tLoss: 3.165694\n",
      "Train Epoch: 8 [631680/697932 (91%)]\tLoss: 3.155523\n",
      "Train Epoch: 8 [632320/697932 (91%)]\tLoss: 3.158824\n",
      "Train Epoch: 8 [632960/697932 (91%)]\tLoss: 3.167242\n",
      "Train Epoch: 8 [633600/697932 (91%)]\tLoss: 3.178158\n",
      "Train Epoch: 8 [634240/697932 (91%)]\tLoss: 3.154151\n",
      "Train Epoch: 8 [634880/697932 (91%)]\tLoss: 3.151040\n",
      "Train Epoch: 8 [635520/697932 (91%)]\tLoss: 3.184627\n",
      "Train Epoch: 8 [636160/697932 (91%)]\tLoss: 3.185385\n",
      "Train Epoch: 8 [636800/697932 (91%)]\tLoss: 3.184652\n",
      "Train Epoch: 8 [637440/697932 (91%)]\tLoss: 3.163628\n",
      "Train Epoch: 8 [638080/697932 (91%)]\tLoss: 3.160224\n",
      "Train Epoch: 8 [638720/697932 (92%)]\tLoss: 3.167784\n",
      "Train Epoch: 8 [639360/697932 (92%)]\tLoss: 3.174399\n",
      "Train Epoch: 8 [640000/697932 (92%)]\tLoss: 3.159953\n",
      "Train Epoch: 8 [640640/697932 (92%)]\tLoss: 3.177384\n",
      "Train Epoch: 8 [641280/697932 (92%)]\tLoss: 3.153056\n",
      "Train Epoch: 8 [641920/697932 (92%)]\tLoss: 3.154076\n",
      "Train Epoch: 8 [642560/697932 (92%)]\tLoss: 3.162867\n",
      "Train Epoch: 8 [643200/697932 (92%)]\tLoss: 3.177464\n",
      "Train Epoch: 8 [643840/697932 (92%)]\tLoss: 3.169151\n",
      "Train Epoch: 8 [644480/697932 (92%)]\tLoss: 3.184855\n",
      "Train Epoch: 8 [645120/697932 (92%)]\tLoss: 3.154789\n",
      "Train Epoch: 8 [645760/697932 (93%)]\tLoss: 3.189310\n",
      "Train Epoch: 8 [646400/697932 (93%)]\tLoss: 3.170227\n",
      "Train Epoch: 8 [647040/697932 (93%)]\tLoss: 3.185323\n",
      "Train Epoch: 8 [647680/697932 (93%)]\tLoss: 3.163188\n",
      "Train Epoch: 8 [648320/697932 (93%)]\tLoss: 3.148337\n",
      "Train Epoch: 8 [648960/697932 (93%)]\tLoss: 3.158956\n",
      "Train Epoch: 8 [649600/697932 (93%)]\tLoss: 3.173888\n",
      "Train Epoch: 8 [650240/697932 (93%)]\tLoss: 3.187260\n",
      "Train Epoch: 8 [650880/697932 (93%)]\tLoss: 3.173900\n",
      "Train Epoch: 8 [651520/697932 (93%)]\tLoss: 3.161599\n",
      "Train Epoch: 8 [652160/697932 (93%)]\tLoss: 3.157800\n",
      "Train Epoch: 8 [652800/697932 (94%)]\tLoss: 3.164671\n",
      "Train Epoch: 8 [653440/697932 (94%)]\tLoss: 3.164391\n",
      "Train Epoch: 8 [654080/697932 (94%)]\tLoss: 3.159364\n",
      "Train Epoch: 8 [654720/697932 (94%)]\tLoss: 3.160584\n",
      "Train Epoch: 8 [655360/697932 (94%)]\tLoss: 3.178201\n",
      "Train Epoch: 8 [656000/697932 (94%)]\tLoss: 3.172801\n",
      "Train Epoch: 8 [656640/697932 (94%)]\tLoss: 3.159592\n",
      "Train Epoch: 8 [657280/697932 (94%)]\tLoss: 3.155575\n",
      "Train Epoch: 8 [657920/697932 (94%)]\tLoss: 3.154365\n",
      "Train Epoch: 8 [658560/697932 (94%)]\tLoss: 3.184689\n",
      "Train Epoch: 8 [659200/697932 (94%)]\tLoss: 3.186122\n",
      "Train Epoch: 8 [659840/697932 (95%)]\tLoss: 3.129825\n",
      "Train Epoch: 8 [660480/697932 (95%)]\tLoss: 3.165958\n",
      "Train Epoch: 8 [661120/697932 (95%)]\tLoss: 3.169753\n",
      "Train Epoch: 8 [661760/697932 (95%)]\tLoss: 3.164686\n",
      "Train Epoch: 8 [662400/697932 (95%)]\tLoss: 3.190244\n",
      "Train Epoch: 8 [663040/697932 (95%)]\tLoss: 3.171648\n",
      "Train Epoch: 8 [663680/697932 (95%)]\tLoss: 3.156615\n",
      "Train Epoch: 8 [664320/697932 (95%)]\tLoss: 3.181243\n",
      "Train Epoch: 8 [664960/697932 (95%)]\tLoss: 3.140332\n",
      "Train Epoch: 8 [665600/697932 (95%)]\tLoss: 3.163947\n",
      "Train Epoch: 8 [666240/697932 (95%)]\tLoss: 3.159741\n",
      "Train Epoch: 8 [666880/697932 (96%)]\tLoss: 3.174566\n",
      "Train Epoch: 8 [667520/697932 (96%)]\tLoss: 3.157886\n",
      "Train Epoch: 8 [668160/697932 (96%)]\tLoss: 3.189814\n",
      "Train Epoch: 8 [668800/697932 (96%)]\tLoss: 3.141858\n",
      "Train Epoch: 8 [669440/697932 (96%)]\tLoss: 3.160055\n",
      "Train Epoch: 8 [670080/697932 (96%)]\tLoss: 3.191454\n",
      "Train Epoch: 8 [670720/697932 (96%)]\tLoss: 3.166752\n",
      "Train Epoch: 8 [671360/697932 (96%)]\tLoss: 3.160227\n",
      "Train Epoch: 8 [672000/697932 (96%)]\tLoss: 3.171816\n",
      "Train Epoch: 8 [672640/697932 (96%)]\tLoss: 3.163462\n",
      "Train Epoch: 8 [673280/697932 (96%)]\tLoss: 3.171643\n",
      "Train Epoch: 8 [673920/697932 (97%)]\tLoss: 3.180941\n",
      "Train Epoch: 8 [674560/697932 (97%)]\tLoss: 3.183976\n",
      "Train Epoch: 8 [675200/697932 (97%)]\tLoss: 3.170068\n",
      "Train Epoch: 8 [675840/697932 (97%)]\tLoss: 3.188825\n",
      "Train Epoch: 8 [676480/697932 (97%)]\tLoss: 3.165953\n",
      "Train Epoch: 8 [677120/697932 (97%)]\tLoss: 3.186744\n",
      "Train Epoch: 8 [677760/697932 (97%)]\tLoss: 3.170217\n",
      "Train Epoch: 8 [678400/697932 (97%)]\tLoss: 3.174499\n",
      "Train Epoch: 8 [679040/697932 (97%)]\tLoss: 3.162644\n",
      "Train Epoch: 8 [679680/697932 (97%)]\tLoss: 3.153869\n",
      "Train Epoch: 8 [680320/697932 (97%)]\tLoss: 3.208095\n",
      "Train Epoch: 8 [680960/697932 (98%)]\tLoss: 3.176237\n",
      "Train Epoch: 8 [681600/697932 (98%)]\tLoss: 3.185016\n",
      "Train Epoch: 8 [682240/697932 (98%)]\tLoss: 3.156486\n",
      "Train Epoch: 8 [682880/697932 (98%)]\tLoss: 3.165063\n",
      "Train Epoch: 8 [683520/697932 (98%)]\tLoss: 3.160845\n",
      "Train Epoch: 8 [684160/697932 (98%)]\tLoss: 3.183228\n",
      "Train Epoch: 8 [684800/697932 (98%)]\tLoss: 3.154274\n",
      "Train Epoch: 8 [685440/697932 (98%)]\tLoss: 3.199351\n",
      "Train Epoch: 8 [686080/697932 (98%)]\tLoss: 3.136117\n",
      "Train Epoch: 8 [686720/697932 (98%)]\tLoss: 3.166066\n",
      "Train Epoch: 8 [687360/697932 (98%)]\tLoss: 3.138343\n",
      "Train Epoch: 8 [688000/697932 (99%)]\tLoss: 3.167991\n",
      "Train Epoch: 8 [688640/697932 (99%)]\tLoss: 3.159448\n",
      "Train Epoch: 8 [689280/697932 (99%)]\tLoss: 3.156856\n",
      "Train Epoch: 8 [689920/697932 (99%)]\tLoss: 3.179279\n",
      "Train Epoch: 8 [690560/697932 (99%)]\tLoss: 3.166487\n",
      "Train Epoch: 8 [691200/697932 (99%)]\tLoss: 3.186789\n",
      "Train Epoch: 8 [691840/697932 (99%)]\tLoss: 3.159474\n",
      "Train Epoch: 8 [692480/697932 (99%)]\tLoss: 3.161558\n",
      "Train Epoch: 8 [693120/697932 (99%)]\tLoss: 3.154872\n",
      "Train Epoch: 8 [693760/697932 (99%)]\tLoss: 3.166720\n",
      "Train Epoch: 8 [694400/697932 (99%)]\tLoss: 3.163321\n",
      "Train Epoch: 8 [695040/697932 (100%)]\tLoss: 3.152018\n",
      "Train Epoch: 8 [695680/697932 (100%)]\tLoss: 3.172724\n",
      "Train Epoch: 8 [696320/697932 (100%)]\tLoss: 3.190573\n",
      "Train Epoch: 8 [696960/697932 (100%)]\tLoss: 3.165107\n",
      "Train Epoch: 8 [697600/697932 (100%)]\tLoss: 3.177061\n",
      "\n",
      "Test set: Avg. loss: 0.0050, Accuracy: 38/116323 (0%)\n",
      "\n",
      "Train Epoch: 9 [0/697932 (0%)]\tLoss: 3.185656\n",
      "Train Epoch: 9 [640/697932 (0%)]\tLoss: 3.186593\n",
      "Train Epoch: 9 [1280/697932 (0%)]\tLoss: 3.137291\n",
      "Train Epoch: 9 [1920/697932 (0%)]\tLoss: 3.179796\n",
      "Train Epoch: 9 [2560/697932 (0%)]\tLoss: 3.168667\n",
      "Train Epoch: 9 [3200/697932 (0%)]\tLoss: 3.146319\n",
      "Train Epoch: 9 [3840/697932 (1%)]\tLoss: 3.156608\n",
      "Train Epoch: 9 [4480/697932 (1%)]\tLoss: 3.163415\n",
      "Train Epoch: 9 [5120/697932 (1%)]\tLoss: 3.149865\n",
      "Train Epoch: 9 [5760/697932 (1%)]\tLoss: 3.153261\n",
      "Train Epoch: 9 [6400/697932 (1%)]\tLoss: 3.177031\n",
      "Train Epoch: 9 [7040/697932 (1%)]\tLoss: 3.191279\n",
      "Train Epoch: 9 [7680/697932 (1%)]\tLoss: 3.160828\n",
      "Train Epoch: 9 [8320/697932 (1%)]\tLoss: 3.176951\n",
      "Train Epoch: 9 [8960/697932 (1%)]\tLoss: 3.177495\n",
      "Train Epoch: 9 [9600/697932 (1%)]\tLoss: 3.161856\n",
      "Train Epoch: 9 [10240/697932 (1%)]\tLoss: 3.151253\n",
      "Train Epoch: 9 [10880/697932 (2%)]\tLoss: 3.147673\n",
      "Train Epoch: 9 [11520/697932 (2%)]\tLoss: 3.175497\n",
      "Train Epoch: 9 [12160/697932 (2%)]\tLoss: 3.152074\n",
      "Train Epoch: 9 [12800/697932 (2%)]\tLoss: 3.164405\n",
      "Train Epoch: 9 [13440/697932 (2%)]\tLoss: 3.178927\n",
      "Train Epoch: 9 [14080/697932 (2%)]\tLoss: 3.183538\n",
      "Train Epoch: 9 [14720/697932 (2%)]\tLoss: 3.183619\n",
      "Train Epoch: 9 [15360/697932 (2%)]\tLoss: 3.166675\n",
      "Train Epoch: 9 [16000/697932 (2%)]\tLoss: 3.170123\n",
      "Train Epoch: 9 [16640/697932 (2%)]\tLoss: 3.170785\n",
      "Train Epoch: 9 [17280/697932 (2%)]\tLoss: 3.163234\n",
      "Train Epoch: 9 [17920/697932 (3%)]\tLoss: 3.153397\n",
      "Train Epoch: 9 [18560/697932 (3%)]\tLoss: 3.172558\n",
      "Train Epoch: 9 [19200/697932 (3%)]\tLoss: 3.170429\n",
      "Train Epoch: 9 [19840/697932 (3%)]\tLoss: 3.166599\n",
      "Train Epoch: 9 [20480/697932 (3%)]\tLoss: 3.171789\n",
      "Train Epoch: 9 [21120/697932 (3%)]\tLoss: 3.147951\n",
      "Train Epoch: 9 [21760/697932 (3%)]\tLoss: 3.164329\n",
      "Train Epoch: 9 [22400/697932 (3%)]\tLoss: 3.171733\n",
      "Train Epoch: 9 [23040/697932 (3%)]\tLoss: 3.150768\n",
      "Train Epoch: 9 [23680/697932 (3%)]\tLoss: 3.179316\n",
      "Train Epoch: 9 [24320/697932 (3%)]\tLoss: 3.144785\n",
      "Train Epoch: 9 [24960/697932 (4%)]\tLoss: 3.175996\n",
      "Train Epoch: 9 [25600/697932 (4%)]\tLoss: 3.163579\n",
      "Train Epoch: 9 [26240/697932 (4%)]\tLoss: 3.168990\n",
      "Train Epoch: 9 [26880/697932 (4%)]\tLoss: 3.190817\n",
      "Train Epoch: 9 [27520/697932 (4%)]\tLoss: 3.165225\n",
      "Train Epoch: 9 [28160/697932 (4%)]\tLoss: 3.168941\n",
      "Train Epoch: 9 [28800/697932 (4%)]\tLoss: 3.166625\n",
      "Train Epoch: 9 [29440/697932 (4%)]\tLoss: 3.160542\n",
      "Train Epoch: 9 [30080/697932 (4%)]\tLoss: 3.167233\n",
      "Train Epoch: 9 [30720/697932 (4%)]\tLoss: 3.165952\n",
      "Train Epoch: 9 [31360/697932 (4%)]\tLoss: 3.144335\n",
      "Train Epoch: 9 [32000/697932 (5%)]\tLoss: 3.153244\n",
      "Train Epoch: 9 [32640/697932 (5%)]\tLoss: 3.179271\n",
      "Train Epoch: 9 [33280/697932 (5%)]\tLoss: 3.170870\n",
      "Train Epoch: 9 [33920/697932 (5%)]\tLoss: 3.192959\n",
      "Train Epoch: 9 [34560/697932 (5%)]\tLoss: 3.171084\n",
      "Train Epoch: 9 [35200/697932 (5%)]\tLoss: 3.179197\n",
      "Train Epoch: 9 [35840/697932 (5%)]\tLoss: 3.190291\n",
      "Train Epoch: 9 [36480/697932 (5%)]\tLoss: 3.183893\n",
      "Train Epoch: 9 [37120/697932 (5%)]\tLoss: 3.171691\n",
      "Train Epoch: 9 [37760/697932 (5%)]\tLoss: 3.182787\n",
      "Train Epoch: 9 [38400/697932 (6%)]\tLoss: 3.149409\n",
      "Train Epoch: 9 [39040/697932 (6%)]\tLoss: 3.167603\n",
      "Train Epoch: 9 [39680/697932 (6%)]\tLoss: 3.164941\n",
      "Train Epoch: 9 [40320/697932 (6%)]\tLoss: 3.139387\n",
      "Train Epoch: 9 [40960/697932 (6%)]\tLoss: 3.159514\n",
      "Train Epoch: 9 [41600/697932 (6%)]\tLoss: 3.195541\n",
      "Train Epoch: 9 [42240/697932 (6%)]\tLoss: 3.155019\n",
      "Train Epoch: 9 [42880/697932 (6%)]\tLoss: 3.154083\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-459-26b4aad1314a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-456-306c4823e29a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#                 print(len(train_loader.dataset))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-434-35a0fc273b2f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2_drop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;31m#         print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 342\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-445-dfb817623348>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_counter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_counter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Train Loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Test Loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'upper right'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'number of training examples seen'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2846\u001b[0m         \u001b[0mverts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2847\u001b[0m         plotnonfinite=plotnonfinite, **({\"data\": data} if data is not\n\u001b[1;32m-> 2848\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2849\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2850\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1597\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1599\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1601\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4441\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4443\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y must be the same size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4445\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd5wU9fkH8M/D3VEUEZBTiaCoQY1YQE+jsfwQUQEFG1FRI6KxxMTYI7wIMWKPUmJHk1gwaixIuWhEBTRIkUNPVKQjTemCgNS75/fHdyYzszezO1tnd+/zfr3mtVO+M/Ps7O6zU79fUVUQEVHhaxB1AERElBlM6ERERYIJnYioSDChExEVCSZ0IqIiURrVilu1aqXt2rWLavVERAVp5syZa1W13G9aZAm9Xbt2qKqqimr1REQFSUSWBE3jKRcioiLBhE5EVCSY0ImIigQTOhFRkWBCJyIqEkzoRERFggmdiKhIFFxCnzwZeOQRYNeuqCMhIsovBZfQR48G7rgDKCsDamujjoaIKH8UXEJ/8EGnv0uX6OIgIso3BZfQS0uB4cNN/4cfAj/7GbB5c7QxERHlg4JL6ABw003AqlWmf84c4Oijo42HiCgfFGRCB4C99zaJHQAWLQKWBFZXQ0RUPxRsQgfMqZfu3U1/u3bA2rWRhkNEFKmCTugA8NZbTn95OaAaXSxERFEq+ITeqBEwbJgz/POfRxcLEVGUCj6hA8DNNwNnnGH6Z8wAZs+ONh4ioigURUIHgPHjnf4OHQAR4IcfoouHiCjXiiahA8CmTd7hceOiiYOIKApFldCbNgWWLnWGL78c2LkzuniIiHKpqBI6ALRtC7z8sjPcsGF0sRAR5VLRJXQA6NPHPEFq++abyEIhIsqZokzoAHDooU5/+/bRxUFElCtFm9AB4KuvzOuuXcCIEdHGQkSUbUWd0A8/3Om//npg5croYiEiyraiTuiAtyqACy+MLg4iomwr+oQOmNsXAWDKFGDIEGDr1mjjISLKhnqR0EeOdPpvvx24557oYiEiypZ6kdABb9N169ZFFwcRUbbUm4Tet6/Tz4ujRFSM6k1C33dfp3/sWODrr6OLhYgoG0IndBEpEZHPRKTSZ1ojEfmXiCwQkeki0i6TQWZKVZV/PxFRMUhmD/0mAEH7tVcD+F5VfwpgGICH0g0sG4491um/4gpg4cLoYiEiyrRQCV1E2gA4G8DfAoqcC+AFq/8NAKeLiKQfXubNnOn0n3xydHEQEWVa2D304QD+AKA2YPp+AJYBgKruArARwF6xhUTkWhGpEpGqNWvWpBBu+g4+2OnnxVEiKiYJE7qInANgtarOjFfMZ1yd5ppV9RlVrVDVivLy8iTCzJxmzbzDO3ZEEgYRUcaF2UM/CUAvEfkGwKsAuojISzFllgNoCwAiUgpgTwDrMxhnxsSeCFqyJJo4iIgyLWFCV9UBqtpGVdsBuATABFW9PKbYWAD2nd69rTJ19tDzxZgxUUdARJR5Kd+HLiKDRaSXNfh3AHuJyAIAtwLon4ngsqVnT6f/ySeji4OIKJMkqh3piooKrYrwZvDjjwdmzDD9+XssQUTkJSIzVbXCb1q9eVI01tSpTj8TOhEVg3qb0EtKnP7Jk6OLg4goU+ptQnc79dSoIyAiSl+9Tuh8UpSIikm9Tugnnhh1BEREmVOvE3pZmdPPC6NEVOjqdUJ3Xxh9883o4iAiyoR6ndB/+Uunv1+/6OIgIsqEep3QjzzS6d+8Obo4iIgyoV4n9FiseZGIClm9T+iXXur033dfdHEQEaWr3if0l1wVAa9aFV0cRETpqvcJ3V0/uvuuFyKiQlPvE7obEzoRFTImdBcmdCIqZEzoLg24NYiogDGFuXAPnYgKGRO6CxM6ERUyJnQXJnQiKmRM6ERERYIJ3YVPihJRIWNCh/fhIiKiQsWEDuD5553+bdsiC4OIKC1M6ACuuMLpX7gwujiIiNLBhG556inzesQR0cZBRJQqJnRLixZRR0BElB4mdEv79lFHQESUHiZ0S5s2UUdARJQeJnRL8+ZRR0BElJ7SRAVEpDGAjwA0ssq/oap3xZTZH8ALAJoDKAHQX1Xfzny42dOwIXDoocABB0QdCRFRasLsoW8H0EVVjwbQEUA3ETkhpswfAbymqp0AXALgycyGmRstWwK1tVFHQUSUmoR76KqqADZbg2VWp7HFADSz+vcE8G2mAsylsjJg166ooyAiSk2oc+giUiIi1QBWA3hPVafHFPkzgMtFZDmAtwHcGLCca0WkSkSq1qxZk0bY2VFaCuzcGXUURESpCZXQVbVGVTsCaAPgeBGJffymD4DnVbUNgB4ARopInWWr6jOqWqGqFeXl5enGnnGlpcB330UdBRFRapK6y0VVNwCYBKBbzKSrAbxmlZkKoDGAVhmIL6fGjwcWLQKmTo06EiKi5CVM6CJSLiLNrf4mALoCmBNTbCmA060yP4NJ6Pl3TiWkL7+MOgIiouQlvCgKoDWAF0SkBOYP4DVVrRSRwQCqVHUsgNsAPCsit8BcIL3SuphakBo3jjoCIqLkhbnLZRaATj7j/+Tqnw3gpMyGFp0mTaKOgIgoeXxS1Af30ImoEDGh+2jYMOoIiIiSx4Tuo3DP/hNRfcaE7mLXuDh7drRxEBGlggndZdQo83rrrdHGQUSUCiZ0lwbcGkRUwJjCXFiPCxEVMiZ0lx07oo6AiCh1TOgurDqXiAoZE7oLb1ckokLGhO7SubPTv3lzYDEiorzEhO5SUuL077EH8PzzkYVCRJQ0JvQ4+vWLOgIiovCY0ImIigQTOhFRkWBCJyIqEkzoMdi4BREVKib0GKwLnYgKFRN6jEaNoo6AiCg1TOgxuIdORIWKCT0GEzoRFSom9BhM6ERUqJjQY5SVRR0BEVFqmNCJiIoEE3oCrCOdiAoFE3qMnj29wzt2AAsXArW10cRDRBQWE3qMwYO9w++9B/z0p8Bjj0UTDxFRWEzoMdx1ogPAeeeZ108/zX0sRETJYEIPqVmzqCMgIoovYUIXkcYi8omIfC4iX4nI3QHlLhKR2VaZlzMfarR4OyMR5bvSEGW2A+iiqptFpAzAZBF5R1Wn2QVEpD2AAQBOUtXvRWTvLMVLREQBEiZ0VVUAdpPJZVanMcWuAfCEqn5vzbM6k0HmA5GoIyAiii/UOXQRKRGRagCrAbynqtNjihwC4BAR+VhEpolIt0wHSkRE8YVK6Kpao6odAbQBcLyIHBFTpBRAewCdAfQB8DcRaR67HBG5VkSqRKRqzZo16UWeRT16RB0BEVHykrrLRVU3AJgEIHYPfDmAMaq6U1UXA5gLk+Bj539GVStUtaK8vDzFkLNv1KioIyAiSl6Yu1zK7b1tEWkCoCuAOTHFRgM4zSrTCuYUzKLMhpo7fo1c8Bw6EeW7MHe5tAbwgoiUwPwBvKaqlSIyGECVqo4F8C6AM0VkNoAaAHeo6rqsRU1ERHWEuctlFoBOPuP/5OpXALdaHRERRYBPihIRFQkm9JB4Dp2I8h0TeoChQ6OOgIgoOUzoAW65BTj00KijICIKjwk9jlLXJeNp04C5c6OLhYgoESb0ONwJffJk4LDDoouFiCgRJvQ4Sn1u6nzuOaC6OvexEBElEubBonrLrw70q64yrxpb3yQRUcS4hx6H3x56kM8/B8aNy14sRESJcA89jmRaKerY0bxyz52IosI99DiS2UMnIooaE3ocTOhEVEiY0OOIl9CPOip3cRARhcGEHke8c+hffJG7OIiIwmBCj6N376gjICIKjwk9jj59oo6AiCg8JvQEXn016giIiMJhQk/g4ouDp82enbs4iIgSYUJPQ4cOUUdARORgQs+inTuBNWuijoKI6gsm9CxYuhT4z3+Afv2AvfcGamrM+KoqYN68aGMjouLFZyHT9OCDpnUjt0MOAbZvd4Zra4GSEuC448ww63shomzgHnoITZoETxswAGjc2DvOncwBJnAiyg0m9BBWrEhv/trazMRBRBQPE3oIu+2W3vxM6ESUC0zoIZSUpDc/EzoR5QITegjJJPQ2beqO4zl0IsoFJvQQRMKX9TvfXlsLjB6duXiIiPwwoYc0cmTq8/74I3D++ZmLhYjIDxN6SJdfnvq8v/pV5uIgIgqSMKGLSGMR+UREPheRr0Tk7jhle4uIikhFZsMsbB98UHfcsmXAE0/kPhYiKl5h9tC3A+iiqkcD6Aigm4icEFtIRPYA8HsA0zMbYv7YtSszyzn/fKBjR+B3vwNWrcrMMomIEiZ0NTZbg2VW53ffxj0A/gJgW+bCyy/p3r5oGz0aWL/e9Nv1vBARpSvUOXQRKRGRagCrAbynqtNjpncC0FZVKxMs51oRqRKRqjWshhAAb2kkoswJldBVtUZVOwJoA+B4ETnCniYiDQAMA3BbiOU8o6oVqlpRXl6easxEROQjqbtcVHUDgEkAurlG7wHgCACTROQbACcAGMsLo0REuRXmLpdyEWlu9TcB0BXAHHu6qm5U1Vaq2k5V2wGYBqCXqlZlKWYiIvIRZg+9NYCJIjILwAyYc+iVIjJYRHplNzwiIgorYQMXqjoLQCef8X8KKN85/bDqjzAXRf/5T6BLF6B16+zHQ0SFi0+KRsx922J1NbDPPt52SL//3jyl+pOf5D42IiosTOgRa9cOuP120//ww8Dq1cD48c70TD3MRETFjwk9DwwZ4j/+oINMkiciCoMJPUlVVcDUqdldh31effFiJnQiCo8JPUnHHgscfXTUUST25pvAeecBF15o6nN/7bWoIyKibGNCT0FZWTTrffVVYMuWcGV79wbGjAFGjTLDtyV8jpeICh0TegpKS4F585zhSy/NzHLttkeDzqn36QPceKP/tBUrTEMaubJzJzBwILBpU+7WSUTxMaGnqH17pz9T57lffdW8VlcH35++dClw7bXAnXd6x7dpA5x5ZmbiCGPkSOD++4FBg3K3TiKKjwk9AxpkYCvef7932N5bj6UKPPss8Je/mHPjjzziTPv44+DlL18OjB2bfpy2HTvM67airSyZqPAwoWdAMo1IBxk40DsctlHpe+7xDg8bZl796m4/99zk4/IzapS5Awdg9b9E+YQJPQOykdR69/YfP2FC/HXfeqt5bdgw8zHt2GHWd+GF5gjBb/1EFB0m9DTMmmXOaUf5NGdQQk2U0H/8EXj+edME3nPPJV7Pzp1Ao0bOU61ElH+Y0NNw5JFA27bR3cYImIQee4EUMMk3nj/8AejXD9h3X+Cqq4AlS+KX377dvI4YUXf9qWjdGujcObV5i8nnn4e/FZUoESb0DNhnH6Cy0lSklWs7dzqnP2zffGPqhAkyaxbw0kt1lxNk9mxg7lzTH3u9INWEvnIl8OGHwdNVTbIrZps3m8bCM3XbKxETeoacfTbQvHnu12vfbeJ24IHx5zn6aGDjRu+4eIm5QwegoiJxuUx64gmT7GKvGWTT5s3mdtRsV+1gs496Jk/Ozfqo+DGhEwDnNsnx44EFC4LLxZ4eCErwmzcDf/xj3T+cv/0NOOusxPHMnGleZ8825+1z8dBUVZV57/37Z39dRNmQsIELSs3ppwMffADsvXf80x+5FpSAVc0FXjvZht0TVwXWrTNHJ+5bJQcPNg9ctW0LXHONOVUjYvrDsP9ghg0DFi0CWrXKfqK133Mmniug6J1yCtCypakCo77gVzdL9trLvDZr5j/9//4vd7G4+Z2iAYATTwQOOCD55a1bZ5Kt/YDT4sXA/PnOHvWOHSbRX3GF//zLlgEzZtQdbzf8YZ+WCPMHowpMnJj6aSH7TyQTzxVQ9CZPDv8wXU0N0LUrMGlSVkPKOib0DGvTBth9d+Cpp0ydLCef7F8uqE6WbPuTb8OBwIYN3mFVk4yrq+Mvb+VK8/rss+bc80EHAYccUrfcSy/VXQcA7L8/cPzxdcfbCX3FCvNaGuJY8sUXTVN9BxyQ2p0j9h9BbEKvrQXWrq1b/sMPgY8+Sn49Qeul6KxcaY6oL7ss6kjSw4SeYYsWmbtdWrY0D/nk24/13XfDlRs0yNz62KlOa7Je7ubyEl1MPO+8cOsGvE3zAeES+sKF5nXZMqBpU+Dww+OX37rV+/kEJfR77gHKy82PftMm5yinc+f0jrTy7buRrMmTgbfeyu06a2qAU081ybdQVFYC69fnZl1M6BlWVua9L93u328/k+yj9sMP4crdd1+4cnYVAD/+CPz5z3Wnu+ukiXebYix7z99mJ/S1a4G+ff33wGMT5NdfBy//22+B3XYDHn/czDd/fnBCt6sgXrXKnEI77TTnVBBgLtpecw1wzDGJL95OmGCOYn78Mbi+Hj92Igv6Q9661Vy3ePbZ9CtMmzAh3J0+p5wCXHBBeutK1urVwH//a9rZzYZM/8muXAn07GlqSs0JVY2kO/bYYzVXLr1U9YEHsrPsbdtUP/ooePq6daq33aa6Y4cZNl8Z1TfecPpz2ZWVZWe5e+zhHb7mmuTmjxU7/cknzfgbbjDDjz1mhmtrVefMUX3nnXDLtU2YYKafeqrqo4+a/nvuMa9nnGHK1NSofvih6hFHmPHjxyd+H/G+C6qqHTuacjNnqn73nelv0cJbZuxY1bvu8o5bs8aU3Wsv/+Xee683ju3b48cRT6Jt51duxQrVadO80+fPN59PurZtM78jez2A6r77JhdfIsuXm7KtW6cep5/HHnPi+OlP0/tcbACqNCCv1os99JdfBgYMyNzyamqcvaubbzZ7TrNn+5dt2dJcMHz5ZbOH3rOnc9dHFOI9QJSO2Iutzz6b3PxbtpinV7du9Z9eWmr2iu1qFuztN2wYcNhhQPfu8Ze/apVzSsZeH2Cud9jnwe2jDXvZF1xgTql8+aUZDls98dy5wNtvm/45c7z3/NtHGnPnBl+E7dULuPtu5/oB4C1rx+nmPmIAEm8PP0uWmKMHW+/e5vbTMK66CjjhBOfzmzLF3NOfiTuGund3bjLQgKOofPD22+a3Xllprj0tXeq9VrZgAfDAA+GPklMSlOmz3WVyD33mTNWbb/buDbz8supbb9n/aOH/qVVVP/1U9eGHg6cDqj17mv6TTjLD//1v3XJz5qguXGjiAlTLy51pb76ZnT3lqLoGDdKb/8Ybnf5GjepOf+457/Djj6sOHpx4uTY7Ptu//uWUOfdc8+o+qnB/b5LpzjnH6V+50rweeaSz3p//3Jl+7bXmNXYP3b28Dz804+xluce/+qrqzp3BsdoWLTJlVVU3bAj+Xg8cWHcZF18cvJftt61uuMHEeumlzrgvvjCvX38dvO543OtZtsz0l5WZ4TffNO8v0Xw//KD6738Hr8Pe809nDz122331lf/ncsklqa/DrCd4D913ZC66TCZ0+3B/40b3m677ZRs6NNwhT+wPIt50O6G7D7V37XK+eIAZtvu3bTPDmUjof/hD+ssolO6yy7zDYZI5YP6YO3Vyhu1Ddfs0CqDavXvd+X71q8zGP2eO9/vi7vbYQ3XLFtXXX1cdMsQ7behQM9+333rHn3GGeX3sMdUXXvBfp/172GsvMzxypHn99FPnu/rUU2aHSNU/oQOqTz/t/W6fd57qBRc401VVRYLf+4AB5vW++0zZBQtU1671/21t3OjE+8knJj73eubN8w4Dqrvv7sz//feqzZqpTpzolNuyxfwxAaojRvivN5mEvv/+qhUVqjNmmD+KXbucWNzdl1/6b49TTkm8jniKNqG7P1zA7BnU1pqkHfuh291996nutpvqlVfG22Cms/d+li1TfeghZ0/FveyTTzb97oQ+aJB3nTt2eIcvuigzCT3oh1wful//OvV5Y78THTrkJuYpU1Tbtk1unoceMvHaCcfuDjnEvD7wQPz5L7nE6XfvNauaRG4PuxNnbHf22SZpXXih6rBhdafbR6BB3Z13mtf77zdHsvZ499HCxx+bc+528vfrqquD1ztjhlmOfZ3j1FOdabvt5p0v9kgBcP6gwiT02Liuusp/vH1kEtudfHLidcRffxEm9G++qfvhL1yo+te/ese5944B7zzBG8x0mzeb4YoKMzxvnne6qjehx37h7M6+EObuRo2K/yMI0+2/f/rLqI+d+zPM9+7ee03i6tPHO75NG/PqvuiW7DZwJ3H3EUts17Gj6mmnBU8fNy7+uuwjyQcf9I6//HITh/v0V7zukUe8w5s2eeNXDb447u7uvNP/9253t9wSP/f4LdO+aO3uZs3yL5vNhF6wF0XbtTMXGNy2bAGGD/eOu+MO77D7Is2WLWYTA+b1ueeAiy5yptvNq9kXtfwejLEvzqiaW+D8+D2c07Spf9lkLF2a/jIov+3caRokf+UV7/jly81rqg+oXXaZ9+LcbrsFl62uNk/gBrn55vjrsmsDjb13fPp083rxxfHnt/37395h94V4EfN7ja10zo+quZh+2mn+bRkMG1b3ts2nnwbeey94meXl/usJWn/WBGX6bHfp7qH7/fO5L6zZXey5vZYtvcNPPGGWF3vbF2BuZYpdl3tP5cwzncO5SZO85xXZsctEF+8URKa6khLVzp1z/9723Vd169bU5//971Obz33tyb5V1a879FBz+tS+aA6Y22cz8d7Ty31pnHIB0BjAJwA+B/AVgLt9ytwKYDaAWQA+AHBAouVmI6Gn0h1yiOpnnwVPnzo13HJGj85cTOzY2d3tt2d/HYcdptq1a+7fW4sW0W/fqLr0cl96p1y2A+iiqkcD6Aigm4icEFPmMwAVqnoUgDcAxDS5kL/mzYv/eHvY+6mTeaydKKygytQyqaYmmvu6o2gQptglTOjWn4L9eEGZ1WlMmYmqaj/0PA1Am4xGGeOFF7K5dK9163K3LqJYjz6a/XXMnx///DBl3ujR2VluqIuiIlIiItUAVgN4T1Wnxyl+NYB3ApZzrYhUiUjVGnetTkm68sqUZ01afapLmYhyY3q8DJqGUAldVWtUtSPMnvfxInKEXzkRuRxABYCHA5bzjKpWqGpFud9l4VCxpDQbFbn99486AqLwspXHkrptUVU3AJgEoFvsNBHpCmAggF6quj12eqaErf6V8sfQocHTxoxxGsdIx5Il6S+DKFeSqWkzGQkTuoiUi0hzq78JgK4A5sSU6QRgBEwyz2qDa2ErC6L84b7X9/zzzT29tiZNTHN96ejZM735g/TokZ3lEkW5h94awEQRmQVgBsw59EoRGSwivawyDwNoCuB1EakWkZANPyUvH2tZo/AuvRS47jrvOHf98am466705g/y299mZ7lRe/HFaNf/zDPRrj+sykrguOOys+zI9tBVdZaqdlLVo1T1CFUdbI3/k6qOtfq7quo+qtrR6nrFX2rqmNDzX9++3mFVU8Wt3e8mkn5CP/ZY8+reU580Kbkfjd/tqY0bpxVW0nr0yM33+7TTsrfsd3xvh3Bs326qj54yJXsxZErbtsAnn2Rn2XlxDj0fpNJWZKYdfLBpgcht1apoYgH82+SMZSfUIM89l5lYAOD5500rPjZVoGNHpz+WXdd1ut5801TPoGrqMfdLjn57XEOHAr/+NdCwoXd88+bpxXPnncDHH5v+jh2BJ5/0L2ffhtugQW4SeoMGQDfrKtjBB/uX6dAh+eX+/vfAoYfGL1NSYl5PPDH55cfTvXvd3yQA7Ltv6su0HwPy07Vr6ssFsreHHqKlxvziPofeujXw3Xe5XX+rVsBNN5kvr9vChUC/fnUT46RJpu3JbBAxyTDMXsSgQfEbwA2T0J94AvjPf4Bx4+KXGz7c2xTbkCHOXvu8eU7dHgDw4IOmYedUHX2003iJ3zN5sWbMqDvur381n9/FFwMjRzrj77wz9bgA4KGHnNteq6uDW5QfMsS8Vlamt754GjRwksgpp5g/qwMO8Db6YauoSNw4uJ/x44ERI+KXad/evGZ6D3XqVP+6lmKbMkyGvRPi5/33U19uVgU9QprtLtVH/1OtXY5dcXalpaYrK1Nt2NA0jtG4semaNAm/nJYtnXq47S6VRjtatTJ1owCq++3nnWZXeevuDjrIVN/brp1pCOOoo0xnT//JT+K/9xNOMN2JJ8aP64QTnP4OHVRPPz34cf/u3f3riE/U9e7t1Ewa1F12mall0V3ffN++Tn/r1qpXX+0/b9++Zhv5TbvxRtUuXeqOjy1/xx3h38/555umAP2m+bVFcNtt/mWHDDH12g8d6oybODGl9Keqqiim6nO//97ZKO6Kt+zqRN0/AHf1oLF1lCfbNWhg2nocO9ZbXeigQaYq3Hfe8baq8957pnv/fdUPPjBtWF50kWlpZ9Ik0+JM//7x17nffqrTp5uK/t3jzzvPfIE/+8xU2Vtdrfr556a6zqlTzXpjlzVnjnd4jz1MQwN260Dz56suXmyqJV6yxCm3bJmppGzFCtPIwrffOm1hAk7DAXa3bp3q+vWmu/56M65/f9MQwKZNptu82Sm/YoWpoGnbNtW5c03LOva0b781dWbPm1e3WmS7S+SRR1RvvdUpP2aM+by2bXMS2rvvOuXd72fjRqd/6VKn36635+uvvbHY7ca62XVid+hghsPGbzfasmpV8Pfjs8+887grmho92rs+d93hq1Y583z6afyY7HHTpqmedZa3nDup3XCDM4+7XqPY9+zWr58z7pe/NP0TJnjnWbrUfCdjBcUcO37jRu/3VVW1adO65eyWpk45RbWyUnXPPZ3qs9ev95bdtcs0mpHos/zoI9Noidsxx5iyVVV1y4dVVAndbetWJyGNG2fG2Y29Dhig+uOPpr91a29Cu/xyp/+118zrUUeZ+TdsMDUwXnutt87yV17xrvsXv9D/JTyb+8cXljtZr19vvsB2UnnwQafcggXJLdvvy+Ye7tjRjFuxwvwJxNq+3SS9II8/7vyQ7WV27+4tY/9h2S3V+MUXL/ZYixYl/hHFs369d9iuOfP9951xvXo5y3b/8dhxnX22U9ZdH3dQLHYzZD/7mfe9+W0vN/toYfVqp/yUKU7/Aw/UbRrO/ac3dqx3farOEcfq1d754m3TL75QffFFZ3jdOtUrrlC97jrTAMx115l5rr/eO9/w4abRCvfya2q8ZWprndZ+du5UffvtujEFsaffdZe3CTr3+1izxn95u+9u+q+4wrzutZd5X6ee6v/noao6eTrz/yAAAAknSURBVLI5ivrHP5xx48d7j7rCsI9gPvkkXHk/RZvQVVV79PAmdFWTZO0vyqOPmr1P9w/LXWWnXQm9vQflZu9puH/EtpUrvR+uqvlSJJtoNm0yh/vuvUR3gwBu27ebI5QwEiX0Ll3Cx+jn9dfNcu69V/V3vzOt4cSyq369997g+PwceGDiZH/wwWavPx3V1aZJuC1bnHGnn+6sY+tWUyPgRReZaZs3O61YqZqEdP758d+LfbRzzjne+AH/PXpb69amjLulopoaswMybZr/PO6WsSorzbiJE03SU3VOBcU2/+aOqVWr4Jj8LF1qTv3EHi34LT8ZgPkDSrTMxx/3jreP0OPFcOGFpn/bNrOjFtQmaRjHHZfc+zv+eFPWbycqrHqX0P1s2WIOY8eM8X7xY/eg3KZNM9OGDAkXy4YNqX15YwUl9GT8/e+mjmu7JRpVc+pn4EDzJ+c+7E5Fba1JLu4EF2vCBLNuvwa0J0xQfekl//k2bQqO7+mnNeHebTp+8xvnM4z33tyuv95pzNnPuHFOc2vu+vjjsb8DGzY4R5Rh2Oe+3Xu7trIyM23dOu94O54XXzStfmXaPvuYP75kjB1rjkqD2En5gw+841ev9v9zcW/zrVvjLzsZdnu1dhN4iUyaZFoa27Qp9XUWdUK/+27zLuLtIcSyzyced5w5xAJUu3XzL/vFF8GtnseKPURP1bJl5tBs5cr0lqNq9kLS+fJkYv2ZVFmZ3YTuPnoL+7knw33uNZ6aGudobOfO8Edm9nWLKVPqTmvY0EyLXdaVV5qLlIWkttYceYc1aJD5s840+7TN4sWZX3aQeAldzPTcq6io0KqqqrSXU1MDfPUVcNRRyc23bJlpBq5FC3P/cpcupj8d27ebh1FEsnefaX337rvmHuoLLjCfWzacfTbw9tsm7WbDmjXA1q3ZqVBs61bTVFvv3nWnNWlimmnbsAHYc8/Mr7s+2roV+PRT4KSTcrdOEZmpqhW+0wo9oeeTXbvMU4/t2gGLF0cdTXGqqTGP+t90k387jpmwdatJusVWg+Puu5vnAzZuBJo1izoaSlW8hF5wDxbls9JS05hvLv+t65uSEuDee7O7jiZNii+ZA94G0qk4MaFn2CWXRB0BkT87oUd0UE45wP9sonqiaVPzyoRevLiHTlRPTJpkLiSnW+kY5S/uoRPVE+3bA/37Rx0FZRMTOhFRkWBCJyIqEkzoRERFggmdiKhIMKETERUJJnQioiLBhE5EVCSY0ImIikRktS2KyBoAS1KcvRWAtRkMJ1cYd24x7twpxJiBwoz7AFX1rWs0soSeDhGpCqo+Mp8x7txi3LlTiDEDhRt3EJ5yISIqEkzoRERFolAT+jNRB5Aixp1bjDt3CjFmoHDj9lWQ59CJiKiuQt1DJyKiGEzoRERFouASuoh0E5G5IrJARHJSXb+ItBWRiSLytYh8JSI3WeNbish7IjLfem1hjRcRedSKcZaIHONaVl+r/HwR6esaf6yIfGHN86iISLx1JBl/iYh8JiKV1vCBIjLdWua/RKShNb6RNbzAmt7OtYwB1vi5InKWa7zv5xG0jiRibi4ib4jIHGu7n5jv21tEbrG+H1+KyCsi0jhft7WI/ENEVovIl65xkW3feOtIEPPD1ndkloi8JSLNXdMysh1T+awio6oF0wEoAbAQwEEAGgL4HMDhOVhvawDHWP17AJgH4HAAfwHQ3xrfH8BDVn8PAO8AEAAnAJhujW8JYJH12sLqb2FN+wTAidY87wDobo33XUeS8d8K4GUAldbwawAusfqfBvAbq/8GAE9b/ZcA+JfVf7i1rRsBOND6DErifR5B60gi5hcA/NrqbwigeT5vbwD7AVgMoInr/V+Zr9sawKkAjgHwpWtcZNs3aB0hYj4TQKnV/5BreRnbjsl+VtnOR3E/1yhXnnSw5gvyrmt4AIABEcQxBsAZAOYCaG2Naw1grtU/AkAfV/m51vQ+AEa4xo+wxrUGMMc1/n/lgtaRRKxtAHwAoAuASusHs9b1I/jfNgXwLoATrf5Sq5zEbme7XNDnEW8dIWNuBpMcJWZ83m5vmIS+DCa5lVrb+qx83tYA2sGbHCPbvkHrSBRzzLTzAfzTvX0ysR2T/azSzS/pdIV2ysX+0diWW+Nyxjrc6gRgOoB9VPU7ALBe97aKBcUZb/xyn/GIs46whgP4A4Baa3gvABtUdZfPuv4XnzV9o1U+2fcTbx1hHARgDYDnxJwq+puI7I483t6qugLAIwCWAvgOZtvNRP5va7cot28mfttXwezlpxJzJn8XkSm0hC4+43J236WINAXwJoCbVfWHeEV9xmkK49MiIucAWK2qM0PEFm9art9PKcyh9VOq2gnAFpjD8yCRb2/rXPC5MIfePwGwO4DucdaTL9s6jFzElNb7EJGBAHYB+GeC5aUSc5TbPimFltCXA2jrGm4D4NtcrFhEymCS+T9VdZQ1epWItLamtwawOkGc8ca38Rkfbx1hnASgl4h8A+BVmNMuwwE0F5FSn3X9Lz5r+p4A1qfwftbGWUcYywEsV9Xp1vAbMAk+n7d3VwCLVXWNqu4EMArAL5D/29otyu2b8m/buhh7DoDL1Dr3kULM8bZjsp9VdKI835NsB7PntghmL8i+oNEhB+sVAC8CGB4z/mF4L/D8xeo/G94LPJ9Y41vCnBtuYXWLAbS0ps2wytoXkXrEW0cK76EznIuir8N78ecGq/+38F78ec3q7wDvxZ9FMBeXAj+PoHUkEe9/ARxq9f/Z2g55u70B/BzAVwB2s5b5AoAb83lbo+459Mi2b9A6QsTcDcBsAOUx5TK2HZP9rLKdj+J+plGuPKWAzdXweTBXlAfmaJ0nwxxKzQJQbXU9YM6jfQBgvvVqf5kFwBNWjF8AqHAt6yoAC6yun2t8BYAvrXkeh/MUr+86UngPneEk9INg7kJYYH2JG1njG1vDC6zpB7nmH2jFNhfWHQvxPo+gdSQRb0cAVdY2Hw2TMPJ6ewO4G8Aca7kjrR96Xm5rAK/AnOvfCbOneXWU2zfeOhLEvADmPLb9u3w609sxlc8qqo6P/hMRFYlCO4dOREQBmNCJiIoEEzoRUZFgQiciKhJM6ERERYIJnYioSDChExEVif8HQOm5gL+9Y4cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = network(example_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(12):\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Prediction: {}\".format(\n",
    "        output.data.max(1, keepdim=True)[1][i].item()))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
